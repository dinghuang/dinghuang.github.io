<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[RocketMQ安装使用]]></title>
    <url>%2F2022%2F03%2F07%2FRocketMQ%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简介RocketMQ 一个纯 Java、分布式、队列模型的开源消息中间件，前身是 MetaQ，是阿里研发的一个队列模型的消息中间件，后开源给 apache 基金会成为了 apache的顶级开源项目，具有高性能、高可靠、高实时、分布式特点。 架构设计 Name Server：是一个几乎无状态节点，可集群部署，在消息队列RocketMQ版中提供命名服务，更新和发现Broker服务。 Broker：消息中转角色，负责存储消息，转发消息。分为Master Broker和Slave Broker，一个Master Broker可以对应多个Slave Broker，但是一个Slave Broker只能对应一个Master Broker。Broker启动后需要完成一次将自己注册至Name Server的操作；随后每隔30s定期向Name Server上报Topic路由信息。 生产者：与Name Server集群中的其中一个节点（随机）建立长连接（Keep-alive），定期从Name Server读取Topic路由信息，并向提供Topic服务的Master Broker建立长连接，且定时向Master Broker发送心跳。 消费者：与Name Server集群中的其中一个节点（随机）建立长连接，定期从Name Server拉取Topic路由信息，并向提供Topic服务的Master Broker、Slave Broker建立长连接，且定时向Master Broker、Slave Broker发送心跳。Consumer既可以从Master Broker订阅消息，也可以从Slave Broker订阅消息，订阅规则由Broker配置决定。 部署架构 NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。 Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave 的对应关系通过指定相同的BrokerName，不同的BrokerId 来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。 注意：当前RocketMQ版本在部署架构上支持一Master多Slave，但只有BrokerId=1的从服务器才会参与消息的读负载。 Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic 服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。 Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer获取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，消费者在向Master拉取消息时，Master服务器会根据拉取偏移量与最大偏移量的距离（判断是否读老消息，产生读I/O），以及从服务器是否可读等因素建议下一次是从Master还是Slave拉取。 结合部署架构图，描述集群工作流程： 启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。 Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。 收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。 Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列，然后与队列所在的Broker建立长连接从而向Broker发消息。 Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。概念 消息模型（Message Model）RocketMQ主要由 Producer、Broker、Consumer 三部分组成，其中Producer 负责生产消息，Consumer 负责消费消息，Broker 负责存储消息。Broker 在实际部署过程中对应一台服务器，每个 Broker 可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker。Message Queue 用于存储消息的物理地址，每个Topic中的消息地址存储于多个 Message Queue 中。ConsumerGroup 由多个Consumer 实例构成。 消息生产者（Producer）负责生产消息，一般由业务系统负责生产消息。一个消息生产者会把业务应用系统里产生的消息发送到broker服务器。RocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。同步和异步方式均需要Broker返回确认信息，单向发送不需要。 消息消费者（Consumer）负责消费消息，一般是后台系统负责异步消费。一个消息消费者会从Broker服务器拉取消息、并将其提供给应用程序。从用户应用的角度而言提供了两种消费形式：拉取式消费、推动式消费。 主题（Topic）表示一类消息的集合，每个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位。 代理服务器（Broker Server）消息中转角色，负责存储消息、转发消息。代理服务器在RocketMQ系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备。代理服务器也存储消息相关的元数据，包括消费者组、消费进度偏移和主题和队列消息等。 Broker包含了以下几个重要子模块： Remoting Module：整个Broker的实体，负责处理来自clients端的请求。 Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息 Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。 HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。 Index Service：根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。名字服务（Name Server）名称服务充当路由消息的提供者。生产者或消费者能够通过名字服务查找各主题相应的Broker IP列表。多个Namesrv实例组成集群，但相互独立，没有信息交换。 拉取式消费（Pull Consumer）Consumer消费的一种类型，应用通常主动调用Consumer的拉消息方法从Broker服务器拉消息、主动权由应用控制。一旦获取了批量消息，应用就会启动消费过程。 推动式消费（Push Consumer）Consumer消费的一种类型，该模式下Broker收到数据后会主动推送给消费端，该消费模式一般实时性较高。 生产者组（Producer Group）同一类Producer的集合，这类Producer发送同一类消息且发送逻辑一致。如果发送的是事务消息且原始生产者在发送之后崩溃，则Broker服务器会联系同一生产者组的其他生产者实例以提交或回溯消费。 消费者组（Consumer Group）同一类Consumer的集合，这类Consumer通常消费同一类消息且消费逻辑一致。消费者组使得在消息消费方面，实现负载均衡和容错的目标变得非常容易。要注意的是，消费者组的消费者实例必须订阅完全相同的Topic。RocketMQ 支持两种消息模式：集群消费（Clustering）和广播消费（Broadcasting）。 集群消费（Clustering）集群消费模式下,相同Consumer Group的每个Consumer实例平均分摊消息。 广播消费（Broadcasting）广播消费模式下，相同Consumer Group的每个Consumer实例都接收全量的消息。 普通顺序消息（Normal Ordered Message）普通顺序消费模式下，消费者通过同一个消息队列（ Topic 分区，称作 Message Queue） 收到的消息是有顺序的，不同消息队列收到的消息则可能是无顺序的。 严格顺序消息（Strictly Ordered Message）严格顺序消息模式下，消费者收到的所有消息均是有顺序的。 消息（Message）消息系统所传输信息的物理载体，生产和消费数据的最小单位，每条消息必须属于一个主题。RocketMQ中每个消息拥有唯一的Message ID，且可以携带具有业务标识的Key。系统提供了通过Message ID和Key查询消息的功能。 标签（Tag）为消息设置的标志，用于同一主题下区分不同类型的消息。来自同一业务单元的消息，可以根据不同业务目的在同一主题下设置不同标签。标签能够有效地保持代码的清晰度和连贯性，并优化RocketMQ提供的查询系统。消费者可以根据Tag实现对不同子主题的不同消费逻辑，实现更好的扩展性。 特性订阅与发布消息的发布是指某个生产者向某个topic发送消息；消息的订阅是指某个消费者关注了某个topic中带有某些tag的消息，进而从该topic消费数据。 消息顺序消息有序指的是一类消息消费时，能按照发送的顺序来消费。例如：一个订单产生了三条消息分别是订单创建、订单付款、订单完成。消费时要按照这个顺序消费才能有意义，但是同时订单之间是可以并行消费的。RocketMQ可以严格的保证消息有序。 顺序消息分为全局顺序消息与分区顺序消息，全局顺序是指某个Topic下的所有消息都要保证顺序；部分顺序消息只要保证每一组消息被顺序消费即可。 全局顺序对于指定的一个 Topic，所有消息按照严格的先入先出（FIFO）的顺序进行发布和消费。适用场景：性能要求不高，所有的消息严格按照 FIFO 原则进行消息发布和消费的场景 分区顺序对于指定的一个 Topic，所有消息根据 sharding key 进行区块分区。 同一个分区内的消息按照严格的 FIFO 顺序进行发布和消费。 Sharding key 是顺序消息中用来区分不同分区的关键字段，和普通消息的 Key 是完全不同的概念。适用场景：性能要求高，以 sharding key 作为分区字段，在同一个区块中严格的按照 FIFO 原则进行消息发布和消费的场景。消息过滤RocketMQ的消费者可以根据Tag进行消息过滤，也支持自定义属性过滤。消息过滤目前是在Broker端实现的，优点是减少了对于Consumer无用消息的网络传输，缺点是增加了Broker的负担、而且实现相对复杂。消息可靠性RocketMQ支持消息的高可靠，影响消息可靠性的几种情况：1) Broker非正常关闭2) Broker异常Crash3) OS Crash4) 机器掉电，但是能立即恢复供电情况5) 机器无法开机（可能是cpu、主板、内存等关键设备损坏）6) 磁盘设备损坏 1)、2)、3)、4) 四种情况都属于硬件资源可立即恢复情况，RocketMQ在这四种情况下能保证消息不丢，或者丢失少量数据（依赖刷盘方式是同步还是异步）。 5)、6)属于单点故障，且无法恢复，一旦发生，在此单点上的消息全部丢失。RocketMQ在这两种情况下，通过异步复制，可保证99%的消息不丢，但是仍然会有极少量的消息可能丢失。通过同步双写技术可以完全避免单点，同步双写势必会影响性能，适合对消息可靠性要求极高的场合，例如与Money相关的应用。注：RocketMQ从3.0版本开始支持同步双写。 至少一次至少一次(At least Once)指每个消息必须投递一次。Consumer先Pull消息到本地，消费完成后，才向服务器返回ack，如果没有消费一定不会ack消息，所以RocketMQ可以很好的支持此特性。 回溯消费回溯消费是指Consumer已经消费成功的消息，由于业务上需求需要重新消费，要支持此功能，Broker在向Consumer投递成功消息后，消息仍然需要保留。并且重新消费一般是按照时间维度，例如由于Consumer系统故障，恢复后需要重新消费1小时前的数据，那么Broker要提供一种机制，可以按照时间维度来回退消费进度。RocketMQ支持按照时间回溯消费，时间维度精确到毫秒。 事务消息RocketMQ事务消息（Transactional Message）是指应用本地事务和发送消息操作可以被定义到全局事务中，要么同时成功，要么同时失败。RocketMQ的事务消息提供类似 X/Open XA 的分布事务功能，通过事务消息能达到分布式事务的最终一致。 定时消息定时消息（延迟队列）是指消息发送到broker后，不会立即被消费，等待特定时间投递给真正的topic。broker有配置项messageDelayLevel，默认值为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，18个level。可以配置自定义messageDelayLevel。注意，messageDelayLevel是broker的属性，不属于某个topic。发消息时，设置delayLevel等级即可：msg.setDelayLevel(level)。level有以下三种情况： level == 0，消息为非延迟消息 1&lt;=level&lt;=maxLevel，消息延迟特定时间，例如level==1，延迟1s level &gt; maxLevel，则level== maxLevel，例如level==20，延迟2h 定时消息会暂存在名为SCHEDULE_TOPIC_XXXX的topic中，并根据delayTimeLevel存入特定的queue，queueId = delayTimeLevel – 1，即一个queue只存相同延迟的消息，保证具有相同发送延迟的消息能够顺序消费。broker会调度地消费SCHEDULE_TOPIC_XXXX，将消息写入真实的topic。 需要注意的是，定时消息会在第一次写入和调度写入真实topic时都会计数，因此发送数量、tps都会变高。 消息重试Consumer消费消息失败后，要提供一种重试机制，令消息再消费一次。Consumer消费消息失败通常可以认为有以下几种情况： 由于消息本身的原因，例如反序列化失败，消息数据本身无法处理（例如话费充值，当前消息的手机号被注销，无法充值）等。这种错误通常需要跳过这条消息，再消费其它消息，而这条失败的消息即使立刻重试消费，99%也不成功，所以最好提供一种定时重试机制，即过10秒后再重试。 由于依赖的下游应用服务不可用，例如db连接不可用，外系统网络不可达等。遇到这种错误，即使跳过当前失败的消息，消费其他消息同样也会报错。这种情况建议应用sleep 30s，再消费下一条消息，这样可以减轻Broker重试消息的压力。 RocketMQ会为每个消费组都设置一个Topic名称为“%RETRY%+consumerGroup”的重试队列（这里需要注意的是，这个Topic的重试队列是针对消费组，而不是针对每个Topic设置的），用于暂时保存因为各种异常而导致Consumer端无法消费的消息。考虑到异常恢复起来需要一些时间，会为重试队列设置多个重试级别，每个重试级别都有与之对应的重新投递延时，重试次数越多投递延时就越大。RocketMQ对于重试消息的处理是先保存至Topic名称为“SCHEDULE_TOPIC_XXXX”的延迟队列中，后台定时任务按照对应的时间进行Delay后重新保存至“%RETRY%+consumerGroup”的重试队列中。 消息重投生产者在发送消息时，同步消息失败会重投，异步消息有重试，oneway没有任何保证。消息重投保证消息尽可能发送成功、不丢失，但可能会造成消息重复，消息重复在RocketMQ中是无法避免的问题。消息重复在一般情况下不会发生，当出现消息量大、网络抖动，消息重复就会是大概率事件。另外，生产者主动重发、consumer负载变化也会导致重复消息。如下方法可以设置消息重试策略： retryTimesWhenSendFailed:同步发送失败重投次数，默认为2，因此生产者会最多尝试发送retryTimesWhenSendFailed + 1次。不会选择上次失败的broker，尝试向其他broker发送，最大程度保证消息不丢。超过重投次数，抛出异常，由客户端保证消息不丢。当出现RemotingException、MQClientException和部分MQBrokerException时会重投。 retryTimesWhenSendAsyncFailed:异步发送失败重试次数，异步重试不会选择其他broker，仅在同一个broker上做重试，不保证消息不丢。 retryAnotherBrokerWhenNotStoreOK:消息刷盘（主或备）超时或slave不可用（返回状态非SEND_OK），是否尝试发送到其他broker，默认false。十分重要消息可以开启。 流量控制生产者流控，因为broker处理能力达到瓶颈；消费者流控，因为消费能力达到瓶颈。 生产者流控： commitLog文件被锁时间超过osPageCacheBusyTimeOutMills时，参数默认为1000ms，返回流控。 如果开启transientStorePoolEnable == true，且broker为异步刷盘的主机，且transientStorePool中资源不足，拒绝当前send请求，返回流控。 broker每隔10ms检查send请求队列头部请求的等待时间，如果超过waitTimeMillsInSendQueue，默认200ms，拒绝当前send请求，返回流控。 broker通过拒绝send 请求方式实现流量控制。 注意，生产者流控，不会尝试消息重投。 消费者流控： 消费者本地缓存消息数超过pullThresholdForQueue时，默认1000。 消费者本地缓存消息大小超过pullThresholdSizeForQueue时，默认100MB。 消费者本地缓存消息跨度超过consumeConcurrentlyMaxSpan时，默认2000。 消费者流控的结果是降低拉取频率。 死信队列死信队列用于处理无法被正常消费的消息。当一条消息初次消费失败，消息队列会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。 RocketMQ将这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），将存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。在RocketMQ中，可以通过使用console控制台对死信队列中的消息进行重发来使得消费者实例再次进行消费。 部署Docker部署构建镜像克隆代码1git clone https://github.com/apache/rocketmq-docker.git 构建镜像rocketmq123cd image-build#sh build-image.sh RMQ-VERSION BASE-IMAGEsh build-image.sh 4.9.2 centos 查看镜像12docker images | grep rocketapacherocketmq/rocketmq 4.9.2 67902205ef2c About a minute ago 519MB 构建rocketmq-dashboard镜像1sh build-image-dashboard.sh 1.0.0 centos 最后如下所示：123REPOSITORY TAG IMAGE ID CREATED SIZEapache/rocketmq-dashboard 1.0.0-centos 0cc392fe7d27 5 minutes ago 821MBapacherocketmq/rocketmq 4.9.2 67902205ef2c 7 days ago 519MB 单机部署（单Master模式）这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。不建议线上环境使用,可以用于本地测试。 1234567# 配置日志路径以及存储路径mkdir -p /Users/dinghuang/Documents/Tool/rocketMQ/data/namesrv/logsmkdir -p /Users/dinghuang/Documents/Tool/rocketMQ/data/namesrv/store# 创建日志、数据存储、以及配置存放的挂载路径mkdir -p /Users/dinghuang/Documents/Tool/rocketMQ/data/broker/logsmkdir -p /Users/dinghuang/Documents/Tool/rocketMQ/data/broker/storemkdir -p /Users/dinghuang/Documents/Tool/rocketMQ/etc/broker Broker配置文件创建1vi /Users/dinghuang/Documents/Tool/rocketMQ/etc/broker/broker.conf 文件内容如下123456789brokerClusterName = dh-dockerbrokerName = dh-docker-abrokerId = 0deleteWhen = 04fileReservedTime = 48brokerRole = ASYNC_MASTERflushDiskType = ASYNC_FLUSH#Docker环境需要设置成宿主机IPbrokerIP1 = 10.38.1.201 编写Docker-compose文件1vi docker-compose.yml 内容如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647version: '3'services: #Service for nameserver namesrv: image: apacherocketmq/rocketmq:4.9.2 container_name: rocketmq-namesrv ports: - 9876:9876 environment: - JAVA_OPT_EXT=-server -Xms256m -Xmx256m -Xmn256m volumes: - /Users/dinghuang/Documents/Tool/rocketMQ/data/namesrv/logs:/root/logs command: sh mqnamesrv #Service for broker broker: image: apacherocketmq/rocketmq:4.9.2 container_name: rocketmq-broker links: - namesrv depends_on: - namesrv ports: - 10909:10909 - 10911:10911 - 10912:10912 environment: - NAMESRV_ADDR=namesrv:9876 - JAVA_OPT_EXT=-server -Xms512m -Xmx512m -Xmn256m volumes: - /Users/dinghuang/Documents/Tool/rocketMQ/data/broker/logs:/home/rocketmq/logs - /Users/dinghuang/Documents/Tool/rocketMQ/data/broker/store:/home/rocketmq/store - /Users/dinghuang/Documents/Tool/rocketMQ/etc/broker/broker.conf:/home/rocketmq/conf/broker.conf command: sh mqbroker -c /home/rocketmq/conf/broker.conf #Service for rocketmq-dashboard dashboard: image: apache/rocketmq-dashboard:1.0.0-centos container_name: rocketmq-dashboard ports: - 8080:8080 links: - namesrv depends_on: - namesrv environment: - NAMESRV_ADDR=namesrv:9876 运行命令1docker-compose -f ./docker-compose.yml up 运行日志如下：1234CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESed6f1b7e8864 apache/rocketmq-dashboard:1.0.0-centos "java -jar bin/rocke…" 4 minutes ago Up 2 seconds 0.0.0.0:8080-&gt;8080/tcp rocketmq-dashboard293cf31b9263 apacherocketmq/rocketmq:4.9.2 "sh mqbroker -c /hom…" 4 minutes ago Up 14 seconds 0.0.0.0:10909-&gt;10909/tcp, 9876/tcp, 0.0.0.0:10911-10912-&gt;10911-10912/tcp rocketmq-broker3db70550d6c2 apacherocketmq/rocketmq:4.9.2 "sh mqnamesrv" 4 minutes ago Up 37 seconds 10909/tcp, 0.0.0.0:9876-&gt;9876/tcp, 10911-10912/tcp rocketmq-namesrv 登录地址：http://localhost:8080/#/ 访问，如图所示： 普通部署可以参考官方文档 单Master模式这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。不建议线上环境使用,可以用于本地测试。 1）启动 NameServer123456### 首先启动Name Server$ nohup sh mqnamesrv &amp; ### 验证Name Server 是否启动成功$ tail -f ~/logs/rocketmqlogs/namesrv.logThe Name Server boot success... 2）启动 Broker123456### 启动Broker$ nohup sh bin/mqbroker -n localhost:9876 &amp;### 验证Broker是否启动成功，例如Broker的IP为：192.168.1.2，且名称为broker-a$ tail -f ~/logs/rocketmqlogs/broker.log The broker[broker-a, 192.169.1.2:10911] boot success... 多Master模式一个集群无Slave，全是Master，例如2个Master或者3个Master，这种模式的优缺点如下： 优点：配置简单，单个Master宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢），性能最高； 缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。 1）启动NameServerNameServer需要先于Broker启动，且如果在生产环境使用，为了保证高可用，建议一般规模的集群启动3个NameServer，各节点的启动命令相同，如下： 123456### 首先启动Name Server$ nohup sh mqnamesrv &amp; ### 验证Name Server 是否启动成功$ tail -f ~/logs/rocketmqlogs/namesrv.logThe Name Server boot success... 2）启动Broker集群1234567### 在机器A，启动第一个Master，例如NameServer的IP为：192.168.1.1$ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-noslave/broker-a.properties &amp; ### 在机器B，启动第二个Master，例如NameServer的IP为：192.168.1.1$ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-noslave/broker-b.properties &amp;... 如上启动命令是在单个NameServer情况下使用的。对于多个NameServer的集群，Broker启动命令中-n后面的地址列表用分号隔开即可，例如 192.168.1.1:9876;192.161.2:9876。 多Master多Slave模式-异步复制每个Master配置一个Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下： 优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样； 缺点：Master宕机，磁盘损坏情况下会丢失少量消息。 1）启动NameServer123456### 首先启动Name Server$ nohup sh mqnamesrv &amp; ### 验证Name Server 是否启动成功$ tail -f ~/logs/rocketmqlogs/namesrv.logThe Name Server boot success... 2）启动Broker集群1234567891011### 在机器A，启动第一个Master，例如NameServer的IP为：192.168.1.1$ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-async/broker-a.properties &amp; ### 在机器B，启动第二个Master，例如NameServer的IP为：192.168.1.1$ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-async/broker-b.properties &amp; ### 在机器C，启动第一个Slave，例如NameServer的IP为：192.168.1.1$ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-async/broker-a-s.properties &amp; ### 在机器D，启动第二个Slave，例如NameServer的IP为：192.168.1.1$ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-async/broker-b-s.properties &amp; 多Master多Slave模式-同步双写每个Master配置一个Slave，有多对Master-Slave，HA采用同步双写方式，即只有主备都写成功，才向应用返回成功，这种模式的优缺点如下： 优点：数据与服务都无单点故障，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高； 缺点：性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。 1）启动NameServer123456### 首先启动Name Server$ nohup sh mqnamesrv &amp; ### 验证Name Server 是否启动成功$ tail -f ~/logs/rocketmqlogs/namesrv.logThe Name Server boot success... 2）启动Broker集群1234567891011### 在机器A，启动第一个Master，例如NameServer的IP为：192.168.1.1$ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-sync/broker-a.properties &amp; ### 在机器B，启动第二个Master，例如NameServer的IP为：192.168.1.1$ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-sync/broker-b.properties &amp; ### 在机器C，启动第一个Slave，例如NameServer的IP为：192.168.1.1$ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-sync/broker-a-s.properties &amp; ### 在机器D，启动第二个Slave，例如NameServer的IP为：192.168.1.1$ nohup sh mqbroker -n 192.168.1.1:9876 -c $ROCKETMQ_HOME/conf/2m-2s-sync/broker-b-s.properties &amp; 以上Broker与Slave配对是通过指定相同的BrokerName参数来配对，Master的BrokerId必须是0，Slave的BrokerId必须是大于0的数。另外一个Master下面可以挂载多个Slave，同一Master下的多个Slave通过指定不同的BrokerId来区分。$ROCKETMQ_HOME指的RocketMQ安装目录，需要用户自己设置此环境变量。 使用加入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.9.1&lt;/version&gt;&lt;/dependency&gt; Producer发送同步消息这种可靠性同步地发送方式使用的比较广泛，比如：重要的消息通知，短信通知。1234567891011121314151617181920212223public class SyncProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer("please_rename_unique_group_name"); // 设置NameServer的地址 producer.setNamesrvAddr("localhost:9876"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message("TopicTest" /* Topic */, "TagA" /* Tag */, ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送消息到一个Broker SendResult sendResult = producer.send(msg); // 通过sendResult返回消息是否成功送达 System.out.printf("%s%n", sendResult); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 查看消息如图所示： 发送异步消息异步消息通常用在对响应时间敏感的业务场景，即发送端不能容忍长时间地等待Broker的响应。12345678910111213141516171819202122232425262728293031323334353637383940public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer("please_rename_unique_group_name"); // 设置NameServer的地址 producer.setNamesrvAddr("localhost:9876"); // 启动Producer实例 producer.start(); producer.setRetryTimesWhenSendAsyncFailed(0); int messageCount = 100; // 根据消息数量实例化倒计时计算器 final CountDownLatch2 countDownLatch = new CountDownLatch2(messageCount); for (int i = 0; i &lt; messageCount; i++) &#123; final int index = i; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message("TopicTest", "TagA", "OrderID188", "Hello world".getBytes(RemotingHelper.DEFAULT_CHARSET)); // SendCallback接收异步返回结果的回调 producer.send(msg, new SendCallback() &#123; @Override public void onSuccess(SendResult sendResult) &#123; countDownLatch.countDown(); System.out.printf("%-10d OK %s %n", index, sendResult.getMsgId()); &#125; @Override public void onException(Throwable e) &#123; countDownLatch.countDown(); System.out.printf("%-10d Exception %s %n", index, e); e.printStackTrace(); &#125; &#125;); &#125; // 等待5s countDownLatch.await(5, TimeUnit.SECONDS); // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125; 单向发送消息这种方式主要用在不特别关心发送结果的场景，例如日志发送。12345678910111213141516171819202122public class OnewayProducer &#123; public static void main(String[] args) throws Exception&#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer("please_rename_unique_group_name"); // 设置NameServer的地址 producer.setNamesrvAddr("localhost:9876"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message("TopicTest" /* Topic */, "TagA" /* Tag */, ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送单向消息，没有任何返回结果 producer.sendOneway(msg); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; Consumer1234567891011121314151617181920212223242526public class Consumer &#123; public static void main(String[] args) throws InterruptedException, MQClientException &#123; // 实例化消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name"); // 设置NameServer的地址 consumer.setNamesrvAddr("localhost:9876"); // 订阅一个或者多个Topic，以及Tag来过滤需要消费的消息 consumer.subscribe("TopicTest", "*"); // 注册回调实现类来处理从broker拉取回来的消息 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf("%s Receive New Messages: %s %n", Thread.currentThread().getName(), msgs); // 标记该消息已经被成功消费 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 启动消费者实例 consumer.start(); System.out.printf("Consumer Started.%n"); &#125;&#125; 顺序消息RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。 顺序消费的原理解析，在默认的情况下消息发送会采取Round Robin轮询方式把消息发送到不同的queue(分区队列)；而消费消息的时候从多个queue上拉取消息，这种情况发送和消费是不能保证顺序。但是如果控制发送的顺序消息只依次发送到同一个queue中，消费的时候只从这个queue上依次拉取，则就保证了顺序。当发送和消费参与的queue只有一个，则是全局有序；如果多个queue参与，则为分区有序，即相对每个queue，消息都是有序的。 下面用订单进行分区有序的示例。一个订单的顺序流程是：创建、付款、推送、完成。订单号相同的消息会被先后发送到同一个队列中，消费时，同一个OrderId获取到的肯定是同一个队列。 顺序消息生产123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147package org.apache.rocketmq.example.order2;import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.client.producer.MessageQueueSelector;import org.apache.rocketmq.client.producer.SendResult;import org.apache.rocketmq.common.message.Message;import org.apache.rocketmq.common.message.MessageQueue;import java.text.SimpleDateFormat;import java.util.ArrayList;import java.util.Date;import java.util.List;/*** Producer，发送顺序消息*/public class Producer &#123; public static void main(String[] args) throws Exception &#123; DefaultMQProducer producer = new DefaultMQProducer("please_rename_unique_group_name"); producer.setNamesrvAddr("127.0.0.1:9876"); producer.start(); String[] tags = new String[]&#123;"TagA", "TagC", "TagD"&#125;; // 订单列表 List&lt;OrderStep&gt; orderList = new Producer().buildOrders(); Date date = new Date(); SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); String dateStr = sdf.format(date); for (int i = 0; i &lt; 10; i++) &#123; // 加个时间前缀 String body = dateStr + " Hello RocketMQ " + orderList.get(i); Message msg = new Message("TopicTest", tags[i % tags.length], "KEY" + i, body.getBytes()); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Long id = (Long) arg; //根据订单id选择发送queue long index = id % mqs.size(); return mqs.get((int) index); &#125; &#125;, orderList.get(i).getOrderId());//订单id System.out.println(String.format("SendResult status:%s, queueId:%d, body:%s", sendResult.getSendStatus(), sendResult.getMessageQueue().getQueueId(), body)); &#125; producer.shutdown(); &#125; /** * 订单的步骤 */ private static class OrderStep &#123; private long orderId; private String desc; public long getOrderId() &#123; return orderId; &#125; public void setOrderId(long orderId) &#123; this.orderId = orderId; &#125; public String getDesc() &#123; return desc; &#125; public void setDesc(String desc) &#123; this.desc = desc; &#125; @Override public String toString() &#123; return "OrderStep&#123;" + "orderId=" + orderId + ", desc='" + desc + '\'' + '&#125;'; &#125; &#125; /** * 生成模拟订单数据 */ private List&lt;OrderStep&gt; buildOrders() &#123; List&lt;OrderStep&gt; orderList = new ArrayList&lt;OrderStep&gt;(); OrderStep orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc("创建"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc("创建"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc("付款"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc("创建"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc("付款"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc("付款"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc("完成"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc("推送"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc("完成"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc("完成"); orderList.add(orderDemo); return orderList; &#125;&#125; 顺序消费消息1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package org.apache.rocketmq.example.order2;import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeOrderlyContext;import org.apache.rocketmq.client.consumer.listener.ConsumeOrderlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerOrderly;import org.apache.rocketmq.common.consumer.ConsumeFromWhere;import org.apache.rocketmq.common.message.MessageExt;import java.util.List;import java.util.Random;import java.util.concurrent.TimeUnit;/*** 顺序消息消费，带事务方式（应用可控制Offset什么时候提交）*/public class ConsumerInOrder &#123; public static void main(String[] args) throws Exception &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name_3"); consumer.setNamesrvAddr("127.0.0.1:9876"); /** * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费&lt;br&gt; * 如果非第一次启动，那么按照上次消费的位置继续消费 */ consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe("TopicTest", "TagA || TagC || TagD"); consumer.registerMessageListener(new MessageListenerOrderly() &#123; Random random = new Random(); @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; // 可以看到每个queue有唯一的consume线程来消费, 订单对每个queue(分区)有序 System.out.println("consumeThread=" + Thread.currentThread().getName() + "queueId=" + msg.getQueueId() + ", content:" + new String(msg.getBody())); &#125; try &#123; //模拟业务逻辑处理中... TimeUnit.SECONDS.sleep(random.nextInt(10)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125; &#125;); consumer.start(); System.out.println("Consumer Started."); &#125;&#125; 延时消息比如电商里，提交了一个订单就可以发送一个延时消息，1h后去检查这个订单的状态，如果还是未付款就取消订单释放库存。 现在RocketMq并不支持任意时间的延时，需要设置几个固定的延时等级(1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h)，从1s到2h分别对应着等级1到18 消息消费失败会进入延时消息队列，消息发送时间与设置的延时等级和重试次数有关，详见代码SendMessageProcessor.java 启动消费者等待传入订阅消息 123456789101112131415161718192021222324252627282930313233343536import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;import org.apache.rocketmq.common.message.MessageExt;import java.util.List;/** * @author dinghuang123@gmail.com * @since 2022/3/4 */public class ScheduledMessageConsumer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("ExampleConsumer"); // 订阅Topics consumer.subscribe("TestTopic", "*"); consumer.setNamesrvAddr("127.0.0.1:9876"); // 注册消息监听者 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; messages, ConsumeConcurrentlyContext context) &#123; for (MessageExt message : messages) &#123; // Print approximate delay time period System.out.println("Receive message[msgId=" + message.getMsgId() + "] " + new String(message.getBody()) + (System.currentTimeMillis() - message.getBornTimestamp()) + "ms later"); &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 启动消费者 consumer.start(); &#125;&#125; 发送延时消息1234567891011121314151617181920212223242526272829import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.common.message.Message;/** * @author dinghuang123@gmail.com * @since 2022/3/4 */public class ScheduledMessageProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化一个生产者来产生延时消息 DefaultMQProducer producer = new DefaultMQProducer("ExampleProducerGroup"); // 启动生产者 producer.setNamesrvAddr("127.0.0.1:9876"); producer.start(); int totalMessagesToSend = 100; for (int i = 0; i &lt; totalMessagesToSend; i++) &#123; Message message = new Message("TestTopic", ("Hello scheduled message " + i).getBytes()); // 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel) message.setDelayTimeLevel(3); // 发送消息 producer.send(message); &#125; // 关闭生产者 producer.shutdown(); &#125;&#125; 将会看到消息的消费比存储时间晚10秒。12Receive message[msgId=7F0000016C4918B4AAC2130BFEB90055] Hello scheduled message 859992ms laterReceive message[msgId=7F0000016C4918B4AAC2130BFEBD0056] Hello scheduled message 869992ms later 批量消息批量发送消息能显著提高传递小消息的性能。限制是这些批量消息应该有相同的topic，相同的waitStoreMsgOK，而且不能是延时消息。此外，这一批消息的总大小不应超过4MB。 每次只发送不超过4MB的消息，则很容易使用批处理，样例如下1234567891011121314151617181920212223242526272829303132import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.common.message.Message;import java.util.ArrayList;import java.util.List;/** * @author dinghuang123@gmail.com * @since 2022/3/3 */public class BatchProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer("please_rename_unique_group_name"); // 设置NameServer的地址 producer.setNamesrvAddr("127.0.0.1:9876"); // 启动Producer实例 producer.start(); List&lt;Message&gt; messages = new ArrayList&lt;&gt;(); messages.add(new Message("BatchTest", "TagA", "OrderID001", "Hello world 0".getBytes())); messages.add(new Message("BatchTest", "TagA", "OrderID002", "Hello world 1".getBytes())); messages.add(new Message("BatchTest", "TagA", "OrderID003", "Hello world 2".getBytes())); try &#123; producer.send(messages); &#125; catch (Exception e) &#123; e.printStackTrace(); //处理error &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;import org.apache.rocketmq.client.exception.MQClientException;import org.apache.rocketmq.common.message.MessageExt;import java.util.List;/** * @author dinghuang123@gmail.com * @since 2022/3/3 */public class BatchConsumer &#123; public static void main(String[] args) throws MQClientException &#123; // 实例化消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name"); // 设置NameServer的地址 consumer.setNamesrvAddr("127.0.0.1:9876"); // 订阅一个或者多个Topic，以及Tag来过滤需要消费的消息 consumer.subscribe("BatchTest", "*"); //指定批量消费的最大值，默认是1 consumer.setConsumeMessageBatchMaxSize(5); //批量拉取消息的数量，默认是32 consumer.setPullBatchSize(30); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.println(Thread.currentThread().getName() + "一次收到" + msgs.size() + "消息"); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 启动消费者实例 consumer.start(); System.out.printf("Consumer Started.%n"); &#125;&#125; 消息列表分割 复杂度只有当你发送大批量时才会增长，你可能不确定它是否超过了大小限制（4MB）。这时候你最好把你的消息列表分割一下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798package com.rocketmq.demo.rocket;import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.common.message.Message;import java.util.ArrayList;import java.util.Iterator;import java.util.List;import java.util.Map;/** * @author dinghuang123@gmail.com * @since 2022/3/3 */public class SplitBatchProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer("please_rename_unique_group_name"); // 设置NameServer的地址 producer.setNamesrvAddr("127.0.0.1:9876"); // 启动Producer实例 producer.start(); //把大的消息分裂成若干个小的消息 List&lt;Message&gt; messages = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 1000; i++) &#123; messages.add(new Message("BatchTest", "TagA", "OrderID002", ("Hello world " + i).getBytes())); &#125; ListSplitter splitter = new ListSplitter(messages); while (splitter.hasNext()) &#123; try &#123; List&lt;Message&gt; listItem = splitter.next(); producer.send(listItem); &#125; catch (Exception e) &#123; e.printStackTrace(); //处理error &#125; &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125; public static class ListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; &#123; private final int SIZE_LIMIT = 1024 * 1024 * 4; private final List&lt;Message&gt; messages; private int currIndex; public ListSplitter(List&lt;Message&gt; messages) &#123; this.messages = messages; &#125; @Override public boolean hasNext() &#123; return currIndex &lt; messages.size(); &#125; @Override public List&lt;Message&gt; next() &#123; int startIndex = getStartIndex(); int nextIndex = startIndex; int totalSize = 0; for (; nextIndex &lt; messages.size(); nextIndex++) &#123; Message message = messages.get(nextIndex); int tmpSize = calcMessageSize(message); if (tmpSize + totalSize &gt; SIZE_LIMIT) &#123; break; &#125; else &#123; totalSize += tmpSize; &#125; &#125; List&lt;Message&gt; subList = messages.subList(startIndex, nextIndex); currIndex = nextIndex; return subList; &#125; private int getStartIndex() &#123; Message currMessage = messages.get(currIndex); int tmpSize = calcMessageSize(currMessage); while (tmpSize &gt; SIZE_LIMIT) &#123; currIndex += 1; Message message = messages.get(currIndex); tmpSize = calcMessageSize(message); &#125; return currIndex; &#125; private int calcMessageSize(Message message) &#123; int tmpSize = message.getTopic().length() + message.getBody().length; Map&lt;String, String&gt; properties = message.getProperties(); for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) &#123; tmpSize += entry.getKey().length() + entry.getValue().length(); &#125; tmpSize = tmpSize + 20; // 增加⽇日志的开销20字节 return tmpSize; &#125; &#125;&#125; 过滤消息TAG是一个简单而有用的设计，其可以来选择您想要的消息。例如：12DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("CID_EXAMPLE");consumer.subscribe("TOPIC", "TAGA || TAGB || TAGC"); 消费者将接收包含TAGA或TAGB或TAGC的消息。但是限制是一个消息只能有一个标签，这对于复杂的场景可能不起作用。在这种情况下，可以使用SQL表达式筛选消息。SQL特性可以通过发送消息时的属性来进行计算。在RocketMQ定义的语法下，可以实现一些简单的逻辑。下面是一个例子：1234567891011121314------------| message ||----------| a &gt; 5 AND b = 'abc'| a = 10 | --------------------&gt; Gotten| b = 'abc'|| c = true |------------------------| message ||----------| a &gt; 5 AND b = 'abc'| a = 1 | --------------------&gt; Missed| b = 'abc'|| c = true |------------ 基本语法RocketMQ只定义了一些基本语法来支持这个特性。你也可以很容易地扩展它。 数值比较，比如：&gt;，&gt;=，&lt;，&lt;=，BETWEEN，=； 字符比较，比如：=，&lt;&gt;，IN； IS NULL 或者 IS NOT NULL； 逻辑符号 AND，OR，NOT； 常量支持类型为： 数值，比如：123，3.1415； 字符，比如：’abc’，必须用单引号包裹起来； NULL，特殊的常量 布尔值，TRUE 或 FALSE 只有使用push模式的消费者才能用使用SQL92标准的sql语句，接口如下：1public void subscribe(finalString topic, final MessageSelector messageSelector) 使用生产者发送消息时，你能通过putUserProperty来设置消息的属性1234567891011DefaultMQProducer producer = new DefaultMQProducer("please_rename_unique_group_name");producer.start();Message msg = new Message("TopicTest", tag, ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET));// 设置一些属性msg.putUserProperty("a", String.valueOf(i));SendResult sendResult = producer.send(msg);producer.shutdown(); 消费者用MessageSelector.bySql来使用sql筛选消息12345678910DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name_4");// 只有订阅的消息有这个属性a, a &gt;=0 and a &lt;= 3consumer.subscribe("TopicTest", MessageSelector.bySql("a between 0 and 3");consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start(); 消息事务事务消息共有三种状态，提交状态、回滚状态、中间状态： TransactionStatus.CommitTransaction: 提交事务，它允许消费者消费此消息。 TransactionStatus.RollbackTransaction: 回滚事务，它代表该消息将被删除，不允许被消费。 TransactionStatus.Unknown: 中间状态，它代表需要检查消息队列来确定状态。 创建事务性生产者使用 TransactionMQProducer类创建生产者，并指定唯一的 ProducerGroup，就可以设置自定义线程池来处理这些检查请求。执行本地事务后、需要根据执行结果对消息队列进行回复。回传的事务状态在请参考前一节。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.rocketmq.demo.rocket;import org.apache.rocketmq.client.exception.MQClientException;import org.apache.rocketmq.client.producer.SendResult;import org.apache.rocketmq.client.producer.TransactionListener;import org.apache.rocketmq.client.producer.TransactionMQProducer;import org.apache.rocketmq.common.message.Message;import org.apache.rocketmq.remoting.common.RemotingHelper;import java.io.UnsupportedEncodingException;import java.util.concurrent.*;/** * @author dinghuang123@gmail.com * @since 2022/3/7 */public class TransactionProducer &#123; public static void main(String[] args) throws MQClientException, InterruptedException &#123; TransactionListener transactionListener = new TransactionListenerImpl(); TransactionMQProducer producer = new TransactionMQProducer("please_rename_unique_group_name"); ExecutorService executorService = new ThreadPoolExecutor(2, 5, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2000), new ThreadFactory() &#123; @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setName("client-transaction-msg-check-thread"); return thread; &#125; &#125;); producer.setNamesrvAddr("127.0.0.1:9876"); producer.setExecutorService(executorService); producer.setTransactionListener(transactionListener); producer.start(); String[] tags = new String[]&#123;"TagA", "TagB", "TagC", "TagD", "TagE"&#125;; for (int i = 0; i &lt; 10; i++) &#123; try &#123; Message msg = new Message("TransactionTopicTest", tags[i % tags.length], "KEY" + i, ("Hello RocketMQ " + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.sendMessageInTransaction(msg, null); System.out.printf("%s%n", sendResult); Thread.sleep(10); &#125; catch (MQClientException | UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; for (int i = 0; i &lt; 100000; i++) &#123; Thread.sleep(1000); &#125; producer.shutdown(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041package com.rocketmq.demo.rocket;import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyContext;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;import org.apache.rocketmq.client.exception.MQClientException;import org.apache.rocketmq.common.message.MessageExt;import java.util.List;/** * @author dinghuang123@gmail.com * @since 2022/3/3 */public class TransactionConsumer &#123; public static void main(String[] args) throws InterruptedException, MQClientException &#123; // 实例化消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name"); // 设置NameServer的地址 consumer.setNamesrvAddr("127.0.0.1:9876"); // 订阅一个或者多个Topic，以及Tag来过滤需要消费的消息 consumer.subscribe("TransactionTopicTest", "*"); // 注册回调实现类来处理从broker拉取回来的消息 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf("%s Receive New Messages: %s %n", Thread.currentThread().getName(), msgs); // 标记该消息已经被成功消费 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 启动消费者实例 consumer.start(); System.out.printf("Consumer Started.%n"); &#125;&#125; 实现事务的监听接口当发送半消息成功时，我们使用 executeLocalTransaction 方法来执行本地事务。它返回前一节中提到的三个事务状态之一。checkLocalTransaction 方法用于检查本地事务状态，并回应消息队列的检查请求。它也是返回前一节中提到的三个事务状态之一。1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.rocketmq.demo.rocket;import org.apache.rocketmq.client.producer.LocalTransactionState;import org.apache.rocketmq.client.producer.TransactionListener;import org.apache.rocketmq.common.message.Message;import org.apache.rocketmq.common.message.MessageExt;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.atomic.AtomicInteger;/** * @author dinghuang123@gmail.com * @since 2022/3/7 */public class TransactionListenerImpl implements TransactionListener &#123; private AtomicInteger transactionIndex = new AtomicInteger(0); private ConcurrentHashMap&lt;String, Integer&gt; localTrans = new ConcurrentHashMap&lt;&gt;(); @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; int value = transactionIndex.getAndIncrement(); int status = value % 3; localTrans.put(msg.getTransactionId(), status); System.out.println(new String(msg.getBody()) + ":executeLocalTransaction:" + msg.getTransactionId() + ":" + status + ":" + value); return LocalTransactionState.UNKNOW; &#125; @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123; Integer status = localTrans.get(msg.getTransactionId()); System.out.println(new String(msg.getBody()) + ":" + "checkLocalTransaction" + ":" + status ); if (null != status) &#123; switch (status) &#123; case 0: return LocalTransactionState.UNKNOW; case 1: return LocalTransactionState.COMMIT_MESSAGE; case 2: return LocalTransactionState.ROLLBACK_MESSAGE; &#125; &#125; return LocalTransactionState.COMMIT_MESSAGE; &#125;&#125; 事务消息使用上的限制 事务消息不支持延时消息和批量消息。 为了避免单个消息被检查太多次而导致半队列消息累积，我们默认将单个消息的检查次数限制为 15 次，但是用户可以通过 Broker 配置文件的 transactionCheckMax参数来修改此限制。如果已经检查某条消息超过 N 次的话（ N = transactionCheckMax ） 则 Broker 将丢弃此消息，并在默认情况下同时打印错误日志。用户可以通过重写 AbstractTransactionalMessageCheckListener 类来修改这个行为。 事务消息将在 Broker 配置文件中的参数 transactionTimeout 这样的特定时间长度之后被检查。当发送事务消息时，用户还可以通过设置用户属性 CHECK_IMMUNITY_TIME_IN_SECONDS 来改变这个限制，该参数优先于 transactionTimeout 参数。 事务性消息可能不止一次被检查或消费。 提交给用户的目标主题消息可能会失败，目前这依日志的记录而定。它的高可用性通过 RocketMQ 本身的高可用性机制来保证，如果希望确保事务消息不丢失、并且事务完整性得到保证，建议使用同步的双重写入机制。 事务消息的生产者 ID 不能与其他类型消息的生产者 ID 共享。与其他类型的消息不同，事务消息允许反向查询、MQ服务器能通过它们的生产者 ID 查询到消费者。 其他地址 最佳实践1 生产者1.1 发送消息注意事项1 Tags的使用一个应用尽可能用一个Topic，而消息子类型则可以用tags来标识。tags可以由应用自由设置，只有生产者在发送消息设置了tags，消费方在订阅消息时才可以利用tags通过broker做消息过滤：message.setTags(“TagA”)。 2 Keys的使用每个消息在业务层面的唯一标识码要设置到keys字段，方便将来定位消息丢失问题。服务器会为每个消息创建索引（哈希索引），应用可以通过topic、key来查询这条消息内容，以及消息被谁消费。由于是哈希索引，请务必保证key尽可能唯一，这样可以避免潜在的哈希冲突。 123// 订单Id String orderId = "20034568923546"; message.setKeys(orderId); 3 日志的打印消息发送成功或者失败要打印消息日志，务必要打印SendResult和key字段。send消息方法只要不抛异常，就代表发送成功。发送成功会有多个状态，在sendResult里定义。以下对每个状态进行说明： SEND_OK 消息发送成功。要注意的是消息发送成功也不意味着它是可靠的。要确保不会丢失任何消息，还应启用同步Master服务器或同步刷盘，即SYNC_MASTER或SYNC_FLUSH。 FLUSH_DISK_TIMEOUT 消息发送成功但是服务器刷盘超时。此时消息已经进入服务器队列（内存），只有服务器宕机，消息才会丢失。消息存储配置参数中可以设置刷盘方式和同步刷盘时间长度，如果Broker服务器设置了刷盘方式为同步刷盘，即FlushDiskType=SYNC_FLUSH（默认为异步刷盘方式），当Broker服务器未在同步刷盘时间内（默认为5s）完成刷盘，则将返回该状态——刷盘超时。 FLUSH_SLAVE_TIMEOUT 消息发送成功，但是服务器同步到Slave时超时。此时消息已经进入服务器队列，只有服务器宕机，消息才会丢失。如果Broker服务器的角色是同步Master，即SYNC_MASTER（默认是异步Master即ASYNC_MASTER），并且从Broker服务器未在同步刷盘时间（默认为5秒）内完成与主服务器的同步，则将返回该状态——数据同步到Slave服务器超时。 SLAVE_NOT_AVAILABLE 消息发送成功，但是此时Slave不可用。如果Broker服务器的角色是同步Master，即SYNC_MASTER（默认是异步Master服务器即ASYNC_MASTER），但没有配置slave Broker服务器，则将返回该状态——无Slave服务器可用。 1.2 消息发送失败处理方式Producer的send方法本身支持内部重试，重试逻辑如下： 至多重试2次。 如果同步模式发送失败，则轮转到下一个Broker，如果异步模式发送失败，则只会在当前Broker进行重试。这个方法的总耗时时间不超过sendMsgTimeout设置的值，默认10s。 如果本身向broker发送消息产生超时异常，就不会再重试。 以上策略也是在一定程度上保证了消息可以发送成功。如果业务对消息可靠性要求比较高，建议应用增加相应的重试逻辑：比如调用send同步方法发送失败时，则尝试将消息存储到db，然后由后台线程定时重试，确保消息一定到达Broker。 上述db重试方式为什么没有集成到MQ客户端内部做，而是要求应用自己去完成，主要基于以下几点考虑：首先，MQ的客户端设计为无状态模式，方便任意的水平扩展，且对机器资源的消耗仅仅是cpu、内存、网络。其次，如果MQ客户端内部集成一个KV存储模块，那么数据只有同步落盘才能较可靠，而同步落盘本身性能开销较大，所以通常会采用异步落盘，又由于应用关闭过程不受MQ运维人员控制，可能经常会发生 kill -9 这样暴力方式关闭，造成数据没有及时落盘而丢失。第三，Producer所在机器的可靠性较低，一般为虚拟机，不适合存储重要数据。综上，建议重试过程交由应用来控制。 1.3选择oneway形式发送通常消息的发送是这样一个过程： 客户端发送请求到服务器 服务器处理请求 服务器向客户端返回应答 所以，一次消息发送的耗时时间是上述三个步骤的总和，而某些场景要求耗时非常短，但是对可靠性要求并不高，例如日志收集类应用，此类应用可以采用oneway形式调用，oneway形式只发送请求不等待应答，而发送请求在客户端实现层面仅仅是一个操作系统系统调用的开销，即将数据写入客户端的socket缓冲区，此过程耗时通常在微秒级。 2 消费者2.1 消费过程幂等RocketMQ无法避免消息重复（Exactly-Once），所以如果业务对消费重复非常敏感，务必要在业务层面进行去重处理。可以借助关系数据库进行去重。首先需要确定消息的唯一键，可以是msgId，也可以是消息内容中的唯一标识字段，例如订单Id等。在消费之前判断唯一键是否在关系数据库中存在。如果不存在则插入，并消费，否则跳过。（实际过程要考虑原子性问题，判断是否存在可以尝试插入，如果报主键冲突，则插入失败，直接跳过） msgId一定是全局唯一标识符，但是实际使用中，可能会存在相同的消息有两个不同msgId的情况（消费者主动重发、因客户端重投机制导致的重复等），这种情况就需要使业务字段进行重复消费。 2.2 消费速度慢的处理方式1 提高消费并行度绝大部分消息消费行为都属于 IO 密集型，即可能是操作数据库，或者调用 RPC，这类消费行为的消费速度在于后端数据库或者外系统的吞吐量，通过增加消费并行度，可以提高总的消费吞吐量，但是并行度增加到一定程度，反而会下降。所以，应用必须要设置合理的并行度。 如下有几种修改消费并行度的方法： 同一个 ConsumerGroup 下，通过增加 Consumer 实例数量来提高并行度（需要注意的是超过订阅队列数的 Consumer 实例无效）。可以通过加机器，或者在已有机器启动多个进程的方式。 提高单个 Consumer 的消费并行线程，通过修改参数 consumeThreadMin、consumeThreadMax实现。 2 批量方式消费某些业务流程如果支持批量方式消费，则可以很大程度上提高消费吞吐量，例如订单扣款类应用，一次处理一个订单耗时 1 s，一次处理 10 个订单可能也只耗时 2 s，这样即可大幅度提高消费的吞吐量，通过设置 consumer的 consumeMessageBatchMaxSize 返个参数，默认是 1，即一次只消费一条消息，例如设置为 N，那么每次消费的消息数小于等于 N。 3 跳过非重要消息发生消息堆积时，如果消费速度一直追不上发送速度，如果业务对数据要求不高的话，可以选择丢弃不重要的消息。例如，当某个队列的消息数堆积到100000条以上，则尝试丢弃部分或全部消息，这样就可以快速追上发送消息的速度。示例代码如下： 1234567891011121314public ConsumeConcurrentlyStatus consumeMessage( List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; long offset = msgs.get(0).getQueueOffset(); String maxOffset = msgs.get(0).getProperty(Message.PROPERTY_MAX_OFFSET); long diff = Long.parseLong(maxOffset) - offset; if (diff &gt; 100000) &#123; // TODO 消息堆积情况的特殊处理 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; // TODO 正常消费过程 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;&#125; 4 优化每条消息消费过程举例如下，某条消息的消费过程如下： 根据消息从 DB 查询【数据 1】 根据消息从 DB 查询【数据 2】 复杂的业务计算 向 DB 插入【数据 3】 向 DB 插入【数据 4】 这条消息的消费过程中有4次与 DB的 交互，如果按照每次 5ms 计算，那么总共耗时 20ms，假设业务计算耗时 5ms，那么总过耗时 25ms，所以如果能把 4 次 DB 交互优化为 2 次，那么总耗时就可以优化到 15ms，即总体性能提高了 40%。所以应用如果对时延敏感的话，可以把DB部署在SSD硬盘，相比于SCSI磁盘，前者的RT会小很多。 2.3 消费打印日志如果消息量较少，建议在消费入口方法打印消息，消费耗时等，方便后续排查问题。 1234567public ConsumeConcurrentlyStatus consumeMessage( List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; log.info("RECEIVE_MSG_BEGIN: " + msgs.toString()); // TODO 正常消费过程 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; 如果能打印每条消息消费耗时，那么在排查消费慢等线上问题时，会更方便。 2.4 其他消费建议1 关于消费者和订阅第一件需要注意的事情是，不同的消费者组可以独立的消费一些 topic，并且每个消费者组都有自己的消费偏移量，请确保同一组内的每个消费者订阅信息保持一致。 2 关于有序消息消费者将锁定每个消息队列，以确保他们被逐个消费，虽然这将会导致性能下降，但是当你关心消息顺序的时候会很有用。我们不建议抛出异常，你可以返回 ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT 作为替代。 3 关于并发消费顾名思义，消费者将并发消费这些消息，建议你使用它来获得良好性能，我们不建议抛出异常，你可以返回 ConsumeConcurrentlyStatus.RECONSUME_LATER 作为替代。 4 关于消费状态Consume Status对于并发的消费监听器，你可以返回 RECONSUME_LATER 来通知消费者现在不能消费这条消息，并且希望可以稍后重新消费它。然后，你可以继续消费其他消息。对于有序的消息监听器，因为你关心它的顺序，所以不能跳过消息，但是你可以返回SUSPEND_CURRENT_QUEUE_A_MOMENT 告诉消费者等待片刻。 5 关于Blocking不建议阻塞监听器，因为它会阻塞线程池，并最终可能会终止消费进程 6 关于线程数设置消费者使用 ThreadPoolExecutor 在内部对消息进行消费，所以你可以通过设置 setConsumeThreadMin 或 setConsumeThreadMax 来改变它。 7 关于消费位点当建立一个新的消费者组时，需要决定是否需要消费已经存在于 Broker 中的历史消息CONSUME_FROM_LAST_OFFSET 将会忽略历史消息，并消费之后生成的任何消息。CONSUME_FROM_FIRST_OFFSET 将会消费每个存在于 Broker 中的信息。你也可以使用 CONSUME_FROM_TIMESTAMP 来消费在指定时间戳后产生的消息。 3 Broker3.1 Broker 角色 Broker 角色分为 ASYNC_MASTER（异步主机）、SYNC_MASTER（同步主机）以及SLAVE（从机）。如果对消息的可靠性要求比较严格，可以采用 SYNC_MASTER加SLAVE的部署方式。如果对消息可靠性要求不高，可以采用ASYNC_MASTER加SLAVE的部署方式。如果只是测试方便，则可以选择仅ASYNC_MASTER或仅SYNC_MASTER的部署方式。 3.2 FlushDiskTypeSYNC_FLUSH（同步刷新）相比于ASYNC_FLUSH（异步处理）会损失很多性能，但是也更可靠，所以需要根据实际的业务场景做好权衡。 3.3 Broker 配置 参数名 默认值 说明 listenPort 10911 接受客户端连接的监听端口 namesrvAddr null nameServer 地址 brokerIP1 网卡的 InetAddress 当前 broker 监听的 IP brokerIP2 跟 brokerIP1 一样 存在主从 broker 时，如果在 broker 主节点上配置了 brokerIP2 属性，broker 从节点会连接主节点配置的 brokerIP2 进行同步 brokerName null broker 的名称 brokerClusterName DefaultCluster 本 broker 所属的 Cluser 名称 brokerId 0 broker id, 0 表示 master, 其他的正整数表示 slave storePathRootDir $HOME/store/ 存储根路径 storePathCommitLog $HOME/store/commitlog/ 存储 commit log 的路径 mappedFileSizeCommitLog 1024 1024 1024(1G) commit log 的映射文件大小 deleteWhen 04 在每天的什么时间删除已经超过文件保留时间的 commit log fileReservedTime 72 以小时计算的文件保留时间 brokerRole ASYNC_MASTER SYNC_MASTER/ASYNC_MASTER/SLAVE flushDiskType ASYNC_FLUSH SYNC_FLUSH/ASYNC_FLUSH SYNC_FLUSH 模式下的 broker 保证在收到确认生产者之前将消息刷盘。ASYNC_FLUSH 模式下的 broker 则利用刷盘一组消息的模式，可以取得更好的性能。 4 NameServerRocketMQ 中，Name Servers 被设计用来做简单的路由管理。其职责包括： Brokers 定期向每个名称服务器注册路由数据。 名称服务器为客户端，包括生产者，消费者和命令行客户端提供最新的路由信息。 5 客户端配置 相对于RocketMQ的Broker集群，生产者和消费者都是客户端。本小节主要描述生产者和消费者公共的行为配置。 5.1 客户端寻址方式RocketMQ可以令客户端找到Name Server, 然后通过Name Server再找到Broker。如下所示有多种配置方式，优先级由高到低，高优先级会覆盖低优先级。 代码中指定Name Server地址，多个namesrv地址之间用分号分割 123producer.setNamesrvAddr("192.168.0.1:9876;192.168.0.2:9876"); consumer.setNamesrvAddr("192.168.0.1:9876;192.168.0.2:9876"); Java启动参数中指定Name Server地址 1-Drocketmq.namesrv.addr=192.168.0.1:9876;192.168.0.2:9876 环境变量指定Name Server地址 1export NAMESRV_ADDR=192.168.0.1:9876;192.168.0.2:9876 HTTP静态服务器寻址（默认） 客户端启动后，会定时访问一个静态HTTP服务器，地址如下：http://jmenv.tbsite.net:8080/rocketmq/nsaddr，这个URL的返回内容如下： 1192.168.0.1:9876;192.168.0.2:9876 客户端默认每隔2分钟访问一次这个HTTP服务器，并更新本地的Name Server地址。URL已经在代码中硬编码，可通过修改/etc/hosts文件来改变要访问的服务器，例如在/etc/hosts增加如下配置：110.232.22.67 jmenv.tbsite.net 推荐使用HTTP静态服务器寻址方式，好处是客户端部署简单，且Name Server集群可以热升级。 5.2 客户端配置DefaultMQProducer、TransactionMQProducer、DefaultMQPushConsumer、DefaultMQPullConsumer都继承于ClientConfig类，ClientConfig为客户端的公共配置类。客户端的配置都是get、set形式，每个参数都可以用spring来配置，也可以在代码中配置，例如namesrvAddr这个参数可以这样配置，producer.setNamesrvAddr(“192.168.0.1:9876”)，其他参数同理。 1 客户端的公共配置 参数名 默认值 说明 namesrvAddr Name Server地址列表，多个NameServer地址用分号隔开 clientIP 本机IP 客户端本机IP地址，某些机器会发生无法识别客户端IP地址情况，需要应用在代码中强制指定 instanceName DEFAULT 客户端实例名称，客户端创建的多个Producer、Consumer实际是共用一个内部实例（这个实例包含网络连接、线程资源等） clientCallbackExecutorThreads 4 通信层异步回调线程数 pollNameServerInteval 30000 轮询Name Server间隔时间，单位毫秒 heartbeatBrokerInterval 30000 向Broker发送心跳间隔时间，单位毫秒 persistConsumerOffsetInterval 5000 持久化Consumer消费进度间隔时间，单位毫秒 2 Producer配置 参数名 默认值 说明 producerGroup DEFAULT_PRODUCER Producer组名，多个Producer如果属于一个应用，发送同样的消息，则应该将它们归为同一组 createTopicKey TBW102 在发送消息时，自动创建服务器不存在的topic，需要指定Key，该Key可用于配置发送消息所在topic的默认路由。 defaultTopicQueueNums 4 在发送消息，自动创建服务器不存在的topic时，默认创建的队列数 sendMsgTimeout 3000 发送消息超时时间，单位毫秒 compressMsgBodyOverHowmuch 4096 消息Body超过多大开始压缩（Consumer收到消息会自动解压缩），单位字节 retryAnotherBrokerWhenNotStoreOK FALSE 如果发送消息返回sendResult，但是sendStatus!=SEND_OK，是否重试发送 retryTimesWhenSendFailed 2 如果消息发送失败，最大重试次数，该参数只对同步发送模式起作用 maxMessageSize 4MB 客户端限制的消息大小，超过报错，同时服务端也会限制，所以需要跟服务端配合使用。 transactionCheckListener 事务消息回查监听器，如果发送事务消息，必须设置 checkThreadPoolMinSize 1 Broker回查Producer事务状态时，线程池最小线程数 checkThreadPoolMaxSize 1 Broker回查Producer事务状态时，线程池最大线程数 checkRequestHoldMax 2000 Broker回查Producer事务状态时，Producer本地缓冲请求队列大小 RPCHook null 该参数是在Producer创建时传入的，包含消息发送前的预处理和消息响应后的处理两个接口，用户可以在第一个接口中做一些安全控制或者其他操作。 3 PushConsumer配置 参数名 默认值 说明 consumerGroup DEFAULT_CONSUMER Consumer组名，多个Consumer如果属于一个应用，订阅同样的消息，且消费逻辑一致，则应该将它们归为同一组 messageModel CLUSTERING 消费模型支持集群消费和广播消费两种 consumeFromWhere CONSUME_FROM_LAST_OFFSET Consumer启动后，默认从上次消费的位置开始消费，这包含两种情况：一种是上次消费的位置未过期，则消费从上次中止的位置进行；一种是上次消费位置已经过期，则从当前队列第一条消息开始消费 consumeTimestamp 半个小时前 只有当consumeFromWhere值为CONSUME_FROM_TIMESTAMP时才起作用。 allocateMessageQueueStrategy AllocateMessageQueueAveragely Rebalance算法实现策略 subscription 订阅关系 messageListener 消息监听器 offsetStore 消费进度存储 consumeThreadMin 20 消费线程池最小线程数 consumeThreadMax 20 消费线程池最大线程数 consumeConcurrentlyMaxSpan 2000 单队列并行消费允许的最大跨度 pullThresholdForQueue 1000 拉消息本地队列缓存消息最大数 pullInterval 0 拉消息间隔，由于是长轮询，所以为0，但是如果应用为了流控，也可以设置大于0的值，单位毫秒 consumeMessageBatchMaxSize 1 批量消费，一次消费多少条消息 pullBatchSize 32 批量拉消息，一次最多拉多少条 4 PullConsumer配置 参数名 默认值 说明 consumerGroup DEFAULT_CONSUMER Consumer组名，多个Consumer如果属于一个应用，订阅同样的消息，且消费逻辑一致，则应该将它们归为同一组 brokerSuspendMaxTimeMillis 20000 长轮询，Consumer拉消息请求在Broker挂起最长时间，单位毫秒 consumerTimeoutMillisWhenSuspend 30000 长轮询，Consumer拉消息请求在Broker挂起超过指定时间，客户端认为超时，单位毫秒 consumerPullTimeoutMillis 10000 非长轮询，拉消息超时时间，单位毫秒 messageModel BROADCASTING 消息支持两种模式：集群消费和广播消费 messageQueueListener 监听队列变化 offsetStore 消费进度存储 registerTopics 注册的topic集合 allocateMessageQueueStrategy AllocateMessageQueueAveragely Rebalance算法实现策略 5 Message数据结构 字段名 默认值 说明 Topic null 必填，消息所属topic的名称 Body null 必填，消息体 Tags null 选填，消息标签，方便服务器过滤使用。目前只支持每个消息设置一个tag Keys null 选填，代表这条消息的业务关键词，服务器会根据keys创建哈希索引，设置后，可以在Console系统根据Topic、Keys来查询消息，由于是哈希索引，请尽可能保证key唯一，例如订单号，商品Id等。 Flag 0 选填，完全由应用来设置，RocketMQ不做干预 DelayTimeLevel 0 选填，消息延时级别，0表示不延时，大于0会延时特定的时间才会被消费 WaitStoreMsgOK TRUE 选填，表示消息是否在服务器落盘后才返回应答。 6 系统配置本小节主要介绍系统（JVM/OS）相关的配置。 6.1 JVM选项推荐使用最新发布的JDK 1.8版本。通过设置相同的Xms和Xmx值来防止JVM调整堆大小以获得更好的性能。简单的JVM配置如下所示： 12-server -Xms8g -Xmx8g -Xmn4g 如果您不关心RocketMQ Broker的启动时间，还有一种更好的选择，就是通过“预触摸”Java堆以确保在JVM初始化期间每个页面都将被分配。那些不关心启动时间的人可以启用它：1-XX:+AlwaysPreTouch 禁用偏置锁定可能会减少JVM暂停，1-XX:-UseBiasedLocking 至于垃圾回收，建议使用带JDK 1.8的G1收集器。 123-XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 这些GC选项看起来有点激进，但事实证明它在我们的生产环境中具有良好的性能。另外不要把-XX:MaxGCPauseMillis的值设置太小，否则JVM将使用一个小的年轻代来实现这个目标，这将导致非常频繁的minor GC，所以建议使用rolling GC日志文件： 123-XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m 如果写入GC文件会增加代理的延迟，可以考虑将GC日志文件重定向到内存文件系统： 1-Xloggc:/dev/shm/mq_gc_%p.log123 6.2 Linux内核参数os.sh脚本在bin文件夹中列出了许多内核参数，可以进行微小的更改然后用于生产用途。下面的参数需要注意，更多细节请参考/proc/sys/vm/*的文档 vm.extra_free_kbytes，告诉VM在后台回收（kswapd）启动的阈值与直接回收（通过分配进程）的阈值之间保留额外的可用内存。RocketMQ使用此参数来避免内存分配中的长延迟。（与具体内核版本相关） vm.min_free_kbytes，如果将其设置为低于1024KB，将会巧妙的将系统破坏，并且系统在高负载下容易出现死锁。 vm.max_map_count，限制一个进程可能具有的最大内存映射区域数。RocketMQ将使用mmap加载CommitLog和ConsumeQueue，因此建议将为此参数设置较大的值。（agressiveness –&gt; aggressiveness） vm.swappiness，定义内核交换内存页面的积极程度。较高的值会增加攻击性，较低的值会减少交换量。建议将值设置为10来避免交换延迟。 File descriptor limits，RocketMQ需要为文件（CommitLog和ConsumeQueue）和网络连接打开文件描述符。我们建议设置文件描述符的值为655350。 Disk scheduler，RocketMQ建议使用I/O截止时间调度器，它试图为请求提供有保证的延迟。)]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式系统认证方案]]></title>
    <url>%2F2022%2F01%2F14%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%A4%E8%AF%81%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[分布式系统认证方案需要满足以下需求 统一认证授权：不同客户端均采用一致的认证、授权、会话判断机制，实现统一认证授权服务。 多样的认证场景：支持用户名密码、短信验证码、二维码、人脸识别等各种认证方式，并可以灵活的切换和扩展。 应用接入认证：，提供安全的系统对接机制，并可开放部分API给第三方使用。并且内部服务和外部第三方服务均采用统一的接入机制。 分布式认证方案基于Session的认证方式session复制将服务器A的session，复制到服务器B，同样将服务器B的session也复制到服务器A，这样两台服务器的session就一致了。像tomcat等web容器都支持session复制的功能，在同一个局域网内，一台服务器的session会广播给其他服务器。 缺点：同一个网段内服务器太多，每个服务器都会去复制session，会造成服务器内存浪费。 session黏性利用Nginx服务器的反向代理，将服务器A和服务器B进行代理，然后采用ip_hash的负载策略，将客户端和服务器进行绑定，也就是说客户端A第一次访问的是服务器B，那么第二次访问也必然是服务器B，这样就不存在session不一致的问题了。 缺点：如果服务器A宕机了，那么客户端A和客户端B的session就会出现丢失。 session集中管理这种方式就是将所有服务器的session进行统一管理，可以使用v等高性能服务器来集中管理session，而且spring官方提供的spirng-session就是这样处理session的一致性问题。这也是目前企业开发用到的比较多的一种分布式session解决方案。 基于Token的认证方式基于token的认证方式，服务端不用存储认证数据，易维护扩展性强， 客户端可以把token存在任意地方，并且可以实现web和app统一认证机制。token认证方式对第三方应用接入更适合，因为它更开放，可使用当前有流行的开放协议Oauth2.0、JWT等。一般情况服务端无需存储会话信息，减轻了服务端的压力。 缺点：token由于自包含信息，因此一般数据量较大，而且每次请求都需要传递，因此比较占带宽。另外，token的签名验签操作也会给cpu带来额外的处理负担。 验证流程1 用户通过接入方（应用）登录，接入方采取OAuth2.0方式在统一认证服务(oauth-service)中认证。 2 认证服务调用验证该用户的身份是否合法，并获取用户权限信息。 3 认证服务获取接入方权限信息，并验证接入方是否合法。 4 若登录用户以及接入方都合法，认证服务生成jwt令牌返回给接入方，其中jwt中包含了用户权限及接入方权限。 5 后续，接入方携带jwt令牌对API网关内的微服务资源进行访问。 6 API网关对令牌解析、并验证接入方的权限是否能够访问本次请求的微服务。 7 如果接入方的权限没问题，API网关将原请求header中附加解析后的明文Token，并将请求转发至微服务。 8 微服务收到请求，明文token中包含登录用户的身份和权限信息。因此后续微服务自己可以干两件事： 用户授权拦截（看当前用户是否有权访问该资源） 将用户信息存储进当前线程上下文（有利于后续业务逻辑随时获取当前用户信息） OAuth2.0OAuth（开放授权）是一个开放标准，允许用户授权第三方移动应用访问他们存储在另外的服务提供者上的信息，而不需要将用户名和密码提供给第三方移动应用或分享他们数据的所有内容。OAuth2.0是OAuth协议的延续版本，但不向后兼容OAuth1.0即完全废止了OAuth1.0。 OAuth2中的四种认证授权模式 授权码模式（authorization code） 简化模式/隐式授权模式（implicit） 密码模式（password） 客户端模式（client credentials） OAuth2.0包括以下角色 客户端:本身不存储资源，需要通过资源拥有者的授权去请求资源服务器的资源，比如:Android客户端、Web客户端（浏览器端）、微信客户端等。 资源拥有者:通常为用户，也可以是应用程序，即该资源的拥有者。 授权服务器（认证服务器）:用于服务提供商对资源拥有的身份进行认证、对访问资源进行授权，认证成功后会给客户端发放令牌（access_token），作为客户端访问资源服务器的凭据。 资源服务器: 存储资源的服务器。 JWT tokenJWT的全称是JSON Web Tokens，它由下面2部分组成： Authorization (授权) : 这是使用JWT的最常见场景。一旦用户登录，后续每个请求都将包含JWT，允许用户访问该令牌允许的路由、服务和资源。单点登录是现在广泛使用的JWT的一个特性，因为它的开销很小，并且可以轻松地跨域使用。 Information Exchange (信息交换) : JWT可以被签名，例如，用公钥/私钥对，可以验证内容没有被篡改。 Header：token的类型（JWT）和算法名称（比如：HMAC SHA256或者RSA等等） Payload：JWT的第二部分是payload，它包含声明（要求）。声明是关于实体(通常是用户)和其他数据的声明。声明有三种类型: registered, public 和 private。 Signature：签名是用于验证消息在传递过程中有没有被更改，并且，对于使用私钥签名的token，它还可以验证JWT的发送方是否为它所称的发送方。 注意，不要在JWT的payload或header中放置敏感信息，除非它们是加密的 授权码模式举例：小米账户授权Authorization Code授权分为两步，首先获取Authorization Code，然后用Code换取Access Token。其流程示意图如下 一般会有下面的注意事项： Authorization Code只能使用一次，不可重复使用 Authorization Code有效时间为5分钟, 在返回Authorization Code5分钟之后失效 简化模式简化模式相对于授权码模式，少了获取code以及用code换token这一步，用户授权后，认证服务器直接返回一个token。 密码模式这个模式流程简单，但很不安全，一般用在强信任的两个系统。 客户端模式分配一个账号密码，每一个账户密码资源服务器会对允许请求的资源做权限控制。可以用这个账号密码来获取token，通过这个token去获取资源服务器允许你请求的资源，之所以使用token而不直接使用账户密码还是为了安全考虑，token有过期机制，过期后需要使用账户密码重新获取token，很多时候这个重新获取的业务场景被称为签到。 认证服务器会给准入的接入方一个身份，用于接入时的凭据:client_id：客户端标识，client_secret：客户端秘钥因此，准确来说，授权服务器对两种OAuth2.0中的两个角色进行认证授权，分别是资源拥有者、客户端。 Spring-Security-OAuth2Spring-Security-OAuth2是对OAuth2的一种实现，OAuth2.0的服务提供方涵盖两个服务，即授权服务 (Authorization Server，也叫认证服务) 和资源服务 (Resource Server)，使用 Spring Security OAuth2 的时候你可以选择把它们在同一个应用程序中实现，也可以选择建立使用同一个授权服务的多个资源服务。 SpringSecurity 过滤器两个至关重要的类：OncePerRequestFilter和GenericFilterBean，在过滤器链的过滤器中，或多或少间接或直接继承到 OncePerRequestFilter顾名思义，能够确保在一次请求只通过一次filter，而不需要重复执行。 GenericFilterBean是javax.servlet.Filter接口的一个基本的实现类 GenericFilterBean将web.xml中filter标签中的配置参数-init-param项作为bean的属性 GenericFilterBean可以简单地成为任何类型的filter的父类 GenericFilterBean的子类可以自定义一些自己需要的属性 GenericFilterBean，将实际的过滤工作留给他的子类来完成，这就导致了他的子类不得不实现doFilter方法 GenericFilterBean不依赖于Spring的ApplicationContext，Filters通常不会直接读取他们的容器信息（ApplicationContext concept）而是通过访问spring容器（Spring root application context）中的service beans来获取，通常是通过调用filter里面的getServletContext() 方法来获取WebAsyncManagerIntegrationFilter 根据请求封装获取WebAsyncManager 从WebAsyncManager获取/注册SecurityContextCallableProcessingInterceptor SecurityContextPersistenceFilter 先实例SecurityContextHolder-&gt;HttpSessionSecurityContextRepository（下面以repo代替）.作用：其会从Session中取出已认证用户的信息,提高效率,避免每一次请求都要查询用户认证信息。 根据请求和响应构建HttpRequestResponseHolder repo根据HttpRequestResponseHolder加载context获取SecurityContext SecurityContextHolder将获得到的SecurityContext设置到Context中，然后继续向下执行其他过滤器 finally-&gt; SecurityContextHolder获取SecurityContext，然后清除，并将其和请求信息保存到repo，从请求中移除FILTER_APPLIED属性 HeaderWriterFilter 往该请求的Header中添加相应的信息,在http标签内部使用security:headers来控制 CsrfFilter csrf又称跨域请求伪造，攻击方通过伪造用户请求访问受信任站点。 对需要验证的请求验证是否包含csrf的token信息，如果不包含，则报错。这样攻击网站无法获取到token信息，则跨域提交的信息都无法通过过滤器的校验。 LogoutFilter 匹配URL,默认为/logout 匹配成功后则用户退出,清除认证信息 RequestCacheAwareFilter 通过HttpSessionRequestCache内部维护了一个RequestCache，用于缓存HttpServletRequest SecurityContextHolderAwareRequestFilter 针对ServletRequest进行了一次包装，使得request具有更加丰富的API AnonymousAuthenticationFilter 当SecurityContextHolder中认证信息为空,则会创建一个匿名用户存入到SecurityContextHolder中。匿名身份过滤器，这个过滤器很重要，需要将它与UsernamePasswordAuthenticationFilter 放在一起比较理解，spring security为了兼容未登录的访问，也走了一套认证流程，只不过是一个匿名的身份。 匿名认证过滤器是Spirng Security为了整体逻辑的统一性，即使是未通过认证的用户，也给予了一个匿名身份。而AnonymousAuthenticationFilter该过滤器的位置也是非常的科学的，它位于常用的身份认证过滤器（如UsernamePasswordAuthenticationFilter、BasicAuthenticationFilter、RememberMeAuthenticationFilter）之后，意味着只有在上述身份过滤器执行完毕后，SecurityContext依旧没有用户信息，AnonymousAuthenticationFilte该过滤器才会有意义—-基于用户一个匿名身份。 SessionManagementFilter securityContextRepository限制同一用户开启多个会话的数量 SessionAuthenticationStrategy防止session-fixation protection attack（保护非匿名用户） ExceptionTranslationFilter ExceptionTranslationFilter异常转换过滤器位于整个springSecurityFilterChain的后方，用来转换整个链路中出现的异常 此过滤器的作用是处理中FilterSecurityInterceptor抛出的异常，然后将请求重定向到对应页面，或返回对应的响应错误代码 FilterSecurityInterceptor 获取到所配置资源访问的授权信息 根据SecurityContextHolder中存储的用户信息来决定其是否有权限 主要一些实现功能在其父类AbstractSecurityInterceptor中 UsernamePasswordAuthenticationFilter 表单认证是最常用的一个认证方式，一个最直观的业务场景便是允许用户在表单中输入用户名和密码进行登录，而这背后的UsernamePasswordAuthenticationFilter，在整个Spring Security的认证体系中则扮演着至关重要的角色 使用pom.xml12345678910111213141516171819202122232425&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-commons&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-oauth2&lt;/artifactId&gt;&lt;/dependency&gt; 授权服务器配置:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Configuration@EnableAuthorizationServerpublic class AuthorizationServer extends AuthorizationServerConfigurerAdapter &#123; @Autowired private TokenStore tokenStore; @Autowired private ClientDetailsService clientDetailsService; @Autowired private AuthorizationCodeServices authorizationCodeServices; @Autowired private AuthenticationManager authenticationManager; //令牌访问端点 @Override public void configure(AuthorizationServerEndpointsConfigurer endpoints) &#123; endpoints .authenticationManager(authenticationManager) .authorizationCodeServices(authorizationCodeServices) .tokenServices(tokenService()) .allowedTokenEndpointRequestMethods(HttpMethod.POST); &#125; //注意这个部分,到时候和请求链接的参数比对 @Override public void configure(ClientDetailsServiceConfigurer clients) throws Exception &#123; clients.inMemory() //用内存存储 .withClient("c1") .secret(new BCryptPasswordEncoder().encode("secret")) //客户端密钥 .resourceIds("res1") //资源列表 .authorizedGrantTypes("authorization_code", "password", "client_credentials", "refresh_token") .scopes("all")//允许授权范围 .autoApprove(false) .redirectUris("http://www.baidu.com"); //验证回调地址 &#125; //令牌管理服务 @Bean public AuthorizationServerTokenServices tokenService() &#123; DefaultTokenServices service = new DefaultTokenServices(); service.setClientDetailsService(clientDetailsService); //客户端服务信息 service.setSupportRefreshToken(true); // 是否产生刷新令牌 service.setTokenStore(tokenStore); //令牌存储策略 service.setAccessTokenValiditySeconds(7200);// 令牌默认有效期2小时 service.setRefreshTokenValiditySeconds(259200);// 刷新令牌默认有效期3天 return service; &#125; // 令牌访问端点安全策略 @Override public void configure(AuthorizationServerSecurityConfigurer security) &#123; security .tokenKeyAccess("permitAll()") //oauth2/token_key .checkTokenAccess("permitAll()") //oauth/check_key .allowFormAuthenticationForClients(); // 表单认证 (申请令牌) &#125; @Bean public AuthorizationCodeServices authorizationCodeServices() &#123; //设置授权码模式的授权码如何 存取，暂时采用内存方式 return new InMemoryAuthorizationCodeServices(); &#125;&#125; 如果要用数据库就在这个UserDetailsService编码1234567891011121314151617181920212223@Componentpublic class CustomUserDetailsService implements UserDetailsService &#123; @Override public UserDetails loadUserByUsername(String login) throws UsernameNotFoundException &#123; // 1. 查询用户 数据库查出角色权限 // 2. 设置角色 Collection&lt;GrantedAuthority&gt; grantedAuthorities = new ArrayList&lt;&gt;(); GrantedAuthority grantedAuthority; if ("admin".equals(login)) &#123; grantedAuthority = new SimpleGrantedAuthority("ADMIN"); &#125; else &#123; grantedAuthority = new SimpleGrantedAuthority("USER"); &#125; grantedAuthorities.add(grantedAuthority); //写死 用户密码123以及角色 USER 查出来的密码和比对的加密算法要传入进去 return new User(login, new BCryptPasswordEncoder().encode("123"), grantedAuthorities); &#125;&#125; 1234567891011/** * 在config包下定义TokenConfig， * 我们暂时先使用InMemoryTokenStore，生成一个普通的令牌。 */@Configurationpublic class TokenConfig &#123; @Bean public TokenStore tokenStore() &#123; return new InMemoryTokenStore(); &#125;&#125; 1234567891011121314151617181920212223242526272829@Configuration@EnableGlobalMethodSecurity(securedEnabled = true,prePostEnabled = true)public class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; //认证管理器 @Bean public AuthenticationManager authenticationManagerBean() throws Exception &#123; return super.authenticationManagerBean(); &#125; //密码编码器 @Bean public PasswordEncoder passwordEncoder() &#123; return new BCryptPasswordEncoder(); &#125; //安全拦截机制（最重要） @Override protected void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable() .authorizeRequests() .antMatchers("/r/r1").hasAnyAuthority("p1") .antMatchers("/login*").permitAll() .anyRequest().authenticated() .and() .formLogin() ; &#125;&#125; 访问http://localhost:8000/oauth/authorize?client_id=pa&amp;reponse_type=code&amp;scope=all&amp;redirect_uri=http://www.baidu.com确认授权:获取到授权码: [参考] 循序渐进之单点登录（4）–分布式系统认证(OAuth2,JWT) Spring Security 核心过滤器链分析]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁]]></title>
    <url>%2F2021%2F11%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[参考文章 PPT下载 分布式锁为什么需要分布式锁常见的是秒杀场景，订单服务部署了多个服务实例。如秒杀商品有 4 个，第一个用户购买 3 个，第二个用户购买 2 个，理想状态下第一个用户能购买成功，第二个用户提示购买失败，反之亦可。而实际可能出现的情况是，两个用户都得到库存为 4，第一个用户买到了 3 个，更新库存之前，第二个用户下了 2 个商品的订单，更新库存为 2，导致业务逻辑出错。 在上面的场景中，商品的库存是共享变量，面对高并发情形，需要保证对资源的访问互斥。在单机环境中，比如 Java 语言中其实提供了很多并发处理相关的 API，但是这些 API 在分布式场景中就无能为力了，由于分布式系统具备多线程和多进程的特点，且分布在不同机器中，synchronized 和 lock 关键字将失去原有锁的效果，。仅依赖这些语言自身提供的 API 并不能实现分布式锁的功能，因此需要想想其它方法实现分布式锁。 分布式锁三个属性和两大类 总的来说，分布式锁服务有三个必备的性质 互斥（Mutual Exclusion），这是锁最基本的功能，同一时刻只能有一个客户端持有锁； 避免死锁（Dead lock free），如果某个客户端获得锁之后花了太长时间处理，或者客户端发生了故障，锁无法释放会导致整个处理流程无法进行下去，所以要避免死锁。最常见的是通过设置一个 TTL(Time To Live，存活时间) 来避免死锁。假设设置 TTL 为 3 秒，如果 3 秒过后锁还没有被释放，系统也会自动释放该锁（TTL 的设置要非常小心！这个时长取决于你的业务逻辑）。可是这也存在一个问题，假如进程1获取了锁，然后由于某些原因（下面会说到）没有来得及更新 TTL；3秒后进程2来获取锁，由于 TTL 已过，进程2可以获得锁并开始处理，此时同时有两个客户端持有锁，可能会产生意外行为。所以不能只有 TTL，还需要给锁附加一个唯一 ID (或 fencing token)来标识锁。上述逻辑中，当进程 1 获取到锁后记为 LOCK_1；TTL 过后进程 2 获取到的锁记为 LOCK_2。之后，可以在应用层面或锁服务层面检查该 id，来阻断旧的请求。 容错（Fault tolerance），为避免单点故障，锁服务需要具有一定容错性。大体有两种容错方式，一种是锁服务本身是一个集群，能够自动故障切换(ZooKeeper、etcd)；另一种是客户端向多个独立的锁服务发起请求，其中某个锁服务故障时仍然可以从其他锁服务读取到锁信息(Redlock)，代价是一个客户端要获取多把锁，并且要求每台机器的时钟都是一样的，否则 TTL 会不一致，可能有的机器会提前释放锁，有的机器会太晚释放锁，导致出现问题。 值得注意的是，容错会以性能为代价，容错性取决于你的系统级别，如果你的系统可以承担分布式锁存在误差，那么单节点或者简单的主从复制也许就能满足；如果你的系统非常严格，例如金融系统或航天系统，那么就要考虑每个 corner case 先把分布式锁分为两大类：自旋类和监听类。 自旋类包括基于数据库的实现和基于 Redis 的实现，这类实现需要客户端不停反复请求锁服务查看是否能够获取到锁； 监听类主要包括基于 ZooKeeper 或 etcd 实现的分布式锁，这类实现客户端只需监听(watch) 某个 key，当锁可用时锁服务会通知客户端，无需客户端不停请求锁服务。 基于数据库的实现基于数据库表的增删 互斥:通过某个独立的数据库（或文件），当获取到数据时，往数据库中插入一条数据。之后的进程想要获取数据，会先检查数据库是否存在记录，就能够知道是否有别的进程持有锁. 避免死锁:增加时间戳字段和自增 id 字段，同时在后台启动一个线程定时释放和清理过期的锁. 容错:通过主从同步复制来实现容错. 字段 作用 id 自增 id，唯一标识锁 key 锁名称 value 自定义字段 ttl 存活时间，定时清理，避免死锁 基于数据库排他锁还可以通过数据库的排他锁来实现分布式锁。基于 Mysql 的 InnoDB 引擎，可以使用以下方法来实现加锁操作：12345678910111213141516171819public void lock()&#123; connection.setAutoCommit(false) int count = 0; while(count &lt; 4)&#123; try&#123; select * from lock where lock_name=xxx for update; if(结果不为空)&#123; //代表获取到锁 return; &#125; &#125;catch(Exception e)&#123; &#125; //为空或者抛异常的话都表示没有获取到锁 sleep(1000); count++; &#125; throw new LockException();&#125; 在查询语句后面增加 for update，数据库会在查询过程中给数据库表增加排他锁。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。其他没有获取到锁的就会阻塞在上述 select 语句上，可能的结果有 2 种，在超时之前获取到了锁，在超时之前仍未获取到锁。 获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行业务逻辑，执行完业务之后释放锁。 总结基于数据库的实现较为繁琐，要自己维护锁的 TTL；除非使用分布式数据库，否则主从复制的故障切换并不轻松。 除了麻烦之外，在高并发常见下数据库读写是非常缓慢的，会导致系统性能存在瓶颈。如果采用多个独立数据库进行容错，那性能就更差了。 于是，为了分布式锁的性能，开始转向基于 Redis 或者 memcache 等内存存储系统来实现分布式锁。 基于 Redis 的实现分布式锁最多的恐怕就是基于 Redis 的实现。首先从单节点 Redis 开始。 基于单节点 Redis 的分布式锁一条命令实现写 key + 设置过期时间，否则原子性无法保证可能出现死锁。于是就有了以下命令(redis的lua脚本):1set key value nx px 10000 set 命令后的 5 个参数分别是： 第一个为 key 作为锁名； 第二个为 value，一般传入一个唯一 id，例如一个随机数或者客户端 mac 地址 + uuid； 第三个为 NX，意思是 SET IF NOT EXIST，即只有 key 不存在时才进行 set 操作；若 key 已经存在(锁已被占)，则不做任何操作； 第四个为 PX，作用是给这个 key 加一个过期时间，具体时间长短由第五个参数决定； 第五个为具体的过期时间，对应第四个参数 PX 是毫秒，EX 是秒； 一般会使用开源的redission去实现，具体逻辑如图所示: 这个方案在互斥性和避免死锁上性能良好，且非常轻量。但单节点的 Redis 存在单点故障。注意，Redis 主从复制是异步的，所以加入从节点会增加破坏互斥性的风险。为了实现容错性，就有了基于多节点 Redis 的分布式锁，即 Redlock。 基于多节点 Redis 的分布式锁Redlock 用到多个独立的 Redis 节点，其思想简而言之，是在多个 Redis 实际都获取锁，其中一个宕机了，只要还有超过半数节点可用，就可以继续提供锁服务。 如图所示，Redlock 获取锁的大致步骤如下，： 依次对多个 Redis 实例进行加锁(一般是3个或5个)，加锁命令使用单实例 Redis 的加锁命令； 为了避免在某个节点长时间获取不到锁而阻塞，每次获取锁操作也有一个超时时间，远小于 TTL，超过超时时间则认为失败，继续向下一个节点获取锁； 计算整个获取多把锁的总消耗时间，只有在超过半数节点都成功获取锁，并且总消耗时间小于 TTL，则认为成功持有锁； 成功获取锁后，要重新计算 TTL = TTL - 总消耗时间； 如果获取锁失败，要向所有 redis 实例发送释放锁的命令。 释放锁操作就是向所有实例都发送删除 key 命令。 Redlock 容错性依赖于一个时间戳的计算，这在分布式系统中并不受待见，于是有了一场著名的论战。 Redlock 论战DDIA 的作者 Martin Kleppmann 大佬发表了著名的文章《How to do distributed locking》，表示 Redlock 并不可靠，该文章主要阐述了两个观点： Redis 命令避免了死锁但可能会不满足互斥性，因为没有自增 id 或 fencing token 来阻断同时获得锁的两个客户端； Redlock 基于时间戳的合理性值得怀疑，多台服务器难以保证时间一致； 第一点如下图所示，Client 1 获取锁后发生了 STW GC(或缺页等问题)，TTL 过期后 Client 2 获取了锁，此时两个客户端持有锁，违反了互斥性。后续写操作自然就可能存在问题。 我们在避免死锁时提到，需要另外用单调递增 id (Martin 称之为 fencing token，也叫序列号)来标识每一个锁。增加 id 后逻辑如下图所示，最后的 Client 1 的写请求因为 token 是旧的，会被存储系统拒绝。 第二点 Martin 认为，Redlock 的时间戳计算方式不可靠，每台服务器的走时并不绝对准确，例如 NTP 进行同步时系统会发生时钟漂移，即当前服务器的时间戳突然变大或变小，这都会影响 Redlock 的计算。 Martin 的这篇文章引起了大家对分布式锁广泛讨论。Redis 作者 antirez 也不甘示弱，发表文章《Is Redlock safe?》进行反驳，回应了上述两个问题，总结了 antirez 的论点： 针对第一点，虽然 Redlock 提供不了自增 id 这样的字段，但是由客户端指定的字段 value 也可以实现唯一标识，并通过 read-modify-write 原子操作来进行检查； 时钟发送漂移肯定会影响 Redlock 安全性，可是通过恰当的运维，例如不要随意人为修改时钟、将一次大的 NTP 时钟调整转换成多次微小的调整等方式，使时钟修改不超过某个范围就不会对 Redlock 产生影响。 非常推荐阅读争论的两篇文章，但篇幅所限我只提取了观点。关于争论的详细内容张铁蕾老师的文章《基于Redis的分布式锁到底安全吗（下）？》也有着比较完整的中文回顾。 对于这两个问题，我想谈谈我的理解。 对于第一个问题，文章开头“三大属性”我们就分析过，增加 TTL 来避免死锁就会对互斥性产生影响，无论基于 Redis 还是基于 Zookeeper 实现都会存在该问题。antirez 观点是 Redlock 也可以用 value 作为唯一标识来阻断操作，这确实没问题，我也挑不出毛病。但我们可以思考下，实际编程中读者您觉得使用一个自增 id 进行判断容易还是使用 read-modify-write 操作更容易呢？（实际上，一开始我都不怎么理解什么是 read-modify-write 操作） 我认为 fencing token 是一个更好的解决方案，一个单调自增的 id 更符合我们的直觉，同时也更好进行 debug。 作为 fencing token 的一个实际参考，Hazelcast 的文章 “Distributed Locks are Dead; Long Live Distributed Locks!” 给出了一个 FencedLock 解决方案，并且通过了 Jepsen 测试。 第二个问题，时钟漂移是否应该引起注意呢？antirez 的观点是时钟确实会影响 Redlock，但可以通过合理运维避免。 Julia Evans(也是很出名的技术博主)也写了一篇后续文章 “TIL: clock skew exists”，来讨论时钟漂移的问题是否真的值得引起注意。最终得出的结论是：有界的时钟漂移不是一个安全的假设。 事实上，时钟问题并不罕见，例如： Nelson Minar 在1999年发表了论文，通过调查发现，NTP 服务器经常提供不正确的时间； aphyr 的文章《The trouble with timestamps》也总结了时间戳在分布式系统中的麻烦； Google 在 Spanner 中投入大量精力来处理时间问题，并发明了 TrueTime 这一授时系统； 闰秒也会导致时钟漂移，不过闰秒确实非常罕见（即使是现在，闰秒依然会导致许多问题，以后我们会专门谈谈）。 通过上述例子，时钟问题是真实存在的，如果你的系统对分布式锁的安全性要求严格，不想造成任何系统和金钱上的损失，那么你应该考虑所有的边缘情况。 Martin Kleppmann 没有回复任何 Hacker News 的评论，他觉得自己想要表达的都已经说完了，他不想参与争论，他认为实际上一个分布式系统到底该怎么做取决于你如何管理你的系统。 本文想表达的也是这样的观点，软件工程没有银弹，这些 trade-off 取决于你系统的重要级别，你怎么管理你的分布式系统。 只不过分布式系统研究人员通常会非常关注那些看似非常不可能在你的电脑上发生的事情(例如：时钟偏移)，原因是： 需要找出某个算法来解决此类问题，因此需要考虑所有 corner case； 分布式系统中会有成千上万的机器，那么不大可能发生的事情会变得极有可能； 其中一些问题其实是很常见的（例如：网络分区）。 基于共识算法实现分布式锁属于分布式互斥问题(distributed mutual exclusion)，实际上 Lamport 在那篇经典论文 “Time, clocks, and the ordering of events in a distributed system” 中早就证明了使用状态机能够去中心化解决多进程互斥问题，而共识算法就能实现这样的状态机。 “共识”的意思是保证所有的参与者都有相同的认知（可以理解为强一致性）。共识算法本身可以依据是否有恶意节点分为两类，大部分时候共识算法指的都是没有恶意节点的那一类，即系统中的节点不会向其他节点发送恶意请求，比如欺骗请求。共识算法中最有名的应该是Paxos算法。 容错性当然离不开共识算法，这个时候不再让客户端依次上多个锁，而是让锁服务器通过共识算法复制到多数派节点，然后再回复客户端。由于共识算法本身不依赖系统时间戳而是逻辑时钟（Raft 的任期或 Paxos 的 epoch），故不存在时钟漂移问题。 其次，死锁避免问题依然需要 TTL 和自增 id 等手段，通过锁服务给每次加锁请求标识上单调递增 id。 通过以上两种方法，可以得到一个更可靠的分布式锁。代价是:需要一个实现共识算法的第三方组件。 基于 ZooKeeper 实现ZooKeeper是一个分布式的、开放源码的分布式协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。由于Hadoop生态系统中很多项目都依赖于zookeeper，如Pig，Hive等， 似乎很像一个动物园管理员，于是取名为Zookeeper。 基于 ZooKeeper 实现的分布式锁依赖以下两个节点属性： sequence：顺序节点，ZooKeeper 会将一个10位带有0填充的序列号附加到客户端设置的 znode 路径之后。例如 locknode/guid-lock- 会返回 locknode/guid-lock-0000000001； ephemeral：临时节点，当客户端和 ZooKeeper 连接断开时，临时节点会被删除，能够避免死锁。但这个断开检测依然有一定心跳延迟，所以仍然需要自增 id 来避免互斥性被破坏。 ZooKeeper 官方文档有提供现成的分布式锁实现方法： 首先调用 create()，锁路径例如 locknode/guid-lock-，并设置 sequence 和 ephemeral 标志。guid 是客户端的唯一标识，如果 create() 创建失败可以通过 guid 来进行检查，下面会提到； 调用 getChildren() 获取子节点列表，不要设置 watch 标志（很重要，可以避免 Herd Effect，即惊群效应）； 检查 2 中的子节点列表，如果步骤 1 中创建成功并且返回的序列号后缀是最小的，则客户端持有该分布式锁，到此结束； 如果发现序列不是最小的，则从子节点列表中选择比当前序列号小一位的节点记为 p，客户端调用 exist(p, watch=true)，即监听 p，当 p 被删除时收到通知（该节点只有比自己小一位的节点释放时才能获得锁）； 如果 exist() 返回 null，即前一个分布式锁被释放了，转到步骤 2；否则需要一直等待步骤 4 中 watch 的通知。 如上图所示，每个客户端只监听比自己小的 znode，可以避免惊群效应。 获取锁的伪代码如下：12345n = create(l + “/guid-lock-”, EPHEMERAL|SEQUENTIAL)C = getChildren(l, false)if n is lowest znode in C, exitp = znode in C ordered just before ngoto 2 释放锁非常简单：客户端直接删除他们在步骤 1 创建的 znode 节点。 有几点需要注意： 删除一个 znode 只会导致一个客户端被唤醒，因为每个节点正好被一个客户端 watch 着，通过这种方式，可以避免惊群效应； 没有轮询或超时； 如果在调用 create() 时 ZooKeeper 创建锁成功但没有返回给客户端就失败了，客户端收到错误响应后，应该先调用 getChildren() 并检查该路径是否包含 guid 来避免这一问题。 当然，虽然 ZooKeeper 的实现看起来更为可靠，但根据你实现锁的方式，可能还是会有大量的锁逻辑调试、锁争抢等问题。 基于 ZooKeeper 的分布式锁性能介于基于 Mysql 和基于 Redis 的实现之间，性能上当然不如单节点 Redis。 此外，Zookeeper 中创建和删除节点只能通过 Leader 节点来执行，然后将数据同步到集群中的其他节点。分布式环境中难免存在网络抖动，导致客户端和 Zookeeper 集群之间的 session 连接中断，此时 Zookeeper 服务端以为客户端挂了，就会删除临时节点。其他客户端就可以获取到分布式锁了，导致了同时获取锁的不一致问题。 ZooKeeper 的另一个缺点是需要另外维护一套 ZooKeeper 服务（已有则忽略） etcdEtcd 是著名的分布式 key-value 存储结构，因在 Kubernetes 中使用而闻名。etcd 同样可以用来实现分布式锁，官方也很贴心的提供了 clientv3 包给开发者快速实现分布式锁。 来看下 etcd 是如何解决分布式锁“三大问题”的： 互斥：etcd 支持事务，通过事务创建 key 和检查 key 是否存在，可以保证互斥性； 容错：etcd 基于 Raft 共识算法，写 key 成功至少需要超过半数节点确认，这就保证了容错性； 死锁：etcd 支持租约(Lease)机制，可以对 key 设置租约存活时间(TTL)，到期后该 key 将失效删除，避免死锁；etc 也支持租约续期，如果客户端还未处理完可以继续续约；同时 etcd 也有自增 id。 为了帮助开发者快速实现分布式锁，etcd 给出了 clientv3 包，其中分布式锁在 concurrency 包中。按照官方文档给出的案例1，首先创建一个新的会话(session)并指定租约的 TTL，然后实例化一个 NewMutex() 之后就可以调用 Lock() 和 Unlock() 进行抢锁和释放锁。代码如下：12345678910111213141516171819202122cli, err := clientv3.New(clientv3.Config&#123;Endpoints: endpoints&#125;)if err != nil &#123; log.Fatal(err)&#125;defer cli.Close()s, err := concurrency.NewSession(cli, concurrency.WithTTL(10))if err != nil &#123; log.Fatal(err)&#125;defer s.Close()m := concurrency.NewMutex(s, "/my-lock/")if err := m.Lock(context.TODO()); err != nil &#123; log.Fatal(err)&#125;fmt.Println("acquired lock for s")if err := m.Unlock(context.TODO()); err != nil &#123; log.Fatal(err)&#125;fmt.Println("released lock for s") 基于如上分析的思路，绘制出实现 etcd 分布式锁的流程图 其中 Lock() 函数的源代码很容易找到，由于篇幅我就不放出来了，但源代码中可以看到的一些其他机制包括： Revision 机制。一个全局序列号，跟 ZooKeeper 的序列号类似，可以用来避免 watch 惊群； Prefix 机制。即上述代码中 etcd 会创建一个前缀为 /my-lock/ 的 key(/my-lock/ + LeaseID)，分布式锁由该前缀下 revision 最小(最早创建)的 key 获得； Watch 机制。跟 ZooKeeper 一样，客户端会监听 revision 比自己小的 key，当比自己小的 key 释放锁后，尝试去获得锁。 本质上 etcd 和 ZooKeeper 对分布式锁的实现是类似的。 选择 etcd 的原因可能有： 生产环境中已经大规模部署了 etcd 集群； etcd 在保证强一致性的同时真的够快，性能介于 Redis 和 ZooKeeper 之间； 许多语言都有 etcd 的客户端库，很容易使用； 该如何实现分布式锁应该区分，分布式锁的用途和业务场景，如果从安全性的角度上考虑，如果要保证绝对的一致性，建议使用zookeeper，同时还要考虑，是否还要使用数据库的锁。 如果只是为了协调各个服务，防止重复处理，锁偶尔失效也可以接受，可以使用Redis。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Seata部署使用(1.4.2)]]></title>
    <url>%2F2021%2F06%2F08%2FSeata%E9%83%A8%E7%BD%B2%E4%BD%BF%E7%94%A8(1.4.2)%2F</url>
    <content type="text"><![CDATA[源码地址： https://github.com/seata/seata.git 前期准备xa模式确保mysql版本&gt;5.7 并且开启了XA事务支持 at模式每个mysql库执行脚本12345678910111213CREATE TABLE IF NOT EXISTS `undo_log`( `branch_id` BIGINT NOT NULL COMMENT 'branch transaction id', `xid` VARCHAR(128) NOT NULL COMMENT 'global transaction id', `context` VARCHAR(128) NOT NULL COMMENT 'undo_log context,such as serialization', `rollback_info` LONGBLOB NOT NULL COMMENT 'rollback info', `log_status` INT(11) NOT NULL COMMENT '0:normal status,1:defense status', `log_created` DATETIME(6) NOT NULL COMMENT 'create datetime', `log_modified` DATETIME(6) NOT NULL COMMENT 'modify datetime', UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`)) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8 COMMENT ='AT transaction mode undo table'; saga模式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364-- -------------------------------- The script used for sage --------------------------------CREATE TABLE IF NOT EXISTS `seata_state_machine_def`( `id` VARCHAR(32) NOT NULL COMMENT 'id', `name` VARCHAR(128) NOT NULL COMMENT 'name', `tenant_id` VARCHAR(32) NOT NULL COMMENT 'tenant id', `app_name` VARCHAR(32) NOT NULL COMMENT 'application name', `type` VARCHAR(20) COMMENT 'state language type', `comment_` VARCHAR(255) COMMENT 'comment', `ver` VARCHAR(16) NOT NULL COMMENT 'version', `gmt_create` DATETIME(3) NOT NULL COMMENT 'create time', `status` VARCHAR(2) NOT NULL COMMENT 'status(AC:active|IN:inactive)', `content` TEXT COMMENT 'content', `recover_strategy` VARCHAR(16) COMMENT 'transaction recover strategy(compensate|retry)', PRIMARY KEY (`id`)) ENGINE = InnoDB DEFAULT CHARSET = utf8;CREATE TABLE IF NOT EXISTS `seata_state_machine_inst`( `id` VARCHAR(128) NOT NULL COMMENT 'id', `machine_id` VARCHAR(32) NOT NULL COMMENT 'state machine definition id', `tenant_id` VARCHAR(32) NOT NULL COMMENT 'tenant id', `parent_id` VARCHAR(128) COMMENT 'parent id', `gmt_started` DATETIME(3) NOT NULL COMMENT 'start time', `business_key` VARCHAR(48) COMMENT 'business key', `start_params` TEXT COMMENT 'start parameters', `gmt_end` DATETIME(3) COMMENT 'end time', `excep` BLOB COMMENT 'exception', `end_params` TEXT COMMENT 'end parameters', `status` VARCHAR(2) COMMENT 'status(SU succeed|FA failed|UN unknown|SK skipped|RU running)', `compensation_status` VARCHAR(2) COMMENT 'compensation status(SU succeed|FA failed|UN unknown|SK skipped|RU running)', `is_running` TINYINT(1) COMMENT 'is running(0 no|1 yes)', `gmt_updated` DATETIME(3) NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `unikey_buz_tenant` (`business_key`, `tenant_id`)) ENGINE = InnoDB DEFAULT CHARSET = utf8;CREATE TABLE IF NOT EXISTS `seata_state_inst`( `id` VARCHAR(48) NOT NULL COMMENT 'id', `machine_inst_id` VARCHAR(128) NOT NULL COMMENT 'state machine instance id', `name` VARCHAR(128) NOT NULL COMMENT 'state name', `type` VARCHAR(20) COMMENT 'state type', `service_name` VARCHAR(128) COMMENT 'service name', `service_method` VARCHAR(128) COMMENT 'method name', `service_type` VARCHAR(16) COMMENT 'service type', `business_key` VARCHAR(48) COMMENT 'business key', `state_id_compensated_for` VARCHAR(50) COMMENT 'state compensated for', `state_id_retried_for` VARCHAR(50) COMMENT 'state retried for', `gmt_started` DATETIME(3) NOT NULL COMMENT 'start time', `is_for_update` TINYINT(1) COMMENT 'is service for update', `input_params` TEXT COMMENT 'input parameters', `output_params` TEXT COMMENT 'output parameters', `status` VARCHAR(2) NOT NULL COMMENT 'status(SU succeed|FA failed|UN unknown|SK skipped|RU running)', `excep` BLOB COMMENT 'exception', `gmt_updated` DATETIME(3) COMMENT 'update time', `gmt_end` DATETIME(3) COMMENT 'end time', PRIMARY KEY (`id`, `machine_inst_id`)) ENGINE = InnoDB DEFAULT CHARSET = utf8; 部署TC执行mysql脚本1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556-- -------------------------------- The script used when storeMode is 'db' ---------------------------------- the table to store GlobalSession dataCREATE TABLE IF NOT EXISTS `global_table`( `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `status` TINYINT NOT NULL, `application_id` VARCHAR(32), `transaction_service_group` VARCHAR(32), `transaction_name` VARCHAR(128), `timeout` INT, `begin_time` BIGINT, `application_data` VARCHAR(2000), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`xid`), KEY `idx_gmt_modified_status` (`gmt_modified`, `status`), KEY `idx_transaction_id` (`transaction_id`)) ENGINE = InnoDB DEFAULT CHARSET = utf8;-- the table to store BranchSession dataCREATE TABLE IF NOT EXISTS `branch_table`( `branch_id` BIGINT NOT NULL, `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `resource_group_id` VARCHAR(32), `resource_id` VARCHAR(256), `branch_type` VARCHAR(8), `status` TINYINT, `client_id` VARCHAR(64), `application_data` VARCHAR(2000), `gmt_create` DATETIME(6), `gmt_modified` DATETIME(6), PRIMARY KEY (`branch_id`), KEY `idx_xid` (`xid`)) ENGINE = InnoDB DEFAULT CHARSET = utf8;-- the table to store lock dataCREATE TABLE IF NOT EXISTS `lock_table`( `row_key` VARCHAR(128) NOT NULL, `xid` VARCHAR(128), `transaction_id` BIGINT, `branch_id` BIGINT NOT NULL, `resource_id` VARCHAR(256), `table_name` VARCHAR(32), `pk` VARCHAR(36), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`row_key`), KEY `idx_branch_id` (`branch_id`)) ENGINE = InnoDB DEFAULT CHARSET = utf8; 如果使用源码编译的话，需要注释掉，或者idea导入插件protobuf support1&lt;!-- &lt;module&gt;seata-serializer-protobuf&lt;/module&gt;--&gt; 修改配置registry.conf、file.conf，如果需要不同的环境区分不同的配置，新建文件registry-dev.conf、file-dev.conf，然后启动启动类io.seata.server.Server，启动的jvm参数加上变量-DseataEnv=uat，这样就可以实现多环境启动了。 到server目录下，打包部署服务器:1mvn clean package -Dmaven.test.skip=true -Prelease-seata 会生成制品，制品目录在/distribution，如果是部署服务器上面或者是通过docker镜像部署的话，可以参考/distribution/Dockerfile，或者直接通过下面的命令启动1sh ./bin/seata-server.sh -p 8091 -h 127.0.0.1 -n 1 -e uat 具体参数如下 参数 全写 作用 备注 -h –host 指定在注册中心注册的 IP 不指定时获取当前的 IP，外部访问部署在云环境和容器中的 server 建议指定 -p –port 指定 server 启动的端口 默认为 8091 -m –storeMode 事务日志存储方式 支持file,db,redis，默认为 file 注:redis需seata-server 1.3版本及以上 -n –serverNode 用于指定seata-server节点ID 如 1,2,3…, 默认为 1 -e –seataEnv 指定 seata-server 运行环境 如 dev, test 等, 服务启动时会使用 registry-dev.conf 这样的配置 可以查看在我本地输出脚本的完整的jvm参数1/Library/Java/JavaVirtualMachines/jdk1.8.0_181.jdk/Contents/Home/bin/java -server -Xmx2048m -Xms2048m -Xmn1024m -Xss512k -XX:SurvivorRatio=10 -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=256m -XX:MaxDirectMemorySize=1024m -XX:-OmitStackTraceInFastThrow -XX:-UseAdaptiveSizePolicy -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/Users/dinghuang/Documents/workSpace/github/seata/distribution/seata-server-1.4.2/logs/java_heapdump.hprof -XX:+DisableExplicitGC -XX:+CMSParallelRemarkEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=75 -Xloggc:/Users/dinghuang/Documents/workSpace/github/seata/distribution/seata-server-1.4.2/logs/seata_gc.log -verbose:gc -Dio.netty.leakDetectionLevel=advanced -Dlogback.color.disable-for-bat=true -classpath /Users/dinghuang/Documents/workSpace/github/seata/distribution/seata-server-1.4.2/conf:/Users/dinghuang/Documents/workSpace/github/seata/distribution/seata-server-1.4.2/lib/* -Dapp.name=seata-server -Dapp.pid=23748 -Dapp.repo=/Users/dinghuang/Documents/workSpace/github/seata/distribution/seata-server-1.4.2/lib -Dapp.home=/Users/dinghuang/Documents/workSpace/github/seata/distribution/seata-server-1.4.2 -Dbasedir=/Users/dinghuang/Documents/workSpace/github/seata/distribution/seata-server-1.4.2 io.seata.server.Server -e uat 如果配置中心使用apollo，可以参考这篇文章：https://www.studying.icu/pages/94a254/#seata （1.4.2有bug，apollo的配置不能用，建议用1.4.1） Spring框架使用pom.xml引入包123456&lt;!-- https://mvnrepository.com/artifact/io.seata/seata-spring-boot-starter --&gt;&lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.4.2&lt;/version&gt;&lt;/dependency&gt; 修改application.yml配置文件（1.4.2有bug，apollo的配置不能用，建议用1.4.1）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133seata: enabled: true application-id: applicationName tx-service-group: my_test_tx_group enable-auto-data-source-proxy: true data-source-proxy-mode: AT use-jdk-proxy: false excludes-for-auto-proxying: firstClassNameForExclude,secondClassNameForExclude client: rm: async-commit-buffer-limit: 10000 report-retry-count: 5 table-meta-check-enable: false report-success-enable: false saga-branch-register-enable: false saga-json-parser: fastjson saga-retry-persist-mode-update: false saga-compensate-persist-mode-update: false lock: retry-interval: 10 retry-times: 30 retry-policy-branch-rollback-on-conflict: true tm: commit-retry-count: 5 rollback-retry-count: 5 default-global-transaction-timeout: 60000 degrade-check: false degrade-check-period: 2000 degrade-check-allow-times: 10 undo: data-validation: true log-serialization: jackson log-table: undo_log only-care-update-columns: true compress: enable: true type: zip threshold: 64k load-balance: type: RandomLoadBalance virtual-nodes: 10 service: vgroup-mapping: my_test_tx_group: default grouplist: default: 127.0.0.1:8091 enable-degrade: false disable-global-transaction: false transport: shutdown: wait: 3 thread-factory: boss-thread-prefix: NettyBoss worker-thread-prefix: NettyServerNIOWorker server-executor-thread-prefix: NettyServerBizHandler share-boss-worker: false client-selector-thread-prefix: NettyClientSelector client-selector-thread-size: 1 client-worker-thread-prefix: NettyClientWorkerThread worker-thread-size: default boss-thread-size: 1 type: TCP server: NIO heartbeat: true serialization: seata compressor: none enable-client-batch-send-request: true config: type: file consul: server-addr: 127.0.0.1:8500 apollo: apollo-meta: http://192.168.1.204:8801 app-id: seata-server namespace: application apollo-accesskey-secret: "" etcd3: server-addr: http://localhost:2379 nacos: namespace: "" server-addr: 127.0.0.1:8848 group: SEATA_GROUP username: "" password: "" zk: server-addr: 127.0.0.1:2181 session-timeout: 6000 connect-timeout: 2000 username: "" password: "" custom: name: "" registry: type: file file: name: file.conf consul: server-addr: 127.0.0.1:8500 acl-token: "" etcd3: server-addr: http://localhost:2379 eureka: weight: 1 service-url: http://localhost:8761/eureka nacos: application: seata-server server-addr: 127.0.0.1:8848 group : "SEATA_GROUP" namespace: "" username: "" password: "" redis: server-addr: localhost:6379 db: 0 password: "" timeout: 0 sofa: server-addr: 127.0.0.1:9603 region: DEFAULT_ZONE datacenter: DefaultDataCenter group: SEATA_GROUP address-wait-time: 3000 application: default zk: server-addr: 127.0.0.1:2181 session-timeout: 6000 connect-timeout: 2000 username: "" password: "" custom: name: "" log: exception-rate: 100 具体的例子可以看https://github.com/seata/seata-samples]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DDD领域驱动设计]]></title>
    <url>%2F2021%2F03%2F18%2FDDD%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[代码地址 什么是DDD对于一个架构师来说，在软件开发中如何降低系统复杂度是一个永恒的挑战，无论是 94 年 GoF 的 Design Patterns ， 99 年的 Martin Fowler 的 Refactoring ， 02 年的 P of EAA ，还是 03 年的 Enterprise Integration Patterns ，都是通过一系列的设计模式或范例来降低一些常见的复杂度。 但是问题在于，这些书的理念是通过技术手段解决技术问题，但并没有从根本上解决业务的问题。所以 03 年 Eric Evans 的 Domain Driven Design 一书，以及后续 Vaughn Vernon 的 Implementing DDD ， Uncle Bob 的 Clean Architecture 等书，真正的从业务的角度出发，为全世界绝大部分做纯业务的开发提供了一整套的架构思路。 DDD 不是一套框架，而是一种架构思想，所以在代码层面缺乏了足够的约束，导致 DDD 在实际应用中上手门槛很高，甚至可以说绝大部分人都对 DDD 的理解有所偏差，所有认知的最终目的都是基于合理的代码结构、框架和约束，来降低 DDD 的实践门槛，提升代码质量、可测试性、安全性、健壮性。 好的架构设计在做架构设计时，一个好的架构应该需要实现以下几个目标： 独立于框架：架构不应该依赖某个外部的库或框架，不应该被框架的结构所束缚。 独立于UI：前台展示的样式可能会随时发生变化（今天可能是网页、明天可能变成console、后天是独立app），但是底层架构不应该随之而变化。 独立于底层数据源：无论今天你用MySQL、Oracle还是MongoDB、CouchDB，甚至使用文件系统，软件架构不应该因为不同的底层数据储存方式而产生巨大改变。 独立于外部依赖：无论外部依赖如何变更、升级，业务的核心逻辑不应该随之而大幅变化。可测试：无论外部依赖了什么数据库、硬件、UI或者服务，业务的逻辑应该都能够快速被验证正确性。 概念领域模型（DOMAIN） 模型是对客观世界事物的一种抽象和简化。 它是从某个角度反映人对客观世界事物的一种认识。 它用于对事物的本质进行深入细致的研究。 举一个常见的例子：一个函数写了几千行，里面的if-else写了一大堆，计算各种业务规则。另一个人接手之后，分析了好几个月，才把业务逻辑彻底理清楚。从表面来看，这是代码写的不规范，要重构，把一个几千行的函数拆成一个个小的函数。从根本上来讲，就是“重要逻辑”隐藏在代码里面，没有“显性”的表达出来。这里可以引用一个观点：建模的本质就是把“重要的东西进行显性化，并进而把这些显性化的构造块，互相串联起来，组成一个体系“。 DDD通过建立一个业务域到软件域的通用模型，把问题空间同解决方案空间联系在一起，真正把领域的知识挖掘出来，让领域专家可以去驱动软件的实现。 映射概念：切分的服务。 领域就是范围。范围的重点是边界。领域的核心思想是将问题逐级细分来减低业务和系统的复杂度，这也是 DDD 讨论的核心。 如果说你要盖一栋房子，那么你需要以下的东西 有一块地楼共有6层每层有4个套房那么你的领域是什么呢？ 领域是房子么？可能，但是你应该知道，如果你把房子作为你的领域，那么你可能会忽略很多的小的需求。你设计的房子必须设计那里是让人住的。那么，一般而言的“房子”可能会让我们忽略一些细节，所以，我们应该缩小我们的领域，那就是“民房”。 那么，当你和建筑工人或买房子的人说起你设计的房子时，你所说的“民房”就可以很容易的被人理解了。当承包商告诉你要设计一个6层每层4套房子的时候，在语言上你是否稍微修改了一下呢？现在如果你让建筑工人到一个地方建“房子”，他们可能并没有考虑到一些“民房”的一些特性。但是如果你说了“民房”呢，他们肯定会做出合理的分析。 这就是我们将要说到的“通用语言” 子域映射概念：子服务。 领域可以进一步划分成子领域，即子域。这是处理高度复杂领域的设计思想，它试图分离技术实现的复杂性。这个拆分的里面在很多架构里都有，比如 C4。 核心域映射概念：核心服务。 在领域划分过程中，会不断划分子域，子域按重要程度会被划分成三类：核心域、通用域、支撑域。 决定产品核心竞争力的子域就是核心域，没有太多个性化诉求。 桃树的例子，有根、茎、叶、花、果、种子等六个子域，不同人理解的核心域不同，比如在果园里，核心域就是果是核心域，在公园里，核心域则是花。有时为了核心域的营养供应，还会剪掉通用域和支撑域（茎、叶等）。 通用域映射概念：中间件服务或第三方服务。 被多个子域使用的通用功能就是通用域，没有太多企业特征，比如权限认证。 支撑域映射概念：企业公共服务。 对于功能来讲是必须存在的，但它不对产品核心竞争力产生影响，也不包含通用功能，有企业特征，不具有通用性，比如数据代码类的数字字典系统。 统一语言（ Ubiquitous language ）映射概念：统一概念。 关于统一语言必要性，有一个经典的通天塔故事，人类想建一座通天塔，进度很快，上帝害怕了，于是上帝让建造者说不通的语言，这样通天塔就再也没有能建起来了。统一语言是一件事情能顺利开展的基础。 由于语言上存在鸿沟，领域专家们只能模糊地描述他们想要的东西，开发人员虽然努力去理解一个自己不熟悉的领域但也只能形成模糊的认识，结果就是各说各的话，或者都是一知半解，最后到上线前才会发现漏了这个漏了那个。 定义上下文的含义。它的价值是可以解决交流障碍，不管你是 RD、PM、QA 等什么角色，让每个团队使用统一的语言（概念）来交流，甚至可读性更好的代码。 通用语言包含属于和用例场景，并且能直接反应在代码中。 可以在事件风暴（开会）中来统一语言，甚至是中英文的映射、业务与代码模型的映射等。可以使用一个表格来记录。 通用语言也并不是像，XML、Schema或Java这样的语言，它是一种自然的但经过浓缩的领域语言，它是一种开发与用户共享的语言，用来描述问题和领域模型。通用语言不是把从用户那里听到的内容翻译为开发的语言，而是为了减少误解，让用户更容易理解的草图，从而可以真正的帮助纠正错误，帮助开发获取有关的领域新知识。 统一语言体现在两个方面： 统一的领域术语 领域术语通常表示对象命名，如商品、订单等，对应实体对象 例子民航业的运输统计指标为例，牵涉到与运量、运力以及周转量相关的术语，就存在 ICAO（International Civil Aviation Organization，国际民用航空组织）与IATA（International Air Transport Association，国际航空运输协会）两大体系，而中国民航局又有自己的中文解释，航空公司和各大机场亦有自己衍生的定义 如果我们不明白城市对运量与航段运量的真正含义，就可能混淆这两种指标的统计计算规则。这种术语理解错误带来的缺陷往往难以发现，除非业务分析人员、开发人员与测试人员能就此知识达成一致的正确理解。 限界上下文（ Bounded Context ）映射概念：服务职责划分的边界。 限界上下文，限的意思就是划分、规定，界就是界限、或者一个边界，上下文就是业务的整个流程，总的来说，可以称限界上下文为业务流程在一个划定的界限中，我们知道，业务的描述是通过通用语言来表述的，限界上下文和通用语言的关系就是：在一个特定的限界上下文只使用一套通用语言，并且保证它的清晰性和简洁性。 定义上下文的边界。领域模型存在边界之内。对于同一个概念，不同上下文会有不同的理解，比如商品，在销售阶段叫商品，在运输阶段就叫货品。理论上，限界上下文的边界就是微服务的边界，因此，理解限界上下文在设计中非常重要。 一个有界上下文可以是一个很小的程序，包括他自己的领域，自己的代码和自己的存储机制，在一个上下文里，他们应该在逻辑上一致，每个有界上下文应该独立于其他的有界上下文。 上下文映射图（Context Mapping） 有界上下文例子考虑一下电商系统，最初你可以认为他是一个商店上下文，但是你看的更细点，你会发现其他的上下文，例如：库存，物流，账户等。 合理的拆分一个大型的有界上下文可以让你的应用程序模块化，并且让你区分不同的关注点，而且让应用程序更易于管理和升级。每个有界上下文都有相应的责任和操作。合理的上下文划分可以让我们更容易的找到逻辑所在的位置，从而避免“大泥球”。 什么是“大泥球”（BBOM，Big ball of mud）大泥球是一个不规则的、杂乱的、松散的泥巴，这类系统是典型的高度重复，快速修复，无意义增长的系统。混乱的消息传递，在一个地方几乎所有的重要信息都是全局的和重复的，所有的系统架构都可能没有被很好的定义。 我们的目标是避免所有的BBOM 我们还来说说“民房领域”吧，我们有几个有界上下文： 电力供应 停车位 套房 等等 详细说一下“套房”吧，套房是由不同的房间组成，每个房间又有不同的门窗。那么现在关于屋里面的窗户就有两个问题了： 问题1：你可以想象出来没有屋子的窗户么？ 问题2：如果一个窗户没有了容纳他的屋子，那么它有没有唯一的标识？ 回答上面的问题会揭示出DDD中下面的概念： 实体（Entity） 值对象(Value Object) 聚合和聚合根(Aggreates &amp; Aggrate root) 实体（ Entity ）映射概念：Domain 或 entity。 许多对象不是由它们的属性来定义，而是通过一系列的连续性（continuity）和标识（identity）来从根本上定义的。只要一个对象在生命周期中能够保持连续性，并且独立于它的属性（即使这些属性对系统用户非常重要），那它就是一个实体。 对于实体Entity，实体核心是用唯一的标识符来定义，而不是通过属性来定义。即即使属性完全相同也可能是两个不同的对象。同时实体本身有状态的，实体又演进的生命周期，实体本身会体现出相关的业务行为，业务行为会实体属性或状态造成影响和改变。无论两个实体是多么的相似，他们都是不同的实体。 例如： 你家的卧室 博客的文章 博客的用户 值对象（ Value Objects ）映射概念：Domain 或 entity。 当你只关心某个对象的属性时，该对象便可作为一个值对象。为其添加有意义的属性，并赋予它相应的行为。我们需要将值对象看成不变对象，不要给它任何身份标识，还应该尽量避免像实体对象一样的复杂性。 如果从值对象本身无状态，不可变，并且不分配具体的标识层面来看。那么值对象可以仅仅理解为实际的Entity对象的一个属性结合而已。该值对象附属在一个实际的实体对象上面。值对象本身不存在一个独立的生命周期，也一般不会产生独立的行为。 定义值对象的关键是值对象没有“唯一标识”。 比如 money，让它具有 id 显然是不合理的，你也不可能通过 id 查询一个 money。 定义值对象要依照具体场景的区分来看，你甚至可以把 Article 中的 Author 当成一个值对象，但一定要清楚，Author 独立存在的时候是实体，或者要拿 Author 做复杂的业务逻辑，那么 Author 也会升级为聚合根。 防腐层（facade）亦称适配层。在一个上下文中，有时需要对外部上下文进行访问，通常会引入防腐层的概念来对外部上下文的访问进行一次转义。 有以下几种情况会考虑引入防腐层： 需要将外部上下文中的模型翻译成本上下文理解的模型。 不同上下文之间的团队协作关系，如果是供奉者关系，建议引入防腐层，避免外部上下文变化对本上下文的侵蚀。 该访问本上下文使用广泛，为了避免改动影响范围过大。 如果内部多个上下文对外部上下文需要访问，那么可以考虑将其放到通用上下文中。 领域服务（ Domain Services ）领域中的一些概念不太适合建模为对象，即归类到实体对象或值对象，因为它们本质上就是一些操作，一些动作，而不是事物。这些操作或动作往往会涉及到多个领域对象，并且需要协调这些领域对象共同完成这个操作或动作。如果强行将这些操作职责分配给任何一个对象，则被分配的对象就是承担一些不该承担的职责，从而会导致对象的职责不明确很混乱。但是基于类的面向对象语言规定任何属性或行为都必须放在对象里面。所以我们需要寻找一种新的模式来表示这种跨多个对象的操作，DDD认为服务是一个很自然的范式用来对应这种跨多个对象的操作，所以就有了领域服务这个模式。和领域对象不同，领域服务是以动词开头来命名的，比如资金转帐服务可以命名为MoneyTransferService。当然，你也可以把服务理解为一个对象，但这和一般意义上的对象有些区别。因为一般的领域对象都是有状态和行为的，而领域服务没有状态只有行为。需要强调的是领域服务是无状态的，它存在的意义就是协调领域对象共完成某个操作，所有的状态还是都保存在相应的领域对象中。我觉得模型（实体）与服务（场景）是对领域的一种划分，模型关注领域的个体行为，场景关注领域的群体行为，模型关注领域的静态结构，场景关注领域的动态功能。这也符合了现实中出现的各种现象，有动有静，有独立有协作。 领域服务还有一个很重要的功能就是可以避免领域逻辑泄露到应用层。因为如果没有领域服务，那么应用层会直接调用领域对象完成本该是属于领域服务该做的操作，这样一来，领域层可能会把一部分领域知识泄露到应用层。因为应用层需要了解每个领域对象的业务功能，具有哪些信息，以及它可能会与哪些其他领域对象交互，怎么交互等一系列领域知识。因此，引入领域服务可以有效的防治领域层的逻辑泄露到应用层。对于应用层来说，从可理解的角度来讲，通过调用领域服务提供的简单易懂但意义明确的接口肯定也要比直接操纵领域对象容易的多。 说到领域服务，还需要提一下软件中一般有三种服务：应用层服务、领域服务、基础服务。 应用层服务 获取输入（如一个XML请求）； 发送消息给领域层服务，要求其实现转帐的业务逻辑； 领域层服务处理成功，则调用基础层服务发送Email通知； 领域层服务 获取源帐号和目标帐号，分别通知源帐号和目标帐号进行扣除金额和增加金额的操作； 提供返回结果给应用层； 基础层服务按照应用层的请求，发送Email通知； 所以，从上面的例子中可以清晰的看出，每种服务的职责 领域事件（ Domain Events ）领域专家所关心的发生在领域中的一些事件。将领域中所发生的活动建模成一系列的离散事件。每个事件都用领域对象来表示。领域事件是领域模型的组成部分，表示领域中所发生的事情。 一个领域事件可以理解为是发生在一个特定领域中的事件，是你希望在同一个领域中其他部分知道并产生后续动作的事件。但是并不是所有发生过的事情都可以成为领域事件。一个领域事件必须对业务有价值，有助于形成完整的业务闭环，也即一个领域事件将导致进一步的业务操作。 领域事件可以是业务流程的一个步骤，例如订单提交，客户付费100元，订单完工等。领域事件也可以是定时发生的事情，例如每晚对账完成。或者是一个事件发生后引发的后续动作，例如客户输错密码三次后发生锁定账户的事件。 如果在通用语言中存在“当a发生时，我们就需要做到b。”这样的描述，则表明a可以定义成一个领域事件。领域事件的命名一般也就是“产生事件的对象名称+完成的动作的过去式”的形式，比如：订单已经发货的事件（OrderDispatchedEvent）、订单已被收货和确认的事件（OrderConfirmedEvent）等。 为什么需要领域事件领域事件也是一种基于事件的架构（EDA）。事件架构的好处可以把处理的流程解耦，实现系统可扩展性，提高主业务流程的内聚性。 举例而言：用户提交一个订单，系统在完成订单保存后，可能还需要发送一个通知，另外可以产生一系列的后台服务的活动。如果把这一系列的动作放入一个处理过程中，会产生几个的明显问题：一个是订单提交的的事务比较长，性能会有问题，甚至在极端情况下容易引发数据库的严重故障；另外订单提交的服务内聚性差，可维护性差，在业务流程发生变更时候，需要频繁修改主程序。 如果改为事件驱动模式，把订单提交后触发一个事件，在订单保存后，触发订单提交事件。通知和后续的各种服务动作可以通过订阅这个事件，在自己的实现空间内实现对应的逻辑，这样就把订单提交和后续其他非主要活动从订单提交业务中剥离，实现了订单提交业务高内聚和低耦合性。 领域事件也继承了事件的作用，当领域中发生了一些活动后，通过领域事件可以把这些活动所产生的副作用显式而不是隐式的表达出来，这种影响可以影响一个或多个聚合对象，而且可以获得更好的扩展性，对数据的锁影响也更小。 领域事件的特点首先是解决领域的聚合性问题。DDD中的聚合有一个原则是，在单个事务中，只允许对一个聚合对象进行修改，由此产生的其他改变必须在单独的事务中完成。如果一个业务跨多个聚合对象，领域事件会是一个不错的工具来解决这个问题。通过领域事件的方式可以达到各个组件之间的数据一致性，通过最终一致性取代事务一致性。 首先是解决领域的聚合性问题。DDD中的聚合有一个原则是，在单个事务中，只允许对一个聚合对象进行修改，由此产生的其他改变必须在单独的事务中完成。如果一个业务跨多个聚合对象，领域事件会是一个不错的工具来解决这个问题。通过领域事件的方式可以达到各个组件之间的数据一致性，通过最终一致性取代事务一致性。 其次领域事件也是一种领域分析的工具，有时从领域专家的话中，我们看不出领域事件的迹象，但是业务需求依然有可能需要领域事件。动态流的事件模型加上结合DDD的聚合实体状态和BC，可以有效进行领域建模。 领域事件可以通过观察者模式和订阅模式进行实现。比较常见的实现方式是事件总线（Event Bus）。 模块（ Modules ）模块（Module）是 DDD 中明确提到的一种控制限界上下文的手段，在我们的工程中，一般尽量用一个模块来表示一个领域的限界上下文。 如代码中所示，一般的工程中包的组织方式为 {com.公司名.组织架构.业务.上下文.*}，这样的组织结构能够明确地将一个上下文限定在包的内部。 123import com.company.team.bussiness.counter.*;//计数上下文import com.company.team.bussiness.category.*;//分类上下文import com.company.team.bussiness.comment.*;//评论上下文 对于模块内的组织结构，一般情况下我们是按照领域对象、领域服务、领域资源库、防腐层等组织方式定义的。 123456import com.company.team.bussiness.cms.domain.valobj.*;//领域对象-值对象import com.company.team.bussiness.cms.domain.entity.*;//领域对象-实体import com.company.team.bussiness.cms.domain.aggregate.*;//领域对象-聚合根import com.company.team.bussiness.cms.service.*;//领域服务import com.company.team.bussiness.cms.repo.*;//领域资源库import com.company.team.bussiness.cms.facade.*;//领域防腐层 聚合（ Aggregate ）映射概念：包。 聚合，它通过定义对象之间清晰的所属关系和边界来实现领域模型的内聚，并避免了错综复杂的难以维护的对象关系网的形成。聚合定义了一组具有内聚关系的相关对象的集合，我们把聚合看作是一个修改数据的单元。 聚合有以下一些特点： 每个聚合有一个根和一个边界，边界定义了一个聚合内部有哪些实体或值对象，根是聚合内的某个实体； 聚合内部的对象之间可以相互引用，但是聚合外部如果要访问聚合内部的对象时，必须通过聚合根开始导航，绝对不能绕过聚合根直接访问聚合内的对象，也就是说聚合根是外部可以保持 对它的引用的唯一元素； 聚合内除根以外的其他实体的唯一标识都是本地标识，也就是只要在聚合内部保持唯一即可，因为它们总是从属于这个聚合的； 聚合根负责与外部其他对象打交道并维护自己内部的业务规则； 基于聚合的以上概念，我们可以推论出从数据库查询时的单元也是以聚合为一个单元，也就是说我们不能直接查询聚合内部的某个非根的对象； 聚合内部的对象可以保持对其他聚合根的引用； 删除一个聚合根时必须同时删除该聚合内 聚合根映射概念：包。 一个上下文内可能包含多个聚合，每个聚合都有一个根实体，叫做聚合根，一个聚合只有一个聚合根。 关于如何识别聚合以及聚合根的问题：可以先从业务的角度深入思考，然后慢慢分析出有哪些对象是： 有独立存在的意义，即它是不依赖于其他对象的存在它才有意义的； 可以被独立访问的，还是必须通过某个其他对象导航得到的； 如何识别聚合我觉得这个需要从业务的角度深入分析哪些对象它们的关系是内聚的，即我们会把他们看成是一个整体来考虑的；然后这些对象我们就可以把它们放在一个聚合内。所谓关系是内聚的，是指这些对象之间必须保持一个固定规则，固定规则是指在数据变化时必须保持不变的一致性规则。当我们在修改一个聚合时，我们必须在事务级别确保整个聚合内的所有对象满足这个固定规则。作为一条建议，聚合尽量不要太大，否则即便能够做到在事务级别保持聚合的业务规则完整性，也可能会带来一定的性能问题。有分析报告显示，通常在大部分领域模型中，有70%的聚合通常只有一个实体，即聚合根，该实体内部没有包含其他实体，只包含一些值对象；另外30%的聚合中，基本上也只包含两到三个实体。这意味着大部分的聚合都只是一个实体，该实体同时也是聚合根。 如何识别聚合根如果一个聚合只有一个实体，那么这个实体就是聚合根；如果有多个实体，那么我们可以思考聚合内哪个对象有独立存在的意义并且可以和外部直接进行交互。 上面给出的例子中： 房子、订单和问题是聚合根窗户、订单备注和问题详情是聚合当数据改变时，所有相关的对象被看作一个整体。 所有的外部数据访问都需要通过同一个根节点进入，这个根就是根节点 资源库（ Repository ） 仓储被设计出来的目的是基于这个原因：领域模型中的对象自从被创建出来后不会一直留在内存中活动的，当它不活动时会被持久化到数据库中，然后当需要的时候我们会重建该对象；重建对象就是根据数据库中已存储的对象的状态重新创建对象的过程；所以，可见重建对象是一个和数据库打交道的过程。从更广义的角度来理解，我们经常会像集合一样从某个类似集合的地方根据某个条件获取一个或一些对象，往集合中添加对象或移除对象。也就是说，我们需要提供一种机制，可以提供类似集合的接口来帮助我们管理对象。仓储就是基于这样的思想被设计出来的； 仓储里面存放的对象一定是聚合，原因是之前提到的领域模型中是以聚合的概念去划分边界的；聚合是我们更新对象的一个边界，事实上我们把整个聚合看成是一个整体概念，要么一起被取出来，要么一起被删除。我们永远不会单独对某个聚合内的子对象进行单独查询或做更新操作。因此，我们只对聚合设计仓储。 仓储还有一个重要的特征就是分为仓储定义部分和仓储实现部分，在领域模型中我们定义仓储的接口，而在基础设施层实现具体的仓储。这样做的原因是：由于仓储背后的实现都是在和数据库打交道，但是我们又不希望客户（如应用层）把重点放在如何从数据库获取数据的问题上，因为这样做会导致客户（应用层）代码很混乱，很可能会因此而忽略了领域模型的存在。所以我们需要提供一个简单明了的接口，供客户使用，确保客户能以最简单的方式获取领域对象，从而可以让它专心的不会被什么数据访问代码打扰的情况下协调领域对象完成业务逻辑。这种通过接口来隔离封装变化的做法其实很常见。由于客户面对的是抽象的接口并不是具体的实现，所以我们可以随时替换仓储的真实实现，这很有助于我们做单元测试。 尽管仓储可以像集合一样在内存中管理对象，但是仓储一般不负责事务处理。一般事务处理会交给一个叫“工作单元（Unit Of Work）”的东西。关于工作单元的详细信息我在下面的讨论中会讲到。 另外，仓储在设计查询接口时，可能还会用到规格模式（Specification Pattern），我见过的最厉害的规格模式应该就是LINQ以及DLINQ查询了。一般我们会根据项目中查询的灵活度要求来选择适合的仓储查询接口设计。通常情况下只需要定义简单明了的具有固定查询参数的查询接口就可以了。只有是在查询条件是动态指定的情况下才可能需要用到Specification等模式。 领域对象需要资源存储，资源库可以理解成 DAO，但它比 DAO 更宽泛，存储的手段可以是多样化的，常见的无非是数据库、分布式缓存、本地缓存等。资源库（Repository）的作用，就是对领域的存储和访问进行统一管理的对象。 在系统中，我们是通过如下的方式组织资源库的。 12345import com.company.team.bussiness.repo.dao.ArticleDao;//数据库访问对象-文章import com.company.team.bussiness.repo.dao.CommentDao;//数据库访问对象-评论import com.company.team.bussiness.repo.dao.po.ArticlePO;//数据库持久化对象-文章import com.company.team.bussiness.repo.dao.po.CommentPO;//数据库持久化对象-评论import com.company.team.bussiness.repo.cache.ArticleObj;//分布式缓存访问对象-文章缓存访问 资源库对外的整体访问由 Repository 提供，它聚合了各个资源库的数据信息，同时也承担了资源存储的逻辑（例如缓存更新机制等）。 四种 Domain 模式除了晦涩难懂的概念外，让我们最难接受的可能就是模型的运用了，Spring 思想中，Domain 只是数据的载体，所有行为都在 Service 中使用 Domain 封装后流转，而 OOP 讲究一对象维度来执行业务，所以，DDD 中的对象是用行为的（理解这点非常重要哦）。 这里我为你总结了全部的四种领域模式，供你区分和理解： 失血模型 贫血模型 充血模型 胀血模型 失血模型Domain Object 只有属性的 getter/setter 方法的纯数据类，所有的业务逻辑完全由 business object 来完成。 贫血模型简单来说，就是 Domain Object 包含了不依赖于持久化的领域逻辑，而那些依赖持久化的领域逻辑被分离到 Service 层。 意这个模式不在 Domain 层里依赖 DAO。持久化的工作还需要在 DAO 或者 Service 中进行。 这样做的优缺点 优点：各层单向依赖，结构清晰。 缺点： Domain Object 的部分比较紧密依赖的持久化 Domain Logic 被分离到 Service 层，显得不够 OO Service 层过于厚重 充血模型充血模型和第二种模型差不多，区别在于业务逻辑划分，将绝大多数业务逻辑放到 Domain 中，Service 是很薄的一层，封装少量业务逻辑，并且不和 DAO 打交道： Service (事务封装) —&gt; Domain Object &lt;—&gt; DAO 所有业务逻辑都在 Domain 中，事务管理也在 Item 中实现。这样做的优缺点如下。 优点： 更加符合 OO 的原则； Service 层很薄，只充当 Facade 的角色，不和 DAO 打交道。缺点： DAO 和 Domain Object 形成了双向依赖，复杂的双向依赖会导致很多潜在的问题。 如何划分 Service 层逻辑和 Domain 层逻辑是非常含混的，在实际项目中，由于设计和开发人员的水平差异，可能 导致整个结构的混乱无序。 充血模型基于充血模型的第三个缺点，干脆取消 Service 层，只剩下 Domain Object 和 DAO 两层，在 Domain Object 的 Domain Logic 上面封装事务。 Domain Object (事务封装，业务逻辑) &lt;—&gt; DAO 似乎 Ruby on rails 就是这种模型，它甚至把 Domain Object 和 DAO 都合并了。 这样做的优缺点： 简化了分层 也算符合 OO 该模型缺点： 很多不是 Domain Logic 的 Service 逻辑也被强行放入 Domain Object ，引起了 Domain Object 模型的不稳定； Domain Object 暴露给 Web 层过多的信息，可能引起意想不到的副作用。 总结 DDD分层架构优点： 开发人员可以只关注整个结构中的某一层。 可以很容易的用新的实现来替换原有层次的实现。 可以降低层与层之间的依赖。 有利于标准化。 利于各层逻辑的复用。缺点： 降低了系统的性能。这是显然的，因为增加了中间层，不过可以通过缓存机制来改善。 可能会导致级联的修改。这种修改尤其体现在自上而下的方向，不过可以通过依赖倒置来改善。 四层架构 User Interface为用户界面层（或表示层），负责向用户显示信息和解释用户命令。这里指的用户可以是另一个计算机系统，不一定是使用用户界面的人。 Application为应用层，定义软件要完成的任务，并且指挥表达领域概念的对象来解决问题。这一层所负责的工作对业务来说意义重大，也是与其它系统的应用层进行交互的必要渠道。应用层要尽量简单，不包含业务规则或者知识，而只为下一层中的领域对象协调任务，分配工作，使它们互相协作。它没有反映业务情况的状态，但是却可以具有另外一种状态，为用户或程序显示某个任务的进度。 Domain为领域层（或模型层），负责表达业务概念，业务状态信息以及业务规则。尽管保存业务状态的技术细节是由基础设施层实现的，但是反映业务情况的状态是由本层控制并且使用的。领域层是业务软件的核心，领域模型位于这一层。 Infrastructure层为基础实施层，向其他层提供通用的技术能力：为应用层传递消息，为领域层提供持久化机制，为用户界面层绘制屏幕组件，等等。基础设施层还能够通过架构框架来支持四个层次间的交互模式。传统的四层架构都是限定型松散分层架构，即Infrastructure层的任意上层都可以访问该层（“L”型），而其它层遵守严格分层架构 在四层架构模式的实践中，对于分层的本地化定义主要为： User Interface层主要是Restful消息处理，配置文件解析，等等。 Application层主要是多进程管理及调度，多线程管理及调度，多协程调度和状态机管理，等等。 Domain层主要是领域模型的实现，包括领域对象的确立，这些对象的生命周期管理及关系，领域服务的定义，领域事件的发布，等等。 Infrastructure层主要是业务平台，编程框架，第三方库的封装，基础算法，等等。 严格意义上来说，User Interface指的是用户界面，Restful消息和配置文件解析等处理应该放在Application层，User Interface层没有的话就空缺。但User Interface也可以理解为用户接口，所以将Restful消息和配置文件解析等处理放在User Interface层也行。 五层架构 User Interface是用户接口层，主要用于处理用户发送的Restful请求和解析用户输入的配置文件等，并将信息传递给Application层的接口。 Application层是应用层，负责多进程管理及调度、多线程管理及调度、多协程调度和维护业务实例的状态模型。当调度层收到用户接口层的请求后，委托Context层与本次业务相关的上下文进行处理。 Context是环境层，以上下文为单位，将Domain层的领域对象cast成合适的role，让role交互起来完成业务逻辑。 Domain层是领域层，定义领域模型，不仅包括领域对象及其之间关系的建模，还包括对象的角色role的显式建模。 Infrastructure层是基础实施层，为其他层提供通用的技术能力：业务平台，编程框架，持久化机制，消息机制，第三方库的封装，通用算法，等等。 很多DDD落地实践，都是面向控制面或管理面且消息交互比较多的系统。这类系统的一次业务，包含一组同步消息或异步消息构成的序列，如果都放在Context层，会导致该层的代码比较复杂，于是我们考虑： Context层在面向控制面或管理面且消息交互比较多的系统中又分裂成两层，即Context层和大Context层。 Context层处理单位为Action，对应一条同步消息或异步消息。 大Context层对应一个事务处理，由一个Action序列组成，一般通过Transaction DSL实现，所以我们习惯把大Context层叫做Transaction DSL层。 Application层在面向控制面或管理面且消息交互比较多的系统中经常会做一些调度相关的工作，所以我们习惯把Application层叫做Scheduler层。 因此，在面向控制面或管理面且消息交互比较多的系统中，DDD分层架构模式就变成了六层， 在实践中，将这六层的本地化定义为： User Interface是用户接口层，主要用于处理用户发送的Restful请求和解析用户输入的配置文件等，并将信息传递给Scheduler层的接口。 Scheduler是调度层，负责多进程管理及调度、多线程管理及调度、多协程调度和维护业务实例的状态模型。当调度层收到用户接口层的请求后，委托Transaction层与本次操作相关的事务进行处理。 Transaction是事务层，对应一个业务流程，比如UE Attach，将多个同步消息或异步消息的处理序列组合成一个事务，而且在大多场景下，都有选择结构。万一事务执行失败，则立即进行回滚。当事务层收到调度层的请求后，委托Context层的Action进行处理，常常还伴随使用Context层的Specification（谓词）进行Action的选择。 Context是环境层，以Action为单位，处理一条同步消息或异步消息，将Domain层的领域对象cast成合适的role，让role交互起来完成业务逻辑。环境层通常也包括Specification的实现，即通过Domain层的知识去完成一个条件判断。 Domain层是领域层，定义领域模型，不仅包括领域对象及其之间关系的建模，还包括对象的角色role的显式建模。 Infrastructure层是基础实施层，为其他层提供通用的技术能力：业务平台，编程框架，持久化机制，消息机制，第三方库的封装，通用算法，等等。 事务层的核心是事务模型，事务模型的框架代码一般放在基础设施层。 综上所述，DDD六层架构可以看做是DDD五层架构在特定领域的变体，我们统称为DDD五层架构，而DDD五层架构与传统的四层架构类似，都是限定型松散分层架构。 六边形架构有一种方法可以改进分层架构，即依赖倒置原则(Dependency Inversion Principle, DIP)，它通过改变不同层之间的依赖关系达到改进目的。 依赖倒置原则由Robert C. Martin提出，正式定义为：高层模块不应该依赖于底层模块，两者都应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。 根据该定义，DDD分层架构中的低层组件应该依赖于高层组件提供的接口，即无论高层还是低层都依赖于抽象，整个分层架构好像被推平了。如果我们把分层架构推平，再向其中加入一些对称性，就会出现一种具有对称性特征的架构风格，即六边形架构。六边形架构是Alistair Cockburn在2005年提出的，在这种架构中，不同的客户通过“平等”的方式与系统交互。需要新的客户吗？不是问题。只需要添加一个新的适配器将客户输入转化成能被系统API所理解的参数就行。同时，对于每种特定的输出，都有一个新建的适配器负责完成相应的转化功能。 六边形架构也称为端口与适配器，如下图所示： 六边形每条不同的边代表了不同类型的端口，端口要么处理输入，要么处理输出。对于每种外界类型，都有一个适配器与之对应，外界通过应用层API与内部进行交互。上图中有3个客户请求均抵达相同的输入端口（适配器A、B和C），另一个客户请求使用了适配器D。假设前3个请求使用了HTTP协议（浏览器、REST和SOAP等），而后一个请求使用了AMQP协议（比如RabbitMQ）。端口并没有明确的定义，它是一个非常灵活的概念。无论采用哪种方式对端口进行划分，当客户请求到达时，都应该有相应的适配器对输入进行转化，然后端口将调用应用程序的某个操作或者向应用程序发送一个事件，控制权由此交给内部区域。应用程序通过公共API接收客户请求，使用领域模型来处理请求。我们可以将DDD战术设计的建模元素Repository的实现看作是持久化适配器，该适配器用于访问先前存储的聚合实例或者保存新的聚合实例。正如图中的适配器E、F和G所展示的，我们可以通过不同的方式实现资源库，比如关系型数据库、基于文档的存储、分布式缓存或内存存储等。如果应用程序向外界发送领域事件消息，我们将使用适配器H进行处理。该适配器处理消息输出，而上面提到的处理AMQP消息的适配器则是处理消息输入的，因此应该使用不同的端口。 我们在实际的项目开发中，不同层的组件可以同时开发。当一个组件的功能明确后，就可以立即启动开发。由于该组件的用户有多个，并且这些用户的侧重点不同，所以需要提供多个不同的接口。同时，这些用户的认识也是不断深入的，可能会多次重构相关的接口。于是，组件的多个用户经常会找组件的开发者讨论这些问题，无形中降低了组件的开发效率。我们换一种方式，组件的开发者在明确了组件的功能后就专注于功能的开发，确保功能稳定和高效。组件的用户自己定义组件的接口（端口），然后基于接口写测试，并不断演进接口。在跨层集成测试时，由组件开发者或用户再开发一个适配器就可以了。 六边形架构模式的演变尽管六边形架构模式已经很好，但是没有最好只有更好，演变没有尽头。在六边形架构模式提出后的这些年，又依次衍生出三种六边形架构模式的变体，感兴趣的读者可以点击链接自行学习： Jeffrey Palermo在2008年提出了洋葱架构，六边形架构是洋葱架构的一个超集。 Robert C. Martin在2012年提出了干净架构（Clean Architecture），这是六边形架构的一个变体。 Russ Miles在2013年提出了Life Preserver设计，这是一种基于六边形架构的设计。 DDD实践假如你是一个团队 Leader 或者架构师，当你接手一个旧系统维护及重构的任务时，你该如何改造呢？是否觉得哪里都不对但由于业务认知的不熟悉而无从下手呢？ 通过公共平台大概梳理出系统之间的调用关系（一般中等以上公司都具备 RPC 和 HTTP 调用关系，无脑的挨个系统查询即可），画出来的可能会很乱，也可能会比较清晰，但这就是现状。 分配组员每个人认领几个项目，来梳理项目维度关系，这些关系包括：对外接口、交互、用例、MQ 等的详细说明。个别核心系统可以画出内部实体或者聚合根。 小组开会，挨个 review 每个系统的业务概念，达到组内统一语言。 根据以上资料，即可看出哪些不合理的调用关系（比如循环调用、不规范的调用等），甚至不合理的分层。 根据主线业务自顶向下细分领域，以及限界上下文。此过程可能会颠覆之前的系统划分。 根据业务复杂性，指定领域模型，选择贫血或者充血模型。团队内部最好实行统一习惯，以免出现交接成本过大。 分工进行开发，并设置 deadline，注意，不要单一的设置一个 deadline，要设置中间 check 时间，比如 dealline 是 1 月 20 日，还要设置两个 check 时间，分别沟通代码风格及边界职责，以免 deadline 时延期。 事件风暴（Event Storming）事件风暴也被称为事件建模，形式有点类似于头脑风暴的方法,通过事件风暴的方法可以快速分析复杂业务领域，完成领域建模的目标。 事件风暴是一项团队活动，旨在通过领域事件识别出聚合根，进而划分微服务的限界上下文。在活动中，团队先通过头脑风暴的形式罗列出领域中所有的领域事件，整合之后形成最终的领域事件集合，然后对于每一个事件，标注出导致该事件的命令（Command），再然后为每个事件标注出命令发起方的角色，命令可以是用户发起，也可以是第三方系统调用或者是定时器触发等。最后对事件进行分类整理出聚合根以及限界上下文。 事件风暴方法通常有以下几个步骤： 邀请合适的人参加 提供无限制的建模空间 发掘领域事件，可使用橙色贴纸标识 发掘领域事件的来源，探询命令，可使用蓝色贴纸标识。多种来源也可以- 考虑用不同颜色来区分，例如用黄色表示角色，粉色表示外部系统，红色表示时间触发。 寻找聚合，可用绿色贴纸标识 持续探索，发掘子域，BC，用户角色，验收测试标准，补充信息等。 事件风暴的步骤可以如下图所示： 在我们的一次产品的重构活动中也采用了事件风暴方法。系统代码维护了10几年，代码中存在大量的“坏味道”：重复代码，过长函数，过大的类，过长的参数列表，发散式变化，霰弹式修改，镀金问题，注释不清等问题。实际研发过程中也是经常出现一点改动都可能会引起不可预测的结果，重构势在必行。 但是在重构过程中，也没有人可以说清楚现有系统的逻辑，如何重构成为了一个难题。重构过程我们引入了咨询公司给我们的方法，采用了事件风暴的办法，通过对领域中所发生的事情（也就是领域事件）来探索这个领域，并且使用便签来描述领域中的事件，这些便签会沿着时间轴贴到一个很大的建模面板上。 举例来说，能够引发事件的事情包括用户行为、外部系统所发生的事情以及时间的流逝。事件也有助于找到领域的边界，对术语的不同阐述可能就意味着存在边界。 准备工作，四色贴纸： 橙色：事件，某个动作的结果，以“XX已XX”的方式表示，比如“用户信息已查询” 蓝色：属性，事件相关的输入、输出数据等 黄色：命令，某个动作，比如“查找用户信息” 绿色：实体，命令的触发者 开始梳理业务，将结果贴到白版上 继续深入梳理，将整个过程的模型、关键数据等梳理出来，贴在白板上确定重构指导思路，执行重构动作，重构的同时引入单元测试保障重构的质量 实践我们先看一个简单的例子，这个 case 的业务逻辑如下： 一个新应用在全国通过 地推业务员 做推广，需要做一个用户注册系统，同时希望在用户注册后能够通过用户电话（先假设仅限座机）的地域（区号）对业务员发奖金。 先不要去纠结这个根据用户电话去发奖金的业务逻辑是否合理，也先不要去管用户是否应该在注册时和业务员做绑定，这里我们看的主要还是如何更加合理的去实现这个逻辑。一个简单的用户和用户注册的代码实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class User &#123; Long userId; String name; String phone; String address; Long repId;&#125;public class RegistrationServiceImpl implements RegistrationService &#123; private SalesRepRepository salesRepRepo; private UserRepository userRepo; public User register(String name, String phone, String address) throws ValidationException &#123; // 校验逻辑 if (name == null || name.length() == 0) &#123; throw new ValidationException("name"); &#125; if (phone == null || !isValidPhoneNumber(phone)) &#123; throw new ValidationException("phone"); &#125; // 此处省略address的校验逻辑 // 取电话号里的区号，然后通过区号找到区域内的SalesRep String areaCode = null; String[] areas = new String[]&#123;"0571", "021", "010"&#125;; for (int i = 0; i &lt; phone.length(); i++) &#123; String prefix = phone.substring(0, i); if (Arrays.asList(areas).contains(prefix)) &#123; areaCode = prefix; break; &#125; &#125; SalesRep rep = salesRepRepo.findRep(areaCode); // 最后创建用户，落盘，然后返回 User user = new User(); user.name = name; user.phone = phone; user.address = address; if (rep != null) &#123; user.repId = rep.repId; &#125; return userRepo.save(user); &#125; private boolean isValidPhoneNumber(String phone) &#123; String pattern = "^0[1-9]&#123;2,3&#125;-?\\d&#123;8&#125;$"; return phone.matches(pattern); &#125;&#125; 我们日常绝大部分代码和模型其实都跟这个是类似的，乍一看貌似没啥问题，但我们再深入一步，从以下四个维度去分析一下：接口的清晰度（可阅读性）、数据验证和错误处理、业务逻辑代码的清晰度、和可测试性。 问题1 - 接口的清晰度在Java代码中，对于一个方法来说所有的参数名在编译时丢失，留下的仅仅是一个参数类型的列表，所以我们重新看一下以上的接口定义，其实在运行时仅仅是： 1User register(String, String, String); 所以以下的代码是一段编译器完全不会报错的，很难通过看代码就能发现的 bug ： 1service.register("殷浩", "浙江省杭州市余杭区文三西路969号", "0571-12345678"); 当然，在真实代码中运行时会报错，但这种 bug 是在运行时被发现的，而不是在编译时。普通的 Code Review 也很难发现这种问题，很有可能是代码上线后才会被暴露出来。这里的思考是，有没有办法在编码时就避免这种可能会出现的问题？ 另外一种常见的，特别是在查询服务中容易出现的例子如下： 123User findByName(String name);User findByPhone(String phone);User findByNameAndPhone(String name, String phone); 在这个场景下，由于入参都是 String 类型，不得不在方法名上面加上 ByXXX 来区分，而 findByNameAndPhone 同样也会陷入前面的入参顺序错误的问题，而且和前面的入参不同，这里参数顺序如果输错了，方法不会报错只会返回 null，而这种 bug 更加难被发现。这里的思考是，有没有办法让方法入参一目了然，避免入参错误导致的 bug ？ 问题2 - 数据验证和错误处理在前面这段数据校验代码：123if (phone == null || !isValidPhoneNumber(phone)) &#123; throw new ValidationException("phone");&#125; 在日常编码中经常会出现，一般来说这种代码需要出现在方法的最前端，确保能够 fail-fast 。但是假设你有多个类似的接口和类似的入参，在每个方法里这段逻辑会被重复。而更严重的是如果未来我们要拓展电话号去包含手机时，很可能需要加入以下代码： 123if (phone == null || !isValidPhoneNumber(phone) || !isValidCellNumber(phone)) &#123; throw new ValidationException("phone");&#125; 如果你有很多个地方用到了 phone 这个入参，但是有个地方忘记修改了，会造成 bug 。这是一个 DRY 原则被违背时经常会发生的问题。 如果有个新的需求，需要把入参错误的原因返回，那么这段代码就变得更加复杂： 12345if (phone == null) &#123; throw new ValidationException("phone不能为空");&#125; else if (!isValidPhoneNumber(phone)) &#123; throw new ValidationException("phone格式错误");&#125; 可以想像得到，代码里充斥着大量的类似代码块时，维护成本要有多高。 最后，在这个业务方法里，会（隐性或显性的）抛 ValidationException，所以需要外部调用方去try/catch，而业务逻辑异常和数据校验异常被混在了一起，是否是合理的？ 在传统Java架构里有几个办法能够去解决一部分问题，常见的如BeanValidation注解或ValidationUtils类，比如：1234567891011121314// Use Bean ValidationUser registerWithBeanValidation( @NotNull @NotBlank String name, @NotNull @Pattern(regexp = "^0?[1-9]&#123;2,3&#125;-?\\d&#123;8&#125;$") String phone, @NotNull String address);// Use ValidationUtils:public User registerWithUtils(String name, String phone, String address) &#123; ValidationUtils.validateName(name); // throws ValidationException ValidationUtils.validatePhone(phone); ValidationUtils.validateAddress(address); ...&#125; 但这几个传统的方法同样有问题， BeanValidation： 通常只能解决简单的校验逻辑，复杂的校验逻辑一样要写代码实现定制校验器 在添加了新校验逻辑时，同样会出现在某些地方忘记添加一个注解的情况，DRY原则还是会被违背 ValidationUtils类： 当大量的校验逻辑集中在一个类里之后，违背了Single Responsibility单一性原则，导致代码混乱和不可维护 业务异常和校验异常还是会混杂 所以，有没有一种方法，能够一劳永逸的解决所有校验的问题以及降低后续的维护成本和异常处理成本呢？ 问题3 - 业务代码的清晰度在这段代码里： 12345678910String areaCode = null;String[] areas = new String[]&#123;"0571", "021", "010"&#125;;for (int i = 0; i &lt; phone.length(); i++) &#123; String prefix = phone.substring(0, i); if (Arrays.asList(areas).contains(prefix)) &#123; areaCode = prefix; break; &#125;&#125;SalesRep rep = salesRepRepo.findRep(areaCode); 实际上出现了另外一种常见的情况，那就是从一些入参里抽取一部分数据，然后调用一个外部依赖获取更多的数据，然后通常从新的数据中再抽取部分数据用作其他的作用。这种代码通常被称作“胶水代码”，其本质是由于外部依赖的服务的入参并不符合我们原始的入参导致的。比如，如果SalesRepRepository包含一个findRepByPhone的方法，则上面大部分的代码都不必要了。 所以，一个常见的办法是将这段代码抽离出来，变成独立的一个或多个方法： 1234567891011121314private static String findAreaCode(String phone) &#123; for (int i = 0; i &lt; phone.length(); i++) &#123; String prefix = phone.substring(0, i); if (isAreaCode(prefix)) &#123; return prefix; &#125; &#125; return null;&#125;private static boolean isAreaCode(String prefix) &#123; String[] areas = new String[]&#123;"0571", "021"&#125;; return Arrays.asList(areas).contains(prefix);&#125; 然后原始代码变为： 12String areaCode = findAreaCode(phone);SalesRep rep = salesRepRepo.findRep(areaCode); 而为了复用以上的方法，可能会抽离出一个静态工具类 PhoneUtils 。但是这里要思考的是，静态工具类是否是最好的实现方式呢？当你的项目里充斥着大量的静态工具类，业务代码散在多个文件当中时，你是否还能找到核心的业务逻辑呢？ 问题4 - 可测试性为了保证代码质量，每个方法里的每个入参的每个可能出现的条件都要有 TC 覆盖（假设我们先不去测试内部业务逻辑），所以在我们这个方法里需要以下的 TC ： 假如一个方法有 N 个参数，每个参数有 M 个校验逻辑，至少要有 N * M 个 TC 。 如果这时候在该方法中加入一个新的入参字段 fax ，即使 fax 和 phone 的校验逻辑完全一致，为了保证 TC 覆盖率，也一样需要 M 个新的 TC 。 而假设有 P 个方法中都用到了 phone 这个字段，这 P 个方法都需要对该字段进行测试，也就是说整体需要： P N M 个测试用例才能完全覆盖所有数据验证的问题，在日常项目中，这个测试的成本非常之高，导致大量的代码没被覆盖到。而没被测试覆盖到的代码才是最有可能出现问题的地方。 在这个情况下，降低测试成本 == 提升代码质量，如何能够降低测试的成本呢？ 解决方案我们回头先重新看一下原始的 use case，并且标注其中可能重要的概念： 一个新应用在全国通过 地推业务员 做推广，需要做一个用户的注册系统，在用户注册后能够通过用户电话号的区号对业务员发奖金。 在分析了 use case 后，发现其中地推业务员、用户本身自带 ID 属性，属于 Entity（实体），而注册系统属于 Application Service（应用服务），这几个概念已经有存在。但是发现电话号这个概念却完全被隐藏到了代码之中。我们可以问一下自己，取电话号的区号的逻辑是否属于用户（用户的区号？）？是否属于注册服务（注册的区号？）？如果都不是很贴切，那就说明这个逻辑应该属于一个独立的概念。所以这里引入我们第一个原则： Make Implicit Concepts Explicit 将隐性的概念显性化在这里，我们可以看到，原来电话号仅仅是用户的一个参数，属于隐形概念，但实际上电话号的区号才是真正的业务逻辑，而我们需要将电话号的概念显性化，通过写一个Value Object： 12345678910111213141516171819202122232425262728293031323334353637public class PhoneNumber &#123; private final String number; public String getNumber() &#123; return number; &#125; public PhoneNumber(String number) &#123; if (number == null) &#123; throw new ValidationException("number不能为空"); &#125; else if (isValid(number)) &#123; throw new ValidationException("number格式错误"); &#125; this.number = number; &#125; public String getAreaCode() &#123; for (int i = 0; i &lt; number.length(); i++) &#123; String prefix = number.substring(0, i); if (isAreaCode(prefix)) &#123; return prefix; &#125; &#125; return null; &#125; private static boolean isAreaCode(String prefix) &#123; String[] areas = new String[]&#123;"0571", "021", "010"&#125;; return Arrays.asList(areas).contains(prefix); &#125; public static boolean isValid(String number) &#123; String pattern = "^0?[1-9]&#123;2,3&#125;-?\\d&#123;8&#125;$"; return number.matches(pattern); &#125;&#125; 这里面有几个很重要的元素： 通过 private final String number 确保 PhoneNumber 是一个（Immutable）Value Object。（一般来说 VO 都是 Immutable 的，这里只是重点强调一下） 校验逻辑都放在了 constructor 里面，确保只要 PhoneNumber 类被创建出来后，一定是校验通过的。 之前的 findAreaCode 方法变成了 PhoneNumber 类里的 getAreaCode ，突出了 areaCode 是 PhoneNumber 的一个计算属性。 这样做完之后，我们发现把 PhoneNumber 显性化之后，其实是生成了一个 Type（数据类型）和一个 Class（类）： Type 指我们在今后的代码里可以通过 PhoneNumber 去显性的标识电话号这个概念 Class 指我们可以把所有跟电话号相关的逻辑完整的收集到一个文件里这两个概念加起来，构造成了本文标题的 Domain Primitive（DP）。 我们看一下全面使用了 DP 之后效果：123456789101112131415161718192021222324252627public class User &#123; UserId userId; Name name; PhoneNumber phone; Address address; RepId repId;&#125;public User register( @NotNull Name name, @NotNull PhoneNumber phone, @NotNull Address address) &#123; // 找到区域内的SalesRep SalesRep rep = salesRepRepo.findRep(phone.getAreaCode()); // 最后创建用户，落盘，然后返回，这部分代码实际上也能用Builder解决 User user = new User(); user.name = name; user.phone = phone; user.address = address; if (rep != null) &#123; user.repId = rep.repId; &#125; return userRepo.saveUser(user);&#125; 我们可以看到在使用了 DP 之后，所有的数据验证逻辑和非业务流程的逻辑都消失了，剩下都是核心业务逻辑，可以一目了然。我们重新用上面的四个维度评估一下： 评估1 - 接口的清晰度重构后的方法签名变成了很清晰的： 1public User register(Name, PhoneNumber, Address) 而之前容易出现的bug，如果按照现在的写法 1service.register(new Name("殷浩"), new Address("浙江省杭州市余杭区文三西路969号"), new PhoneNumber("0571-12345678")); 让接口 API 变得很干净，易拓展。 评估2 - 数据验证和错误处理12345public User register( @NotNull Name name, @NotNull PhoneNumber phone, @NotNull Address address) // no throws 如前文代码展示的，重构后的方法里，完全没有了任何数据验证的逻辑，也不会抛 ValidationException 。原因是因为 DP 的特性，只要是能够带到入参里的一定是正确的或 null（Bean Validation 或 lombok 的注解能解决 null 的问题）。所以我们把数据验证的工作量前置到了调用方，而调用方本来就是应该提供合法数据的，所以更加合适。 再展开来看，使用DP的另一个好处就是代码遵循了 DRY 原则和单一性原则，如果未来需要修改 PhoneNumber 的校验逻辑，只需要在一个文件里修改即可，所有使用到了 PhoneNumber 的地方都会生效。 评估3 - 业务代码的清晰度123SalesRep rep = salesRepRepo.findRep(phone.getAreaCode());User user = xxx;return userRepo.save(user); 除了在业务方法里不需要校验数据之外，原来的一段胶水代码 findAreaCode 被改为了 PhoneNumber 类的一个计算属性 getAreaCode ，让代码清晰度大大提升。而且胶水代码通常都不可复用，但是使用了 DP 后，变成了可复用、可测试的代码。我们能看到，在刨除了数据验证代码、胶水代码之后，剩下的都是核心业务逻辑。（ Entity 相关的重构在后面文章会谈到，这次先忽略） 评估4 - 可测试性当我们将 PhoneNumber 抽取出来之后，在来看测试的 TC ： 首先 PhoneNumber 本身还是需要 M 个测试用例，但是由于我们只需要测试单一对象，每个用例的代码量会大大降低，维护成本降低。每个方法里的每个参数，现在只需要覆盖为 null 的情况就可以了，其他的 case 不可能发生（因为只要不是 null 就一定是合法的）所以，单个方法的 TC 从原来的 N * M 变成了今天的 N + M 。同样的，多个方法的 TC 数量变成了 N + M + P 这个数量一般来说要远低于原来的数量 N M P ，让测试成本极大的降低。 评估总结进阶使用在上文我介绍了 DP 的第一个原则：将隐性的概念显性化。在这里我将介绍 DP 的另外两个原则，用一个新的案例。 ▍案例1 - 转账假设现在要实现一个功能，让A用户可以支付 x 元给用户 B ，可能的实现如下： 123public void pay(BigDecimal money, Long recipientId) &#123; BankService.transfer(money, "CNY", recipientId);&#125; 如果这个是境内转账，并且境内的货币永远不变，该方法貌似没啥问题，但如果有一天货币变更了（比如欧元区曾经出现的问题），或者我们需要做跨境转账，该方法是明显的 bug ，因为 money 对应的货币不一定是 CNY 。 在这个 case 里，当我们说“支付 x 元”时，除了 x 本身的数字之外，实际上是有一个隐含的概念那就是货币“元”。但是在原始的入参里，之所以只用了 BigDecimal 的原因是我们认为 CNY 货币是默认的，是一个隐含的条件，但是在我们写代码时，需要把所有隐性的条件显性化，而这些条件整体组成当前的上下文。所以 DP 的第二个原则是： Make Implicit Context Explicit 将 隐性的 上下文 显性化 所以当我们做这个支付功能时，实际上需要的一个入参是支付金额 + 支付货币。我们可以把这两个概念组合成为一个独立的完整概念：Money。 123456789@Valuepublic class Money &#123; private BigDecimal amount; private Currency currency; public Money(BigDecimal amount, Currency currency) &#123; this.amount = amount; this.currency = currency; &#125;&#125; 而原有的代码则变为： 123public void pay(Money money, Long recipientId) &#123; BankService.transfer(money, recipientId);&#125; 通过将默认货币这个隐性的上下文概念显性化，并且和金额合并为 Money ，我们可以避免很多当前看不出来，但未来可能会暴雷的bug。 案例2 - 跨境转账前面的案例升级一下，假设用户可能要做跨境转账从 CNY 到 USD ，并且货币汇率随时在波动： 12345678910public void pay(Money money, Currency targetCurrency, Long recipientId) &#123; if (money.getCurrency().equals(targetCurrency)) &#123; BankService.transfer(money, recipientId); &#125; else &#123; BigDecimal rate = ExchangeService.getRate(money.getCurrency(), targetCurrency); BigDecimal targetAmount = money.getAmount().multiply(new BigDecimal(rate)); Money targetMoney = new Money(targetAmount, targetCurrency); BankService.transfer(targetMoney, recipientId); &#125;&#125; 在这个case里，由于 targetCurrency 不一定和 money 的 Curreny 一致，需要调用一个服务去取汇率，然后做计算。最后用计算后的结果做转账。 这个case最大的问题在于，金额的计算被包含在了支付的服务中，涉及到的对象也有2个 Currency ，2 个 Money ，1 个 BigDecimal ，总共 5 个对象。这种涉及到多个对象的业务逻辑，需要用 DP 包装掉，所以这里引出 DP 的第三个原则： Encapsulate Multi-Object Behavior 封装 多对象 行为 在这个 case 里，可以将转换汇率的功能，封装到一个叫做 ExchangeRate 的 DP 里： 12345678910111213141516171819@Valuepublic class ExchangeRate &#123; private BigDecimal rate; private Currency from; private Currency to; public ExchangeRate(BigDecimal rate, Currency from, Currency to) &#123; this.rate = rate; this.from = from; this.to = to; &#125; public Money exchange(Money fromMoney) &#123; notNull(fromMoney); isTrue(this.from.equals(fromMoney.getCurrency())); BigDecimal targetAmount = fromMoney.getAmount().multiply(rate); return new Money(targetAmount, to); &#125;&#125; ExchangeRate汇率对象，通过封装金额计算逻辑以及各种校验逻辑，让原始代码变得极其简单：12345public void pay(Money money, Currency targetCurrency, Long recipientId) &#123; ExchangeRate rate = ExchangeService.getRate(money.getCurrency(), targetCurrency); Money targetMoney = rate.exchange(money); BankService.transfer(targetMoney, recipientId);&#125; 讨论和总结▍Domain Primitive 的定义让我们重新来定义一下 Domain Primitive ：Domain Primitive 是一个在特定领域里，拥有精准定义的、可自我验证的、拥有行为的 Value Object 。 DP是一个传统意义上的Value Object，拥有Immutable的特性DP是一个完整的概念整体，拥有精准定义DP使用业务域中的原生语言DP可以是业务域的最小组成部分、也可以构建复杂组合注：Domain Primitive的概念和命名来自于Dan Bergh Johnsson &amp; Daniel Deogun的书 Secure by Design。 ▍使用 Domain Primitive 的三原则让隐性的概念显性化让隐性的上下文显性化封装多对象行为 ▍Domain Primitive 和 DDD 里 Value Object 的区别在 DDD 中， Value Object 这个概念其实已经存在： 在 Evans 的 DDD 蓝皮书中，Value Object 更多的是一个非 Entity 的值对象在Vernon的IDDD红皮书中，作者更多的关注了Value Object的Immutability、Equals方法、Factory方法等Domain Primitive 是 Value Object 的进阶版，在原始 VO 的基础上要求每个 DP 拥有概念的整体，而不仅仅是值对象。在 VO 的 Immutable 基础上增加了 Validity 和行为。当然同样的要求无副作用（side-effect free）。 ▍Domain Primitive 和 Data Transfer Object (DTO) 的区别在日常开发中经常会碰到的另一个数据结构是 DTO ，比如方法的入参和出参。DP 和 DTO 的区别如下： ▍什么情况下应该用 Domain Primitive常见的 DP 的使用场景包括： 有格式限制的 String：比如Name，PhoneNumber，OrderNumber，ZipCode，Address等有限制的Integer：比如OrderId（&gt;0），Percentage（0-100%），Quantity（&gt;=0）等可枚举的 int ：比如 Status（一般不用Enum因为反序列化问题）Double 或 BigDecimal：一般用到的 Double 或 BigDecimal 都是有业务含义的，比如 Temperature、Money、Amount、ExchangeRate、Rating 等复杂的数据结构：比如 Map&lt;String, List&gt; 等，尽量能把 Map 的所有操作包装掉，仅暴露必要行为 实战 - 老应用重构的流程在新应用中使用 DP 是比较简单的，但在老应用中使用 DP 是可以遵循以下流程按部就班的升级。在此用本文的第一个 case 为例。 ▍第一步 - 创建 Domain Primitive，收集所有 DP 行为在前文中，我们发现取电话号的区号这个是一个可以独立出来的、可以放入 PhoneNumber 这个 Class 的逻辑。类似的，在真实的项目中，以前散落在各个服务或工具类里面的代码，可以都抽出来放在 DP 里，成为 DP 自己的行为或属性。这里面的原则是：所有抽离出来的方法要做到无状态，比如原来是 static 的方法。如果原来的方法有状态变更，需要将改变状态的部分和不改状态的部分分离，然后将无状态的部分融入 DP 。因为 DP 本身不能带状态，所以一切需要改变状态的代码都不属于 DP 的范畴。 (代码参考 PhoneNumber 的代码，这里不再重复) ▍第二步 - 替换数据校验和无状态逻辑为了保障现有方法的兼容性，在第二步不会去修改接口的签名，而是通过代码替换原有的校验逻辑和根 DP 相关的业务逻辑。比如： 123456789101112131415161718192021public User register(String name, String phone, String address) throws ValidationException &#123; if (name == null || name.length() == 0) &#123; throw new ValidationException("name"); &#125; if (phone == null || !isValidPhoneNumber(phone)) &#123; throw new ValidationException("phone"); &#125; String areaCode = null; String[] areas = new String[]&#123;"0571", "021", "010"&#125;; for (int i = 0; i &lt; phone.length(); i++) &#123; String prefix = phone.substring(0, i); if (Arrays.asList(areas).contains(prefix)) &#123; areaCode = prefix; break; &#125; &#125; SalesRep rep = salesRepRepo.findRep(areaCode); // 其他代码...&#125; 通过 DP 替换代码后： 12345678910public User register(String name, String phone, String address) throws ValidationException &#123; Name _name = new Name(name); PhoneNumber _phone = new PhoneNumber(phone); Address _address = new Address(address); SalesRep rep = salesRepRepo.findRep(_phone.getAreaCode()); // 其他代码...&#125; 通过 new PhoneNumber(phone) 这种代码，替代了原有的校验代码。 通过 _phone.getAreaCode() 替换了原有的无状态的业务逻辑。 ▍第三步 - 创建新接口创建新接口，将DP的代码提升到接口参数层： 123public User register(Name name, PhoneNumber phone, Address address) &#123; SalesRep rep = salesRepRepo.findRep(phone.getAreaCode());&#125; ▍第四步 - 修改外部调用 外部调用方需要修改调用链路，比如： 1234service.register("殷浩", "0571-12345678", "浙江省杭州市余杭区文三西路969号");改为：service.register(new Name("殷浩"), new PhoneNumber("0571-12345678"), new Address("浙江省杭州市余杭区文三西路969号")); 通过以上 4 步，就能让你的代码变得更加简洁、优雅、健壮、安全。你还在等什么？今天就去尝试吧！ 应用架构设计设计原则 单一性原则（Single Responsibility Principle）：单一性原则要求一个对象/类应该只有一个变更的原因。但是在这个案例里，代码可能会因为任意一个外部依赖或计算逻辑的改变而改变。 依赖反转原则（Dependency Inversion Principle）：依赖反转原则要求在代码中依赖抽象，而不是具体的实现。在这个案例里外部依赖都是具体的实现，比如YahooForexService虽然是一个接口类，但是它对应的是依赖了Yahoo提供的具体服务，所以也算是依赖了实现。同样的KafkaTemplate、MyBatis的DAO实现都属于具体实现。 开放封闭原则（Open Closed Principle）：开放封闭原则指开放扩展，但是封闭修改。在这个案例里的金额计算属于可能会被修改的代码，这个时候该逻辑应该需要被包装成为不可修改的计算类，新功能通过计算类的拓展实现。 需求背景我们先看一个简单的案例需求如下： 用户可以通过银行网页转账给另一个账号，支持跨币种转账。 同时因为监管和对账需求，需要记录本次转账活动。 拿到这个需求之后，一个开发可能会经历一些技术选型，最终可能拆解需求如下： 1、从MySql数据库中找到转出和转入的账户，选择用 MyBatis 的 mapper 实现 DAO；2、从 Yahoo（或其他渠道）提供的汇率服务获取转账的汇率信息（底层是 http 开放接口）； 3、计算需要转出的金额，确保账户有足够余额，并且没超出每日转账上限； 4、实现转入和转出操作，扣除手续费，保存数据库； 5、发送 Kafka 审计消息，以便审计和对账用； 而一个简单的代码实现如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class TransferController &#123; private TransferService transferService; public Result&lt;Boolean&gt; transfer(String targetAccountNumber, BigDecimal amount, HttpSession session) &#123; Long userId = (Long) session.getAttribute("userId"); return transferService.transfer(userId, targetAccountNumber, amount, "CNY"); &#125;&#125;public class TransferServiceImpl implements TransferService &#123; private static final String TOPIC_AUDIT_LOG = "TOPIC_AUDIT_LOG"; private AccountMapper accountDAO; private KafkaTemplate&lt;String, String&gt; kafkaTemplate; private YahooForexService yahooForex; @Override public Result&lt;Boolean&gt; transfer(Long sourceUserId, String targetAccountNumber, BigDecimal targetAmount, String targetCurrency) &#123; // 1. 从数据库读取数据，忽略所有校验逻辑如账号是否存在等 AccountDO sourceAccountDO = accountDAO.selectByUserId(sourceUserId); AccountDO targetAccountDO = accountDAO.selectByAccountNumber(targetAccountNumber); // 2. 业务参数校验 if (!targetAccountDO.getCurrency().equals(targetCurrency)) &#123; throw new InvalidCurrencyException(); &#125; // 3. 获取外部数据，并且包含一定的业务逻辑 // exchange rate = 1 source currency = X target currency BigDecimal exchangeRate = BigDecimal.ONE; if (sourceAccountDO.getCurrency().equals(targetCurrency)) &#123; exchangeRate = yahooForex.getExchangeRate(sourceAccountDO.getCurrency(), targetCurrency); &#125; BigDecimal sourceAmount = targetAmount.divide(exchangeRate, RoundingMode.DOWN); // 4. 业务参数校验 if (sourceAccountDO.getAvailable().compareTo(sourceAmount) &lt; 0) &#123; throw new InsufficientFundsException(); &#125; if (sourceAccountDO.getDailyLimit().compareTo(sourceAmount) &lt; 0) &#123; throw new DailyLimitExceededException(); &#125; // 5. 计算新值，并且更新字段 BigDecimal newSource = sourceAccountDO.getAvailable().subtract(sourceAmount); BigDecimal newTarget = targetAccountDO.getAvailable().add(targetAmount); sourceAccountDO.setAvailable(newSource); targetAccountDO.setAvailable(newTarget); // 6. 更新到数据库 accountDAO.update(sourceAccountDO); accountDAO.update(targetAccountDO); // 7. 发送审计消息 String message = sourceUserId + "," + targetAccountNumber + "," + targetAmount + "," + targetCurrency; kafkaTemplate.send(TOPIC_AUDIT_LOG, message); return Result.success(true); &#125;&#125; 流程图在重构之前，我们先画一张流程图，描述当前代码在做的每个步骤： 这是一个传统的三层分层结构：UI层、业务层、和基础设施层。上层对于下层有直接的依赖关系，导致耦合度过高。在业务层中对于下层的基础设施有强依赖，耦合度高。我们需要对这张图上的每个节点做抽象和整理，来降低对外部依赖的耦合度。 抽象数据存储层第一步常见的操作是将Data Access层做抽象，降低系统对数据库的直接依赖。具体的方法如下： 新建Account实体对象：一个实体（Entity）是拥有ID的域对象，除了拥有数据之外，同时拥有行为。Entity和数据库储存格式无关，在设计中要以该领域的通用严谨语言（Ubiquitous Language）为依据。新建对象储存接口类AccountRepository：Repository只负责Entity对象的存储和读取，而Repository的实现类完成数据库存储的细节。通过加入Repository接口，底层的数据库连接可以通过不同的实现类而替换。 具体的简单代码实现如下： Account实体类：12345678910111213141516@Datapublic class Account &#123; private AccountId id; private AccountNumber accountNumber; private UserId userId; private Money available; private Money dailyLimit; public void withdraw(Money money) &#123; // 转出 &#125; public void deposit(Money money) &#123; // 转入 &#125;&#125; 和AccountRepository及MyBatis实现类：123456789101112131415161718192021222324252627282930313233343536373839404142434445public interface AccountRepository &#123; Account find(AccountId id); Account find(AccountNumber accountNumber); Account find(UserId userId); Account save(Account account);&#125;public class AccountRepositoryImpl implements AccountRepository &#123; @Autowired private AccountMapper accountDAO; @Autowired private AccountBuilder accountBuilder; @Override public Account find(AccountId id) &#123; AccountDO accountDO = accountDAO.selectById(id.getValue()); return accountBuilder.toAccount(accountDO); &#125; @Override public Account find(AccountNumber accountNumber) &#123; AccountDO accountDO = accountDAO.selectByAccountNumber(accountNumber.getValue()); return accountBuilder.toAccount(accountDO); &#125; @Override public Account find(UserId userId) &#123; AccountDO accountDO = accountDAO.selectByUserId(userId.getId()); return accountBuilder.toAccount(accountDO); &#125; @Override public Account save(Account account) &#123; AccountDO accountDO = accountBuilder.fromAccount(account); if (accountDO.getId() == null) &#123; accountDAO.insert(accountDO); &#125; else &#123; accountDAO.update(accountDO); &#125; return accountBuilder.toAccount(accountDO); &#125;&#125; Account实体类和AccountDO数据类的对比如下： Data Object数据类：AccountDO是单纯的和数据库表的映射关系，每个字段对应数据库表的一个column，这种对象叫Data Object。DO只有数据，没有行为。AccountDO的作用是对数据库做快速映射，避免直接在代码里写SQL。无论你用的是MyBatis还是Hibernate这种ORM，从数据库来的都应该先直接映射到DO上，但是代码里应该完全避免直接操作 DO。 Entity实体类：Account 是基于领域逻辑的实体类，它的字段和数据库储存不需要有必然的联系。Entity包含数据，同时也应该包含行为。在 Account 里，字段也不仅仅是String等基础类型，而应该尽可能用上一讲的 Domain Primitive 代替，可以避免大量的校验代码。 DAO 和 Repository 类的对比如下： DAO对应的是一个特定的数据库类型的操作，相当于SQL的封装。所有操作的对象都是DO类，所有接口都可以根据数据库实现的不同而改变。比如，insert 和 update 属于数据库专属的操作。 Repository对应的是Entity对象读取储存的抽象，在接口层面做统一，不关注底层实现。比如，通过 save 保存一个Entity对象，但至于具体是 insert 还是 update 并不关心。Repository的具体实现类通过调用DAO来实现各种操作，通过Builder/Factory对象实现AccountDO 到 Account之间的转化 Repository和Entity 通过Account对象，避免了其他业务逻辑代码和数据库的直接耦合，避免了当数据库字段变化时，大量业务逻辑也跟着变的问题。 通过Repository，改变业务代码的思维方式，让业务逻辑不再面向数据库编程，而是面向领域模型编程。 Account属于一个完整的内存中对象，可以比较容易的做完整的测试覆盖，包含其行为。 Repository作为一个接口类，可以比较容易的实现Mock或Stub，可以很容易测试。 AccountRepositoryImpl实现类，由于其职责被单一出来，只需要关注Account到AccountDO的映射关系和Repository方法到DAO方法之间的映射关系，相对于来说更容易测试。 抽象第三方服务类似对于数据库的抽象，所有第三方服务也需要通过抽象解决第三方服务不可控，入参出参强耦合的问题。在这个例子里我们抽象出 ExchangeRateService 的服务，和一个ExchangeRate的Domain Primitive类： 123456789101112131415161718public interface ExchangeRateService &#123; ExchangeRate getExchangeRate(Currency source, Currency target);&#125;public class ExchangeRateServiceImpl implements ExchangeRateService &#123; @Autowired private YahooForexService yahooForexService; @Override public ExchangeRate getExchangeRate(Currency source, Currency target) &#123; if (source.equals(target)) &#123; return new ExchangeRate(BigDecimal.ONE, source, target); &#125; BigDecimal forex = yahooForexService.getExchangeRate(source.getValue(), target.getValue()); return new ExchangeRate(forex, source, target); &#125;&#125; 防腐层（ACL）这种常见的设计模式叫做Anti-Corruption Layer（防腐层或ACL）。很多时候我们的系统会去依赖其他的系统，而被依赖的系统可能包含不合理的数据结构、API、协议或技术实现，如果对外部系统强依赖，会导致我们的系统被”腐蚀“。这个时候，通过在系统间加入一个防腐层，能够有效的隔离外部依赖和内部逻辑，无论外部如何变更，内部代码可以尽可能的保持不变。 ACL 不仅仅只是多了一层调用，在实际开发中ACL能够提供更多强大的功能： 适配器：很多时候外部依赖的数据、接口和协议并不符合内部规范，通过适配器模式，可以将数据转化逻辑封装到ACL内部，降低对业务代码的侵入。在这个案例里，我们通过封装了ExchangeRate和Currency对象，转化了对方的入参和出参，让入参出参更符合我们的标准。 缓存：对于频繁调用且数据变更不频繁的外部依赖，通过在ACL里嵌入缓存逻辑，能够有效的降低对于外部依赖的请求压力。同时，很多时候缓存逻辑是写在业务代码里的，通过将缓存逻辑嵌入ACL，能够降低业务代码的复杂度。 兜底：如果外部依赖的稳定性较差，一个能够有效提升我们系统稳定性的策略是通过ACL起到兜底的作用，比如当外部依赖出问题后，返回最近一次成功的缓存或业务兜底数据。这种兜底逻辑一般都比较复杂，如果散落在核心业务代码中会很难维护，通过集中在ACL中，更加容易被测试和修改。 易于测试：类似于之前的Repository，ACL的接口类能够很容易的实现Mock或Stub，以便于单元测试。 功能开关：有些时候我们希望能在某些场景下开放或关闭某个接口的功能，或者让某个接口返回一个特定的值，我们可以在ACL配置功能开关来实现，而不会对真实业务代码造成影响。同时，使用功能开关也能让我们容易的实现Monkey测试，而不需要真正物理性的关闭外部依赖。 抽象中间件类似于2.2的第三方服务的抽象，对各种中间件的抽象的目的是让业务代码不再依赖中间件的实现逻辑。因为中间件通常需要有通用型，中间件的接口通常是String或Byte[] 类型的，导致序列化/反序列化逻辑通常和业务逻辑混杂在一起，造成胶水代码。通过中间件的ACL抽象，减少重复胶水代码。 在这个案例里，我们通过封装一个抽象的AuditMessageProducer和AuditMessage DP对象，实现对底层kafka实现的隔离： 1234567891011121314151617181920212223242526272829303132333435363738@Value@AllArgsConstructorpublic class AuditMessage &#123; private UserId userId; private AccountNumber source; private AccountNumber target; private Money money; private Date date; public String serialize() &#123; return userId + "," + source + "," + target + "," + money + "," + date; &#125; public static AuditMessage deserialize(String value) &#123; // todo return null; &#125;&#125;public interface AuditMessageProducer &#123; SendResult send(AuditMessage message);&#125;public class AuditMessageProducerImpl implements AuditMessageProducer &#123; private static final String TOPIC_AUDIT_LOG = "TOPIC_AUDIT_LOG"; @Autowired private KafkaTemplate&lt;String, String&gt; kafkaTemplate; @Override public SendResult send(AuditMessage message) &#123; String messageBody = message.serialize(); kafkaTemplate.send(TOPIC_AUDIT_LOG, messageBody); return SendResult.success(); &#125;&#125; 封装业务逻辑用Domain Primitive封装跟实体无关的无状态计算逻辑在这个案例里使用ExchangeRate来封装汇率计算逻辑：12345BigDecimal exchangeRate = BigDecimal.ONE;if (sourceAccountDO.getCurrency().equals(targetCurrency)) &#123; exchangeRate = yahooForex.getExchangeRate(sourceAccountDO.getCurrency(), targetCurrency);&#125;BigDecimal sourceAmount = targetAmount.divide(exchangeRate, RoundingMode.DOWN); 变为：12ExchangeRate exchangeRate = exchangeRateService.getExchangeRate(sourceAccount.getCurrency(), targetMoney.getCurrency());Money sourceMoney = exchangeRate.exchangeTo(targetMoney); 用Entity封装单对象的有状态的行为，包括业务校验用Account实体类封装所有Account的行为，包括业务校验如下： 1234567891011121314151617181920212223242526272829303132@Datapublic class Account &#123; private AccountId id; private AccountNumber accountNumber; private UserId userId; private Money available; private Money dailyLimit; public Currency getCurrency() &#123; return this.available.getCurrency(); &#125; // 转入 public void deposit(Money money) &#123; if (!this.getCurrency().equals(money.getCurrency())) &#123; throw new InvalidCurrencyException(); &#125; this.available = this.available.add(money); &#125; // 转出 public void withdraw(Money money) &#123; if (this.available.compareTo(money) &lt; 0) &#123; throw new InsufficientFundsException(); &#125; if (this.dailyLimit.compareTo(money) &lt; 0) &#123; throw new DailyLimitExceededException(); &#125; this.available = this.available.subtract(money); &#125;&#125; 原有的业务代码则可以简化为：12sourceAccount.deposit(sourceMoney);targetAccount.withdraw(targetMoney); 用Domain Service封装多对象逻辑在这个案例里，我们发现这两个账号的转出和转入实际上是一体的，也就是说这种行为应该被封装到一个对象中去。特别是考虑到未来这个逻辑可能会产生变化：比如增加一个扣手续费的逻辑。这个时候在原有的TransferService中做并不合适，在任何一个Entity或者Domain Primitive里也不合适，需要有一个新的类去包含跨域对象的行为。这种对象叫做Domain Service。 我们创建一个AccountTransferService的类：1234567891011121314public interface AccountTransferService &#123; void transfer(Account sourceAccount, Account targetAccount, Money targetMoney, ExchangeRate exchangeRate);&#125;public class AccountTransferServiceImpl implements AccountTransferService &#123; private ExchangeRateService exchangeRateService; @Override public void transfer(Account sourceAccount, Account targetAccount, Money targetMoney, ExchangeRate exchangeRate) &#123; Money sourceMoney = exchangeRate.exchangeTo(targetMoney); sourceAccount.deposit(sourceMoney); targetAccount.withdraw(targetMoney); &#125;&#125; 而原始代码则简化为一行：1accountTransferService.transfer(sourceAccount, targetAccount, targetMoney, exchangeRate); 重构后结果分析12345678910111213141516171819202122232425262728293031public class TransferServiceImplNew implements TransferService &#123; private AccountRepository accountRepository; private AuditMessageProducer auditMessageProducer; private ExchangeRateService exchangeRateService; private AccountTransferService accountTransferService; @Override public Result&lt;Boolean&gt; transfer(Long sourceUserId, String targetAccountNumber, BigDecimal targetAmount, String targetCurrency) &#123; // 参数校验 Money targetMoney = new Money(targetAmount, new Currency(targetCurrency)); // 读数据 Account sourceAccount = accountRepository.find(new UserId(sourceUserId)); Account targetAccount = accountRepository.find(new AccountNumber(targetAccountNumber)); ExchangeRate exchangeRate = exchangeRateService.getExchangeRate(sourceAccount.getCurrency(), targetMoney.getCurrency()); // 业务逻辑 accountTransferService.transfer(sourceAccount, targetAccount, targetMoney, exchangeRate); // 保存数据 accountRepository.save(sourceAccount); accountRepository.save(targetAccount); // 发送审计消息 AuditMessage message = new AuditMessage(sourceAccount, targetAccount, targetMoney); auditMessageProducer.send(message); return Result.success(true); &#125;&#125; 可以看出来，经过重构后的代码有以下几个特征： 业务逻辑清晰，数据存储和业务逻辑完全分隔。 Entity、Domain Primitive、Domain Service都是独立的对象，没有任何外部依赖，但是却包含了所有核心业务逻辑，可以单独完整测试。 原有的TransferService不再包括任何计算逻辑，仅仅作为组件编排，所有逻辑均delegate到其他组件。这种仅包含Orchestration（编排）的服务叫做Application Service（应用服务）。 我们可以根据新的结构重新画一张图： 然后通过重新编排后该图变为： 我们可以发现，通过对外部依赖的抽象和内部逻辑的封装重构，应用整体的依赖关系变了： 最底层不再是数据库，而是Entity、Domain Primitive和Domain Service。这些对象不依赖任何外部服务和框架，而是纯内存中的数据和操作。这些对象我们打包为Domain Layer（领域层）。领域层没有任何外部依赖关系。 再其次的是负责组件编排的Application Service，但是这些服务仅仅依赖了一些抽象出来的ACL类和Repository类，而其具体实现类是通过依赖注入注进来的。Application Service、Repository、ACL等我们统称为Application Layer（应用层）。应用层 依赖 领域层，但不依赖具体实现。 最后是ACL，Repository等的具体实现，这些实现通常依赖外部具体的技术实现和框架，所以统称为Infrastructure Layer（基础设施层）。Web框架里的对象如Controller之类的通常也属于基础设施层。 如果今天能够重新写这段代码，考虑到最终的依赖关系，我们可能先写Domain层的业务逻辑，然后再写Application层的组件编排，最后才写每个外部依赖的具体实现。这种架构思路和代码组织结构就叫做Domain-Driven Design（领域驱动设计，或DDD）。所以DDD不是一个特殊的架构设计，而是所有Transction Script代码经过合理重构后一定会抵达的终点。 DDD的六边形架构在我们传统的代码里，我们一般都很注重每个外部依赖的实现细节和规范，但是今天我们需要敢于抛弃掉原有的理念，重新审视代码结构。在上面重构的代码里，如果抛弃掉所有Repository、ACL、Producer等的具体实现细节，我们会发现每一个对外部的抽象类其实就是输入或输出，类似于计算机系统中的I/O节点。这个观点在CQRS架构中也同样适用，将所有接口分为Command（输入）和Query（输出）两种。除了I/O之外其他的内部逻辑，就是应用业务的核心逻辑。基于这个基础，Alistair Cockburn在2005年提出了Hexagonal Architecture（六边形架构），又被称之为Ports and Adapters（端口和适配器架构）。 在这张图中： I/O的具体实现在模型的最外层 每个I/O的适配器在灰色地带 每个Hex的边是一个端口 Hex的中央是应用的核心领域模型 在Hex中，架构的组织关系第一次变成了一个二维的内外关系，而不是传统一维的上下关系。同时在Hex架构中我们第一次发现UI层、DB层、和各种中间件层实际上是没有本质上区别的，都只是数据的输入和输出，而不是在传统架构中的最上层和最下层。 除了2005年的Hex架构，2008年 Jeffery Palermo的Onion Architecture（洋葱架构）和2017年 Robert Martin的Clean Architecture（干净架构），都是极为类似的思想。除了命名不一样、切入点不一样之外，其他的整体架构都是基于一个二维的内外关系。这也说明了基于DDD的架构最终的形态都是类似的。Herberto Graca有一个很全面的图包含了绝大部分现实中的端口类，值得借鉴。 代码组织结构为了有效的组织代码结构，避免下层代码依赖到上层实现的情况，在Java中我们可以通过POM Module和POM依赖来处理相互的关系。通过Spring/SpringBoot的容器来解决运行时动态注入具体实现的依赖的问题。一个简单的依赖关系图如下： Types 模块Types模块是保存可以对外暴露的Domain Primitives的地方。Domain Primitives因为是无状态的逻辑，可以对外暴露，所以经常被包含在对外的API接口中，需要单独成为模块。Types模块不依赖任何类库，纯 POJO 。 Domain 模块Domain 模块是核心业务逻辑的集中地，包含有状态的Entity、领域服务Domain Service、以及各种外部依赖的接口类（如Repository、ACL、中间件等。Domain模块仅依赖Types模块，也是纯 POJO 。 Application模块Application模块主要包含Application Service和一些相关的类。Application模块依赖Domain模块。还是不依赖任何框架，纯POJO。 Infrastructure模块Infrastructure模块包含了Persistence、Messaging、External等模块。比如：Persistence模块包含数据库DAO的实现，包含Data Object、ORM Mapper、Entity到DO的转化类等。Persistence模块要依赖具体的ORM类库，比如MyBatis。如果需要用Spring-Mybatis提供的注解方案，则需要依赖Spring。 Web模块Web模块包含Controller等相关代码。如果用SpringMVC则需要依赖Spring。 Start模块Start模块是SpringBoot的启动类。 测试 Types，Domain模块都属于无外部依赖的纯POJO，基本上都可以100%的被单元测试覆盖。 Application模块的代码依赖外部抽象类，需要通过测试框架去Mock所有外部依赖，但仍然可以100%被单元测试。 Infrastructure的每个模块的代码相对独立，接口数量比较少，相对比较容易写单测。但是由于依赖了外部I/O，速度上不可能很快，但好在模块的变动不会很频繁，属于一劳永逸。 Web模块有两种测试方法：通过Spring的MockMVC测试，或者通过HttpClient调用接口测试。但是在测试时最好把Controller依赖的服务类都Mock掉。一般来说当你把Controller的逻辑都后置到Application Service中时，Controller的逻辑变得极为简单，很容易100%覆盖。 Start模块：通常应用的集成测试写在start里。当其他模块的单元测试都能100%覆盖后，集成测试用来验证整体链路的真实性。 代码的演进/变化速度在传统架构中，代码从上到下的变化速度基本上是一致的，改个需求需要从接口、到业务逻辑、到数据库全量变更，而第三方变更可能会导致整个代码的重写。但是在DDD中不同模块的代码的演进速度是不一样的： Domain层属于核心业务逻辑，属于经常被修改的地方。比如：原来不需要扣手续费，现在需要了之类的。通过Entity能够解决基于单个对象的逻辑变更，通过Domain Service解决多个对象间的业务逻辑变更。 Application层属于Use Case（业务用例）。业务用例一般都是描述比较大方向的需求，接口相对稳定，特别是对外的接口一般不会频繁变更。添加业务用例可以通过新增Application Service或者新增接口实现功能的扩展。 Infrastructure层属于最低频变更的。一般这个层的模块只有在外部依赖变更了之后才会跟着升级，而外部依赖的变更频率一般远低于业务逻辑的变更频率。所以在DDD架构中，能明显看出越外层的代码越稳定，越内层的代码演进越快，真正体现了领域“驱动”的核心思想。 总结DDD不是一个什么特殊的架构，而是任何传统代码经过合理的重构之后最终一定会抵达的终点。DDD的架构能够有效的解决传统架构中的问题： 高可维护性：当外部依赖变更时，内部代码只用变更跟外部对接的模块，其他业务逻辑不变。 高可扩展性：做新功能时，绝大部分的代码都能复用，仅需要增加核心业务逻辑即可。 高可测试性：每个拆分出来的模块都符合单一性原则，绝大部分不依赖框架，可以快速的单元测试，做到100%覆盖。 代码结构清晰：通过POM module可以解决模块间的依赖关系， 所有外接模块都可以单独独立成Jar包被复用。当团队形成规范后，可以快速的定位到相关代码。 Repository模式为什么要用 Repository 实体模型 vs. 贫血模型 Entity（实体）这个词在计算机领域的最初应用可能是来自于Peter Chen在1976年的“The Entity-Relationship Model - Toward a Unified View of Data”（ER模型），用来描述实体之间的关系，而ER模型后来逐渐的演变成为一个数据模型，在关系型数据库中代表了数据的储存方式。而2006年的JPA标准，通过@Entity等注解，以及Hibernate等ORM框架的实现，让很多Java开发对Entity的理解停留在了数据映射层面，忽略了Entity实体的本身行为，造成今天很多的模型仅包含了实体的数据和属性，而所有的业务逻辑都被分散在多个服务、Controller、Utils工具类中，这个就是Martin Fowler所说的的Anemic Domain Model（贫血领域模型）。如何知道你的模型是贫血的呢？可以看一下你代码中是否有以下的几个特征： 有大量的XxxDO对象：这里DO虽然有时候代表了Domain Object，但实际上仅仅是数据库表结构的映射，里面没有包含（或包含了很少的）业务逻辑； 服务和Controller里有大量的业务逻辑：比如校验逻辑、计算逻辑、格式转化逻辑、对象关系逻辑、数据存储逻辑等； 大量的Utils工具类等。 而贫血模型的缺陷是非常明显的： 无法保护模型对象的完整性和一致性：因为对象的所有属性都是公开的，只能由调用方来维护模型的一致性，而这个是没有保障的；之前曾经出现的案例就是调用方没有能维护模型数据的一致性，导致脏数据使用时出现bug，这一类的 bug还特别隐蔽，很难排查到。 对象操作的可发现性极差：单纯从对象的属性上很难看出来都有哪些业务逻辑，什么时候可以被调用，以及可以赋值的边界是什么；比如说，Long类型的值是否可以是0或者负数？ 代码逻辑重复：比如校验逻辑、计算逻辑，都很容易出现在多个服务、多个代码块里，提升维护成本和bug出现的概率；一类常见的bug就是当贫血模型变更后，校验逻辑由于出现在多个地方，没有能跟着变，导致校验失败或失效。 代码的健壮性差：比如一个数据模型的变化可能导致从上到下的所有代码的变更。 强依赖底层实现：业务代码里强依赖了底层数据库、网络/中间件协议、第三方服务等，造成核心逻辑代码的僵化且维护成本高。 虽然贫血模型有很大的缺陷，但是在我们日常的代码中，我见过的99%的代码都是基于贫血模型，为什么呢？我总结了以下几点： 数据库思维：从有了数据库的那一天起，开发人员的思考方式就逐渐从“写业务逻辑“转变为了”写数据库逻辑”，也就是我们经常说的在写CRUD代码。 贫血模型“简单”：贫血模型的优势在于“简单”，仅仅是对数据库表的字段映射，所以可以从前到后用统一格式串通。这里简单打了引号，是因为它只是表面上的简单，实际上当未来有模型变更时，你会发现其实并不简单，每次变更都是非常复杂的事情 脚本思维：很多常见的代码都属于“脚本”或“胶水代码”，也就是流程式代码。脚本代码的好处就是比较容易理解，但长久来看缺乏健壮性，维护成本会越来越高。 但是可能最核心的原因在于，实际上我们在日常开发中，混淆了两个概念： 数据模型（Data Model）：指业务数据该如何持久化，以及数据之间的关系，也就是传统的ER模型； 业务模型/领域模型（Domain Model）：指业务逻辑中，相关联的数据该如何联动。 所以，解决这个问题的根本方案，就是要在代码里严格区分Data Model和Domain Model，具体的规范会在后文详细描述。在真实代码结构中，Data Model和 Domain Model实际上会分别在不同的层里，Data Model只存在于数据层，而Domain Model在领域层，而链接了这两层的关键对象，就是Repository。 Repository的价值 在传统的数据库驱动开发中，我们会对数据库操作做一个封装，一般叫做Data Access Object（DAO）。DAO的核心价值是封装了拼接SQL、维护数据库连接、事务等琐碎的底层逻辑，让业务开发可以专注于写代码。但是在本质上，DAO的操作还是数据库操作，DAO的某个方法还是在直接操作数据库和数据模型，只是少写了部分代码。在Uncle Bob的《代码整洁之道》一书里，作者用了一个非常形象的描述： 硬件（Hardware）：指创造了之后不可（或者很难）变更的东西。数据库对于开发来说，就属于”硬件“，数据库选型后基本上后面不会再变，比如：用了MySQL就很难再改为MongoDB，改造成本过高。 软件（Software）：指创造了之后可以随时修改的东西。对于开发来说，业务代码应该追求做”软件“，因为业务流程、规则在不停的变化，我们的代码也应该能随时变化。 固件（Firmware）：即那些强烈依赖了硬件的软件。我们常见的是路由器里的固件或安卓的固件等等。固件的特点是对硬件做了抽象，但仅能适配某款硬件，不能通用。所以今天不存在所谓的通用安卓固件，而是每个手机都需要有自己的固件。 从上面的描述我们能看出来，数据库在本质上属于”硬件“，DAO 在本质上属于”固件“，而我们自己的代码希望是属于”软件“。但是，固件有个非常不好的特性，那就是会传播，也就是说当一个软件强依赖了固件时，由于固件的限制，会导致软件也变得难以变更，最终让软件变得跟固件一样难以变更。 模型对象代码规范这边要解决这个问题，首先要指定编码规约 对象类型 在讲Repository规范之前，我们需要先讲清楚3种模型的区别，Entity、Data Object (DO)和Data Transfer Object (DTO)： Data Object （DO、数据对象）：实际上是我们在日常工作中最常见的数据模型。但是在DDD的规范里，DO应该仅仅作为数据库物理表格的映射，不能参与到业务逻辑中。为了简单明了，DO的字段类型和名称应该和数据库物理表格的字段类型和名称一一对应，这样我们不需要去跑到数据库上去查一个字段的类型和名称。（当然，实际上也没必要一摸一样，只要你在Mapper那一层做到字段映射） Entity（实体对象）：实体对象是我们正常业务应该用的业务模型，它的字段和方法应该和业务语言保持一致，和持久化方式无关。也就是说，Entity和DO很可能有着完全不一样的字段命名和字段类型，甚至嵌套关系。Entity的生命周期应该仅存在于内存中，不需要可序列化和可持久化。 DTO（传输对象）：主要作为Application层的入参和出参，比如CQRS里的Command、Query、Event，以及Request、Response等都属于DTO的范畴。DTO的价值在于适配不同的业务场景的入参和出参，避免让业务对象变成一个万能大对象。 模型所在模块和转化器于现在从一个对象变为3+个对象，对象间需要通过转化器（Converter/Mapper）来互相转化。而这三种对象在代码中所在的位置也不一样，简单总结如下： 这边DO结尾的文件是跟数据库一一对应的，DTO是跟前端或者其他系统协商的，只有DTO需要序列化，Entity是不固定的，实际的属性设置是根据业务来的。这边我推荐用一个mapper层，所有文件都以Mapper结尾，在Mapper层做转换，这边具体的转换用一个工具很好用，叫MapStruct。 从使用复杂度角度来看，区分了DO、Entity、DTO带来了代码量的膨胀（从1个变成了3+2+N个）。但是在实际复杂业务场景下，通过功能来区分模型带来的价值是功能性的单一和可测试、可预期，最终反而是逻辑复杂性的降低。 我自己的项目因为是简单的业务模型，所以用了通用的贫血模型，规范的项目目录结构如下所示（这边缺少了entity和防腐层的设计）： DDD领域层的一些设计规范上面我主要针对同一个例子对比了OOP、ECS和DDD的3种实现，比较如下： 基于继承关系的OOP代码：OOP的代码最好写，也最容易理解，所有的规则代码都写在对象里，但是当领域规则变得越来越复杂时，其结构会限制它的发展。新的规则有可能会导致代码的整体重构。 基于组件化的ECS代码：ECS代码有最高的灵活性、可复用性、及性能，但极具弱化了实体类的内聚，所有的业务逻辑都写在了服务里，会导致业务的一致性无法保障，对商业系统会有较大的影响。 基于领域对象 + 领域服务的DDD架构：DDD的规则其实最复杂，同时要考虑到实体类的内聚和保证不变性（Invariants），也要考虑跨对象规则代码的归属，甚至要考虑到具体领域服务的调用方式，理解成本比较高。 实体类（Entity）大多数DDD架构的核心都是实体类，实体类包含了一个领域里的状态、以及对状态的直接操作。Entity最重要的设计原则是保证实体的不变性（Invariants），也就是说要确保无论外部怎么操作，一个实体内部的属性都不能出现相互冲突，状态不一致的情况。所以几个设计原则如下： 创建即一致在贫血模型里，通常见到的代码是一个模型通过手动new出来之后，由调用方一个参数一个参数的赋值，这就很容易产生遗漏，导致实体状态不一致。所以DDD里实体创建的方法有两种： constructor参数要包含所有必要属性，或者在constructor里有合理的默认值。 使用Factory模式来降低调用方复杂度 尽量避免public setter一个最容易导致不一致性的原因是实体暴露了public的setter方法，特别是set单一参数会导致状态不一致的情况。比如，一个订单可能包含订单状态（下单、已支付、已发货、已收货）、支付单、物流单等子实体，如果一个调用方能随意去set订单状态，就有可能导致订单状态和子实体匹配不上，导致业务流程走不通的情况。所以在实体里，需要通过行为方法来修改内部状态。 通过聚合根保证主子实体的一致性在稍微复杂一点的领域里，通常主实体会包含子实体，这时候主实体就需要起到聚合根的作用，即： 子实体不能单独存在，只能通过聚合根的方法获取到。任何外部的对象都不能直接保留子实体的引用 子实体没有独立的Repository，不可以单独保存和取出，必须要通过聚合根的Repository实例化 子实体可以单独修改自身状态，但是多个子实体之间的状态一致性需要聚合根来保障 常见的电商域中聚合的案例如主子订单模型、商品/SKU模型、跨子订单优惠、跨店优惠模型等。很多聚合根和Repository的设计规范在我前面一篇关于Repository的文章中已经详细解释过，可以拿来参考。 不可以强依赖其他聚合根实体或领域服务一个实体的原则是高内聚、低耦合，即一个实体类不能直接在内部直接依赖一个外部的实体或服务。这个原则和绝大多数ORM框架都有比较严重的冲突，所以是一个在开发过程中需要特别注意的。这个原则的必要原因包括：对外部对象的依赖性会直接导致实体无法被单测；以及一个实体无法保证外部实体变更后不会影响本实体的一致性和正确性。 所以，正确的对外部依赖的方法有两种： 只保存外部实体的ID：这里我再次强烈建议使用强类型的ID对象，而不是Long型ID。强类型的ID对象不单单能自我包含验证代码，保证ID值的正确性，同时还能确保各种入参不会因为参数顺序变化而出bug。具体可以参考Domain Primitive。 针对于“无副作用”的外部依赖，通过方法入参的方式传入。比如上文中的equip(Weapon，EquipmentService）方法。 如果方法对外部依赖有副作用，不能通过方法入参的方式，只能通过Domain Service解决，见下文。 任何实体的行为只能直接影响到本实体（和其子实体）这个原则更多是一个确保代码可读性、可理解的原则，即任何实体的行为不能有“直接”的”副作用“，即直接修改其他的实体类。这么做的好处是代码读下来不会产生意外。 另一个遵守的原因是可以降低未知的变更的风险。在一个系统里一个实体对象的所有变更操作应该都是预期内的，如果一个实体能随意被外部直接修改的话，会增加代码bug的风险。 领域服务（Domain Service）在上文讲到，领域服务其实也分很多种，在这里根据上文总结出来三种常见的： 单对象策略型这种领域对象主要面向的是单个实体对象的变更，但涉及到多个领域对象或外部依赖的一些规则。在上文中，EquipmentService即为此类： 变更的对象是Player的参数 读取的是Player和Weapon的数据，可能还包括从外部读取一些数据 在这种类型下，实体应该通过方法入参的方式传入这种领域服务，然后通过Double Dispatch来反转调用领域服务的方法。 跨对象事务型当一个行为会直接修改多个实体时，不能再通过单一实体的方法作处理，而必须直接使用领域服务的方法来做操作。在这里，领域服务更多的起到了跨对象事务的作用，确保多个实体的变更之间是有一致性的。 通用组件型这种类型的领域服务更像ECS里的System，提供了组件化的行为，但本身又不直接绑死在一种实体类上。 策略对象（Domain Policy）Policy或者Strategy设计模式是一个通用的设计模式，但是在DDD架构中会经常出现，其核心就是封装领域规则。 一个Policy是一个无状态的单例对象，通常需要至少2个方法：canApply 和 一个业务方法。其中，canApply方法用来判断一个Policy是否适用于当前的上下文，如果适用则调用方会去触发业务方法。通常，为了降低一个Policy的可测试性和复杂度，Policy不应该直接操作对象，而是通过返回计算后的值，在Domain Service里对对象进行操作。 除了本文里静态注入多个Policy以及手动排优先级之外，在日常开发中经常能见到通过Java的SPI机制或类SPI机制注册Policy，以及通过不同的Priority方案对Policy进行排序，在这里就不作太多的展开了。 领域事件介绍领域事件是一个在领域里发生了某些事后，希望领域里其他对象能够感知到的通知机制。在上面的案例里，代码之所以会越来越复杂，其根本的原因是反应代码（比如升级）直接和上面的事件触发条件（比如收到经验）直接耦合，而且这种耦合性是隐性的。领域事件的好处就是将这种隐性的副作用“显性化”，通过一个显性的事件，将事件触发和事件处理解耦，最终起到代码更清晰、扩展性更好的目的。 所以，领域事件是在DDD里，比较推荐使用的跨实体“副作用”传播机制。 领域事件实现和消息队列中间件不同的是，领域事件通常是立即执行的、在同一个进程内、可能是同步或异步。我们可以通过一个EventBus来实现进程内的通知机制，简单实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 实现者：瑜进 2019/11/28public class EventBus &#123; // 注册器 @Getter private final EventRegistry invokerRegistry = new EventRegistry(this); // 事件分发器 private final EventDispatcher dispatcher = new EventDispatcher(ExecutorFactory.getDirectExecutor()); // 异步事件分发器 private final EventDispatcher asyncDispatcher = new EventDispatcher(ExecutorFactory.getThreadPoolExecutor()); // 事件分发 public boolean dispatch(Event event) &#123; return dispatch(event, dispatcher); &#125; // 异步事件分发 public boolean dispatchAsync(Event event) &#123; return dispatch(event, asyncDispatcher); &#125; // 内部事件分发 private boolean dispatch(Event event, EventDispatcher dispatcher) &#123; checkEvent(event); // 1.获取事件数组 Set&lt;Invoker&gt; invokers = invokerRegistry.getInvokers(event); // 2.一个事件可以被监听N次，不关心调用结果 dispatcher.dispatch(event, invokers); return true; &#125; // 事件总线注册 public void register(Object listener) &#123; if (listener == null) &#123; throw new IllegalArgumentException("listener can not be null!"); &#125; invokerRegistry.register(listener); &#125; private void checkEvent(Event event) &#123; if (event == null) &#123; throw new IllegalArgumentException("event"); &#125; if (!(event instanceof Event)) &#123; throw new IllegalArgumentException("Event type must by " + Event.class); &#125; &#125;&#125; 调用方式：12345678910111213141516171819202122232425public class LevelUpEvent implements Event &#123; private Player player;&#125;public class LevelUpHandler &#123; public void handle(Player player);&#125;public class Player &#123; public void receiveExp(int value) &#123; this.exp += value; if (this.exp &gt;= 100) &#123; LevelUpEvent event = new LevelUpEvent(this); EventBus.dispatch(event); this.exp = 0; &#125; &#125;&#125;@Testpublic void test() &#123; EventBus.register(new LevelUpHandler()); player.setLevel(1); player.receiveExp(100); assertThat(player.getLevel()).equals(2);&#125; 目前领域事件的缺陷和展望从上面代码可以看出来，领域事件的很好的实施依赖EventBus、Dispatcher、Invoker这些属于框架级别的支持。同时另一个问题是因为Entity不能直接依赖外部对象，所以EventBus目前只能是一个全局的Singleton，而大家都应该知道全局Singleton对象很难被单测。这就容易导致Entity对象无法被很容易的被完整单测覆盖全。 另一种解法是侵入Entity，对每个Entity增加一个List:12345678910111213141516171819202122232425public class Player &#123; List&lt;Event&gt; events; public void receiveExp(int value) &#123; this.exp += value; if (this.exp &gt;= 100) &#123; LevelUpEvent event = new LevelUpEvent(this); events.add(event); // 把event加进去 this.exp = 0; &#125; &#125;&#125;@Testpublic void test() &#123; EventBus.register(new LevelUpHandler()); player.setLevel(1); player.receiveExp(100); for(Event event: player.getEvents()) &#123; // 在这里显性的dispatch事件 EventBus.dispatch(event); &#125; assertThat(player.getLevel()).equals(2);&#125; 但是能看出来这种解法不但会侵入实体本身，同时也需要比较啰嗦的显性在调用方dispatch事件，也不是一个好的解决方案。 也许未来会有一个框架能让我们既不依赖全局Singleton，也不需要显性去处理事件，但目前的方案基本都有或多或少的缺陷，大家在使用中可以注意。 总结在真实的业务逻辑里，我们的领域模型或多或少的都有一定的“特殊性”，如果100%的要符合DDD规范可能会比较累，所以最主要的是梳理一个对象行为的影响面，然后作出设计决策，即： 是仅影响单一对象还是多个对象， 规则未来的拓展性、灵活性， 性能要求， 副作用的处理，等等 当然，很多时候一个好的设计是多种因素的取舍，需要大家有一定的积累，真正理解每个架构背后的逻辑和优缺点。一个好的架构师不是有一个正确答案，而是能从多个方案中选出一个最平衡的方案。 参考文章： 阿里技术专家详解 DDD 系列 第一讲- Domain Primitive 阿里技术专家详解DDD系列 第二讲 - 应用架构 阿里技术专家详解DDD系列 第三讲 - Repository模式 阿里技术专家详解DDD系列 第四讲 - 领域层设计规范]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Skyworking实践]]></title>
    <url>%2F2020%2F12%2F11%2FSkyworking%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[简介SkyWalking是一个开源的可观察性平台，用于收集，分析，聚合和可视化来自服务和云本机基础结构的数据。SkyWalking提供了一种简便的方法来维护您的分布式系统的清晰视图，即使在整个云中也是如此。它是一种现代APM，专门为基于云的基于容器的分布式系统而设计。 为什么要使用SkyWalkingSkyWalking提供了用于在许多不同情况下观察和监视分布式系统的解决方案。首先，与传统方法一样，SkyWalking为服务提供自动仪器代理，例如Java，C＃，Node.js，Go，PHP和Nginx LUA。（并呼吁提供Python和C ++ SDK贡献）。在多语言，持续部署的环境中，云本机基础架构变得越来越强大，但也越来越复杂。SkyWalking的服务网格接收器使SkyWalking能够从Istio / Envoy和Linkerd等服务网格框架接收遥测数据，从而使用户能够了解整个分布式系统。 SkyWalking为服务，服务实例，端点提供可观察性功能。服务，实例和端点这些术语在当今到处都有使用，因此值得在SkyWalking的上下文中定义它们的特定含义： 服务。表示一组/一组工作负载，这些工作负载为传入请求提供相同的行为。您可以在使用乐器代理或SDK时定义服务名称。SkyWalking也可以使用您在Istio等平台中定义的名称。 服务实例。服务组中的每个单独工作负载都称为实例。像pods在Kubernetes中一样，它不必是单个OS进程，但是，如果您使用仪器代理，则实例实际上是一个真正的OS进程。 端点。服务中用于传入请求的路径，例如HTTP URI路径或gRPC服务类+方法签名。通过SkyWalking，用户可以了解服务和端点之间的拓扑关系，查看每个服务/服务实例/端点的指标并设置警报规则。 此外，可以整合 其他使用SkyWalking本机代理程序和SDK以及Zipkin，Jaeger和OpenCensus进行的分布式跟踪。 其他度量系统，例如Prometheus，Sleuth（Micrometer）。 架构设计SkyWalking分为四个部分： 探针：收集数据并重新格式化以符合SkyWalking要求（不同的探针支持不同的来源）。 平台后端：支持数据聚合，分析并驱动从探针到UI的流程。该分析包括SkyWalking本机跟踪和度量标准，包括Istio和Envoy遥测的第三方，Zipkin跟踪格式等。您甚至可以通过使用针对本机度量标准的Observability Analysis Language和针对扩展度量标准的Meter System来定制聚合和分析。 存储：存储设备通过开放/可插入的界面存储SkyWalking数据。您可以选择现有的实现，例如ElasticSearch，H2或由Sharding-Sphere管理的MySQL集群，也可以实现自己的实现。欢迎新存储实现者使用补丁！ UI：是一个高度可定制的基于Web的界面，允许SkyWalking最终用户可视化和管理SkyWalking数据。 使用本文章基于官方源码tag:v8.3.0 源码编译修改.mvn/jvm.config123456-Dhttp.proxyHost=proxy_ip-Dhttp.proxyPort=proxy_port-Dhttps.proxyHost=proxy_ip-Dhttps.proxyPort=proxy_port -Dhttp.proxyUser=username-Dhttp.proxyPassword=password 下载git源码123git clone --branch v8.3.0 https://github.com/apache/skywalking.gitgit submodule initgit submodule update 执行编译1./mvnw clean package -DskipTests 打包后的都会在/dist目录下 下载制品推荐直接下载成品 服务启动进入目录/bin，windows和linux的启动脚本都在里面，可以直接启动。 执行命令1./dist-material/bin/startup.sh 现在服务端就启起来了，可以打开后台地址查看(默认是8080端口): http://localhost:8080,界面如下： 客户端需要提前准备开墙信息，默认的启动端口是8080，数据采集的端口是11800 默认的存储是用内存数据库H2来存储的，建议改掉，不然数据会跟着服务重启丢失，而且服务占用内存会很大。修改的话在目录/config下有3个文件可以改： application.yml log4j.xml alarm-settings.yml 其中application.yml配置如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388cluster: selector: $&#123;SW_CLUSTER:standalone&#125; standalone: # Please check your ZooKeeper is 3.5+, However, it is also compatible with ZooKeeper 3.4.x. Replace the ZooKeeper 3.5+ # library the oap-libs folder with your ZooKeeper 3.4.x library. zookeeper: nameSpace: $&#123;SW_NAMESPACE:""&#125; hostPort: $&#123;SW_CLUSTER_ZK_HOST_PORT:localhost:2181&#125; # Retry Policy baseSleepTimeMs: $&#123;SW_CLUSTER_ZK_SLEEP_TIME:1000&#125; # initial amount of time to wait between retries maxRetries: $&#123;SW_CLUSTER_ZK_MAX_RETRIES:3&#125; # max number of times to retry # Enable ACL enableACL: $&#123;SW_ZK_ENABLE_ACL:false&#125; # disable ACL in default schema: $&#123;SW_ZK_SCHEMA:digest&#125; # only support digest schema expression: $&#123;SW_ZK_EXPRESSION:skywalking:skywalking&#125; kubernetes: namespace: $&#123;SW_CLUSTER_K8S_NAMESPACE:default&#125; labelSelector: $&#123;SW_CLUSTER_K8S_LABEL:app=collector,release=skywalking&#125; uidEnvName: $&#123;SW_CLUSTER_K8S_UID:SKYWALKING_COLLECTOR_UID&#125; consul: serviceName: $&#123;SW_SERVICE_NAME:"SkyWalking_OAP_Cluster"&#125; # Consul cluster nodes, example: 10.0.0.1:8500,10.0.0.2:8500,10.0.0.3:8500 hostPort: $&#123;SW_CLUSTER_CONSUL_HOST_PORT:localhost:8500&#125; aclToken: $&#123;SW_CLUSTER_CONSUL_ACLTOKEN:""&#125; etcd: serviceName: $&#123;SW_SERVICE_NAME:"SkyWalking_OAP_Cluster"&#125; # etcd cluster nodes, example: 10.0.0.1:2379,10.0.0.2:2379,10.0.0.3:2379 hostPort: $&#123;SW_CLUSTER_ETCD_HOST_PORT:localhost:2379&#125; nacos: serviceName: $&#123;SW_SERVICE_NAME:"SkyWalking_OAP_Cluster"&#125; hostPort: $&#123;SW_CLUSTER_NACOS_HOST_PORT:localhost:8848&#125; # Nacos Configuration namespace namespace: $&#123;SW_CLUSTER_NACOS_NAMESPACE:"public"&#125; # Nacos auth username username: $&#123;SW_CLUSTER_NACOS_USERNAME:""&#125; password: $&#123;SW_CLUSTER_NACOS_PASSWORD:""&#125; # Nacos auth accessKey accessKey: $&#123;SW_CLUSTER_NACOS_ACCESSKEY:""&#125; secretKey: $&#123;SW_CLUSTER_NACOS_SECRETKEY:""&#125;core: selector: $&#123;SW_CORE:default&#125; default: # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate # Receiver: Receive agent data, Level 1 aggregate # Aggregator: Level 2 aggregate role: $&#123;SW_CORE_ROLE:Mixed&#125; # Mixed/Receiver/Aggregator restHost: $&#123;SW_CORE_REST_HOST:0.0.0.0&#125; restPort: $&#123;SW_CORE_REST_PORT:12800&#125; restContextPath: $&#123;SW_CORE_REST_CONTEXT_PATH:/&#125; restMinThreads: $&#123;SW_CORE_REST_JETTY_MIN_THREADS:1&#125; restMaxThreads: $&#123;SW_CORE_REST_JETTY_MAX_THREADS:200&#125; restIdleTimeOut: $&#123;SW_CORE_REST_JETTY_IDLE_TIMEOUT:30000&#125; restAcceptorPriorityDelta: $&#123;SW_CORE_REST_JETTY_DELTA:0&#125; restAcceptQueueSize: $&#123;SW_CORE_REST_JETTY_QUEUE_SIZE:0&#125; gRPCHost: $&#123;SW_CORE_GRPC_HOST:0.0.0.0&#125; gRPCPort: $&#123;SW_CORE_GRPC_PORT:11800&#125; maxConcurrentCallsPerConnection: $&#123;SW_CORE_GRPC_MAX_CONCURRENT_CALL:0&#125; maxMessageSize: $&#123;SW_CORE_GRPC_MAX_MESSAGE_SIZE:0&#125; gRPCThreadPoolQueueSize: $&#123;SW_CORE_GRPC_POOL_QUEUE_SIZE:-1&#125; gRPCThreadPoolSize: $&#123;SW_CORE_GRPC_THREAD_POOL_SIZE:-1&#125; gRPCSslEnabled: $&#123;SW_CORE_GRPC_SSL_ENABLED:false&#125; gRPCSslKeyPath: $&#123;SW_CORE_GRPC_SSL_KEY_PATH:""&#125; gRPCSslCertChainPath: $&#123;SW_CORE_GRPC_SSL_CERT_CHAIN_PATH:""&#125; gRPCSslTrustedCAPath: $&#123;SW_CORE_GRPC_SSL_TRUSTED_CA_PATH:""&#125; downsampling: - Hour - Day # Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted. enableDataKeeperExecutor: $&#123;SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:true&#125; # Turn it off then automatically metrics data delete will be close. dataKeeperExecutePeriod: $&#123;SW_CORE_DATA_KEEPER_EXECUTE_PERIOD:5&#125; # How often the data keeper executor runs periodically, unit is minute recordDataTTL: $&#123;SW_CORE_RECORD_DATA_TTL:3&#125; # Unit is day metricsDataTTL: $&#123;SW_CORE_METRICS_DATA_TTL:7&#125; # Unit is day # Cache metrics data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute, # the metrics may not be accurate within that minute. enableDatabaseSession: $&#123;SW_CORE_ENABLE_DATABASE_SESSION:true&#125; topNReportPeriod: $&#123;SW_CORE_TOPN_REPORT_PERIOD:10&#125; # top_n record worker report cycle, unit is minute # Extra model column are the column defined by in the codes, These columns of model are not required logically in aggregation or further query, # and it will cause more load for memory, network of OAP and storage. # But, being activated, user could see the name in the storage entities, which make users easier to use 3rd party tool, such as Kibana-&gt;ES, to query the data by themselves. activeExtraModelColumns: $&#123;SW_CORE_ACTIVE_EXTRA_MODEL_COLUMNS:false&#125; # The max length of service + instance names should be less than 200 serviceNameMaxLength: $&#123;SW_SERVICE_NAME_MAX_LENGTH:70&#125; instanceNameMaxLength: $&#123;SW_INSTANCE_NAME_MAX_LENGTH:70&#125; # The max length of service + endpoint names should be less than 240 endpointNameMaxLength: $&#123;SW_ENDPOINT_NAME_MAX_LENGTH:150&#125; # Define the set of span tag keys, which should be searchable through the GraphQL. searchableTracesTags: $&#123;SW_SEARCHABLE_TAG_KEYS:http.method,status_code,db.type,db.instance,mq.queue,mq.topic,mq.broker&#125;storage: selector: $&#123;SW_STORAGE:h2&#125; elasticsearch: nameSpace: $&#123;SW_NAMESPACE:""&#125; clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:localhost:9200&#125; protocol: $&#123;SW_STORAGE_ES_HTTP_PROTOCOL:"http"&#125; user: $&#123;SW_ES_USER:""&#125; password: $&#123;SW_ES_PASSWORD:""&#125; trustStorePath: $&#123;SW_STORAGE_ES_SSL_JKS_PATH:""&#125; trustStorePass: $&#123;SW_STORAGE_ES_SSL_JKS_PASS:""&#125; secretsManagementFile: $&#123;SW_ES_SECRETS_MANAGEMENT_FILE:""&#125; # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool. dayStep: $&#123;SW_STORAGE_DAY_STEP:1&#125; # Represent the number of days in the one minute/hour/day index. indexShardsNumber: $&#123;SW_STORAGE_ES_INDEX_SHARDS_NUMBER:1&#125; # Shard number of new indexes indexReplicasNumber: $&#123;SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:1&#125; # Replicas number of new indexes # Super data set has been defined in the codes, such as trace segments.The following 3 config would be improve es performance when storage super size data in es. superDatasetDayStep: $&#123;SW_SUPERDATASET_STORAGE_DAY_STEP:-1&#125; # Represent the number of days in the super size dataset record index, the default value is the same as dayStep when the value is less than 0 superDatasetIndexShardsFactor: $&#123;SW_STORAGE_ES_SUPER_DATASET_INDEX_SHARDS_FACTOR:5&#125; # This factor provides more shards for the super data set, shards number = indexShardsNumber * superDatasetIndexShardsFactor. Also, this factor effects Zipkin and Jaeger traces. superDatasetIndexReplicasNumber: $&#123;SW_STORAGE_ES_SUPER_DATASET_INDEX_REPLICAS_NUMBER:0&#125; # Represent the replicas number in the super size dataset record index, the default value is 0. bulkActions: $&#123;SW_STORAGE_ES_BULK_ACTIONS:1000&#125; # Execute the async bulk record data every $&#123;SW_STORAGE_ES_BULK_ACTIONS&#125; requests syncBulkActions: $&#123;SW_STORAGE_ES_SYNC_BULK_ACTIONS:50000&#125; # Execute the sync bulk metrics data every $&#123;SW_STORAGE_ES_SYNC_BULK_ACTIONS&#125; requests flushInterval: $&#123;SW_STORAGE_ES_FLUSH_INTERVAL:10&#125; # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: $&#123;SW_STORAGE_ES_CONCURRENT_REQUESTS:2&#125; # the number of concurrent requests resultWindowMaxSize: $&#123;SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000&#125; metadataQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_MAX_SIZE:5000&#125; segmentQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200&#125; profileTaskQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200&#125; advanced: $&#123;SW_STORAGE_ES_ADVANCED:""&#125; elasticsearch7: nameSpace: $&#123;SW_NAMESPACE:""&#125; clusterNodes: $&#123;SW_STORAGE_ES_CLUSTER_NODES:localhost:9200&#125; protocol: $&#123;SW_STORAGE_ES_HTTP_PROTOCOL:"http"&#125; trustStorePath: $&#123;SW_STORAGE_ES_SSL_JKS_PATH:""&#125; trustStorePass: $&#123;SW_STORAGE_ES_SSL_JKS_PASS:""&#125; dayStep: $&#123;SW_STORAGE_DAY_STEP:1&#125; # Represent the number of days in the one minute/hour/day index. indexShardsNumber: $&#123;SW_STORAGE_ES_INDEX_SHARDS_NUMBER:1&#125; # Shard number of new indexes indexReplicasNumber: $&#123;SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:1&#125; # Replicas number of new indexes # Super data set has been defined in the codes, such as trace segments.The following 3 config would be improve es performance when storage super size data in es. superDatasetDayStep: $&#123;SW_SUPERDATASET_STORAGE_DAY_STEP:-1&#125; # Represent the number of days in the super size dataset record index, the default value is the same as dayStep when the value is less than 0 superDatasetIndexShardsFactor: $&#123;SW_STORAGE_ES_SUPER_DATASET_INDEX_SHARDS_FACTOR:5&#125; # This factor provides more shards for the super data set, shards number = indexShardsNumber * superDatasetIndexShardsFactor. Also, this factor effects Zipkin and Jaeger traces. superDatasetIndexReplicasNumber: $&#123;SW_STORAGE_ES_SUPER_DATASET_INDEX_REPLICAS_NUMBER:0&#125; # Represent the replicas number in the super size dataset record index, the default value is 0. user: $&#123;SW_ES_USER:""&#125; password: $&#123;SW_ES_PASSWORD:""&#125; secretsManagementFile: $&#123;SW_ES_SECRETS_MANAGEMENT_FILE:""&#125; # Secrets management file in the properties format includes the username, password, which are managed by 3rd party tool. bulkActions: $&#123;SW_STORAGE_ES_BULK_ACTIONS:1000&#125; # Execute the async bulk record data every $&#123;SW_STORAGE_ES_BULK_ACTIONS&#125; requests syncBulkActions: $&#123;SW_STORAGE_ES_SYNC_BULK_ACTIONS:50000&#125; # Execute the sync bulk metrics data every $&#123;SW_STORAGE_ES_SYNC_BULK_ACTIONS&#125; requests flushInterval: $&#123;SW_STORAGE_ES_FLUSH_INTERVAL:10&#125; # flush the bulk every 10 seconds whatever the number of requests concurrentRequests: $&#123;SW_STORAGE_ES_CONCURRENT_REQUESTS:2&#125; # the number of concurrent requests resultWindowMaxSize: $&#123;SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000&#125; metadataQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_MAX_SIZE:5000&#125; segmentQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200&#125; profileTaskQueryMaxSize: $&#123;SW_STORAGE_ES_QUERY_PROFILE_TASK_SIZE:200&#125; advanced: $&#123;SW_STORAGE_ES_ADVANCED:""&#125; h2: driver: $&#123;SW_STORAGE_H2_DRIVER:org.h2.jdbcx.JdbcDataSource&#125; url: $&#123;SW_STORAGE_H2_URL:jdbc:h2:mem:skywalking-oap-db&#125; user: $&#123;SW_STORAGE_H2_USER:sa&#125; metadataQueryMaxSize: $&#123;SW_STORAGE_H2_QUERY_MAX_SIZE:5000&#125; maxSizeOfArrayColumn: $&#123;SW_STORAGE_MAX_SIZE_OF_ARRAY_COLUMN:20&#125; numOfSearchableValuesPerTag: $&#123;SW_STORAGE_NUM_OF_SEARCHABLE_VALUES_PER_TAG:2&#125; mysql: properties: jdbcUrl: $&#123;SW_JDBC_URL:"jdbc:mysql://localhost:3306/swtest"&#125; dataSource.user: $&#123;SW_DATA_SOURCE_USER:root&#125; dataSource.password: $&#123;SW_DATA_SOURCE_PASSWORD:root@1234&#125; dataSource.cachePrepStmts: $&#123;SW_DATA_SOURCE_CACHE_PREP_STMTS:true&#125; dataSource.prepStmtCacheSize: $&#123;SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250&#125; dataSource.prepStmtCacheSqlLimit: $&#123;SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048&#125; dataSource.useServerPrepStmts: $&#123;SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true&#125; metadataQueryMaxSize: $&#123;SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000&#125; maxSizeOfArrayColumn: $&#123;SW_STORAGE_MAX_SIZE_OF_ARRAY_COLUMN:20&#125; numOfSearchableValuesPerTag: $&#123;SW_STORAGE_NUM_OF_SEARCHABLE_VALUES_PER_TAG:2&#125; tidb: properties: jdbcUrl: $&#123;SW_JDBC_URL:"jdbc:mysql://localhost:4000/tidbswtest"&#125; dataSource.user: $&#123;SW_DATA_SOURCE_USER:root&#125; dataSource.password: $&#123;SW_DATA_SOURCE_PASSWORD:""&#125; dataSource.cachePrepStmts: $&#123;SW_DATA_SOURCE_CACHE_PREP_STMTS:true&#125; dataSource.prepStmtCacheSize: $&#123;SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_SIZE:250&#125; dataSource.prepStmtCacheSqlLimit: $&#123;SW_DATA_SOURCE_PREP_STMT_CACHE_SQL_LIMIT:2048&#125; dataSource.useServerPrepStmts: $&#123;SW_DATA_SOURCE_USE_SERVER_PREP_STMTS:true&#125; dataSource.useAffectedRows: $&#123;SW_DATA_SOURCE_USE_AFFECTED_ROWS:true&#125; metadataQueryMaxSize: $&#123;SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000&#125; maxSizeOfArrayColumn: $&#123;SW_STORAGE_MAX_SIZE_OF_ARRAY_COLUMN:20&#125; numOfSearchableValuesPerTag: $&#123;SW_STORAGE_NUM_OF_SEARCHABLE_VALUES_PER_TAG:2&#125; influxdb: # InfluxDB configuration url: $&#123;SW_STORAGE_INFLUXDB_URL:http://localhost:8086&#125; user: $&#123;SW_STORAGE_INFLUXDB_USER:root&#125; password: $&#123;SW_STORAGE_INFLUXDB_PASSWORD:&#125; database: $&#123;SW_STORAGE_INFLUXDB_DATABASE:skywalking&#125; actions: $&#123;SW_STORAGE_INFLUXDB_ACTIONS:1000&#125; # the number of actions to collect duration: $&#123;SW_STORAGE_INFLUXDB_DURATION:1000&#125; # the time to wait at most (milliseconds) batchEnabled: $&#123;SW_STORAGE_INFLUXDB_BATCH_ENABLED:true&#125; fetchTaskLogMaxSize: $&#123;SW_STORAGE_INFLUXDB_FETCH_TASK_LOG_MAX_SIZE:5000&#125; # the max number of fetch task log in a requestagent-analyzer: selector: $&#123;SW_AGENT_ANALYZER:default&#125; default: sampleRate: $&#123;SW_TRACE_SAMPLE_RATE:10000&#125; # The sample rate precision is 1/10000. 10000 means 100% sample in default. slowDBAccessThreshold: $&#123;SW_SLOW_DB_THRESHOLD:default:200,mongodb:100&#125; # The slow database access thresholds. Unit ms. forceSampleErrorSegment: $&#123;SW_FORCE_SAMPLE_ERROR_SEGMENT:true&#125; # When sampling mechanism active, this config can open(true) force save some error segment. true is default. segmentStatusAnalysisStrategy: $&#123;SW_SEGMENT_STATUS_ANALYSIS_STRATEGY:FROM_SPAN_STATUS&#125; # Determine the final segment status from the status of spans. Available values are `FROM_SPAN_STATUS` , `FROM_ENTRY_SPAN` and `FROM_FIRST_SPAN`. `FROM_SPAN_STATUS` represents the segment status would be error if any span is in error status. `FROM_ENTRY_SPAN` means the segment status would be determined by the status of entry spans only. `FROM_FIRST_SPAN` means the segment status would be determined by the status of the first span only. # Nginx and Envoy agents can't get the real remote address. # Exit spans with the component in the list would not generate the client-side instance relation metrics. noUpstreamRealAddressAgents: $&#123;SW_NO_UPSTREAM_REAL_ADDRESS:6000,9000&#125; slowTraceSegmentThreshold: $&#123;SW_SLOW_TRACE_SEGMENT_THRESHOLD:-1&#125; # Setting this threshold about the latency would make the slow trace segments sampled if they cost more time, even the sampling mechanism activated. The default value is `-1`, which means would not sample slow traces. Unit, millisecond. meterAnalyzerActiveFiles: $&#123;SW_METER_ANALYZER_ACTIVE_FILES:&#125; # Which files could be meter analyzed, files split by ","receiver-sharing-server: selector: $&#123;SW_RECEIVER_SHARING_SERVER:default&#125; default: # For Jetty server restHost: $&#123;SW_RECEIVER_SHARING_REST_HOST:0.0.0.0&#125; restPort: $&#123;SW_RECEIVER_SHARING_REST_PORT:0&#125; contextPath: $&#123;SW_RECEIVER_SHARING_REST_CONTEXT_PATH:/&#125; restMinThreads: $&#123;SW_RECEIVER_SHARING_JETTY_MIN_THREADS:1&#125; restMaxThreads: $&#123;SW_RECEIVER_SHARING_JETTY_MAX_THREADS:200&#125; restIdleTimeOut: $&#123;SW_RECEIVER_SHARING_JETTY_IDLE_TIMEOUT:30000&#125; restAcceptorPriorityDelta: $&#123;SW_RECEIVER_SHARING_JETTY_DELTA:0&#125; restAcceptQueueSize: $&#123;SW_RECEIVER_SHARING_JETTY_QUEUE_SIZE:0&#125; # For gRPC server gRPCHost: $&#123;SW_RECEIVER_GRPC_HOST:0.0.0.0&#125; gRPCPort: $&#123;SW_RECEIVER_GRPC_PORT:0&#125; maxConcurrentCallsPerConnection: $&#123;SW_RECEIVER_GRPC_MAX_CONCURRENT_CALL:0&#125; maxMessageSize: $&#123;SW_RECEIVER_GRPC_MAX_MESSAGE_SIZE:0&#125; gRPCThreadPoolQueueSize: $&#123;SW_RECEIVER_GRPC_POOL_QUEUE_SIZE:0&#125; gRPCThreadPoolSize: $&#123;SW_RECEIVER_GRPC_THREAD_POOL_SIZE:0&#125; gRPCSslEnabled: $&#123;SW_RECEIVER_GRPC_SSL_ENABLED:false&#125; gRPCSslKeyPath: $&#123;SW_RECEIVER_GRPC_SSL_KEY_PATH:""&#125; gRPCSslCertChainPath: $&#123;SW_RECEIVER_GRPC_SSL_CERT_CHAIN_PATH:""&#125; authentication: $&#123;SW_AUTHENTICATION:""&#125;receiver-register: selector: $&#123;SW_RECEIVER_REGISTER:default&#125; default:receiver-trace: selector: $&#123;SW_RECEIVER_TRACE:default&#125; default:receiver-jvm: selector: $&#123;SW_RECEIVER_JVM:default&#125; default:receiver-clr: selector: $&#123;SW_RECEIVER_CLR:default&#125; default:receiver-profile: selector: $&#123;SW_RECEIVER_PROFILE:default&#125; default:service-mesh: selector: $&#123;SW_SERVICE_MESH:default&#125; default:envoy-metric: selector: $&#123;SW_ENVOY_METRIC:default&#125; default: acceptMetricsService: $&#123;SW_ENVOY_METRIC_SERVICE:true&#125; alsHTTPAnalysis: $&#123;SW_ENVOY_METRIC_ALS_HTTP_ANALYSIS:""&#125; # `k8sServiceNameRule` allows you to customize the service name in ALS via Kubernetes metadata, # the available variables are `pod`, `service`, f.e., you can use `$&#123;service.metadata.name&#125;-$&#123;pod.metadata.labels.version&#125;` # to append the version number to the service name. # Be careful, when using environment variables to pass this configuration, use single quotes(`''`) to avoid it being evaluated by the shell. k8sServiceNameRule: $&#123;K8S_SERVICE_NAME_RULE:"$&#123;service.metadata.name&#125;"&#125;prometheus-fetcher: selector: $&#123;SW_PROMETHEUS_FETCHER:-&#125; default: enabledRules: $&#123;SW_PROMETHEUS_FETCHER_ENABLED_RULES:"self"&#125;kafka-fetcher: selector: $&#123;SW_KAFKA_FETCHER:-&#125; default: bootstrapServers: $&#123;SW_KAFKA_FETCHER_SERVERS:localhost:9092&#125; partitions: $&#123;SW_KAFKA_FETCHER_PARTITIONS:3&#125; replicationFactor: $&#123;SW_KAFKA_FETCHER_PARTITIONS_FACTOR:2&#125; enableMeterSystem: $&#123;SW_KAFKA_FETCHER_ENABLE_METER_SYSTEM:false&#125; isSharding: $&#123;SW_KAFKA_FETCHER_IS_SHARDING:false&#125; consumePartitions: $&#123;SW_KAFKA_FETCHER_CONSUME_PARTITIONS:""&#125; kafkaHandlerThreadPoolSize: $&#123;SW_KAFKA_HANDLER_THREAD_POOL_SIZE:-1&#125; kafkaHandlerThreadPoolQueueSize: $&#123;SW_KAFKA_HANDLER_THREAD_POOL_QUEUE_SIZE:-1&#125;receiver-meter: selector: $&#123;SW_RECEIVER_METER:default&#125; default:receiver-otel: selector: $&#123;SW_OTEL_RECEIVER:-&#125; default: enabledHandlers: $&#123;SW_OTEL_RECEIVER_ENABLED_HANDLERS:"oc"&#125; enabledOcRules: $&#123;SW_OTEL_RECEIVER_ENABLED_OC_RULES:"istio-controlplane"&#125;receiver_zipkin: selector: $&#123;SW_RECEIVER_ZIPKIN:-&#125; default: host: $&#123;SW_RECEIVER_ZIPKIN_HOST:0.0.0.0&#125; port: $&#123;SW_RECEIVER_ZIPKIN_PORT:9411&#125; contextPath: $&#123;SW_RECEIVER_ZIPKIN_CONTEXT_PATH:/&#125; jettyMinThreads: $&#123;SW_RECEIVER_ZIPKIN_JETTY_MIN_THREADS:1&#125; jettyMaxThreads: $&#123;SW_RECEIVER_ZIPKIN_JETTY_MAX_THREADS:200&#125; jettyIdleTimeOut: $&#123;SW_RECEIVER_ZIPKIN_JETTY_IDLE_TIMEOUT:30000&#125; jettyAcceptorPriorityDelta: $&#123;SW_RECEIVER_ZIPKIN_JETTY_DELTA:0&#125; jettyAcceptQueueSize: $&#123;SW_RECEIVER_ZIPKIN_QUEUE_SIZE:0&#125;receiver_jaeger: selector: $&#123;SW_RECEIVER_JAEGER:-&#125; default: gRPCHost: $&#123;SW_RECEIVER_JAEGER_HOST:0.0.0.0&#125; gRPCPort: $&#123;SW_RECEIVER_JAEGER_PORT:14250&#125;receiver-browser: selector: $&#123;SW_RECEIVER_BROWSER:default&#125; default: # The sample rate precision is 1/10000. 10000 means 100% sample in default. sampleRate: $&#123;SW_RECEIVER_BROWSER_SAMPLE_RATE:10000&#125;query: selector: $&#123;SW_QUERY:graphql&#125; graphql: path: $&#123;SW_QUERY_GRAPHQL_PATH:/graphql&#125;alarm: selector: $&#123;SW_ALARM:default&#125; default:telemetry: selector: $&#123;SW_TELEMETRY:none&#125; none: prometheus: host: $&#123;SW_TELEMETRY_PROMETHEUS_HOST:0.0.0.0&#125; port: $&#123;SW_TELEMETRY_PROMETHEUS_PORT:1234&#125; sslEnabled: $&#123;SW_TELEMETRY_PROMETHEUS_SSL_ENABLED:false&#125; sslKeyPath: $&#123;SW_TELEMETRY_PROMETHEUS_SSL_KEY_PATH:""&#125; sslCertChainPath: $&#123;SW_TELEMETRY_PROMETHEUS_SSL_CERT_CHAIN_PATH:""&#125;configuration: selector: $&#123;SW_CONFIGURATION:none&#125; none: grpc: host: $&#123;SW_DCS_SERVER_HOST:""&#125; port: $&#123;SW_DCS_SERVER_PORT:80&#125; clusterName: $&#123;SW_DCS_CLUSTER_NAME:SkyWalking&#125; period: $&#123;SW_DCS_PERIOD:20&#125; apollo: apolloMeta: $&#123;SW_CONFIG_APOLLO:http://localhost:8080&#125; apolloCluster: $&#123;SW_CONFIG_APOLLO_CLUSTER:default&#125; apolloEnv: $&#123;SW_CONFIG_APOLLO_ENV:""&#125; appId: $&#123;SW_CONFIG_APOLLO_APP_ID:skywalking&#125; period: $&#123;SW_CONFIG_APOLLO_PERIOD:5&#125; zookeeper: period: $&#123;SW_CONFIG_ZK_PERIOD:60&#125; # Unit seconds, sync period. Default fetch every 60 seconds. nameSpace: $&#123;SW_CONFIG_ZK_NAMESPACE:/default&#125; hostPort: $&#123;SW_CONFIG_ZK_HOST_PORT:localhost:2181&#125; # Retry Policy baseSleepTimeMs: $&#123;SW_CONFIG_ZK_BASE_SLEEP_TIME_MS:1000&#125; # initial amount of time to wait between retries maxRetries: $&#123;SW_CONFIG_ZK_MAX_RETRIES:3&#125; # max number of times to retry etcd: period: $&#123;SW_CONFIG_ETCD_PERIOD:60&#125; # Unit seconds, sync period. Default fetch every 60 seconds. group: $&#123;SW_CONFIG_ETCD_GROUP:skywalking&#125; serverAddr: $&#123;SW_CONFIG_ETCD_SERVER_ADDR:localhost:2379&#125; clusterName: $&#123;SW_CONFIG_ETCD_CLUSTER_NAME:default&#125; consul: # Consul host and ports, separated by comma, e.g. 1.2.3.4:8500,2.3.4.5:8500 hostAndPorts: $&#123;SW_CONFIG_CONSUL_HOST_AND_PORTS:1.2.3.4:8500&#125; # Sync period in seconds. Defaults to 60 seconds. period: $&#123;SW_CONFIG_CONSUL_PERIOD:60&#125; # Consul aclToken aclToken: $&#123;SW_CONFIG_CONSUL_ACL_TOKEN:""&#125; k8s-configmap: period: $&#123;SW_CONFIG_CONFIGMAP_PERIOD:60&#125; namespace: $&#123;SW_CLUSTER_K8S_NAMESPACE:default&#125; labelSelector: $&#123;SW_CLUSTER_K8S_LABEL:app=collector,release=skywalking&#125; nacos: # Nacos Server Host serverAddr: $&#123;SW_CONFIG_NACOS_SERVER_ADDR:127.0.0.1&#125; # Nacos Server Port port: $&#123;SW_CONFIG_NACOS_SERVER_PORT:8848&#125; # Nacos Configuration Group group: $&#123;SW_CONFIG_NACOS_SERVER_GROUP:skywalking&#125; # Nacos Configuration namespace namespace: $&#123;SW_CONFIG_NACOS_SERVER_NAMESPACE:&#125; # Unit seconds, sync period. Default fetch every 60 seconds. period: $&#123;SW_CONFIG_NACOS_PERIOD:60&#125; # Nacos auth username username: $&#123;SW_CONFIG_NACOS_USERNAME:""&#125; password: $&#123;SW_CONFIG_NACOS_PASSWORD:""&#125; # Nacos auth accessKey accessKey: $&#123;SW_CONFIG_NACOS_ACCESSKEY:""&#125; secretKey: $&#123;SW_CONFIG_NACOS_SECRETKEY:""&#125;exporter: selector: $&#123;SW_EXPORTER:-&#125; grpc: targetHost: $&#123;SW_EXPORTER_GRPC_HOST:127.0.0.1&#125; targetPort: $&#123;SW_EXPORTER_GRPC_PORT:9870&#125;health-checker: selector: $&#123;SW_HEALTH_CHECKER:-&#125; default: checkIntervalSeconds: $&#123;SW_HEALTH_CHECKER_INTERVAL_SECONDS:5&#125; 插件安装Java代理插件都是可插入的。可以optional-plugins在代理或第三方存储库下的文件夹中提供可选插件。要使用这些插件，需要将目标插件jar文件放入/plugins。 目前已有的插件有： Plugin of tracing Spring annotation beans tracing Oracle and Resin Filter traces through specified endpoint name patterns Plugin of Gson serialization lib in optional plugin folder. Plugin of Zookeeper 3.4.x in optional plugin folder. The reason of being optional plugin is, many business irrelevant traces are generated, which cause extra payload to agents and backends. At the same time, those traces may be just heartbeat(s). Customize enhance Trace methods based on description files, rather than write plugin or change source codes. Plugin of Spring Cloud Gateway 2.1.x in optional plugin folder. Please only active this plugin when you install agent in Spring Gateway. spring-cloud-gateway-2.x-plugin and spring-webflux-5.x-plugin are both required. Plugin of Spring Transaction in optional plugin folder. The reason of being optional plugin is, many local span are generated, which also spend more CPU, memory and network. Plugin of Kotlin coroutine provides the tracing across coroutines automatically. As it will add local spans to all across routines scenarios, Please assess the performance impact. Plugin of quartz-scheduler-2.x in the optional plugin folder. The reason for being an optional plugin is, many task scheduling systems are based on quartz-scheduler, this will cause duplicate tracing and link different sub-tasks as they share the same quartz level trigger, such as ElasticJob. Plugin of spring-webflux-5.x in the optional plugin folder. Please only activate this plugin when you use webflux alone as a web container. If you are using SpringMVC 5 or Spring Gateway, you don’t need this plugin. 前端配置前端配置在文件夹webapp的webapp.yml文件里面。 客户端接入java应用执行命令里面加上1java -javaagent:/path/to/skywalking-agent/skywalking-agent.jar -Dskywalking_config=/path/to/agent.config -jar yourApp.jar 这里另外设置了agent的配置，具体agent的配置可以参考官方文档，这里贴上我自己的配置:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108# Licensed to the Apache Software Foundation (ASF) under one# or more contributor license agreements. See the NOTICE file# distributed with this work for additional information# regarding copyright ownership. The ASF licenses this file# to you under the Apache License, Version 2.0 (the# "License"); you may not use this file except in compliance# with the License. You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an "AS IS" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# The agent namespaceagent.namespace=$&#123;SW_AGENT_NAMESPACE:LOCAL&#125;# The service name in UIagent.service_name=$&#123;SW_AGENT_NAME:Activiti&#125;# The number of sampled traces per 3 seconds# Negative or zero means off, by defaultagent.sample_n_per_3_secs=$&#123;SW_AGENT_SAMPLE:-1&#125;# Authentication active is based on backend setting, see application.yml for more details.# agent.authentication = $&#123;SW_AGENT_AUTHENTICATION:xxxx&#125;# The max amount of spans in a single segment.# Through this config item, SkyWalking keep your application memory cost estimated.# agent.span_limit_per_segment=$&#123;SW_AGENT_SPAN_LIMIT:150&#125;# Ignore the segments if their operation names end with these suffix.# agent.ignore_suffix=$&#123;SW_AGENT_IGNORE_SUFFIX:.jpg,.jpeg,.js,.css,.png,.bmp,.gif,.ico,.mp3,.mp4,.html,.svg&#125;# If true, SkyWalking agent will save all instrumented classes files in `/debugging` folder.# SkyWalking team may ask for these files in order to resolve compatible problem.# agent.is_open_debugging_class = $&#123;SW_AGENT_OPEN_DEBUG:true&#125;# If true, SkyWalking agent will cache all instrumented classes files to memory or disk files (decided by class cache mode),# allow other javaagent to enhance those classes that enhanced by SkyWalking agent.# agent.is_cache_enhanced_class = $&#123;SW_AGENT_CACHE_CLASS:false&#125;# The instrumented classes cache mode: MEMORY or FILE# MEMORY: cache class bytes to memory, if instrumented classes is too many or too large, it may take up more memory# FILE: cache class bytes in `/class-cache` folder, automatically clean up cached class files when the application exits# agent.class_cache_mode = $&#123;SW_AGENT_CLASS_CACHE_MODE:MEMORY&#125;# The operationName max length# Notice, in the current practice, we don't recommend the length over 190.# agent.operation_name_threshold=$&#123;SW_AGENT_OPERATION_NAME_THRESHOLD:150&#125;# If true, skywalking agent will enable profile when user create a new profile task. Otherwise disable profile.# profile.active=$&#123;SW_AGENT_PROFILE_ACTIVE:true&#125;# Parallel monitor segment count# profile.max_parallel=$&#123;SW_AGENT_PROFILE_MAX_PARALLEL:5&#125;# Max monitor segment time(minutes), if current segment monitor time out of limit, then stop it.# profile.duration=$&#123;SW_AGENT_PROFILE_DURATION:10&#125;# Max dump thread stack depth# profile.dump_max_stack_depth=$&#123;SW_AGENT_PROFILE_DUMP_MAX_STACK_DEPTH:500&#125;# Snapshot transport to backend buffer size# profile.snapshot_transport_buffer_size=$&#123;SW_AGENT_PROFILE_SNAPSHOT_TRANSPORT_BUFFER_SIZE:50&#125;# Backend service addresses.collector.backend_service=$&#123;SW_AGENT_COLLECTOR_BACKEND_SERVICES:127.0.0.1:11800&#125;# Logging file_namelogging.file_name=$&#123;SW_LOGGING_FILE_NAME:skywalking-api.log&#125;# Logging levellogging.level=$&#123;SW_LOGGING_LEVEL:INFO&#125;# Logging dir# logging.dir=$&#123;SW_LOGGING_DIR:""&#125;# Logging max_file_size, default: 300 * 1024 * 1024 = 314572800# logging.max_file_size=$&#123;SW_LOGGING_MAX_FILE_SIZE:314572800&#125;# The max history log files. When rollover happened, if log files exceed this number,# then the oldest file will be delete. Negative or zero means off, by default.# logging.max_history_files=$&#123;SW_LOGGING_MAX_HISTORY_FILES:-1&#125;# Listed exceptions would not be treated as an error. Because in some codes, the exception is being used as a way of controlling business flow.# Besides, the annotation named IgnoredException in the trace toolkit is another way to configure ignored exceptions.# statuscheck.ignored_exceptions=$&#123;SW_STATUSCHECK_IGNORED_EXCEPTIONS:&#125;# The max recursive depth when checking the exception traced by the agent. Typically, we don't recommend setting this more than 10, which could cause a performance issue. Negative value and 0 would be ignored, which means all exceptions would make the span tagged in error status.# statuscheck.max_recursive_depth=$&#123;SW_STATUSCHECK_MAX_RECURSIVE_DEPTH:1&#125;# Mount the specific folders of the plugins. Plugins in mounted folders would work.plugin.mount=$&#123;SW_MOUNT_FOLDERS:plugins,activations&#125;# Exclude activated plugins# plugin.exclude_plugins=$&#123;SW_EXCLUDE_PLUGINS:&#125;# mysql plugin configurationplugin.mysql.trace_sql_parameters=$&#123;SW_MYSQL_TRACE_SQL_PARAMETERS:true&#125;# Kafka producer configuration# plugin.kafka.bootstrap_servers=$&#123;SW_KAFKA_BOOTSTRAP_SERVERS:localhost:9092&#125;# Match spring bean with regex expression for classname# plugin.springannotation.classname_match_regex=$&#123;SW_SPRINGANNOTATION_CLASSNAME_MATCH_REGEX:&#125; NodeJs接入123456789import Agent from 'skywalking';Agent.start(&#123; serviceName: '', serviceInstance: '', collectorAddress: '', authorization: '', maxBufferSize: 1000,&#125;); 参数包括： Environment Variable | Description | Default| — | — | — || SW_AGENT_NAME | The name of the service | your-nodejs-service || SW_AGENT_INSTANCE | The name of the service instance | Randomly generated || SW_AGENT_COLLECTOR_BACKEND_SERVICES | The backend OAP server address | 127.0.0.1:11800 || SW_AGENT_AUTHENTICATION | The authentication token to verify that the agent is trusted by the backend OAP, as for how to configure the backend, refer to the yaml. | not set || SW_AGENT_LOGGING_LEVEL | The logging level, could be one of CRITICAL, FATAL, ERROR, WARN(WARNING), INFO, DEBUG | INFO || SW_AGENT_MAX_BUFFER_SIZE | The maximum buffer size before sending the segment data to backend | &#39;1000&#39; | 前端接入可以参考官方文档 高级功能自己开发插件可以参考文章，已经写得很好了。。。我不需要再表述了. 开发插件后，可以给官方贡献一下 浏览器端监控、使用标签查询、指标分析语言参考官方文档 SkyWalking浏览器监视也提供以下数据: PV（page views，页面浏览量）， UV（unique visitors，独立访客数），浏览量前 N 的页面（Top N Page Views）等。这些数据可以为产品队伍优化他们的产品提供线索。 服务性能指标监控Skywalking还可以查看具体Service的性能指标，根据相关的性能指标可以分析系统的瓶颈所在并提出优化方案。 在服务调用拓扑图上点击相应的节点我们可以看到该服务的 SLA: 服务可用性（主要是通过请求成功与失败次数来计算） CPM: 每分钟调用次数 Avg Response Time: 平均响应时间 从应用整体外部来看我们可以监测到应用在一定时间段内的 服务可用性指标SLA 每分钟平均响应数 平均响应时间 服务进程PID 服务所在物理机的IP、HostName、Operation System 服务告警通过webhook的方式让我们可以自定义我们告警信息的通知方式。诸如:邮件通知、微信通知、短信通知等。 先来看一下告警的规则配置。在alarm-settings.xml中可以配置告警规则，告警规则支持自定义。 一份告警配置由以下几部分组成： service_resp_time_rule：告警规则名称 ***_rule （规则名称可以自定义但是必须以_rule结尾 indicator-name：指标数据名称： 定义参见http://t.cn/EGhfbmd op: 操作符： &gt; , &lt; , = 【当然你可以自己扩展开发其他的操作符】 threshold：目标值：指标数据的目标数据 如sample中的1000就是服务响应时间，配合上操作符就是大于1000ms的服务响应 period: 告警检查周期：多久检查一次当前的指标数据是否符合告警规则 counts: 达到告警阈值的次数 silence-period：忽略相同告警信息的周期 message：告警信息 webhooks：服务告警通知服务地 Skywalking通过HttpClient的方式远程调用在配置项webhooks中定义的告警通知服务地址。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql最佳实践]]></title>
    <url>%2F2020%2F12%2F08%2FMysql%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[建表规约强制要求 表达是与否概念的字段，必须使用 is_xxx 的方式命名，数据类型是 unsigned tinyint （1 表示是， 0 表示否）。 说明： 任何字段如果为非负数，必须是 unsigned。 正例： 表达逻辑删除的字段名 is_deleted， 1 表示删除， 0 表示未删除。 表名、字段名必须使用小写字母或数字，禁止出现数字开头，禁止两个下划线中间只出现数字。 数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。 说明： MySQL 在 Windows 下不区分大小写，但在 Linux 下默认是区分大小写。因此，数据库名、表名、字段名，都不允许出现任何大写字母，避免节外生枝。 正例： hap_admin， rdc_config， level3_name 反例： HapAdmin， rdcConfig， level_3_name 表名不使用复数名词。 说明： 表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于 DO 类名也是单数形式，符合表达习惯。 禁用保留字，如 desc、 range、 match、 delayed 等， 请参考 MySQL 官方保留字。 主键索引名为 pk_字段名； 唯一索引名为 uk_字段名； 普通索引名则为 idx_字段名。 说明： pk_ 即 primary key； uk_ 即 unique key； idx_ 即 index 的简称。 小数类型为 decimal，禁止使用 float 和 double。 说明： float 和 double 在存储的时候，存在精度损失的问题，很可能在值的比较时，得到不正确的结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数分开存储。 如果存储的字符串长度几乎相等，使用 char 定长字符串类型。 varchar 是可变长字符串，不预先分配存储空间，长度不要超过5000，如果存储长度大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效率。 说明： 该表的命名以 原表名_字段缩写 的格式命名。 表必备字段： id, create_date, last_update_date, create_by , last_update_by , object_version_number。 说明： 其中 id 必为主键，类型为 unsigned bigint、单表时自增、步长为 1。 create_date, last_update_date 的类型均为 datetime 类型，前者现在时表示主动创建，后者过去分词表示被动更新。 12345column(name: "object_version_number", type: "BIGINT UNSIGNED", defaultValue: "1")column(name: "created_by", type: "BIGINT UNSIGNED", defaultValue: "0")column(name: "creation_date", type: "DATETIME", defaultValueComputed: "CURRENT_TIMESTAMP")column(name: "last_updated_by", type: "BIGINT UNSIGNED", defaultValue: "0")column(name: "last_update_date", type: "DATETIME", defaultValueComputed: "CURRENT_TIMESTAMP") 表的命名最好是加上“业务名称_表的作用”。 正例： kanban_task / devops_project / website_config id类型没有特殊要求，必须使用bigint unsigned，禁止使用int，即使现在的数据量很小。id如果是数字类型的话，必须是8个字节。参见最后例子 方便对接外部系统，还有可能产生很多废数据 避免废弃数据对系统id的影响 未来分库分表，自动生成id，一般也是8个字节 更新数据表记录时，必须同时更新记录对应的 last_update_date 字段值为当前时间, 推荐规约 库名与应用名称尽量一致。 如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。 字段允许适当冗余，以提高查询性能，但必须考虑数据一致。冗余字段应遵循： 不是频繁修改的字段。 不是 varchar 超长字段，更不能是 text 字段。 正例： 商品类目名称使用频率高， 字段长度短，名称基本一成不变， 可在相关联的表中冗余存储类目名称，避免关联查询。 单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。 说明： 如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。 规约参考 合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度。 正例： 如下表，其中无符号值可以避免误存负数，且扩大了表示范围。 |对象|年龄区间|类型|字节|表示范围||—-|——–|—-|—-|——–||人|150岁之内|unsigned tinyint|1|无符号值： 0 到 255||龟|数百岁|unsigned smallint|2|无符号值： 0 到 65535||恐龙化石|数千万年|unsigned int|4|无符号值： 0 到约 42.9 亿||太阳|约 50 亿年|unsigned bigint|8|无符号值： 0 到约 10 的 19 次方| 索引规约强制要求 业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。 说明：不要以为唯一索引影响了insert速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。 超过三个表禁止join。需要join的字段，数据类型必须绝对一致；多表关联查询时，保证被关联的字段需要有索引。 说明：即使双表join也要注意表索引、SQL性能。 在varchar字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度即可。 说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达90%以上，可以使用 count(distinct left(列名,索引长度))/count(*)的区分度来确定。 页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决(项目前期数据量不大可以不遵循这个要求，后续改进，不过需要留痕)。 说明：索引文件具有B-Tree的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。 推荐规约 如果有order by的场景，请注意利用索引的有序性。order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，避免出现file_sort的情况，影响查询性能。 正例： where a=? and b=? order by c; 索引： a_b_c 反例： 索引中有范围查找，那么索引有序性无法利用，如： WHERE a&gt;10 ORDER BY b; 索引a_b无法排序。 利用覆盖索引来进行查询操作， 避免回表。 说明：如果一本书需要知道第 11 章是什么标题，会翻开第 11章对应的那一页吗？目录浏览一下就好，这个目录就是起到覆盖索引的作用。 正例：能够建立索引的种类分为主键索引、唯一索引、普通索引三种，而覆盖索引只是一种查询的一种效果，用explain 的结果，extra 列会出现： using index。 利用延迟关联或者子查询优化超多分页场景。 说明：MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前offset行，返回N行，那当 offset 特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。 正例：先快速定位需要获取的 id 段，然后再关联： 1SELECT a.* FROM 表 1 a, (select id from 表 1 where 条件 LIMIT 100000,20 ) b where a.id=b.id SQL 性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts最好。 说明： consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。 ref 指的是使用普通的索引（normal index） 。 range 对索引进行范围检索。 反例： explain 表的结果， type=index，索引物理文件全扫描，速度非常慢，这个 index 级别比较 range 还低，与全表扫描是小巫见大巫。 建组合索引的时候，区分度最高的在最左边。 正例： 如果 where a=? and b=? ， a列的几乎接近于唯一值，那么只需要单建 idx_a 索引即可。 说明： 存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。如： where a&gt;? and b=? 那么即使 a 的区分度更高，也必须把 b 放在索引的最前列。 防止因字段类型不同造成的隐式转换，导致索引失效。 总结 索引占磁盘空间，不要重复的索引，尽量短 只给常用的查询条件加索引 过滤性高的列建索引，取值范围固定的列不建索引 唯一的记录添加唯一索引 频繁更新的列不要建索引 不要对索引列运算 同样过滤效果下，保持索引长度最小 合理利用组合索引，注意索引字段先后顺序 多列组合索引，过滤性高的字段最前 order by 字段建立索引，避免 filesort 组合索引，不同的排序顺序不能使用索引 &lt;&gt;!=无法使用索引 规约参考 创建索引时避免有如下极端误解： 宁滥勿缺。 认为一个查询就需要建一个索引。 宁缺勿滥。认为索引会消耗空间、严重拖慢更新和新增速度。 抵制惟一索引。认为业务的惟一性一律需要在应用层通过“先查后插”方式解决。 SQL 语句强制要求 不要使用 count(列名)或 count(常量)来替代 count(\*)， count(*)是 SQL92 定义的标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。 说明： count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。 count(distinct col) 计算该列除 NULL 之外的不重复行数， 注意 count(distinct col1, col2) 如果其中一列全为 NULL，那么即使另一列有不同的值，也返回为 0。 当某一列的值全是 NULL 时， count(col)的返回结果为 0，但 sum(col)的返回结果为 NULL，因此使用 sum()时需注意 NPE 问题。 正例： 可以使用如下方式来避免 sum 的 NPE 问题： 12SELECT IF(ISNULL(SUM(g)),0,SUM(g))FROM table; 使用 ISNULL()来判断是否为 NULL 值。 说明： NULL 与任何值的直接比较都为 NULL。 NULL&lt;&gt;NULL 的返回结果是 NULL， 而不是 false。 NULL=NULL 的返回结果是 NULL， 而不是 true。 NULL&lt;&gt;1 的返回结果是 NULL，而不是 true。 在代码中写分页查询逻辑时，若 count 为 0 应直接返回，避免执行后面的分页语句。 不得使用外键与级联，一切外键概念必须在应用层解决。 说明：以学生和成绩的关系为例，学生表中的 student_id是主键，那么成绩表中的 student_id 则为外键。如果更新学生表中的 student_id，同时触发成绩表中的 student_id 更新， 即为级联更新。外键与级联更新适用于单机低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险:外键影响数据库的插入速度。 禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。 数据订正（特别是删除、 修改记录操作） 时，要先 select，避免出现误删除，确认无误才能执行更新语句。 推荐规约 in 操作能避免则避免，若实在避免不了，需要仔细评估 in 后边的集合元素数量，控制在 1000 个之内。(多的话用 EXISTS 或 NOT EXISTS 代替) 规约参考 如果有全球化需要，所有的字符存储与表示，均以 utf-8 编码，注意字符统计函数的区别。 说明： 12SELECT LENGTH("轻松工作")；\\返回为 12SELECT CHARACTER_LENGTH("轻松工作")；\\返回为 4 如果需要存储表情，那么选择 utf8mb4 来进行存储，注意它与 utf-8 编码的区别。 不建议在开发代码中使用此语句 TRUNCATE TABLE TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但 TRUNCATE 无事务且不触发 trigger，有可能造成事故，故不建议在开发代码中使用此语句。 说明： TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同。 总结 能够快速缩小结果集的 WHERE 条件写在前面，如果有恒量条 件，也尽量放在前面 ，例如 where 1=1 避免使用 GROUP BY、DISTINCT 等语句的使用，避免联表查 询和子查询 能够使用索引的字段尽量进行有效的合理排列 针对索引字段使用 &gt;, &gt;=, =, &lt;, &lt;=, IF NULL 和 BETWEEN 将会 使用索引，如果对某个索引字段进行 LIKE 查询，使用 LIKE ‘%abc%’ 不能使用索引，使用 LIKE ‘abc%’ 将能够使用索引 如果在 SQL 里使用了 MySQL部分自带函数，索引将失效 避免直接使用 select *,只取需要的字段，增加使用覆盖索引使用的可能 对于大数据量的查询，尽量避免在 SQL 语句中使用 order by 字句 连表查询的情况下，要确保关联条件的数据类型一致，避免嵌套子查询 对于连续的数值，使用 between 代替 in where 语句中尽量不要使用 CASE 条件 当只要一行数据时使用 LIMIT 1 ORM 映射强制要求 在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明。 说明： 增加查询分析器解析成本. 增减字段容易与 resultMap 配置不一致。 POJO 类的布尔属性不能加 is，而数据库字段必须加 is_，要求在 resultMap 中进行字段与属性之间的映射。 不要用 resultClass 当返回参数，即使所有类属性名与数据库字段一一对应，也需要定义；反过来，每一个表也必然有一个与之对应。 说明： 配置映射关系，使字段与 DO 类解耦，方便维护。 sql.xml 配置参数使用： #{}， #param# 不要使用${} 此种方式容易出现 SQL 注入。 iBATIS 自带的 queryForList(String statementName,int start,int size)不推荐使用。 说明：其实现方式是在数据库取到 statementName对应的SQL语句的所有记录，再通过 subList取 start,size 的子集合。 正例： 123Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();map.put("start", start);map.put("size", size); 不允许直接拿 HashMap 与 Hashtable 作为查询结果集的输出。 说明： resultClass=”Hashtable”， 会置入字段名和属性值，但是值的类型不可控。 更新数据表记录时，必须同时更新记录对应的 gmt_modified 字段值为当前时间。 推荐规约 不要写一个大而全的数据更新接口。 传入为 POJO 类，不管是不是自己的目标更新字段，都进行 update table set c1=value1,c2=value2,c3=value3; 这是不对的。执行 SQL时， 不要更新无改动的字段，一是易出错； 二是效率低； 三是增加 binlog 存储。 规约参考 @Transactional 事务不要滥用。事务会影响数据库的 QPS，另外使用事务的地方需要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。 &lt;isEqual&gt;中的 compareValue 是与属性值对比的常量，一般是数字，表示相等时带上此条件； &lt;isNotEmpty&gt;表示不为空且不为 null 时执行；&lt;isNotNull&gt;表示不为 null 值时执行。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git提交规范]]></title>
    <url>%2F2020%2F11%2F08%2FGit%E6%8F%90%E4%BA%A4%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[设置用户首次拉代码后，在目录下用命令行设置用户信息 123git config core.ignorecase falsegit config --global user.name "张三"git config --global user.email san.zhang@gmail.com Git Commit规范规定格式如下：123&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt; #issue_number&lt;description&gt; 其中，type、scope、subject是必需的，description 可以省略。不管是哪一个部分，任何一行都不得超过72个字符（或100个字符）。这是为了避免自动换行影响美观。 type(必须)取值说明type用于说明 commit 的类别: feat: (feature)增加新功能 fix: 修补bug docs: 文档（documentation）， 只改动了文档相关的内容 style: 不影响代码含义的改动，例如去掉空格、改变缩进、增删分号 build: 构造工具的或者外部依赖的改动，例如webpack，npm refactor: 代码重构时使用 revert：回滚到上一个版本,执行git revert打印的message test: 添加测试或者修改现有测试 pref: 提高性能的改动 chore: 不修改src或者test的其余修改，例如构建过程或辅助工具的变动 merge：代码合并 sync：同步主线或分支的Bug ci: 与CI（持续集成服务）有关的改动 scope(可选)取值说明scope用于说明 commit影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。例如：node-pc/common rrd-h5/activity，而we-sdk不需指定模块名。如果一次commit修改多个模块，建议拆分成多次commit，以便更好追踪和维护。后加入项目的新成员应遵循已有的 scope 约定（通过 git log可以查看某个文件的提交历史），不要自己编造。使用首字母小写的驼峰命名。除具体的模块、组件名之外，可以使用 base 表示基础结构、框架相关的改动，用 misc 表示杂项改动，用 all 表示大范围重构。 例如在Angular，可以是location，browser，compile，compile，rootScope， ngHref，ngClick，ngView等。如果你的修改影响了不止一个scope，你可以使用*代替。 subject(必须)subject是 commit 目的的简短描述，50 个字符左右的简要说明。 中文 结尾不加句号或其他标点符号。 根据以上规范git commit message将是如下的格式：12fix(DAO):用户查询缺少username属性 feat(Controller):用户查询接口开发 以上就是我们梳理的git commit规范，那么我们这样规范git commit到底有哪些好处呢？ 便于程序员对提交历史进行追溯，了解发生了什么情况。 一旦约束了commit message，意味着我们将慎重的进行每一次提交，不能再一股脑的把各种各样的改动都放在一个git commit里面，这样一来整个代码改动的历史也将更加清晰。 格式化的commit message才可以用于自动化输出Change log。 英文首字母小写，通常是动宾结构，描述做了什么事情，动词用一般现在时，禁止出现 update code ， fix bug 等无实际意义的描述，好的例子： select connector by sorting free memory （不需要形如 update about how to select connector … 的啰嗦写法）, fix success tip can not show on IE8 （不需要形如 fix bug of … 的啰嗦写法） 以动词开头，使用第一人称现在时，比如change，而不是changed或changes 尽量使用简单句保证简洁性 第一个字母小写 结尾不加句号（.） 通过翻译检测工具确认英文的正确性和可读性 bodybody填写详细描述，主要描述改动之前的情况及修改动机，对于小的修改不作要求，但是重大需求、更新等必须添加body来作说明。 break changesbreak changes指明是否产生了破坏性修改，涉及break changes的改动必须指明该项，类似版本升级、接口参数减少、接口删除、迁移等。 affect issuesaffect issues指明是否影响了某个问题。例如我们使用jira时，我们在commit message中可以填写其影响的JIRA_ID，若要开启该功能需要先打通jira与gitlab。 使用Commitizen工具安装commitizen1npm install -g commitizen 安装完成后，使用123456789101112131415161718192021222324252627282930313233343536373839(base) [@dinghuangMacPro:test (master)]$git add .(base) [@dinghuangMacPro:test (master)]$git cz#会出现下面的，按照提示写入(base) [@dinghuangMacPro:test (master)]$ git czcz-cli@4.2.2, cz-conventional-changelog@3.3.0? Select the type of change that you're committing: (Use arrow keys)❯ feat: A new feature fix: A bug fix docs: Documentation only changes style: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc) refactor: A code change that neither fixes a bug nor adds a feature perf: A code change that improves performance test: Adding missing tests or correcting existing tests(Move up and down to reveal more choices)#选择类型后? Select the type of change that you're committing: feat: A new feature? What is the scope of this change (e.g. component or file name): (press enter to skip) add aa.txt? Write a short, imperative tense description of the change (max 82 chars): (4) 新增文件? Provide a longer description of the change: (press enter to skip) 长描述：这是我第一次的提交? Are there any breaking changes? No? Does this change affect any open issues? Yes? Add issue references (e.g. "fix #123", "re #123".): feat #123#查看生成的git commit信息(base) [@dinghuangMacPro:test (master)]$ git logcommit 00d63b2c54c502bb75725e5a461d6ce9499910bc (HEAD -&gt; master)Author: 丁煌 &lt;dinghuang123@gmail.com&gt;Date: Wed Nov 25 13:39:13 2020 +0800 feat(add aa.txt): 新增文件 长描述：这是我第一次的提交 feat #123 自动生成Change log12npm install -g conventional-changelog-cliconventional-changelog -p angular -i CHANGELOG.md -s 这个插件是根据当前分支提交的所有commit信息来生成对应的changelog，一般是在开发完成后，封代码后去进行生成。如果自动生成的有问题，可以根据自己的需求进行修改。 分支规范分支基本原则基本原则：master为保护分支，不直接在master上进行代码修改和提交。 开发日常需求或者项目时，从master分支上checkout一个feature分支进行开发或者bugfix分支进行bug修复，功能测试完毕并且项目发布上线后，将feature分支合并到主干master，并且打Tag发布，最后删除开发分支。 分支命名规范例如： 分支版本命名规则：分支类型 分支发布时间 分支功能。比如：feature_20200401_#issueNum 分支类型包括：feature、bugfix、refactor三种类型，即新功能开发、bug修复和代码重构 时间使用年月日进行命名，不足2位补0 分支功能命名使用snake case命名法，即下划线命名。 Tag包括3位版本，前缀使用v。比如v1.2.31。Tag命名规范： 新功能开发使用第2位版本号，bug修复使用第3位版本号 核心基础库或者Node中间价可以在大版本发布请使用灰度版本号，在版本后面加上后缀，用中划线分隔。alpha或者belta后面加上次数，即第几次alpha(具体可以查看语义化版本)： v2.0.0-alpha-1 v2.0.0-belta-1]]></content>
      <categories>
        <category>GIT</category>
      </categories>
      <tags>
        <tag>GIT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot2.X Security Oauth2 JWT]]></title>
    <url>%2F2020%2F10%2F20%2FSpringBoot2.X%20Security%20Oauth2%20JWT%2F</url>
    <content type="text"><![CDATA[简介官网地址 官方文档 Spring Security，这是一种基于 Spring AOP 和 Servlet 过滤器的安全框架。它提供全面的安全性解决方案，同时在 Web 请求级和方法调用级处理身份确认和授权。 Spring Security当前支持与所有以下技术的身份验证集 HTTP BASIC authentication headers (an IETF RFC-based standard) HTTP Digest authentication headers (an IETF RFC-based standard) HTTP X.509 client certificate exchange (an IETF RFC-based standard) LDAP (a very common approach to cross-platform authentication needs, especially in large environments) Form-based authentication (for simple user interface needs) OpenID authentication Authentication based on pre-established request headers (such as Computer Associates Siteminder) JA-SIG Central Authentication Service (otherwise known as CAS, which is a popular open source single sign-on system) Transparent authentication context propagation for Remote Method Invocation (RMI) and HttpInvoker (a Spring remoting protocol) Automatic “remember-me” authentication (so you can tick a box to avoid re-authentication for a predetermined period of time) Anonymous authentication (allowing every unauthenticated call to automatically assume a particular security identity) Run-as authentication (which is useful if one call should proceed with a different security identity) Java Authentication and Authorization Service (JAAS) JEE container autentication (so you can still use Container - Managed Authentication if desired) Kerberos Java Open Source Single Sign On (JOSSO) * OpenNMS Network Management Platform * AppFuse * AndroMDA * Mule ESB * Direct Web Request (DWR) * Grails * Tapestry * JTrac * Jasypt * Roller * Elastic Path * Atlassian Crowd * Your own authentication systems (see below) 涉及以下系统组件：客户端：它可以是任何平台上的任何Web服务使用者。简而言之，它可以是另一个WebService，UI应用程序或Mobile平台，它们希望通过应用程序以安全的方式读写数据。授权服务器：验证用户凭据，并颁发令牌。它根据不同的授予类型发行令牌。下面列出了最常见的OAuth 2.0授权类型： Authorization Code Implicit Password Client Credentials Device Code Refresh Token 名词解释可以看SpringOauth2官方文档 架构设计 名词解释– WebSecurityConfigurerAdapter 是我们安全实施的关键。它提供HttpSecurity配置以配置cors，csrf，会话管理以及受保护资源的规则。我们还可以扩展和定制包含以下元素的默认配置。 – UserDetailsService 接口有一种方法可以按用户名加载User并返回UserDetailsSpring Security可以用于认证和验证的对象。 – UserDetails 包含用于构建身份验证对象的必要信息（例如：用户名，密码，授权机构）。 – UsernamePasswordAuthenticationToken 从登录请求中获取{用户名，密码}，AuthenticationManager将使用它来认证登录帐户。 – AuthenticationManager 有一个DaoAuthenticationProvider（与帮助UserDetailsService＆PasswordEncoder）来验证UsernamePasswordAuthenticationToken对象。如果成功，则AuthenticationManager返回完全填充的身份验证对象（包括授予的权限）。 – OncePerRequestFilter 对我们API的每个请求执行一次。它提供了一种doFilterInternal()方法，我们将实现解析和验证JWT，加载用户详细信息（使用UserDetailsService），检查授权（使用UsernamePasswordAuthenticationToken）。 – AuthenticationEntryPoint 当客户端未经身份验证访问受保护的资源时，将捕获未经授权的错误并返回401。 认证流程 实践引入maven包123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;org.springframework.security.oauth2&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2-parent&lt;/artifactId&gt; &lt;version&gt;1.0.0.BUILD-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;auth-server&lt;/module&gt; &lt;module&gt;client-app&lt;/module&gt; &lt;module&gt;resource-server&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security.oauth&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2&lt;/artifactId&gt; &lt;version&gt;2.4.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security.oauth.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-security-oauth2-autoconfigure&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring-security-jwt&lt;/artifactId&gt; &lt;version&gt;1.1.0.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;version&gt;2.2.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 核心代码：1234567891011121314151617181920212223242526package org.springframework.security.oauth.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.core.AuthenticationException;import org.springframework.security.web.AuthenticationEntryPoint;import javax.servlet.ServletException;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */@Configurationpublic class CustomerAuthenticationEntryPointConfiguration implements AuthenticationEntryPoint &#123; @Override public void commence(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, AuthenticationException e) throws IOException, ServletException &#123; //处理异常消息通知 httpServletResponse.getWriter().write("暂无权限访问"); &#125;&#125; 123456789101112131415161718192021222324252627282930313233package org.springframework.security.oauth.config;import org.springframework.context.annotation.Configuration;import org.springframework.security.authentication.AuthenticationProvider;import org.springframework.security.authentication.UsernamePasswordAuthenticationToken;import org.springframework.security.core.Authentication;import org.springframework.security.core.AuthenticationException;import org.springframework.security.core.authority.AuthorityUtils;import org.springframework.security.core.context.SecurityContextHolder;import org.springframework.security.core.userdetails.User;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */@Configurationpublic class CustomerAuthenticationProviderConfiguration implements AuthenticationProvider &#123; @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; //这里做自定义的用户校验,可以对用户进行继承扩展 User user = new User((String) authentication.getPrincipal(), (String) authentication.getCredentials(), AuthorityUtils.commaSeparatedStringToAuthorityList("admin")); //这里可以通过继承AbstractAuthenticationToken进行扩展 UsernamePasswordAuthenticationToken usernamePasswordAuthenticationToken = new UsernamePasswordAuthenticationToken(authentication.getPrincipal(), authentication.getCredentials()); usernamePasswordAuthenticationToken.setDetails(user); SecurityContextHolder.getContext().setAuthentication(usernamePasswordAuthenticationToken); return usernamePasswordAuthenticationToken; &#125; @Override public boolean supports(Class&lt;?&gt; aClass) &#123; return false; &#125;&#125; 1234567891011121314151617181920212223package org.springframework.security.oauth.config;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.security.authentication.AuthenticationManager;import org.springframework.security.core.Authentication;import org.springframework.security.core.AuthenticationException;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */@Configurationpublic class CustomerAuthenticationManager implements AuthenticationManager &#123; @Autowired private CustomerAuthenticationProviderConfiguration customerAuthenticationProviderConfiguration; @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException &#123; return customerAuthenticationProviderConfiguration.authenticate(authentication); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package org.springframework.security.oauth.config;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import org.springframework.security.oauth.properties.Oauth2ClientProperties;import org.springframework.security.oauth.properties.Oauth2Properties;import org.springframework.security.oauth2.config.annotation.builders.InMemoryClientDetailsServiceBuilder;import org.springframework.security.oauth2.config.annotation.configurers.ClientDetailsServiceConfigurer;import org.springframework.security.oauth2.config.annotation.web.configuration.AuthorizationServerConfigurerAdapter;import org.springframework.security.oauth2.config.annotation.web.configuration.EnableAuthorizationServer;import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerEndpointsConfigurer;import org.springframework.security.oauth2.config.annotation.web.configurers.AuthorizationServerSecurityConfigurer;import org.springframework.security.oauth2.provider.token.TokenStore;import org.springframework.security.oauth2.provider.token.store.JwtAccessTokenConverter;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */@Configuration@EnableAuthorizationServerpublic class CustomerAuthorizationServerConfiguration extends AuthorizationServerConfigurerAdapter &#123; @Autowired private TokenStore tokenStore; @Autowired private JwtAccessTokenConverter jwtAccessTokenConverter; @Autowired private CustomerAuthenticationManager customerAuthenticationManager; @Autowired private Oauth2Properties oauth2Properties; @Autowired private CustomerWebResponseExceptionTranslator customerWebResponseExceptionTranslator; @Override public void configure(AuthorizationServerEndpointsConfigurer authorizationServerEndpointsConfigurer) &#123; authorizationServerEndpointsConfigurer.tokenEnhancer(jwtAccessTokenConverter) .tokenStore(tokenStore) .authenticationManager(customerAuthenticationManager) .exceptionTranslator(customerWebResponseExceptionTranslator); &#125; @Override public void configure(AuthorizationServerSecurityConfigurer authorizationServerSecurityConfigurer) throws Exception &#123; authorizationServerSecurityConfigurer.tokenKeyAccess("permitAll()") .allowFormAuthenticationForClients() .checkTokenAccess("isAuthenticated"); &#125; @Override public void configure(ClientDetailsServiceConfigurer clientDetailsServiceConfigurer) throws Exception &#123; InMemoryClientDetailsServiceBuilder inMemoryClientDetailsServiceBuilder = clientDetailsServiceConfigurer.inMemory(); for (Oauth2ClientProperties oauth2ClientProperties : oauth2Properties.getClients()) &#123; inMemoryClientDetailsServiceBuilder.withClient(oauth2ClientProperties.getClientId()) .secret(bCryptPasswordEncoder().encode(oauth2ClientProperties.getClientSecret())) .accessTokenValiditySeconds(oauth2ClientProperties.getAccessTokenValiditySeconds()) .refreshTokenValiditySeconds(oauth2ClientProperties.getRefreshTokenValiditySeconds()) .authorizedGrantTypes("refresh_token", "password", "authorization_code") .scopes(oauth2ClientProperties.getScopes()); &#125; &#125; @Bean public BCryptPasswordEncoder bCryptPasswordEncoder() &#123; return new BCryptPasswordEncoder(); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738package org.springframework.security.oauth.config;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.security.authentication.AuthenticationManager;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.oauth.filter.CustomerOauth2AuthenticationProcessingFilter;import org.springframework.security.web.authentication.AnonymousAuthenticationFilter;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */@Configuration@EnableWebSecuritypublic class CustomerSecurityConfiguration extends WebSecurityConfigurerAdapter &#123; @Autowired private CustomerAuthenticationManager customerAuthenticationManager; @Autowired private CustomerAuthenticationEntryPointConfiguration customerAuthenticationEntryPointConfiguration; @Autowired private CustomerOauth2AuthenticationProcessingFilter customerOauth2AuthenticationProcessingFilter; @Override protected void configure(HttpSecurity httpSecurity) throws Exception&#123; httpSecurity.authorizeRequests().anyRequest().authenticated().and().addFilterBefore(customerOauth2AuthenticationProcessingFilter, AnonymousAuthenticationFilter.class) .csrf().disable().exceptionHandling().authenticationEntryPoint(customerAuthenticationEntryPointConfiguration); &#125; @Override public AuthenticationManager authenticationManager()&#123; return customerAuthenticationManager; &#125;&#125; 12345678910111213141516171819package org.springframework.security.oauth.config;import org.springframework.context.annotation.Configuration;import org.springframework.http.ResponseEntity;import org.springframework.security.oauth2.common.exceptions.OAuth2Exception;import org.springframework.security.oauth2.provider.error.WebResponseExceptionTranslator;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */@Configurationpublic class CustomerWebResponseExceptionTranslator implements WebResponseExceptionTranslator&lt;OAuth2Exception&gt; &#123; @Override public ResponseEntity&lt;OAuth2Exception&gt; translate(Exception e) throws Exception &#123; //自定义认证失败信息 return null; &#125;&#125; 123456789101112131415161718192021package org.springframework.security.oauth.config.token;import org.springframework.context.annotation.Configuration;import org.springframework.security.authentication.AbstractAuthenticationToken;import org.springframework.security.oauth2.provider.OAuth2Authentication;import org.springframework.security.oauth2.provider.token.AuthenticationKeyGenerator;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */@Configurationpublic class CustomerAuthenticationKeyGeneratorConfiguration implements AuthenticationKeyGenerator &#123; @Override public String extractKey(OAuth2Authentication authentication) &#123; //自定义token生成，可以用来实现ip控制登录用户只能有一个，顶掉登录 return null; &#125;&#125; 123456789101112131415161718192021package org.springframework.security.oauth.config.token;import io.jsonwebtoken.JwtHandlerAdapter;import org.springframework.context.annotation.Configuration;import org.springframework.security.oauth2.common.OAuth2AccessToken;import org.springframework.security.oauth2.provider.OAuth2Authentication;import org.springframework.security.oauth2.provider.token.store.JwtAccessTokenConverter;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */@Configurationpublic class CustomerJwtAccessTokenConverterConfiguration extends JwtAccessTokenConverter &#123; @Override public OAuth2AccessToken enhance(OAuth2AccessToken oAuth2AccessToken, OAuth2Authentication oAuth2Authentication)&#123; //可以实现jwt的token放一些用户信息 return super.enhance(oAuth2AccessToken,oAuth2Authentication); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940package org.springframework.security.oauth.config.token;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.security.oauth.properties.Oauth2Properties;import org.springframework.security.oauth2.provider.token.TokenStore;import org.springframework.security.oauth2.provider.token.store.JwtAccessTokenConverter;import org.springframework.security.oauth2.provider.token.store.redis.RedisTokenStore;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */@Configurationpublic class CustomerJwtStoreConfiguration &#123; @Autowired private RedisConnectionFactory redisConnectionFactory; @Autowired private Oauth2Properties oauth2Properties; @Autowired private CustomerAuthenticationKeyGeneratorConfiguration customerAuthenticationKeyGeneratorConfiguration; @Autowired private CustomerJwtAccessTokenConverterConfiguration customerJwtAccessTokenConverterConfiguration; @Bean public TokenStore redisTokenStore() &#123; RedisTokenStore redisTokenStore = new RedisTokenStore(redisConnectionFactory); redisTokenStore.setAuthenticationKeyGenerator(customerAuthenticationKeyGeneratorConfiguration); return redisTokenStore; &#125; @Bean public JwtAccessTokenConverter jwtAccessTokenConverter() &#123; customerJwtAccessTokenConverterConfiguration.setSigningKey(oauth2Properties.getJwtSigningKey()); return customerJwtAccessTokenConverterConfiguration; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package org.springframework.security.oauth.filter;import org.springframework.beans.factory.InitializingBean;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.security.core.Authentication;import org.springframework.security.core.context.SecurityContextHolder;import org.springframework.security.oauth.config.CustomerAuthenticationProviderConfiguration;import org.springframework.security.oauth.properties.Oauth2Properties;import org.springframework.stereotype.Component;import org.springframework.util.AntPathMatcher;import javax.servlet.*;import javax.servlet.http.HttpServletRequest;import java.io.IOException;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */@Componentpublic class CustomerOauth2AuthenticationProcessingFilter implements Filter, InitializingBean &#123; @Autowired private Oauth2Properties oauth2Properties; @Autowired private CustomerAuthenticationProviderConfiguration customerAuthenticationProviderConfiguration; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest httpServletRequest = (HttpServletRequest) servletRequest; //白名单过滤 AntPathMatcher antPathMatcher = new AntPathMatcher(); for (String path : oauth2Properties.getPermitUrl().split(",")) &#123; if (antPathMatcher.match(path, httpServletRequest.getPathInfo())) &#123; filterChain.doFilter(servletRequest, servletResponse); &#125; &#125; //自定义验证 Authentication authentication = getFromRequest(httpServletRequest); if (authentication == null) &#123; SecurityContextHolder.clearContext(); &#125; else &#123; SecurityContextHolder.getContext().setAuthentication(customerAuthenticationProviderConfiguration.authenticate(authentication)); &#125; filterChain.doFilter(servletRequest, servletResponse); &#125; private Authentication getFromRequest(HttpServletRequest httpServletRequest) &#123; //todo 这里可以自己去实现 return null; &#125; @Override public void afterPropertiesSet() throws Exception &#123; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package org.springframework.security.oauth.properties;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */public class Oauth2ClientProperties &#123; private String clientId; private String clientSecret; private String scopes; private Integer accessTokenValiditySeconds; private Integer refreshTokenValiditySeconds; public String getClientId() &#123; return clientId; &#125; public void setClientId(String clientId) &#123; this.clientId = clientId; &#125; public String getClientSecret() &#123; return clientSecret; &#125; public void setClientSecret(String clientSecret) &#123; this.clientSecret = clientSecret; &#125; public String getScopes() &#123; return scopes; &#125; public void setScopes(String scopes) &#123; this.scopes = scopes; &#125; public Integer getAccessTokenValiditySeconds() &#123; return accessTokenValiditySeconds; &#125; public void setAccessTokenValiditySeconds(Integer accessTokenValiditySeconds) &#123; this.accessTokenValiditySeconds = accessTokenValiditySeconds; &#125; public Integer getRefreshTokenValiditySeconds() &#123; return refreshTokenValiditySeconds; &#125; public void setRefreshTokenValiditySeconds(Integer refreshTokenValiditySeconds) &#123; this.refreshTokenValiditySeconds = refreshTokenValiditySeconds; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940package org.springframework.security.oauth.properties;import org.springframework.boot.context.properties.ConfigurationProperties;/** * @author dinghuang123@gmail.com * @since 2020/10/20 */@ConfigurationProperties(prefix = "security.oauth2")public class Oauth2Properties &#123; private String jwtSigningKey; private String permitUrl; private Oauth2ClientProperties[] clients = &#123;&#125;; public String getJwtSigningKey() &#123; return jwtSigningKey; &#125; public void setJwtSigningKey(String jwtSigningKey) &#123; this.jwtSigningKey = jwtSigningKey; &#125; public String getPermitUrl() &#123; return permitUrl; &#125; public void setPermitUrl(String permitUrl) &#123; this.permitUrl = permitUrl; &#125; public Oauth2ClientProperties[] getClients() &#123; return clients; &#125; public void setClients(Oauth2ClientProperties[] clients) &#123; this.clients = clients; &#125;&#125; 1234567891011121314151617181920212223server: port: 8090spring: redis: host: 127.0.0.1 port: 6379 password:security: oauth2: jwtSigningKey: admin permitUrl: /oauth/** clients[0]: clientId: client clientSecret: client scopes: all accessTokenValiditySeconds: 864000 refreshTokenValiditySeconds: 864000logging: level: root: WARN org.springframework.web: INFO org.springframework.security: INFO org.springframework.security.oauth2: INFO 验证1curl -H "Content-Type: application/json" -X POST "http://localhost:8090/oauth/token?client_id=client&amp;client_secret=client&amp;grant_type=pwssword&amp;username=admin&amp;password&amp;admin" 代码地址 结合网关架构设计]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何画架构设计图]]></title>
    <url>%2F2020%2F09%2F08%2F%E5%A6%82%E4%BD%95%E7%94%BB%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[如何画架构设计图转载于知乎 定义什么是架构架构就是对系统中的实体以及实体之间的关系所进行的抽象描述，是一系列的决策。 架构是结构和愿景。 系统架构是概念的体现，是对物/信息的功能与形式元素之间的对应情况所做的分配，是对元素之间的关系以及元素同周边环境之间的关系所做的定义。 做好架构是个复杂的任务有了架构之后，就需要让干系人理解、遵循相关决策。 什么是架构图系统架构图是为了抽象的表示软件系统的整体轮廓和各个组件之间的相互关系和约束边界，以及软件系统的物理部署和软件系统的演进方向的整体视图。 架构图的作用一图胜千言。要让干系人理解、遵循架构决策，就需要把架构信息传递出去。架构图就是一个很好的载体。那么，画架构图是为了： 解决沟通障碍 达成共识 减少歧义 架构图分类搜集了很多资料，分类有很多，有一种比较流行的是4+1视图，分别为场景视图、逻辑视图、物理视图、处理流程视图和开发视图。 场景视图场景视图用于描述系统的参与者与功能用例间的关系,反映系统的最终需求和交互设计,通常由用例图表示。 逻辑视图逻辑视图用于描述系统软件功能拆解后的组件关系,组件约束和边界,反映系统整体组成与系统如何构建的过程,通常由UML的组件图和类图来表示。 物理视图物理视图用于描述系统软件到物理硬件的映射关系,反映出系统的组件是如何部署到一组可计算机器节点上,用于指导软件系统的部署实施过程 处理流程视图处理流程视图用于描述系统软件组件之间的通信时序,数据的输入输出,反映系统的功能流程与数据流程,通常由时序图和流程图表示。 开发视图开发视图用于描述系统的模块划分和组成,以及细化到内部包的组成设计,服务于开发人员,反映系统开发实施过程。 5 种架构视图从不同角度表示一个软件系统的不同特征，组合到一起作为架构蓝图描述系统架构。 好的架构图上面的分类是前人的经验总结，图也是从网上摘来的，那么这些图画的好不好呢？是不是我们要依葫芦画瓢去画这样一些图？ 先不去管这些图好不好，我们通过对这些图的分类以及作用，思考了一下，总结下来，我们认为，在画出一个好的架构图之前， 首先应该要明确其受众，再想清楚要给他们传递什么信息 ，所以，不要为了画一个物理视图去画物理视图，为了画一个逻辑视图去画逻辑视图，而应该根据受众的不同，传递的信息的不同，用图准确地表达出来，最后的图可能就是在这样一些分类里。那么，画出的图好不好的一个直接标准就是：受众有没有准确接收到想传递的信息。 明确这两点之后，从受众角度来说，一个好的架构图是不需要解释的，它应该是自描述的，并且要具备一致性和足够的准确性，能够与代码相呼应。 常见问题 方框代表什么？ 为什么适用方框而不是圆形，它有什么特殊的含义吗？随意使用方框或者其它形状可能会引起混淆。 虚线、实线什么意思？箭头什么意思？颜色什么意思？ 随意使用线条或者箭头可能会引起误会。 运行时与编译时冲突？层级冲突？ 架构是一项复杂的工作，只使用单个图表来表示架构很容易造成莫名其妙的语义混乱。 如何更好的表达软件架构C4 C4 模型使用容器（应用程序、数据存储、微服务等）、组件和代码来描述一个软件系统的静态结构。这几种图比较容易画，也给出了画图要点，但最关键的是，我们认为，它明确指出了每种图可能的受众以及意义。 下面的案例来自C4官网，然后加上了一些我们的理解。 语境图(System Context Diagram) 这是一个想象的待建设的互联网银行系统，它使用外部的大型机银行系统存取客户账户、交易信息，通过外部电邮系统给客户发邮件。可以看到，非常简单、清晰，相信不需要解释，都看的明白，里面包含了需要建设的系统本身，系统的客户，和这个系统有交互的周边系统。 用途这样一个简单的图，可以告诉我们，要构建的系统是什么；它的用户是谁，谁会用它，它要如何融入已有的IT环境。这个图的受众可以是开发团队的内部人员、外部的技术或非技术人员。即： 构建的系统是什么 谁会用它 如何融入已有的IT环境 怎么画中间是自己的系统，周围是用户和其它与之相互作用的系统。这个图的关键就是梳理清楚待建设系统的用户和高层次的依赖，梳理清楚了画下来只需要几分钟时间。 容器图(Container Diagram)容器图是把语境图里待建设的系统做了一个展开。 上图中，除了用户和外围系统，要建设的系统包括一个基于java\spring mvc的web应用提供系统的功能入口，基于xamarin架构的手机app提供手机端的功能入口，一个基于java的api应用提供服务，一个mysql数据库用于存储，各个应用之间的交互都在箭头线上写明了。 看这张图的时候，不会去关注到图中是直角方框还是圆角方框，不会关注是实线箭头还是虚线箭头，甚至箭头的指向也没有引起太多注意。 我们有许多的画图方式，都对框、线的含义做了定义，这就需要画图的人和看图的人都清晰的理解这些定义，才能读全图里的信息，而现实是，这往往是非常高的一个要求，所以，很多图只能看个大概的含义。 用途这个图的受众可以是团队内部或外部的开发人员，也可以是运维人员。用途可以罗列为： 展现了软件系统的整体形态 体现了高层次的技术决策 系统中的职责是如何分布的，容器间的是如何交互的 告诉开发者在哪里写代码 怎么画用一个框图来表示，内部可能包括名称、技术选择、职责，以及这些框图之间的交互，如果涉及外部系统，最好明确边界 组件图(Component Diagram) 组件图是把某个容器进行展开，描述其内部的模块。 用途这个图主要是给内部开发人员看的，怎么去做代码的组织和构建。其用途有 描述了系统由哪些组件/服务组成 厘清了组件之间的关系和依赖 为软件开发如何分解交付提供了框架 类图(Code/Class Diagram) 工具使用本地协作Mac:OmniGraffleOmniGraffle 是由 The Omni Group 制作的一款绘图软件，它曾获得苹果设计奖。OmniGraffle 可以支持流程图、逻辑图或者网页产品模型设计等，功能非常强大。与 Graffle 对应的是在Windows平台广泛应用的 MS Visio（ Graffle 这个词据说就是为了和Visio区分而硬造出来的） Windows:VisioOffice Visio 是office软件系列中的负责绘制流程图和示意图的软件，是一款便于IT和商务人员就复杂信息、系统和流程进行可视化处理、分析和交流的软件。使用具有专业外观的 Office Visio 图表，可以促进对系统和流程的了解，深入了解复杂信息并利用这些知识做出更好的业务决策。Microsoft Office Visio帮助您创建具有专业外观的图表，以便理解、记录和分析信息、数据、系统和过程。 在线协作Process On是一款用HTML5、Canvas以及JavaScript技术开发而成的在线网页版作图工具。只需在工具栏拖放对应的图形到画布中,就可进行编辑，还支持流程图、思维导图、原型、拓扑图等，最让人心动的就是有实时协助的功能，从此再也不需要和同学、老师、领导之间来回传送文件，直接邀请，一起协作完成。 案例分享下面是 城市运营态势 工具的一个架构图。作为一个应该自描述的架构图，这里不多做解释了。如果有看不明白的，那肯定是还画的不够好。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK日志管理系统]]></title>
    <url>%2F2020%2F07%2F06%2FELK%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[简介官方文档:https://www.elastic.co/guide/en/elastic-stack/current/overview.html 搭建本教程基于Elasticsearch版本7.7.0 要在docker中搭建，要起3个套件 其中elasticearch会遇到docker内存问题，可以看这个解决https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html 或者macOS with Docker for Mac The vm.max_map_count setting must be set within the xhyve virtual machine: From the command line, run: 1screen ~/Library/Containers/com.docker.docker/Data/vms/0/tty Press enter and usesysctl to configure vm.max_map_count:1sysctl -w vm.max_map_count=262144 To exit the screen session, type Ctrl a d. 1234567docker network create elasticsearchdocker pull docker.elastic.co/elasticsearch/elasticsearch:7.7.0docker run -d -p 9200:9200 -p 9300:9300 --network elasticsearch -e "discovery.type=single-node" --name elasticsearch docker.elastic.co/elasticsearch/elasticsearch:7.7.0docker pull docker.elastic.co/kibana/kibana:7.7.0docker run -d --link elasticsearch:elasticsearch --name kibana -p 5601:5601 --network elasticsearch docker.elastic.co/kibana/kibana:7.7.0docker pull docker.elastic.co/logstash/logstash:7.7.0docker run -d -p 5044:5044 --network elasticsearch --link elasticsearch:elasticsearch --name logstash docker.elastic.co/logstash/logstash:7.7.0 遇到错误1Security must be explicitly enabled when using a [basic] license. Enable security by setting [xpack.security.enabled] to [true] in the elasticsearch.yml file and restart the node. 编辑elasticsearch.yml，加入xpack.security.enabled:true,然后重启节点重启时遇到错误:12ERROR: [1] bootstrap checks failed [1]: Transport SSL must be enabled if security is enabled on a [basic] license. Please set [xpack.security.transport.ssl.enabled] to [true] or disable security by setting [xpack.security.enabled] to [false] 编辑elasticsearch.yml，加入xpack.security.transport.ssl.enabled:true,然后重启节点 执行设置用户名和密码的命令,这里需要为4个用户分别设置密码，elastic, kibana, logstash_system,beats_system 1bin/elasticsearch-setup-passwords interactive 配置文件修改进入logstash容器里面修改配置文件12docker exec -it 54b504186a47 /bin/bash # 这里 54b504186a47是容器idvi /usr/share/logstash/config/logstash.yml logstash.yml配置文件如下1234http.host: "0.0.0.0"xpack.monitoring.elasticsearch.hosts: [ "http://elasticsearch:9200" ]path.config: /usr/share/logstash/config/*.confpath.logs: /var/log/logstash 修改logstash-sample.conf1234567891011121314151617input &#123; tcp &#123; mode =&gt; "server" host =&gt; "0.0.0.0" codec =&gt; json_lines port =&gt; 5044 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; ["http://elasticsearch:9200"] index =&gt; "springboot-logstash-%&#123;+YYYY.MM.dd&#125;" #user =&gt; "elastic" #password =&gt; "changeme" &#125;&#125; 这样logstash的读取就是通过一个tcp服务读取 springboot结合引入包12345&lt;dependency&gt; &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt; &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt; &lt;version&gt;6.4&lt;/version&gt;&lt;/dependency&gt; 添加配置文件logback-spring.xml1234567891011121314151617181920212223242526272829303132333435&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration&gt; &lt;include resource="org/springframework/boot/logging/logback/base.xml" /&gt; &lt;appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender"&gt; &lt;destination&gt;127.0.0.1:5044&lt;/destination&gt; &lt;!-- 日志输出编码 --&gt; &lt;encoder charset="UTF-8" class="net.logstash.logback.encoder.LoggingEventCompositeJsonEncoder"&gt; &lt;providers&gt; &lt;timestamp&gt; &lt;timeZone&gt;UTC&lt;/timeZone&gt; &lt;/timestamp&gt; &lt;pattern&gt; &lt;pattern&gt; &#123; "logLevel": "%level", "serviceName": "$&#123;springAppName:-&#125;", "pid": "$&#123;PID:-&#125;", "thread": "%thread", "class": "%logger&#123;40&#125;", "rest": "%message" &#125; &lt;/pattern&gt; &lt;/pattern&gt; &lt;/providers&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="LOGSTASH" /&gt; &lt;appender-ref ref="CONSOLE" /&gt; &lt;/root&gt;&lt;/configuration&gt; 启动应用，配置kibana的索引，如图所示 如果添加了索引，页面没有显示索引，还要继续添加的话，这个是Kibana的问题，重启一下Kibana容器就好了。]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[业务埋点设计]]></title>
    <url>%2F2020%2F06%2F23%2F%E4%B8%9A%E5%8A%A1%E5%9F%8B%E7%82%B9%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[概念可以先看一本书《精通Web Analytics 2.0》 埋点是什么所谓埋点就是在应用中特定的流程收集一些信息，用来跟踪应用使用的状况，后续用来进一步优化产品或是提供运营的数据支撑，包括访问数（Visits），访客数（Visitor），停留时长（Time On Site），页面浏览数（Page Views）和跳出率（Bounce Rate）。这样的信息收集可以大致分为两种：页面统计（track this virtual page view），统计操作行为（track this button by an event）。 埋点是谁的工作现在公司通常都会有数据产品经理或业务线数据分析师，结合版本迭代过程进行埋点规划。如果是代码埋点，还需要开发完成相应的埋点代码。 埋点的意义埋点就是为了对产品进行持续追踪，通过深度数据分析不断优化产品。好比去医院体检，医生测了你身体的各个健康指标，以此来判断你的健康状况。埋点的目的，其实就是随时或者定期监测你的产品的“健康”状况。 任何一个系统在设计初始阶段只关心核心业务的功能，等到系统上线以后，数据分析师对用户行为分析时会发现缺少很多数据，此时需要采用埋点的方法进行采集需要的数据。 业务人员主要通过自有或第三方的数据统计平台了解产品的概览性数据指标，包括新增用户数、活跃用户数等。这些指标能帮助企业宏观的了解用户访问的整体情况和趋势，从整体上把握产品的运营状况，但很难基于这些指标直接得到切实的产品改进策略。 而埋点将产品数据分析的深度下钻到流量分布和流动层面，通过对产品中的用户交互行为的统计分析，对宏观指标进行深入剖析，发现指标背后的问题，寻找人群的行为特点和关系，洞察用户行为与提升业务价值之间的潜在关联，了解组成特定数据现象的原因，并据此构建产品优化 迭代 和运营策略。 对于产品来说，用户在你的产品里做了什么、停留了多久、有什么异样，都是需要关注的。比如用户点击率怎么样？用户在核心使用路径上是否顺畅？有没有得到用户的认可？有没有因为设计按钮过多导致用户行为无效？用户希望有什么样的功能更新等等问题都可以通过埋点的方法实现。 埋点做好才能用来进行数据驱动产品和精细化运营。而埋点质量的好坏也直接影响到了产品运营的质量。因此它贯穿了产品的整个生命周期，为产品优化指明了方向。所以说，好的数据埋点，就成功了一半。 when &amp;&amp; where埋点是目的导向。 在产品规划时就要思考数据埋点问题，如果在产品外发后再考虑怎么埋点，就会导致前期版本用户的数据无法收集，想要看某个数据时就会非常无奈，只有等到新版本完善来弥补。 思考要埋哪些点、埋点的形式，需要紧密结合产品迭代的方向、运营需求，并和数据开发等进行充分沟通以确认： 埋点能够得到想要的数据解决/支持； 能够得到当前版本的复盘情况； 后续版本的数据支撑。 通常的沟通过程以 埋点文档为载体；数据埋点评审为终结。 当前版本的复盘情况： 新版本功能使用情况，是否符合预期； 新功能上线后对其他功能点的影响？是否为整体均有积极作用； 版本运营活动目标群体的特征获取; 新增商业化目标的监测…… 后续版本的数据支撑： 规划方向的用户行为分析 画像特征分析 埋点指标：基础指标基础指标是一些常用的参数指标，比如用户行为相关的，有用户数、新增用户数、活跃用户数等；用户设备相关的，比如电脑系统、地区、语言、国家、产品版本等；用户属性相关的，性别、年龄等。这一部分一般很难通过埋点拿到，但是通过一般第三方工具可以看个大概。 用户行为数据指标用户行为的行为数据，就是埋点的核心了。这一部分根据不同的产品，收集的数据也不同。再拿PC端的腾讯视频举例，每个用户每天使用腾讯视频的时长是多少？每次看的是哪些视频？用户最喜欢看哪个频道的视频？每个频道的使用情况是怎么样的？用户一般是在一天中的哪个时间段打开腾讯视频的。想要看的数据非常多，而这些，都是要提前规划好，有目的性得去决定要埋什么点、怎么埋。如果你的目的是为了研究一下用户对弹幕的接受程度，那围绕弹幕，设置一些指标数据，比如发布弹幕的次数和频率？看视频时是否开启了弹幕？这样的话，就能够通过数据，看出用户对弹幕的真实反映，对于提升产品功能和运营都有很大帮助。 核心质量指标Crash等一些因为产品质量引起的问题，都是用户所不能忍受的。而且用户量越大，越容易出现产品质量问题。尤其是一些产品，他的产品属性决定了，产品质量是吸引用户购买的一个很重要的因素。比如迅雷、photoshop等软件，核心质量的指标能帮助我们监控产品的“健康”情况。 这里说的质量指标，不单单指产品的 异常退出率、Crash率， 还包括和产品自身业务相关的指标。比如，对于视频编辑产品， 编辑成功率 是很重要的指标；对于迅雷， 下载成功率 是核心指标；对于在线类产品， 资源解析 成功率 是核心指标…… 访问与访客访问次数（Visits）与访问人数（Vistors）是几乎所有应用都需要统计的指标，这也是最基础的指标。对于应用的统计来说，经常看到的DAU（日活跃用户数量），MAU（用户数量统计），UV（独立（IP）访客）等指标都是指统计访客（Vistors）。访问（Visits）是指会话层，用户打开应用花一段时间浏览又离开，从指标定义（访问次数）来说这被称之为统计会话（Session）数。一次会话（Session 或 Visit）是打开应用的第一个请求（打开应用）和最后一个请求决定的。如果用户打开应用然后放下手机或是离开电脑，并在接下来30分钟内没有任何动作，此次会话自动结束，通常也算作一次访问或会话期（30分钟是早起网页版应用约定俗成的会话数定义，目前用户停留在应用的时长变长，30分钟的限定也可能随之不同，总之是能代表一次用户访问的时长）。在计算访问人数（Vistors）时，埋点上报的数据是尽可能接近真实访客的人数。对于有需要统计独立访客这个指标的场景，这里还是需要强调一下，访问人数（Vistors）并不是真实独立的人，因此收集数据时必须知道访问人数虽然能够很好的反映使用应用的真实访问者的数量，但不等于使用应用的真实人数。（原因是，重复安装的应用，或是手机参数被修改都会使得独立访客的指标收到影响。计算访问人数的埋点都是依赖Cookie，用户打开应用，应用都会在此人的终端创建一个独立Cookie, Cookie会被保留，但还是难免会被用户手动清理或是Cookie被禁用导致同一用户使用应用Cookie不一致，所以独立访客只能高度接近于使用应用的真实人数。） 停留时长停留时长用来衡量用户在应用的某一个页面或是一次访问（会话）所停留的时间。页面停留时长，表示在每个页面所花费的时间；例如：首页就是进入首页（10：00）到离开首页进入下一个页面(10:01)的时长，首页停留时长计算为1分钟。页面A是2分钟。停留时长的数据并不都是一定采集得到的，比如页面B进入时间（10：03），离开出现异常或是退出时间没有记录，这时候计算就是0 （所以指标计算时需要了解埋点的状况，剔除这样的无效数据）。应用的停留时长，表示一次访问（会话）所停留的时间，计算起来就是所有页面的访问时长，同样是上一个流程，应用的停留时长就是4分钟。 跳出率跳出率的计算方法现在在各个公司还是很多种，最经常被使用的是：用户只访问了一个页面所占的会话比例（原因是：假设这种场景，用户来了访问了一个页面就离开了，想想用户使用的心里画面应该是：打开应用，心想什么鬼，然后关闭应用甚至卸载了。这个场景多可怕，这也是为什么跳出率指标被如此关注）跳出率可以分解到两个层次：一是整个应用的跳出率，二是重点的着陆页的跳出率，甚至是搜索关键词的跳出率。跳出率的指标可操作性非常强，通过统计跳出率可以直接发现页面的问题发现关键词的问题。 退出率退出率是针对页面的，这个指标的目标很简单，就是在针对某个页面有多少用户离开了应用，主要用户反映用户从应用离开的情况。哪些页面需要被改进最快的方式被发掘。（注意：退出率高不一定是坏事。例如：预测流程的最终节点的退出率就应该是高的） 转化率我们在产品上投入这么多，不就是为了衡量产出么？所以对于电商类应用，还有比转化率更值得关注的指标吗？转化率的计算方法是某种产出除以独立访客或是访问量，对于电商产品来说，就是提交订单用户数除以独立访客。转化率的计算看起来想到那简单，但却是埋点中最贴近业务的数据收集。这也是最体现埋点技巧的指标，需要结合业务特点制定计算方法。提交订单量/访客数是最基本的转化率，转化率还可以分层次，指定用户路径的，如：完成某条路径的提交订单数/访客数。 参与度参与度并不是一个指标，而是一系列的指标的统称，例如访问深度，访问频次，针对电商的下单次数，针对内容服务商的播放次数，及用户行为序列这些都可以是衡量参与度的指标。之所以把参与度列为一个指标，是希望大家明白把指标结合业务，产生化学反应，活学活用去发现事物的本质。 数据采集普遍遇到的几个问题 实时性，对于工具性产品在无网条件下的数据，无法实时上报； 完整性，由于用户隐私协议&amp;欧盟通用数据保护条例的，部分数据无法采集； 异常，android_id、idfa、idfv 随版本升级变化或无法获取。 怎么埋点代码埋点以为需要监测网站上/app上用户的行为，是需要在网页/app中加上一些代码的，当用户触发相应行为时，进行数据上报，也就是代码埋点。这样的代码，在网站上叫监测代码，在app中叫SDK（Software Development Kit）。市场上的第三方数据采集均支持代码埋点，GA, GrowingIO，神策等。 优点 采集的数据比较具有针对性，更加适合精细化数据分析。 同时也能提高数据的准确性。 缺点 每一个控件的埋点都需要添加相应的代码，不仅工作量大，而且限定了必须是技术开发人员才能完成。 每一次产品迭代，都需要更新埋点方案。 适用场景 有具体的业务分析需求，且按照各个事件埋点的方式不能满足。 需要对埋点事件进行传参等自定义属性设置。代码埋点虽然较复杂，但功能最完善，覆盖了埋点中的不同业务需求。 可视化埋点利用可视化交互手段，数据产品/数据分析师可以通过可视化界面（管理后台连接设备） 配置事件，如下是腾讯移动分析的可视化埋点界面。可视化埋点仍需要先配置相关事件，再采集。 例如腾讯的https://mta.qq.com/ 蚂蚁金服的移动开发平台https://tech.antfin.com/docs/2/49549 优点 业务人员可用，无需技术人员进行SDK嵌入，不懂代码的产品运营人员也可通过后台可视化界面配置和统计埋点并实时下发到客户端生效。 无需版本更新，由于不需要嵌入新SDK，不需要发布新版本，可谓即时生效。 对所有版本生效：新增埋点在所有版本生效，不存在迭代问题。 缺点 可覆盖的功能有限，目前并不是所有控件操作都可以通过这种方案进行定制。 不能自定义交互事件属性，由于获取的是交互事件元素的DOMpath，无法对具体事件设置参数。 不支持可以不断加载的内容瀑布流交互。 适用场景 分析或统计需求简单，不需要对埋点事件进行传参等自定义属性设置。 频繁上线或更新的H5类型的运营活动 无埋点无埋点是指开发人员集成采集 SDK 后，SDK 便直接开始捕捉和监测用户在应用里的所有行为，并全部上报，不需要开发人员添加额外代码。 数据分析师/数据产品 通过管理后台的圈选功能来选出自己关注的用户行为，并给出事件命名。之后就可以结合时间属性、用户属性、事件进行分析了。所以无埋点并不是真的不用埋点了。目前市场第三方工具GrowingIO支持无埋点全量行为数据抓取https://growingio.jinshuju.com/ 优点 因为无埋点对页面所有元素进行埋点，那么这个页面每个元素被点击的概率你也就知道，对点击概率比较大的元素可以进行深入分析。 可以在系统上线后使用，支持基于全量的数据回溯，因为无埋点在你部署SDK的时候数据就一直在收集，可帮助进行启发式、探索式的数据分析。 它技术门槛低，部署简单。 缺点 无埋点无法采集自定义属性，只使用通用大部门，通用的场景。 数据形式非业务导向，因为是对所有事件数据的自动收集，没有按照业务需求进行事件或区域设置，业务或数据人员在使用时或许不能直接使用，需要二次计算或处理。 兼容性不好，传输时效性较差等问题，因为是对所有的元素数据都收集，会给数据传输和服务器带来较大的压力。 适用场景 分析或统计需求简单，不需要对埋点事件进行传参等自定义属性设置的事件。 针对快速、频繁上线和迭代的H5类型的运营活动的评估。 总体来说，无埋点和可视化埋点更侧重结果的展现，对过程追溯少，更适合产品经理分析基础的产品功能流畅度、用户体验、产品路径设置等。代码埋点和后端埋点，不仅能展现结果，也会记录用户行为过程，支持深度的行为分析和偏好洞察，还可将行为数据与业务数据打通，适合产品和运营人员深度使用。 无论采用哪种埋点方式，都应该根据业务场景和产品阶段，梳理和构建数据分析体系。埋点规划混乱、数据采集无序、数据分析断层，最终将会让企业陷入“有数据而无价值”的境地。 架构设计 通过 日志埋点 来实现业务监控和行为分析主要需要以下4个步骤 数据生成(埋点)数据收集数据解析(结构化)数据落盘数据使用(展示/分析) 数据使用 如何做数据埋点其实这个问题不应该问别人，应该问你自己，通过上文，我们已经知道了，如果你想绘制基础的人群画像你就需要获取用户机型、网络类型、操作系统，IP地域等数据；如果你想分析每一个注册转化率，你就需要获取每一个步骤的点击次数，然后制作成漏斗，看那一步转化率出现了问题……目的不一样，获取的数据也不一样，使用的埋点技术也不一样。 那么，我们该如何选择埋点方式呢？ 我们的目的是实现深度数据分析，不应该采用与其他企业通用的埋点方法，应该采用适合自己的埋点方法。也就是做到“因系统而异、避免千系统一面的情况。 在系统刚上线的初期阶段，我们可以采用无埋点的方式。因为我们通过UV、PV、点击率等基本指标及即可满足数据分析需求。如果产品上线时间很长，我们需要进行深度数据分析则选择代码埋点。它可以帮我们收集需要的属性。另外，如何埋点既可以在前端实现，也可以在后端实现，我们推荐在后端实现。因为后端数据可以保证数据的准确性。最后，如果您为了方便快捷并且免费，可以选择第三方统计工具，但是一定要选择适合自己业务的统计工具。 从业务过程中采集埋点，是数据驱动型公司的必要条件。一般公司的产品功能评审环节，不仅有 PRD (Product requirement document），还加入了对应的 DRD ( Data requirement document）。对于埋点而言，DRD 需要明确业务目标与埋点缺口之间的关系以及需求的优先级。埋点的需求大多来自于 DRD，整个过程会涉及多个角色，主要包括产品经理、业务数据负责人、开发工程师、测试工程师，如图所示。 总之，如果您需要深度分析，选择后端（手动）埋点和无埋点组合的方案；如果您只是想看宏观数据，可以选择无埋点。无论采用哪种埋点方法，一定要慎重，根据需要来设置，最好不要出现错埋或者漏埋的情况。最后，数据分析师一定要和业务工程团队（部署实施埋点的部门）配合好才能实现完美的数据采集方案，有时候沟通比选择埋点方式更重。 优秀的实践案例有赞埋点实践https://tech.youzan.com/track-1/ 美团点评前端无痕埋点实践https://tech.meituan.com/2017/03/02/mt-mobile-analytics-practice.html 产品经理该如何做好数据埋点https://www.uisdc.com/product-manager-makes-data-event-tracking 数据统计埋点工作框架及细节规范https://www.inneed.club/articles/detail/pkx0epxgew]]></content>
      <categories>
        <category>程序设计</category>
      </categories>
      <tags>
        <tag>程序设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activiti7.X结合SpringBoot2.1、Mybatis]]></title>
    <url>%2F2020%2F03%2F14%2FActiviti7.X%E7%BB%93%E5%90%88SpringBoot2.1%E3%80%81Mybatis%2F</url>
    <content type="text"><![CDATA[Activiti7.X结合SpringBoot2.1、MybatisActiviti简介Activiti介绍 Activiti 是由 jBPM 的创建者 Tom Baeyens 离开 JBoss 之后建立的项目，构建在开发 jBPM 版本 1 到 4 时积累的多年经验的基础之上，旨在创建下一代的 BPM 解决方案。 Activiti是一个开源的工作流引擎，它实现了BPMN 2.0规范，可以发布设计好的流程定义，并通过api进行流程调度。 Activiti 作为一个遵从 Apache 许可的工作流和业务流程管理开源平台，其核心是基于Java的超快速、超稳定的 BPMN2.0 流程引擎，强调流程服务的可嵌入性和可扩展性，同时更加强调面向业务人员。 Activiti 流程引擎重点关注在系统开发的易用性和轻量性上。每一项 BPM 业务功能 Activiti 流程引擎都以服务的形式提供给开发人员。通过使用这些服务，开发人员能够构建出功能丰富、轻便且高效的 BPM 应用程序。 Activiti是一个针对企业用户、开发人员、系统管理员的轻量级工作流业务管理平台，其核心是使用Java开发的快速、稳定的BPMN e 2.0流程引擎。Activiti是在ApacheV2许可下发布的，可以运行在任何类型的Java程序中，例如服务器、集群、云服务等。Activiti可以完美地与Spring集成。同时，基于简约思想的设计使Activiti非常轻量级。 目前Activiti有2个版本，一个本地的core，一个可以支持分布式的cloud，本文只介绍core，新版 Activiti 7.0.0 发布后，Activiti Cloud 现在是新一代商业自动化平台，提供一组旨在在分布式基础架构上运行的 Cloud原生构建块。Cloud可以参考官网 Activiti 7.x 主要突出了 Spring Boot 2.x 应用程序中的 ProcessRuntime 和 TaskRuntime API 的使用。 BPMNBPMN（Business Process Model And Notation）-业务流程模型和符号是由BPMI（Business Process Management Initiative）开发的一套标准的业务流程建模符号，使用BPMN提供的符号可以创建业务流程。 Activiti 就是使用BPMN 2.0 进行流程建模、流程执行管理，它包括很多的建模符号，比如：Event 用一个圆圈表示，它是流程中运行过程中发生的事情。 一个bpmn图形的例子： 首先当事人发起一个请假单其次他所在部门的经理对请假单进行审核然后人事经理进行复核并进行备案最后请假流程结束 创建应用代码库地址：https://github.com/dinghuang/activiti-service.git 创建maven应用，pom引入包123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;artifactId&gt;dinghuang-framework-parent&lt;/artifactId&gt; &lt;groupId&gt;org.dinghuang&lt;/groupId&gt; &lt;version&gt;0.1.0-RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;activiti&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;activiti&lt;/name&gt; &lt;description&gt;activiti project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;mapstruct&gt;1.3.0.Final&lt;/mapstruct&gt; &lt;activiti.version&gt;7.1.0.M6&lt;/activiti.version&gt; &lt;spring-boot&gt;2.1.0.RELEASE&lt;/spring-boot&gt; &lt;fastjson&gt;1.2.47&lt;/fastjson&gt; &lt;commons-collections&gt;3.2.2&lt;/commons-collections&gt; &lt;commons-lang3&gt;3.8.1&lt;/commons-lang3&gt; &lt;swagger-annotations&gt;1.5.16&lt;/swagger-annotations&gt; &lt;springfox-swagger2&gt;2.7.0&lt;/springfox-swagger2&gt; &lt;druid&gt;1.1.10&lt;/druid&gt; &lt;mybatis-plus-boot-starter&gt;3.1.0&lt;/mybatis-plus-boot-starter&gt; &lt;feign-hystrix&gt;9.5.0&lt;/feign-hystrix&gt; &lt;lombok&gt;1.16.20&lt;/lombok&gt; &lt;mysql-connector-java&gt;8.0.15&lt;/mysql-connector-java&gt; &lt;liquibase-core&gt;3.5.3&lt;/liquibase-core&gt; &lt;validation-api&gt;2.0.1.Final&lt;/validation-api&gt; &lt;hibernate-validator&gt;6.0.15.Final&lt;/hibernate-validator&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti.dependencies&lt;/groupId&gt; &lt;artifactId&gt;activiti-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;activiti.version&#125;&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;5.1.12.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;activiti.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.postgresql&lt;/groupId&gt; &lt;artifactId&gt;postgresql&lt;/artifactId&gt; &lt;version&gt;42.2.10&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Activiti生成流程图 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-image-generator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.dinghuang&lt;/groupId&gt; &lt;artifactId&gt;dinghuang-framework-core&lt;/artifactId&gt; &lt;version&gt;0.1.0-RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.6.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;annotationProcessorPaths&gt; &lt;!--这个配置是因为lombok跟mapstruct一起用的时候maven对注解的解析器选择有点问题--&gt; &lt;path&gt; &lt;groupId&gt;org.mapstruct&lt;/groupId&gt; &lt;artifactId&gt;mapstruct-processor&lt;/artifactId&gt; &lt;version&gt;$&#123;mapstruct&#125;&lt;/version&gt; &lt;/path&gt; &lt;path&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt; &lt;/path&gt; &lt;/annotationProcessorPaths&gt; &lt;compilerArgs&gt; &lt;compilerArg&gt; -Amapstruct.defaultComponentModel=spring &lt;/compilerArg&gt; &lt;/compilerArgs&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;finalName&gt;demo&lt;/finalName&gt; &lt;/build&gt;&lt;/project&gt; 与mysql结合在resource目录下准备文件activiti.cfg.xml，内容如下：12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="processEngineConfiguration" class="org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration"&gt; &lt;property name="databaseType" value="mysql"&gt;&lt;/property&gt; &lt;property name="jdbcUrl" value="jdbc:mysql://localhost:3306/activiti"&gt;&lt;/property&gt; &lt;property name="jdbcDriver" value="com.mysql.jdbc.Driver"&gt;&lt;/property&gt; &lt;property name="jdbcUsername" value="root"&gt;&lt;/property&gt; &lt;property name="jdbcPassword" value="root"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 执行下面的代码，初始化db数据库或者配置springboot配置文件，会自动生成25个表，代码执行如下：1234567891011121314package org.dinghuang.activiti.conf;import org.activiti.engine.impl.db.DbSchemaCreate;/** * @author dinghuang123@gmail.com * @since 2020/2/28 */public class Test &#123; public static void main(String[] args) &#123; DbSchemaCreate.main(args); &#125;&#125; 配置文件如下：1234567891011121314151617spring: activiti: # 自动建表 database-schema: ACTIVITI #表示启动时检查数据库表，不存在则创建 database-schema-update: true #表示哪种情况下使用历史表，这里配置为full表示全部记录历史，方便绘制流程图 history-level: full #表示使用历史表，如果不配置，则工程启动后可以检查数据库，只建立了17张表，历史表没有建立，则流程图及运行节点无法展示 db-history-used: trueproject: manifest: file: path: classpath:/default-project.jsonlogging: level: org.activiti: debug 数据库说明数据库会生成25张表，ER图如图所示：表的列表： 123456ACT_RE_*: RE表示repository，这个前缀的表包含了流程定义和流程静态资源ACT_RU_*: RU表示runtime，这些运行时的表，包含流程实例，任务，变量，异步任务等运行中的数据。Activiti只在流程实例执行过程中保存这些数据， 在流程结束时就会删除这些记录。ACT_ID_*: ID表示identity，这些表包含身份信息，比如用户，组等。这些表现在已废弃。ACT_HI_*: HI表示history，这些表包含历史数据，比如历史流程实例， 变量，任务等。ACT_GE_*: 通用数据， 用于不同场景下。ACT_EVT_*: EVT表示EVENT，目前只有一张表ACT_EVT_LOG，存储事件处理日志，方便管理员跟踪处理 具体表详解可以参考文章 表详解 表 意义 备注 ACT_EVT_LOG 事件处理日志 ACT_GE_BYTEARRAY 二进制数据表 存储流程定义相关的部署信息。即流程定义文档的存放地。每部署一次就会增加两条记录，一条是关于bpmn规则文件的，一条是图片的（如果部署时只指定了bpmn一个文件，activiti会在部署时解析bpmn文件内容自动生成流程图）。两个文件不是很大，都是以二进制形式存储在数据库中。 ACT_GE_PROPERTY 主键生成表 主张表将生成下次流程部署的主键ID。 ACT_HI_ACTINST 历史节点表 只记录usertask内容,某一次流程的执行一共经历了多少个活动 ACT_HI_ATTACHMENT 历史附件表 ACT_HI_COMMENT 历史意见表 ACT_HI_DETAIL 历史详情表，提供历史变量的查询 流程中产生的变量详细，包括控制流程流转的变量等 ACT_HI_IDENTITYLINK 历史流程人员表 ACT_HI_PROCINST 历史流程实例表 ACT_HI_TASKINST 历史任务实例表 一次流程的执行一共经历了多少个任务 ACT_HI_VARINST 历史变量表 ACT_PROCDEF_INFO ACT_RE_DEPLOYMENT 部署信息表 存放流程定义的显示名和部署时间，每部署一次增加一条记录 ACT_RE_MODEL 流程设计模型部署表 流程设计器设计流程后，保存数据到该表 ACT_RE_PROCDEF 流程定义数据表 存放流程定义的属性信息，部署每个新的流程定义都会在这张表中增加一条记录。注意：当流程定义的key相同的情况下，使用的是版本升级 ACT_RU_EVENT_SUBSCR throwEvent，catchEvent时间监听信息表 ACT_RU_EXECUTION 运行时流程执行实例表 历史流程变量 ACT_RU_IDENTITYLINK 运行时流程人员表 主要存储任务节点与参与者的相关信息 ACT_RU_INTEGRATION ACT_RU_JOB 运行时定时任务数据表 ACT_RU_TIMER_JOB ACT_RU_SUSPENDED_JOB ACT_RU_TASK 运行时任务节点表 ACT_RU_TIMER_JOB ACT_RU_VARIABLE 运行时流程变量数据表 通过JavaBean设置的流程变量，在act_ru_variable中存储的类型为serializable，变量真正存储的地方在act_ge_bytearray中。 ACT_ID_GROUP 用户组信息表 已废弃 ACT_ID_INFO 用户扩展信息表 已废弃 ACT_ID_MEMBERSHIP 用户与用户组对应信息表 已废弃 ACT_ID_USER 用户信息表 已废弃 工作流使用activiti7内置了Spring security框架,官方demo跟spring结合的必须与spring-security结合，这里我不用spring-security，因为现在没有用户表了，所以自定义一些用户角色表去结合，更容易理解。 关于security问题activiti7最新的类似Runtime API和Task API都集成了security。如果使用上述的API,那么必须要使用security，不能屏蔽security，否则会报错。使用引擎服务类的时候，可以排除security，因为这些是最原始的API。但是activiti7官方已经明确说了，随时可能会干掉这些API。不建议开发人员直接使用引擎类以及引擎配置了、服务类等。 相关配置类自定义id策略1234567891011121314151617181920package org.dinghuang.activiti.conf;import com.baomidou.mybatisplus.core.toolkit.IdWorker;import org.activiti.engine.impl.cfg.IdGenerator;import org.springframework.stereotype.Component;/** * 自定义id策略 * * @author dinghuang123@gmail.com * @since 2020/3/4 */@Componentpublic class ActivitiIdGeneratorConfiguration implements IdGenerator &#123; @Override public String getNextId() &#123; return String.valueOf(IdWorker.getId()); &#125;&#125; 自定义用户组activiti7已经抛弃了identity相关的表，同时与springSecurity结合，所以这边如果想自定义可以这么改，但是实际用途不大，最重要的是要结合自己的用户表设计来。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package org.dinghuang.activiti.conf;import org.activiti.api.runtime.shared.identity.UserGroupManager;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;/** * 重写用户权限 * * @author dinghuang123@gmail.com * @since 2020/3/2 */@Componentpublic class ActivitiUserGroupManagerConfiguration implements UserGroupManager &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ActivitiUserGroupManagerConfiguration.class); public static List&lt;String&gt; roles = new ArrayList&lt;&gt;(3); public static List&lt;String&gt; groups = new ArrayList&lt;&gt;(1); public static List&lt;String&gt; users = new ArrayList&lt;&gt;(3); public static Map&lt;String, String&gt; userRoleMap = new HashMap&lt;&gt;(3); static &#123; roles.add("workCreate"); roles.add("workPermit"); roles.add("workLeader"); groups.add("workGroupA"); users.add("admin"); users.add("laowang"); users.add("xiaofang"); userRoleMap.put("admin", "workCreate"); userRoleMap.put("laowang", "workPermit"); userRoleMap.put("xiaofang", "workLeader"); &#125; @Override public List&lt;String&gt; getUserGroups(String s) &#123; LOGGER.info("get user groups"); return groups; &#125; @Override public List&lt;String&gt; getUserRoles(String s) &#123; String role = userRoleMap.get(s); List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(role); LOGGER.info("get user roles"); return list; &#125; @Override public List&lt;String&gt; getGroups() &#123; LOGGER.info("get groups"); return groups; &#125; @Override public List&lt;String&gt; getUsers() &#123; LOGGER.info("get users"); return users; &#125;&#125; 其他自定义配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package org.dinghuang.activiti.conf;import org.activiti.api.runtime.shared.identity.UserGroupManager;import org.activiti.core.common.spring.project.ProjectModelService;import org.activiti.engine.impl.history.HistoryLevel;import org.activiti.spring.SpringAsyncExecutor;import org.activiti.spring.SpringProcessEngineConfiguration;import org.dinghuang.activiti.controller.ActivitiController;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.core.io.Resource;import org.springframework.core.io.support.PathMatchingResourcePatternResolver;import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;import org.springframework.transaction.PlatformTransactionManager;import javax.sql.DataSource;import java.io.IOException;/** * @author dinghuang123@gmail.com * @since 2020/3/2 */@Configurationpublic class ActivitiSpringIdentityAutoConfiguration &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ActivitiController.class); private static final int CORE_POOL_SIZE = 10; private static final int MAX_POOL_SIZE = 30; private static final int KEEP_ALIVE_SECONDS = 300; private static final int QUEUE_CAPACITY = 300; @Autowired private DataSource dataSource; @Autowired private PlatformTransactionManager platformTransactionManager; @Autowired private UserGroupManager userGroupManager; @Autowired private ActivitiIdGeneratorConfiguration activitiIdGeneratorConfiguration; @Autowired private ProjectModelService projectModelService; /** * 处理引擎配置 */ @Bean public SpringProcessEngineConfiguration springProcessEngineConfiguration() &#123; SpringProcessEngineConfiguration configuration = new SpringProcessEngineConfiguration(projectModelService); configuration.setDataSource(this.dataSource); configuration.setTransactionManager(this.platformTransactionManager); SpringAsyncExecutor asyncExecutor = new SpringAsyncExecutor(); asyncExecutor.setTaskExecutor(workFlowAsync()); configuration.setAsyncExecutor(asyncExecutor); configuration.setDatabaseSchemaUpdate("true"); configuration.setUserGroupManager(this.userGroupManager); configuration.setHistoryLevel(HistoryLevel.FULL); configuration.setDbHistoryUsed(true); configuration.setIdGenerator(this.activitiIdGeneratorConfiguration); Resource[] resources = null; // 启动自动部署流程 try &#123; resources = new PathMatchingResourcePatternResolver().getResources("classpath*:bpmn/*.bpmn"); &#125; catch (IOException e) &#123; LOGGER.error("Start the automated deployment process error", e); &#125; configuration.setDeploymentResources(resources); return configuration; &#125; /** * 线程池 */ @Primary @Bean("workFlowTaskExecutor") public ThreadPoolTaskExecutor workFlowAsync() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(CORE_POOL_SIZE); executor.setMaxPoolSize(MAX_POOL_SIZE); executor.setKeepAliveSeconds(KEEP_ALIVE_SECONDS); executor.setQueueCapacity(QUEUE_CAPACITY); executor.setThreadNamePrefix("workFlowTaskExecutor-"); executor.initialize(); return executor; &#125;&#125; 因为去掉了springSecurity,所以启动类得排除springSecurity的自动配置。123456789101112131415161718192021222324252627282930package org.dinghuang.activiti;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.servlet.config.annotation.EnableWebMvc;import org.springframework.web.servlet.view.InternalResourceViewResolver;@SpringBootApplication(exclude = &#123; org.springframework.boot.autoconfigure.security.servlet.SecurityAutoConfiguration.class, org.springframework.boot.actuate.autoconfigure.security.servlet.ManagementWebSecurityAutoConfiguration.class, org.activiti.core.common.spring.identity.config.ActivitiSpringIdentityAutoConfiguration.class&#125;)@EnableWebMvcpublic class ActivitiApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ActivitiApplication.class, args); &#125; @Bean public InternalResourceViewResolver setupViewResolver() &#123; InternalResourceViewResolver resolver = new InternalResourceViewResolver(); /** 设置视图路径的前缀 */ resolver.setPrefix("resources/templates"); /** 设置视图路径的后缀 */ resolver.setSuffix(".html"); return resolver; &#125;&#125; 流程绘制流程绘制这里提供2种，一种用IDEA下载ActiBPM插件去画，这里给一段我自己画的xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;&lt;definitions xmlns="http://www.omg.org/spec/BPMN/20100524/MODEL" xmlns:activiti="http://activiti.org/bpmn" xmlns:bpmndi="http://www.omg.org/spec/BPMN/20100524/DI" xmlns:dc="http://www.omg.org/spec/DD/20100524/DC" xmlns:di="http://www.omg.org/spec/DD/20100524/DI" xmlns:tns="http://sourceforge.net/bpmn/definitions/a123123" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:yaoqiang="http://bpmn.sourceforge.net" expressionLanguage="http://www.w3.org/1999/XPath" id="m1583310491794" name="" targetNamespace="http://sourceforge.net/bpmn/definitions/a123123" typeLanguage="http://www.w3.org/2001/XMLSchema"&gt; &lt;process id="dinghuangTest" isClosed="false" isExecutable="true" name="请假流程" processType="None"&gt; &lt;startEvent id="_2" name="开始"/&gt; &lt;userTask activiti:assignee="bilu" activiti:candidateGroups="manager" activiti:exclusive="true" id="_3" name="部门经理审批"/&gt; &lt;endEvent id="_4" name="结束"/&gt; &lt;sequenceFlow id="_5" sourceRef="_2" targetRef="_3"/&gt; &lt;sequenceFlow id="_6" name="事情不重要" sourceRef="_3" targetRef="_4"&gt; &lt;conditionExpression xsi:type="tFormalExpression"&gt;&lt;![CDATA[$&#123;!important&#125;]]&gt;&lt;/conditionExpression&gt; &lt;/sequenceFlow&gt; &lt;userTask activiti:candidateGroups="admin" activiti:exclusive="true" id="_7" name="总经理审批"/&gt; &lt;sequenceFlow id="_8" name="事情重要" sourceRef="_3" targetRef="_7"&gt; &lt;conditionExpression xsi:type="tFormalExpression"&gt;&lt;![CDATA[$&#123;important&#125;]]&gt;&lt;/conditionExpression&gt; &lt;/sequenceFlow&gt; &lt;sequenceFlow id="_9" name="审批通过" sourceRef="_7" targetRef="_4"/&gt; &lt;/process&gt; &lt;bpmndi:BPMNDiagram documentation="background=#3C3F41;count=1;horizontalcount=1;orientation=0;width=842.4;height=1195.2;imageableWidth=832.4;imageableHeight=1185.2;imageableX=5.0;imageableY=5.0" id="Diagram-_1" name="New Diagram"&gt; &lt;bpmndi:BPMNPlane bpmnElement="dinghuangTest"&gt; &lt;bpmndi:BPMNShape bpmnElement="_2" id="Shape-_2"&gt; &lt;dc:Bounds height="32.0" width="32.0" x="100.0" y="135.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="32.0" width="32.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement="_3" id="Shape-_3"&gt; &lt;dc:Bounds height="55.0" width="85.0" x="235.0" y="140.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="55.0" width="85.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement="_4" id="Shape-_4"&gt; &lt;dc:Bounds height="32.0" width="32.0" x="565.0" y="160.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="32.0" width="32.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement="_7" id="Shape-_7"&gt; &lt;dc:Bounds height="55.0" width="85.0" x="415.0" y="55.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="55.0" width="85.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNEdge bpmnElement="_5" id="BPMNEdge__5" sourceElement="_2" targetElement="_3"&gt; &lt;di:waypoint x="132.0" y="151.0"/&gt; &lt;di:waypoint x="235.0" y="167.5"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement="_6" id="BPMNEdge__6" sourceElement="_3" targetElement="_4"&gt; &lt;di:waypoint x="320.0" y="167.5"/&gt; &lt;di:waypoint x="565.0" y="176.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement="_8" id="BPMNEdge__8" sourceElement="_3" targetElement="_7"&gt; &lt;di:waypoint x="320.0" y="167.5"/&gt; &lt;di:waypoint x="415.0" y="82.5"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement="_9" id="BPMNEdge__9" sourceElement="_7" targetElement="_4"&gt; &lt;di:waypoint x="500.0" y="82.5"/&gt; &lt;di:waypoint x="565.0" y="176.0"/&gt; &lt;bpmndi:BPMNLabel&gt; &lt;dc:Bounds height="0.0" width="0.0" x="0.0" y="0.0"/&gt; &lt;/bpmndi:BPMNLabel&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;/bpmndi:BPMNPlane&gt; &lt;/bpmndi:BPMNDiagram&gt;&lt;/definitions&gt; 这是一个很简单的流程，如图所示: 前端实现自定义流程、输出流程图官方提供bpmn.js可以实现前端拖动画图，github地址：https://github.com/bpmn-io/bpmn-js 可以把这个加到项目中，这里就不解释了。 前端实现输出流程图效果如下，流程节点会高亮显示： 这里是我写的一个小demo，代码可以查看我的github代码库。项目启动后，访问http://localhost:8080/v1/activiti/index 接口调试服务启动后访问地址：http://localhost:8080/swagger-ui.html#/接口已经写在代码中，如果需要调试的话，顺序是 启动实例流程 根据用户名称查询任务列表（用户名bilu，拿到任务id后去完成任务） 审批approve 回退 back 实现随意跳转和回退撤回功能因为activiti7是以图的形式来操作的，所以这边就要考虑连线的情况。 本文写了并行和串行的撤回以及撤回功能的连线的图，最终效果图如图所示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426/** * 输出图像 * * @param response 响应实体 * @param bpmnModel 图像对象 * @param flowIds 已执行的线集合 * @param executedActivityIdList void 已执行的节点ID集合 */ public void outputImg(HttpServletResponse response, BpmnModel bpmnModel, List&lt;String&gt; flowIds, List&lt;String&gt; executedActivityIdList) &#123; InputStream imageStream = null; try &#123; imageStream = new DefaultProcessDiagramGenerator().generateDiagram(bpmnModel, executedActivityIdList, flowIds, "宋体", "微软雅黑", "黑体", true, "png"); // 输出资源内容到相应对象 byte[] b = new byte[1024]; int len; while ((len = imageStream.read(b, 0, 1024)) != -1) &#123; response.getOutputStream().write(b, 0, len); &#125; response.getOutputStream().flush(); &#125; catch (Exception e) &#123; LOGGER.error("out put process img error！", e); &#125; finally &#123; // 流关闭 try &#123; if (imageStream != null) &#123; imageStream.close(); &#125; &#125; catch (IOException e) &#123; LOGGER.error("IoException", e); &#125; &#125; &#125; public void showImg(String instanceKey, HttpServletResponse response) &#123; if (instanceKey == null) &#123; LOGGER.error("process instance not exist"); return; &#125; //获取流程实例 HistoricProcessInstance processInstance = historyService.createHistoricProcessInstanceQuery().processInstanceId(instanceKey).singleResult(); if (processInstance == null) &#123; LOGGER.error("process instance &#123;&#125; not exist", instanceKey); return; &#125; // 根据流程对象获取流程对象模型 BpmnModel bpmnModel = repositoryService.getBpmnModel(processInstance.getProcessDefinitionId()); //查看已执行的节点集合, 获取流程历史中已执行节点，并按照节点在流程中执行先后顺序排序 // 构造历史流程查询 HistoricActivityInstanceQuery historyInstanceQuery = historyService.createHistoricActivityInstanceQuery().processInstanceId(instanceKey); // 查询历史节点,根据id排序 List&lt;HistoricActivityInstance&gt; historicActivityInstanceList = historyInstanceQuery.orderBy(HistoricActivityInstanceQueryProperty.HISTORIC_ACTIVITY_INSTANCE_ID).asc().list(); if (historicActivityInstanceList == null || historicActivityInstanceList.size() == 0) &#123; LOGGER.info("process instance history node info not exist", instanceKey); outputImg(response, bpmnModel, null, null); return; &#125; Map&lt;String, FlowNode&gt; flowNodeMap = getFlowNodeMap(historicActivityInstanceList, processInstance.getProcessDefinitionId()); //处理撤回这种情况 根据id排序 List&lt;Task&gt; tasks = taskService.createTaskQuery().processInstanceId(instanceKey).orderBy(TaskQueryProperty.TASK_ID).asc().list(); Set&lt;String&gt; executedActivityIdList = new LinkedHashSet&lt;&gt;(); List&lt;String&gt; taskIdList = tasks == null ? null : tasks.stream().map(TaskInfo::getId).collect(Collectors.toList()); List&lt;String&gt; taskKeyList = tasks == null ? null : tasks.stream().map(TaskInfo::getTaskDefinitionKey).collect(Collectors.toList()); if (tasks != null) &#123; //串行 if (tasks.size() == 1) &#123; for (int i = 0; i &lt; historicActivityInstanceList.size(); i++) &#123; if (historicActivityInstanceList.get(i).getTaskId() == null || !historicActivityInstanceList.get(i).getActivityId().equals(tasks.get(0).getTaskDefinitionKey())) &#123; executedActivityIdList.add(historicActivityInstanceList.get(i).getActivityId()); &#125; else &#123; executedActivityIdList.add(historicActivityInstanceList.get(i).getActivityId()); break; &#125; &#125; &#125; else &#123; List&lt;HistoricVariableInstance&gt; historicVariableInstances = historyService.createHistoricVariableInstanceQuery() .processInstanceId(processInstance.getId()).list(); Map&lt;String, HistoricVariableInstance&gt; historicVariableInstanceMap = historicVariableInstances.stream() .collect(Collectors.toMap(HistoricVariableInstance::getVariableName, historicVariableInstance -&gt; historicVariableInstance, BinaryOperator.maxBy(Comparator.comparing(HistoricVariableInstance::getId)))); //并行 Collection&lt;FlowElement&gt; flowElementCollection = bpmnModel.getMainProcess().getFlowElements(); Map&lt;String, List&lt;String&gt;&gt; parentMap = new HashMap&lt;&gt;(tasks.size()); for (FlowElement flowElement : flowElementCollection) &#123; List&lt;String&gt; parentCodeList = new LinkedList&lt;&gt;(); if (flowNodeMap.get(flowElement.getId()) != null) &#123; List&lt;SequenceFlow&gt; sequenceFlows = flowNodeMap.get(flowElement.getId()).getIncomingFlows(); if (sequenceFlows != null &amp;&amp; !sequenceFlows.isEmpty()) &#123; for (SequenceFlow sequenceFlow : sequenceFlows) &#123; parentCodeList.add(sequenceFlow.getSourceRef()); &#125; parentMap.put(flowElement.getId(), parentCodeList); &#125; &#125; &#125; Set&lt;String&gt; sameParentTaskCode = new LinkedHashSet&lt;&gt;(); for (Task task : tasks) &#123; //找到所有任务拥有相同父级的集合任务 for (String taskKey : parentMap.get(task.getTaskDefinitionKey())) &#123; for (String key : parentMap.keySet()) &#123; if (parentMap.get(key).contains(taskKey)) &#123; sameParentTaskCode.add(key); break; &#125; &#125; &#125; &#125; //说明是并行，但是做完的任务 for (String sameParentTask : sameParentTaskCode) &#123; if (!taskKeyList.contains(sameParentTask)) &#123; List&lt;SequenceFlow&gt; sequenceFlows = flowNodeMap.get(sameParentTask).getOutgoingFlows(); if (sequenceFlows != null &amp;&amp; !sequenceFlows.isEmpty()) &#123; for (SequenceFlow sequenceFlow : sequenceFlows) &#123; if (querySequenceFlowCondition(sequenceFlow, historicVariableInstanceMap)) &#123; executedActivityIdList.add(sequenceFlow.getTargetRef()); &#125; &#125; &#125; &#125; &#125; for (String taskKey : sameParentTaskCode) &#123; for (int i = 0; i &lt; historicActivityInstanceList.size(); i++) &#123; if (historicActivityInstanceList.get(i).getTaskId() == null || !historicActivityInstanceList.get(i).getActivityId().equals(taskKey)) &#123; executedActivityIdList.add(historicActivityInstanceList.get(i).getActivityId()); &#125; else &#123; executedActivityIdList.add(historicActivityInstanceList.get(i).getActivityId()); break; &#125; &#125; &#125; &#125; &#125; //获取流程走过的线 List&lt;String&gt; executedActivityIdListResult = new ArrayList&lt;&gt;(executedActivityIdList); List&lt;String&gt; flowIds = getHighLightedFlows(bpmnModel, historicActivityInstanceList, executedActivityIdListResult, taskIdList); //输出图像，并设置高亮 outputImg(response, bpmnModel, flowIds, executedActivityIdListResult); &#125; private Map&lt;String, FlowNode&gt; getFlowNodeMap(List&lt;HistoricActivityInstance&gt; historicActivityInstanceList, String processDefinitionId) &#123; org.activiti.bpmn.model.Process process = repositoryService .getBpmnModel(processDefinitionId) .getMainProcess(); Map&lt;String, FlowNode&gt; flowNodeMap = new HashMap&lt;&gt;(historicActivityInstanceList.size()); for (HistoricActivityInstance historicActivityInstance : historicActivityInstanceList) &#123; if (flowNodeMap.get(historicActivityInstance.getActivityId()) == null) &#123; FlowNode sourceNode = (FlowNode) process.getFlowElement(historicActivityInstance.getActivityId()); flowNodeMap.put(historicActivityInstance.getActivityId(), sourceNode); &#125; &#125; return flowNodeMap; &#125; /** * 撤回任务 * * @param currentTaskId currentTaskId * @param targetTaskId targetTaskId 目标任务，如果为空，默认返回上级，如果找到上级有2个，那目标任务必须得传 */ @Transactional(rollbackFor = Exception.class) public void backTask(String currentTaskId, String targetTaskId) &#123; //准备数据 TaskService taskService = processEngine.getTaskService(); // 当前任务 Task currentTask = taskService.createTaskQuery().taskId(currentTaskId).singleResult(); String processInstanceId = currentTask.getProcessInstanceId(); // 获取流程定义 //任务历史数据 List&lt;HistoricTaskInstance&gt; historicTaskInstances = historyService .createHistoricTaskInstanceQuery() .processInstanceId(currentTask.getProcessInstanceId()) .orderBy(HistoricTaskInstanceQueryProperty.HISTORIC_TASK_INSTANCE_ID) .desc() .list(); Map&lt;String, HistoricTaskInstance&gt; historicTaskInstanceMap = historicTaskInstances.stream().collect(Collectors.toMap(HistoricTaskInstance::getId, Function.identity())); //所有节点操作数据 HistoricActivityInstanceQuery historyInstanceQuery = historyService.createHistoricActivityInstanceQuery().processInstanceId(processInstanceId); List&lt;HistoricActivityInstance&gt; historicActivityInstanceList = historyInstanceQuery.orderBy(HistoricActivityInstanceQueryProperty.HISTORIC_ACTIVITY_INSTANCE_ID).asc().list(); Map&lt;String, List&lt;HistoricActivityInstance&gt;&gt; historicActivityInstanceMap = historicActivityInstanceList.stream().collect(Collectors.groupingBy(HistoricActivityInstance::getActivityId)); Map&lt;String, FlowNode&gt; flowNodeMap = getFlowNodeMap(historicActivityInstanceList, currentTask.getProcessDefinitionId()); //排除当前任务外的所有正在进行的任务 List&lt;Task&gt; taskList = taskService.createTaskQuery().processInstanceId(processInstanceId).list().stream().filter(task -&gt; !task.getId().equals(currentTask.getId())).collect(Collectors.toList()); handleBackTask(currentTask, currentTask.getTaskDefinitionKey(), targetTaskId, historicTaskInstanceMap, historicActivityInstanceMap, flowNodeMap, taskList, historicActivityInstanceList); &#125; @Transactional(rollbackFor = Exception.class) public void handleBackTask(Task currentTask, String taskDefinitionKey, String targetTaskId, Map&lt;String, HistoricTaskInstance&gt; historicTaskInstanceMap, Map&lt;String, List&lt;HistoricActivityInstance&gt;&gt; historicActivityInstanceMap, Map&lt;String, FlowNode&gt; flowNodeMap, List&lt;Task&gt; taskList, List&lt;HistoricActivityInstance&gt; historicActivityInstanceList) &#123; //判断是否并行 if (taskList == null || taskList.isEmpty()) &#123; //串行 handleSerial(currentTask, taskDefinitionKey, targetTaskId, historicTaskInstanceMap, historicActivityInstanceMap, flowNodeMap, taskList, historicActivityInstanceList); &#125; else &#123; //并行 handleParallel(currentTask, taskDefinitionKey, targetTaskId, historicTaskInstanceMap, historicActivityInstanceMap, flowNodeMap, taskList, historicActivityInstanceList); &#125; &#125; @Transactional(rollbackFor = Exception.class) public void handleParallel(Task currentTask, String taskDefinitionKey, String targetTaskId, Map&lt;String, HistoricTaskInstance&gt; historicTaskInstanceMap, Map&lt;String, List&lt;HistoricActivityInstance&gt;&gt; historicActivityInstanceMap, Map&lt;String, FlowNode&gt; flowNodeMap, List&lt;Task&gt; taskList, List&lt;HistoricActivityInstance&gt; historicActivityInstanceList) &#123; List&lt;SequenceFlow&gt; sequenceFlows = flowNodeMap.get(taskDefinitionKey).getIncomingFlows(); if (sequenceFlows.size() == 1) &#123; //当前节点的上级节点只有一条 SequenceFlow sequenceFlow = sequenceFlows.get(0); //查询历史节点 HistoricActivityInstance historicActivityInstance = historicActivityInstanceList.stream().filter(query -&gt; query.getActivityId().equals(sequenceFlow.getSourceRef())).collect(Collectors.toList()).get(0); //判断来源类型 if (historicActivityInstance.getActivityType().equals(PARALLEL_GATEWAY)) &#123; //网关 //查找网关的父任务 Set&lt;String&gt; parentFlowNodes = queryParentFlowNode(historicActivityInstance.getActivityId(), flowNodeMap); if (!parentFlowNodes.isEmpty()) &#123; if (parentFlowNodes.size() == 1) &#123; //如果只有一个父节点 String activityId = new ArrayList&lt;&gt;(parentFlowNodes).get(0); if (historicActivityInstanceMap.get(activityId).get(0).getActivityType().equals(USER_TASK)) &#123; //用户任务 deleteTaskMultiple(flowNodeMap, null, null, activityId, currentTask, taskList, historicActivityInstance.getActivityId()); &#125; else &#123; //递归去查找父任务的前一个 handleBackTask(currentTask, historicActivityInstanceMap.get(activityId).get(0).getActivityId(), targetTaskId, historicTaskInstanceMap, historicActivityInstanceMap, flowNodeMap, taskList, historicActivityInstanceList); &#125; &#125; else &#123; //当前节点的上级节点有多条 这里需要指定要回退的taskId deleteTaskMultiple(flowNodeMap, historicTaskInstanceMap, targetTaskId, null, currentTask, taskList, historicActivityInstance.getActivityId()); &#125; &#125; else &#123; //没有父级任务，图有问题 throw new CommonValidateException("bpmn doc error"); &#125; &#125; else if (historicActivityInstance.getActivityType().equals(USER_TASK)) &#123; //用户任务 deleteTaskMultiple(flowNodeMap, null, null, historicActivityInstance.getActivityId(), currentTask, taskList, historicActivityInstance.getActivityId()); &#125; else &#123; //todo 还没想好这种场景 throw new CommonValidateException(BPMN_NOT_SUPPORT); &#125; &#125; else &#123; //当前节点的上级节点有多条 这里需要指定要回退的taskId deleteTaskMultiple(flowNodeMap, historicTaskInstanceMap, targetTaskId, null, currentTask, taskList, null); &#125; &#125; @Transactional(rollbackFor = Exception.class) public void handleSerial(Task currentTask, String taskDefinitionKey, String targetTaskId, Map&lt;String, HistoricTaskInstance&gt; historicTaskInstanceMap, Map&lt;String, List&lt;HistoricActivityInstance&gt;&gt; historicActivityInstanceMap, Map&lt;String, FlowNode&gt; flowNodeMap, List&lt;Task&gt; taskList, List&lt;HistoricActivityInstance&gt; historicActivityInstanceList) &#123; FlowNode currentNode = flowNodeMap.get(taskDefinitionKey); List&lt;SequenceFlow&gt; sequenceFlows = currentNode.getIncomingFlows(); if (sequenceFlows.size() == 1) &#123; SequenceFlow sequenceFlow = sequenceFlows.get(0); HistoricActivityInstance historicActivityInstance = historicActivityInstanceMap.get(sequenceFlow.getSourceRef()).get(0); //网关 if (historicActivityInstance.getActivityType().equals(PARALLEL_GATEWAY) || historicActivityInstance.getActivityType().equals(EXCLUSIVE_GATEWAY)) &#123; //查找网关的父任务 Set&lt;String&gt; parentFlowNodes = queryParentFlowNode(historicActivityInstance.getActivityId(), flowNodeMap); if (!parentFlowNodes.isEmpty()) &#123; handleBackTaskSingle(parentFlowNodes, currentTask, targetTaskId, historicTaskInstanceMap, historicActivityInstanceMap, flowNodeMap, taskList, historicActivityInstanceList); &#125; else &#123; //当前节点的上级节点有多条 这里需要指定要回退的taskId deleteTaskMultiple(flowNodeMap, historicTaskInstanceMap, targetTaskId, null, currentTask, taskList, null); &#125; &#125; else if (historicActivityInstance.getActivityType().equals(USER_TASK)) &#123; deleteTaskSingle(flowNodeMap, historicActivityInstance.getActivityId(), currentTask.getId()); &#125; else &#123; //todo 还没想好这种场景 throw new CommonValidateException(BPMN_NOT_SUPPORT); &#125; &#125; else &#123; Map&lt;String, HistoricVariableInstance&gt; historicVariableInstanceMap = getHistoricVariableInstanceMap(currentTask.getProcessInstanceId()); //串行的也有多条连线，可能是通过排他网关过来的 Set&lt;HistoricActivityInstance&gt; historicActivityInstances = new HashSet&lt;&gt;(); for (SequenceFlow sequenceFlow : sequenceFlows) &#123; //这边他的parent可能是没做过的，要找做过的 if (historicActivityInstanceMap.get(sequenceFlow.getSourceRef()) != null &amp;&amp; querySequenceFlowCondition(sequenceFlow, historicVariableInstanceMap)) &#123; historicActivityInstances.addAll(historicActivityInstanceMap.get(sequenceFlow.getSourceRef())); &#125; &#125; //走过的只有一个 if (historicActivityInstances.size() == 1) &#123; List&lt;HistoricActivityInstance&gt; historicActivityInstancesList = new ArrayList&lt;&gt;(historicActivityInstances); if (historicActivityInstancesList.get(0).getActivityType().equals(USER_TASK)) &#123; deleteTaskSingle(flowNodeMap, historicActivityInstancesList.get(0).getActivityId(), currentTask.getId()); &#125; else if (historicActivityInstancesList.get(0).getActivityType().equals(EXCLUSIVE_GATEWAY)) &#123; //排他网关 Set&lt;String&gt; parentFlowNodes = queryParentFlowNode(historicActivityInstancesList.get(0).getActivityId(), flowNodeMap); handleBackTaskSingle(parentFlowNodes, currentTask, targetTaskId, historicTaskInstanceMap, historicActivityInstanceMap, flowNodeMap, taskList, historicActivityInstanceList); &#125; else &#123; //todo 还没想好这种场景 throw new CommonValidateException(BPMN_NOT_SUPPORT); &#125; &#125; else &#123; //当前节点的上级节点有多条 这里需要指定要回退的taskId deleteTaskMultiple(flowNodeMap, historicTaskInstanceMap, targetTaskId, null, currentTask, taskList, null); &#125; &#125; &#125; private Map&lt;String, HistoricVariableInstance&gt; getHistoricVariableInstanceMap(String processInstanceId) &#123; List&lt;HistoricVariableInstance&gt; historicVariableInstances = historyService.createHistoricVariableInstanceQuery() .processInstanceId(processInstanceId).list(); Map&lt;String, HistoricVariableInstance&gt; historicVariableInstanceMap = historicVariableInstances.stream() .collect(Collectors.toMap(HistoricVariableInstance::getVariableName, historicVariableInstance -&gt; historicVariableInstance, BinaryOperator.maxBy(Comparator.comparing(HistoricVariableInstance::getId)))); return historicVariableInstanceMap; &#125; @Transactional(rollbackFor = Exception.class) public void handleBackTaskSingle(Set&lt;String&gt; parentFlowNodes, Task currentTask, String targetTaskId, Map&lt;String, HistoricTaskInstance&gt; historicTaskInstanceMap, Map&lt;String, List&lt;HistoricActivityInstance&gt;&gt; historicActivityInstanceMap, Map&lt;String, FlowNode&gt; flowNodeMap, List&lt;Task&gt; taskList, List&lt;HistoricActivityInstance&gt; historicActivityInstanceList) &#123; if (parentFlowNodes.size() == 1) &#123; List&lt;String&gt; parentFlowNodeList = new ArrayList&lt;&gt;(parentFlowNodes); if (historicActivityInstanceMap.get(parentFlowNodeList.get(0)).get(0).getActivityType().equals(USER_TASK)) &#123; deleteTaskSingle(flowNodeMap, parentFlowNodeList.get(0), currentTask.getId()); &#125; else &#123; //递归去查找父任务的前一个 handleBackTask(currentTask, historicActivityInstanceMap.get(parentFlowNodeList.get(0)).get(0).getActivityId(), targetTaskId, historicTaskInstanceMap, historicActivityInstanceMap, flowNodeMap, taskList, historicActivityInstanceList); &#125; &#125; else &#123; //当前节点的上级节点有多条 这里需要指定要回退的taskId deleteTaskMultiple(flowNodeMap, historicTaskInstanceMap, targetTaskId, null, currentTask, taskList, null); &#125; &#125; private void validatorTargetTask(Map&lt;String, HistoricTaskInstance&gt; historicTaskInstanceMap, String targetTaskId) &#123; if (StringUtils.isEmpty(targetTaskId) || StringUtils.isBlank(targetTaskId)) &#123; throw new CommonValidateException("target task id cannot be null"); &#125; if (historicTaskInstanceMap == null || historicTaskInstanceMap.isEmpty()) &#123; throw new CommonValidateException("historic task instance cannot be null"); &#125; &#125; @Transactional(rollbackFor = Exception.class) public void deleteTaskMultiple(Map&lt;String, FlowNode&gt; flowNodeMap, Map&lt;String, HistoricTaskInstance&gt; historicTaskInstanceMap, String targetTaskId, String targetTaskDefinitionKey, Task currentTask, List&lt;Task&gt; taskList, String targetParentTaskDefinitionKey) &#123; if (StringUtils.isEmpty(targetTaskDefinitionKey) || StringUtils.isBlank(targetTaskDefinitionKey)) &#123; validatorTargetTask(historicTaskInstanceMap, targetTaskId); targetTaskDefinitionKey = historicTaskInstanceMap.get(targetTaskId).getTaskDefinitionKey(); &#125; FlowNode targetNode = flowNodeMap.get(targetTaskDefinitionKey); ManagementService managementService = processEngine.getManagementService(); //删除当前任务 managementService.executeCommand(new DeleteTaskCmd(currentTask.getId())); // 删除当前运行的其他相同父任务的子任务 Set&lt;Task&gt; sameParentTasks = getSameParentTasks(flowNodeMap, taskList, targetParentTaskDefinitionKey); for (Task task : sameParentTasks) &#123; managementService.executeCommand(new DeleteTaskCmd(task.getId())); &#125; // 流程执行到来源节点 managementService.executeCommand(new SetFLowNodeAndGoCmd(targetNode, currentTask.getExecutionId())); &#125; @Transactional(rollbackFor = Exception.class) public void deleteTaskSingle(Map&lt;String, FlowNode&gt; flowNodeMap, String targetTaskActivitiId, String currentTaskId) &#123; ManagementService managementService = processEngine.getManagementService(); FlowNode targetNode = flowNodeMap.get(targetTaskActivitiId); // 删除当前运行任务 String executionEntityId = managementService.executeCommand(new DeleteTaskCmd(currentTaskId)); // 流程执行到来源节点 managementService.executeCommand(new SetFLowNodeAndGoCmd(targetNode, executionEntityId)); &#125; private Set&lt;String&gt; queryParentFlowNode(String activityId, Map&lt;String, FlowNode&gt; flowNodeMap) &#123; Set&lt;String&gt; flowNodeList = new HashSet&lt;&gt;(); for (String key : flowNodeMap.keySet()) &#123; if (!key.equals(activityId)) &#123; FlowNode flowNode = flowNodeMap.get(key); List&lt;SequenceFlow&gt; sequenceFlows = flowNode.getOutgoingFlows(); for (SequenceFlow sequenceFlow : sequenceFlows) &#123; if (sequenceFlow.getTargetRef().equals(activityId)) &#123; flowNodeList.add(key); break; &#125; &#125; &#125; &#125; return flowNodeList; &#125; private Set&lt;Task&gt; getSameParentTasks(Map&lt;String, FlowNode&gt; flowNodeMap, List&lt;Task&gt; taskList, String taskDefinitionKey) &#123; if (taskDefinitionKey == null) &#123; return new HashSet&lt;&gt;(taskList); &#125; Set&lt;Task&gt; tasks = new HashSet&lt;&gt;(); for (Task task : taskList) &#123; List&lt;SequenceFlow&gt; sequenceFlows = flowNodeMap.get(task.getTaskDefinitionKey()).getIncomingFlows(); for (SequenceFlow sequenceFlow : sequenceFlows) &#123; if (sequenceFlow.getSourceRef().equals(taskDefinitionKey)) &#123; tasks.add(task); break; &#125; &#125; &#125; return tasks; &#125; @Transactional(rollbackFor = Exception.class) public void importBpmnFile(MultipartFile file, String type, String typeName) &#123; try &#123; InputStream fileInputStream = file.getInputStream(); //创建转换对象 BpmnXMLConverter bpmnXMLConverter = new BpmnXMLConverter(); //读取xml文件 XMLInputFactory xmlInputFactory = XMLInputFactory.newInstance(); XMLStreamReader xmlStreamReader = xmlInputFactory.createXMLStreamReader(fileInputStream); //将xml文件转换成BpmnModel BpmnModel bpmnModel = bpmnXMLConverter.convertToBpmnModel(xmlStreamReader); bpmnModel.getMainProcess().setId(type); bpmnModel.getMainProcess().setName(typeName); Deployment deployment = repositoryService.createDeployment() .addBpmnModel(typeName + ".bpmn", bpmnModel) .key(IdWorker.getIdStr()) .deploy(); ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery().deploymentId(deployment.getId()).singleResult(); BpmnModel model = repositoryService.getBpmnModel(processDefinition.getId()); if (model != null) &#123; Collection&lt;FlowElement&gt; flowElementCollection = model.getMainProcess().getFlowElements(); for (FlowElement e : flowElementCollection) &#123; LOGGER.info("flowelement id:" + e.getId() + " name:" + e.getName() + " class:" + e.getClass().toString()); &#125; &#125; activitiRepository.updateActReProcdef(processDefinition.getId()); &#125; catch (Exception e) &#123; LOGGER.error("导入流程定义失败:&#123;&#125;", e.getMessage(), e); &#125; &#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试分享(七).操作系统相关]]></title>
    <url>%2F2019%2F09%2F18%2F%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB(%E4%B8%83).%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[操作系统相关什么是socket，网络传输有哪几个层级什么是socket网络上的两个程序通过一个双向的通信连接实现数据的交换，这个连接的一端称为一个socket。 建立网络通信连接至少要一对端口号(socket)。socket本质是编程接口(API)，对TCP/IP的封装，TCP/IP也要提供可供程序员做网络开发所用的接口，这就是Socket编程接口;HTTP是轿车，提供了封装或者显示数据的具体形式;Socket是发动机，提供了网络通信的能力。 Socket的英文原义是”孔”或”插座”。作为BSD UNIX的进程通信机制，取后一种意思。通常也称作”套接字”，用于描述IP地址和端口，是一个通信链的句柄，可以用来实现不同虚拟机或不同计算机之间的通信。在Internet上的主机一般运行了多个服务软件，同时提供几种服务。每种服务都打开一个Socket，并绑定到一个端口上，不同的端口对应于不同的服务。 Socket正如其英文原意那样，像一个多孔插座。一台主机犹如布满各种插座的房间，每个插座有一个编号，有的插座提供220伏交流电， 有的提供110伏交流电，有的则提供有线电视节目。 客户软件将插头插到不同编号的插座，就可以得到不同的服务。 网络传输有哪几个层级所谓的协议就是双方进行数据传输的一种格式。 网络中，一帧以太网数据包的格式： 层级 名称 包含的协议 7 应用层 例如HTTP、SMTP、SNMP、FTP、Telnet、SIP、SSH、NFS、RTSP、XMPP、Whois、ENRP 6 表示层 例如XDR、ASN.1、SMB、AFP、NCP 5 会话层 例如ASAP、TLS、SSH、ISO 8327 / CCITT X.225、RPC、NetBIOS、ASP、Winsock、BSD sockets 4 传输层 例如TCP、UDP、RTP、SCTP、SPX、ATP、IL 3 网络层 例如IP、ICMP、IGMP、IPX、BGP、OSPF、RIP、IGRP、EIGRP、ARP、RARP、 X.25 2 数据链路层 例如以太网、令牌环、HDLC、帧中继、ISDN、ATM、IEEE 802.11、FDDI、PPP 1 物理层 例如线路、无线电、光纤、信鸽 层级 名称 功能 7 应用层 文件传输，电子邮件，文件服务，虚拟终端 6 表示层 数据格式化，代码转换，数据加密 5 会话层 解除或建立与别的结点的联系 4 传输层 提供端对端的接口 3 网络层 为数据包选择路由 2 数据链路层 传输有地址的帧以及错误检测功能 1 物理层 以二进制数据形式在物理媒体上传输数据 TCP/IP是传输层协议，主要解决数据如何在网络中传输；而HTTP是应用层协议，主要解决如何包装数据。 把IP想像成一种高速公路，它允许其它协议在上面行驶并找到到其它电脑的出口。TCP和UDP是高速公路上的“卡车”，它们携带的货物就是像HTTP，文件传输协议FTP这样的协议等。(可以这样理解:TCP和UDP都是用来传输其他协议的) 而Socket是对TCP/IP协议的封装，Socket本身并不是协议，而是一个调用接口（API），通过Socket，我们才能使用TCP/IP协议。 ip地址 每个IP地址包括两个标识码（ID），即网络ID和主机ID。同一个物理网络上的所有主机都使用同一个网络ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机ID与其对应。 Internet委员会定义了5种IP地址类型以适合不同容量的网络，即A类~E类。其中A、B、C3类（如下表格）由InternetNIC在全球范围内统一分配，D、E类为特殊地址 TIME_WAIT是什么状态还记得吗，什么情况下网络会出现这个状态出现原因分析TCP连接的终止TCP建立一个连接至少需要交换三个分组，也因此称之为TCP的三路握手（three-way handshake），然而在TCP终止连接时，由于双方都需要发送一个FIN分节给对端确认，因此TCP终止连接一般是需要交换四个分节。具体来看： 1、 应用进程（active close）首先调用close，于是导致TCP发送一个FIN分节，表示数据已分送完毕，请求关闭套接字。 2、 另一端应用进程（passive close）接受收到FIN，并由该端的TCP确认（确认的过程是TCP发送ACK分节给对端套接字）。FIN的接受也作为文件结束符传递给上层应用进程。这里的文件结束符并非应用进程的EOF，在TCP字节流中，EOF的读或写通过收发一个特殊的FIN分节来实现 3、 另端（passive close）应用进程在接受到文件束符后，会调用close关闭它的套接字，这导致该端的TCP也发送了一个FIN分节。 4、 主动关闭端（active close）接受到这个FIN后，TCP对它进行确认。（TCP发送ACK分节，值得注意的是主动关闭端在未接受到FIN之前，它的状态就是TIME_WAIT）。 综上所述：TIME_WAIT状态出现场景是主动关闭端在未接受到FIN之前，它的状态就是TIME_WAIT。 TCP为什么如此设计1。防止上一次连接中的包(特别是最后一个ACK包)，迷路后重新出现，影响新连接 （经过2MSL(max segment lifetime)，上一次连接中所有的重复包都会消失）。 2。可靠的关闭TCP连接 在主动关闭方发送的最后一个 ack(fin) ，有可能丢失，这时被动方会重新发 fin, 如果这时主动方处于 CLOSED 状态 ，就会响应 rst 而不是 ack。所以 主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。TIME_WAIT 并不会占用很大资源的，除非受到攻击。还有，如果一方 send 或 recv 超时，就会直接进入 CLOSED 状态。 规避大量出现TIME_WAIT的方法 net.ipv4.tcp_tw_reuse和net.ipv4.tcp_tw_recycle的开启都是为了回收处于TIME_WAIT状态的资源。 net.ipv4.tcp_fin_timeout这个时间可以减少在异常情况下服务器从FIN-WAIT-2转到TIME_WAIT的时间。 net.ipv4.tcp_keepalive_*一系列参数，是用来设置服务器检测连接存活的相关配置。 在服务器的日常维护过程中，会经常用到下面的命令： 1netstat -n | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;' 它会显示例如下面的信息： 123456TIME_WAIT 814CLOSE_WAIT 1FIN_WAIT1 1ESTABLISHED 634SYN_RECV 2LAST_ACK 1 常用的三个状态是：ESTABLISHED 表示正在通信，TIME_WAIT 表示主动关闭，CLOSE_WAIT 表示被动关闭。 三次握手的详细描述第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认； 第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。 为什么要三次握手既然总结了TCP的三次握手，那为什么非要三次呢？怎么觉得两次就可以完成了。那TCP为什么非要进行三次连接呢？在谢希仁的《计算机网络》中是这样说的： 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。 在书中同时举了一个例子，如下： “已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。” 这就很明白了，防止了服务器端的一直等待而浪费资源。 四次挥手的详细描述当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，肯定是要断开TCP连接的啊。那对于TCP的断开连接，这里就有了神秘的“四次分手”。 第一次分手：主机1（可以使客户端，也可以是服务器端），设置Sequence Number和Acknowledgment Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了； 第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我也没有数据要发送了，可以进行关闭连接了； 第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入CLOSE_WAIT状态； 第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。 至此，TCP的四次分手就这么愉快的完成了。当你看到这里，你的脑子里会有很多的疑问，很多的不懂，感觉很凌乱；没事，我们继续总结。 为什么要四次分手那四次分手又是为何呢？TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。如果要正确的理解四次分手的原理，就需要了解四次分手过程中的状态变化。 FIN_WAIT_1: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。（主动方） FIN_WAIT_2：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，我暂时还有点数据需要传送给你(ACK信息)，稍后再关闭连接。（主动方） CLOSE_WAIT：这种状态的含义其实是表示在等待关闭。怎么理解呢？当对方close一个SOCKET后发送FIN报文给自己，你系统毫无疑问地会回应一个ACK报文给对方，此时则进入到CLOSE_WAIT状态。接下来呢，实际上你真正需要考虑的事情是察看你是否还有数据发送给对方，如果没有的话，那么你也就可以 close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接。（被动方） LAST_ACK: 这个状态还是比较容易好理解的，它是被动关闭一方在发送FIN报文后，最后等待对方的ACK报文。当收到ACK报文后，也即可以进入到CLOSED可用状态了。（被动方） TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FINWAIT1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（主动方） CLOSED: 表示连接中断。 哪些典型的应用用的是UDP？TCP应用（1）FTP：文件传输协议； （2）SSH：安全登录、文件传送(SCP)和端口重定向； （3）Telnet：不安全的文本传送； （4）SMTP：简单邮件传输协议Simple Mail Transfer Protocol (E-mail)； （5）HTTP：超文本传送协议 (WWW)； UDP应用（1）流媒体 采用TCP，一旦发生丢包，TCP会将后续包缓存起来，等前面的包重传并接收到后再继续发送，延迟会越来越大。基于UDP的协议如WebRTC是极佳的选择。 （2）实时游戏 对实时要求较为严格的情况下，采用自定义的可靠UDP协议，比如Enet、RakNet（用户有sony online game、minecraft）等，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成的影响。 采用UDP的经典游戏如FPS游戏Quake、CS，著名的游戏引擎Unity3D采用的也是RakNet。 （3）物联网 2014年google旗下的Nest建立Thread Group，推出了物联网通信协议Thread，完善物联网通信。 全球将近50%的人都在使用互联网，人们不断的追求更快、更好的服务，一切都在变化，在越来越多的领域，UDP将会抢占TCP的主导地位。 （4）QQ 文件传输、QQ语音、QQ视频 对于网络通讯质量要求不高的情况下，要求网络通讯速度能尽量快捷方便，就可以使用UDP技术。 内核态和用户态、cas 和 sout 哪个用到了内核态和用户态的切换究竟什么是用户态，什么是内核态，这两个基本概念以前一直理解得不是很清楚，根本原因个人觉得是在于因为大部分时候我们在写程序时关注的重点和着眼的角度放在了实现的功能和代码的逻辑性上，先看一个例子： 123456789101112void testfork()&#123; if(0 = = fork())&#123; printf(“create new process success!\n”); &#125; printf(“testfork ok\n”); &#125; 这段代码很简单，从功能的角度来看，就是实际执行了一个fork()，生成一个新的进程，从逻辑的角度看，就是判断了如果fork()返回的是则打印相关语句，然后函数最后再打印一句表示执行完整个testfork()函数。代码的执行逻辑和功能上看就是如此简单，一共四行代码，从上到下一句一句执行而已，完全看不出来哪里有体现出用户态和进程态的概念。 如果说前面两种是静态观察的角度看的话，我们还可以从动态的角度来看这段代码，即它被转换成CPU执行的指令后加载执行的过程，这时这段程序就是一个动态执行的指令序列。而究竟加载了哪些代码，如何加载就是和操作系统密切相关了。 特权级熟悉Unix/Linux系统的人都知道，fork的工作实际上是以系统调用的方式完成相应功能的，具体的工作是由sys_fork负责实施。其实无论是不是Unix或者Linux，对于任何操作系统来说，创建一个新的进程都是属于核心功能，因为它要做很多底层细致地工作，消耗系统的物理资源，比如分配物理内存，从父进程拷贝相关信息，拷贝设置页目录页表等等，这些显然不能随便让哪个程序就能去做，于是就自然引出特权级别的概念，显然，最关键性的权力必须由高特权级的程序来执行，这样才可以做到集中管理，减少有限资源的访问和使用冲突。 特权级显然是非常有效的管理和控制程序执行的手段，因此在硬件上对特权级做了很多支持，就Intel x86架构的CPU来说一共有0~3四个特权级，0级最高，3级最低，硬件上在执行每条指令时都会对指令所具有的特权级做相应的检查，相关的概念有 CPL、DPL和RPL，这里不再过多阐述。硬件已经提供了一套特权级使用的相关机制，软件自然就是好好利用的问题，这属于操作系统要做的事情，对于 Unix/Linux来说，只使用了0级特权级和3级特权级。也就是说在Unix/Linux系统中，一条工作在级特权级的指令具有了CPU能提供的最高权力，而一条工作在3级特权级的指令具有CPU提供的最低或者说最基本权力。 用户态和内核态现在我们从特权级的调度来理解用户态和内核态就比较好理解了，当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；反之，当程序运行在级特权级上时，就可以称之为运行在内核态。 虽然用户态下和内核态下工作的程序有很多差别，但最重要的差别就在于特权级的不同，即权力的不同。运行在用户态下的程序不能直接访问操作系统内核数据结构和程序，比如上面例子中的testfork()就不能直接调用 sys_fork()，因为前者是工作在用户态，属于用户态程序，而sys_fork()是工作在内核态，属于内核态程序。 当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态，比如testfork()最初运行在用户态进程下，当它调用fork()最终触发 sys_fork()的执行时，就切换到了内核态。 用户态和内核态的转换1）用户态切换到内核态的3种方式 a. 系统调用 这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。 b. 异常 当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。 c. 外围设备的中断 当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。 这3种方式是系统在运行时由用户态转到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。 2）具体的切换操作 从触发方式上看，可以认为存在前述3种不同的类型，但是从最终实际完成由用户态到内核态的切换操作上来说，涉及的关键步骤是完全一致的，没有任何区别，都相当于执行了一个中断响应的过程，因为系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本上也是一致的，关于它们的具体区别这里不再赘述。关于中断处理机制的细节和步骤这里也不做过多分析，涉及到由用户态切换到内核态的步骤主要包括： [1] 从当前进程的描述符中提取其内核栈的ss0及esp0信息。 [2] 使用ss0和esp0指向的内核栈将当前进程的cs,eip,eflags,ss,esp信息保存起来，这个 过程也完成了由用户栈到内核栈的切换过程，同时保存了被暂停执行的程序的下一 条指令。 [3] 将先前由中断向量检索得到的中断处理程序的cs,eip信息装入相应的寄存器，开始 执行中断处理程序，这时就转到了内核态的程序执行了。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试分享(六).算法相关]]></title>
    <url>%2F2019%2F08%2F18%2F%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB(%E5%85%AD).%E7%AE%97%E6%B3%95%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[算法相关 递归使用中有什么需要注意的地方，递归写法一般可以用什么去替换？ 如下图所示： 设计一个发号器，考虑集群和高并发的情况，要求发号器生成的id是递增趋势，通过id可以区分出来是今天生成的id还是昨天生成的id，但是生成的id中不能直接带有日期，要具有一定的混淆功能，白纸写代码 一个二位数组，每个元素都可以往上下左右四个方向走，寻找最长递增路径。如下图所示，最长递增路径即红色字体路径。白纸写代码。 反转链表，要求时间复杂度O(N)，空间复杂度O(1) 非递归实现斐波那契数列 这一周股市价格为[2,6,1,4,8]，求哪一天买入哪一天卖出，可获得最大收益，最大收益为多少 按照箭头方向查找二叉树 表a b c之间用ID关联，求阴影部分的数据 一个整形无序数组，里面三个数只和等于一个目标值，求这三个数 链表问题 扑克牌问题有十张扑克牌，从上面开始抽，抽出一张放桌子上，然后再抽出一张放扑克牌的最下面，这样循环往复的操作，直到手里的牌都没有了。这时，桌子上牌的顺序正好是1 2 3 4 5 6 7 8 9 10。要求写代码求出原顺序 手写大顶堆 手写LRU 算法 字符串相加两个数字类型的字符串，直接转int或者double肯定都放不下，然后求这两个数的和，返回值还是字符串，15分钟时间，要求无Bug 寻找目标值位置有一个二维数组，数组横向有序，纵向有序，求目标值的位置，10分钟时间 求字符串“efabcbaefehiabcba”中最长的回文数，不去重 反转int类型的值x，不要借用String，只用int 即可。&amp;&amp; 针对该程序，写出其应有的测试用例 top K 问题]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试分享(五).相关工具使用]]></title>
    <url>%2F2019%2F07%2F18%2F%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB(%E4%BA%94).%E7%9B%B8%E5%85%B3%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[相关工具使用RedisRedis 中有几种类型 &amp; 各自底层怎么实现的 &amp; 项目中哪个地方用了什么类型，怎么使用的？redis底层原理 使用 ziplist 存储链表，ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。 使用 skiplist(跳跃表)来存储有序集合对象、查找上先从高Level查起、时间复杂度和红黑树相当，实现容易，无锁、并发性好。 1 单线程模型 Redis客户端对服务端的每次调用都经历了发送命令，执行命令，返回结果三个过程。其中执行命令阶段，由于Redis是单线程来处理命令的，所有每一条到达服务端的命令不会立刻执行，所有的命令都会进入一个队列中，然后逐个被执行。并且多个客户端发送的命令的执行顺序是不确定的。但是可以确定的是不会有两条命令被同时执行，不会产生并发问题，这就是Redis的单线程基本模型。 2 单线程模型每秒万级别处理能力的原因 （1）纯内存访问。数据存放在内存中，内存的响应时间大约是100纳秒，这是Redis每秒万亿级别访问的重要基础。 （2）非阻塞I/O，Redis采用epoll做为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接，读写，关闭都转换为了时间，不在I/O上浪费过多的时间。 （3）单线程避免了线程切换和竞态产生的消耗。 （4）Redis采用单线程模型，每条命令执行如果占用大量时间，会造成其他线程阻塞，对于Redis这种高性能服务是致命的，所以Redis是面向高速执行的数据库。 字符串string字符串类型是Redis中最为基础的数据存储类型，是一个由字节组成的序列，他在Redis中是二进制安全的，这便意味着该类型可以接受任何格式的数据，如JPEG图像数据货Json对象描述信息等，是标准的key-value，一般来存字符串，整数和浮点数。Value最多可以容纳的数据长度为512MB应用场景：很常见的场景用于统计网站访问数量，当前在线人数等。incr命令(++操作) 列表listRedis的列表允许用户从序列的两端推入或者弹出元素，列表由多个字符串值组成的有序可重复的序列，是链表结构，所以向列表两端添加元素的时间复杂度为0(1)，获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元素的列表，获取头部或尾部的10条记录也是极快的。List中可以包含的最大元素数量是4294967295。应用场景：1.最新消息排行榜。2.消息队列，以完成多程序之间的消息交换。可以用push操作将任务存在list中（生产者），然后线程在用pop操作将任务取出进行执行。（消费者） 散列hashRedis中的散列可以看成具有String key和String value的map容器，可以将多个key-value存储到一个key中。每一个Hash可以存储4294967295个键值对。应用场景：例如存储、读取、修改用户属性（name，age，pwd等） 集合setRedis的集合是无序不可重复的，和列表一样，在执行插入和删除和判断是否存在某元素时，效率是很高的。集合最大的优势在于可以进行交集并集差集操作。Set可包含的最大元素数量是4294967295。应用场景：1.利用交集求共同好友。2.利用唯一性，可以统计访问网站的所有独立IP。3.好友推荐的时候根据tag求交集，大于某个threshold（临界值的）就可以推荐。 有序集合sorted set和set很像，都是字符串的集合，都不允许重复的成员出现在一个set中。他们之间差别在于有序集合中每一个成员都会有一个分数(score)与之关联，Redis正是通过分数来为集合中的成员进行从小到大的排序。尽管有序集合中的成员必须是卫衣的，但是分数(score)却可以重复。应用场景：可以用于一个大型在线游戏的积分排行榜，每当玩家的分数发生变化时，可以执行zadd更新玩家分数(score)，此后在通过zrange获取几分top ten的用户信息。 key的通用操作所有的数据类型都可以使用的 Redis如何实现分布式锁，zk如何实现分布式锁，两者的区别。如果service还没执行完，分布式锁在Redis中已经过期了，怎么解决这种问题？解决redis分布式锁过期时间到了业务没执行完问题 很多同学在用分布式锁时,都是直接百度搜索找一个Redis分布式锁工具类就直接用了，其实Redis分布式锁比较正确的姿势是采用redisson这个客户端工具 默认情况下,加锁的时间是30秒.如果加锁的业务没有执行完,那么到 30-10 = 20秒的时候,就会进行一次续期,把锁重置成30秒.那这个时候可能又有同学问了,那业务的机器万一宕机了呢?宕机了定时任务跑不了,就续不了期,那自然30秒之后锁就解开了呗。 Redisson分布式锁的底层原理 1）加锁机制 咱们来看上面那张图，现在某个客户端要加锁。如果该客户端面对的是一个redis cluster集群，他首先会根据hash节点选择一台机器。 这里注意，仅仅只是选择一台机器！这点很关键！ 紧接着，就会发送一段lua脚本到redis上，那段lua脚本如下所示： 为啥要用lua脚本呢？ 因为一大坨复杂的业务逻辑，可以通过封装在lua脚本中发送给redis，保证这段复杂业务逻辑执行的原子性。 那么，这段lua脚本是什么意思呢？ KEYS[1]代表的是你加锁的那个key，比如说： 1RLock lock = redisson.getLock("myLock"); 这里你自己设置了加锁的那个锁key就是“myLock”。 ARGV[1]代表的就是锁key的默认生存时间，默认30秒。 ARGV[2]代表的是加锁的客户端的ID，类似于下面这样： 8743c9c0-0795-4907-87fd-6c719a6b4586:1 给大家解释一下，第一段if判断语句，就是用“exists myLock”命令判断一下，如果你要加锁的那个锁key不存在的话，你就进行加锁。 如何加锁呢？很简单，用下面的命令： 12hset myLock 8743c9c0-0795-4907-87fd-6c719a6b4586:1 1 通过这个命令设置一个hash数据结构，这行命令执行后，会出现一个类似下面的数据结构： 上述就代表“8743c9c0-0795-4907-87fd-6c719a6b4586:1”这个客户端对“myLock”这个锁key完成了加锁。 接着会执行“pexpire myLock 30000”命令，设置myLock这个锁key的生存时间是30秒。 好了，到此为止，ok，加锁完成了。 （2）锁互斥机制 那么在这个时候，如果客户端2来尝试加锁，执行了同样的一段lua脚本，会咋样呢？ 很简单，第一个if判断会执行“exists myLock”，发现myLock这个锁key已经存在了。 接着第二个if判断，判断一下，myLock锁key的hash数据结构中，是否包含客户端2的ID，但是明显不是的，因为那里包含的是客户端1的ID。 所以，客户端2会获取到pttl myLock返回的一个数字，这个数字代表了myLock这个锁key的剩余生存时间。比如还剩15000毫秒的生存时间。 此时客户端2会进入一个while循环，不停的尝试加锁。 （3）watch dog自动延期机制 客户端1加锁的锁key默认生存时间才30秒，如果超过了30秒，客户端1还想一直持有这把锁，怎么办呢？ 简单！只要客户端1一旦加锁成功，就会启动一个watch dog看门狗，他是一个后台线程，会每隔10秒检查一下，如果客户端1还持有锁key，那么就会不断的延长锁key的生存时间。 （4）可重入加锁机制 那如果客户端1都已经持有了这把锁了，结果可重入的加锁会怎么样呢？ 比如下面这种代码： 这时我们来分析一下上面那段lua脚本。 第一个if判断肯定不成立，“exists myLock”会显示锁key已经存在了。 第二个if判断会成立，因为myLock的hash数据结构中包含的那个ID，就是客户端1的那个ID，也就是8743c9c0-0795-4907-87fd-6c719a6b4586:1 此时就会执行可重入加锁的逻辑，他会用： 123incrby myLock 8743c9c0-0795-4907-87fd-6c71a6b4586:1 1 通过这个命令，对客户端1的加锁次数，累加1。 此时myLock数据结构变为下面这样：（5）释放锁机制 如果执行lock.unlock()，就可以释放分布式锁，此时的业务逻辑也是非常简单的。 其实说白了，就是每次都对myLock数据结构中的那个加锁次数减1。 如果发现加锁次数是0了，说明这个客户端已经不再持有锁了，此时就会用： “del myLock”命令，从redis里删除这个key。 然后呢，另外的客户端2就可以尝试完成加锁了。 这就是所谓的分布式锁的开源Redisson框架的实现机制。 一般我们在生产系统中，可以用Redisson框架提供的这个类库来基于redis进行分布式锁的加锁与释放锁。 （6）上述Redis分布式锁的缺点 其实上面那种方案最大的问题，就是如果你对某个redis master实例，写入了myLock这种锁key的value，此时会异步复制给对应的master slave实例。 但是这个过程中一旦发生redis master宕机，主备切换，redis slave变为了redis master。 接着就会导致，客户端2来尝试加锁的时候，在新的redis master上完成了加锁，而客户端1也以为自己成功加了锁。 此时就会导致多个客户端对一个分布式锁完成了加锁。 这时系统在业务语义上一定会出现问题，导致各种脏数据的产生。 所以这个就是redis cluster，或者是redis master-slave架构的主从异步复制导致的redis分布式锁的最大缺陷：在redis master实例宕机的时候，可能导致多个客户端同时完成加锁。 Ehcache支持哪些缓存？EhcacheEhCache 是一个纯Java的进程内缓存框架，具有快速、精干等特点，是Hibernate中默认的CacheProvider。Ehcache是一种广泛使用的开源Java分布式缓存。 优点： 快速 简单 缓存数据有两级：内存和磁盘，因此无需担心容量问题 缓存数据会在虚拟机重启的过程中写入磁盘 可以通过RMI、可插入API等方式进行分布式缓存 具有缓存和缓存管理器的侦听接口 支持多缓存管理器实例，以及一个实例的多个缓存区域 提供Hibernate的缓存实现 多种缓存策略，Ehcache提供了对大数据的内存和硬盘的存储，最近版本允许多实例、保存对象高灵活性、提供LRU、LFU、FIFO淘汰算法，基础属性支持热配置、支持的插件多 缺点： 使用磁盘Cache的时候非常占用磁盘空间； 不能保证数据的安全 memcachememcache 是一种高性能、分布式对象缓存系统，最初设计于缓解动态网站数据库加载数据的延迟性，你可以把它想象成一个大的内存HashTable，就是一个key-value键值缓存。 memcache C语言所编写，依赖于最近版本的GCC和libevent。多线程支持 优点： 一.部分容灾 假设只用一台memcache，如果这台memcache服务器挂掉了，那么请求将不断的冲击数据库，这样有可能搞死数据库，从而引发”雪崩“。如果使用多台memcache服务器，由于memcache使用一致性哈希算法，万一其中一台挂掉了，部分请求还是可以在memcache中命中，为修复系统赢得一些时间。 二.容量问题 一台memcache服务器的容量毕竟有限，可以使用多台memcache服务器，增加缓存容量。 三.均衡请求 使用多台memcache服务器，可以均衡请求，避免所有请求都冲进一台memcache服务器，导致服务器挂掉。 四.利用memcache分布式特性 使用一台memcache服务器，并没有利用memcache的数据分布式特性。 缺点： 不能持久化存储 存储数据有限制：1M 【大于1M，认为就行分割】（内存碎片） mm存储数据只能key-value 集群数据没有复制和同步机制 【崩溃不会影响程序，会从数据库中取数据】 内存回收不能及时 LRU(算法)：未使用内存》过期内存》最近最少使用内存 这是惰性删除 redis单线程、读写性能优异、支持数据持久化，支持AOF和RDB两种持久化方式、支持主从复制，主机会自动将数据同步到从机，可以进行读写分离；数据结构丰富：除了支持string类型的value外还支持string、hash、set、sortedset、list等数据结构。 缺点： 1 Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复。 2 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性。 3 Redis的主从复制采用全量复制，复制过程中主机会fork出一个子进程对内存做一份快照，并将子进程的内存快照保存为文件发送给从机，这一过程需要确保主机有足够多的空余内存。若快照文件较大，对集群的服务能力会产生较大的影响，而且复制过程是在从机新加入集群或者从机和主机网络断开重连时都会进行，也就是网络波动都会造成主机和从机间的一次全量的数据复制，这对实际的系统运营造成了不小的麻烦。 4 Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。 ehcache直接在jvm虚拟机中缓存，速度快，效率高；但是缓存共享麻烦，集群分布式应用不方便。redis是通过socket访问到缓存服务，效率比ecache低，比数据库要快很多，处理集群和分布式缓存方便，有成熟的方案。如果是单个应用或者对缓存访问要求很高的应用，用ehcache。如果是大型系统，存在缓存共享、分布式部署、缓存内容很大的，建议用redis。 Redis是单线程的还是多线程的，为什么这么快？Redis是一个开源的内存中的数据结构存储系统，它可以用作：数据库、缓存和消息中间件。 它支持多种类型的数据结构，如字符串（String），散列（Hash），列表（List），集合（Set），有序集合（Sorted Set或者是ZSet）与范围查询，Bitmaps，Hyperloglogs 和地理空间（Geospatial）索引半径查询。其中常见的数据结构类型有：String、List、Set、Hash、ZSet这5种。 Redis 内置了复制（Replication），LUA脚本（Lua scripting）， LRU驱动事件（LRU eviction），事务（Transactions） 和不同级别的磁盘持久化（Persistence），并通过 Redis哨兵（Sentinel）和自动分区（Cluster）提供高可用性（High Availability）。 Redis也提供了持久化的选项，这些选项可以让用户将自己的数据保存到磁盘上面进行存储。根据实际情况，可以每隔一定时间将数据集导出到磁盘（快照），或者追加到命令日志中（AOF只追加文件），他会在执行写命令时，将被执行的写命令复制到硬盘里面。您也可以关闭持久化功能，将Redis作为一个高效的网络的缓存数据功能使用。 Redis不使用表，他的数据库不会预定义或者强制去要求用户对Redis存储的不同数据进行关联。 数据库的工作模式按存储方式可分为：硬盘数据库和内存数据库。Redis 将数据储存在内存里面，读写数据的时候都不会受到硬盘 I/O 速度的限制，所以速度极快。 （1）硬盘数据库的工作模式：（2）内存数据库的工作模式： Redis为什么这么快1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 2、数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的； 3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 4、使用多路I/O复用模型，非阻塞IO； 5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； 以上几点都比较好理解，下边我们针对多路 I/O 复用模型进行简单的探讨： （1）多路 I/O 复用模型 多路I/O复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。 这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。 那么为什么Redis是单线程的我们首先要明白，上边的种种分析，都是为了营造一个Redis很快的氛围！官方FAQ表示，因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。 看到这里，你可能会气哭！本以为会有什么重大的技术要点才使得Redis使用单线程就可以这么快，没想到就是一句官方看似糊弄我们的回答！但是，我们已经可以很清楚的解释了为什么Redis这么快，并且正是由于在单线程模式的情况下已经很快了，就没有必要在使用多线程了！ 但是，我们使用单线程的方式是无法发挥多核CPU 性能，不过我们可以通过在单机开多个Redis 实例来完善！ 警告1：这里我们一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的Redis Server运行的时候肯定是不止一个线程的，这里需要大家明确的注意一下！例如Redis进行持久化的时候会以子进程或者子线程的方式执行（具体是子线程还是子进程待读者深入研究）；例如我在测试服务器上查看Redis进程，然后找到该进程下的线程： Redis Hash中某个key过大，变为String类型的大key，怎么处理，使用中如何避免出现这种问题?由于redis是单线程运行的，如果一次操作的value很大会对整个redis的响应时间造成负面影响，所以，业务上能拆则拆，下面举几个典型的分拆方案。 单个简单的key存储的value很大1.1、 改对象需要每次都整存整取可以尝试将对象分拆成几个key-value， 使用multiGet获取值，这样分拆的意义在于分拆单次操作的压力，将操作压力平摊到多个redis实例中，降低对单个redis的IO影响； 1.2、该对象每次只需要存取部分数据可以像第一种做法一样，分拆成几个key-value， 也可以将这个存储在一个hash中，每个field代表一个具体的属性，使用hget,hmget来获取部分的value，使用hset，hmset来更新部分属性 hash， set，zset，list 中存储过多的元素类似于场景一种的第一个做法，可以将这些元素分拆。 以hash为例，原先的正常存取流程是 hget(hashKey, field) ; hset(hashKey, field, value)现在，固定一个桶的数量，比如 10000， 每次存取的时候，先在本地计算field的hash值，模除 10000， 确定了该field落在哪个key上。123newHashKey = hashKey + (*hash*(field) % 10000）; hset (newHashKey, field, value) ; hget(newHashKey, field) set, zset, list 也可以类似上述做法. 但有些不适合的场景，比如，要保证 lpop 的数据的确是最早push到list中去的，这个就需要一些附加的属性，或者是在 key的拼接上做一些工作（比如list按照时间来分拆）。 哨兵机制、Redis两种备份方式的区别，项目中用的哪种，为什么？持久化机制 为了解决一旦断电或者宕机，内存数据库中的数据将会全部丢失这个缺点，Redis提供了将内存数据持久化到硬盘，以及用持久化文件来恢复数据的功能。Redis 支持两种形式的持久化，一种是RDB快照（snapshotting），另外一种是AOF（append-only-file）。 （1）RDB是把当前内存中的数据集快照写入磁盘，也就是 Snapshot 快照（数据库中所有键值对数据）。恢复时是将快照文件直接读到内存里，RDB持久化有两种触发机制，分别是自动触发和手动触发。在redis.windows.conf(linux就是redis.conf)文件的SNAPSHOTTING 下有个自动触发rdb持久化的策略： 其中分别表示900s内，如果至少有一个key值变化，则保存到rdb；300s内，至少有10个key变化就保存；60s内至少有10000个key变化就保存。如果只需要redis的缓存功能那么就可以关掉rdb持久化，使用空串停用，如：save “”“”。 在这个配置下面还有几个关于rdb持久化的配置： stop-writes-on-bgsave-error yes：默认yes，表示在后台通过rdb保存数据失败之后是否停止向redis写入数据（接收数据）。这样可以让用户意识到后台持久化失败了，避免后面数据不能持久化。 rdbcompression yes：默认yes，表示存储的rdb快照是否进行压缩存储，如果关闭则快照会比较大。 rdbchecksum yes：默认yes，存储之后是否对数据进行校验，若希望提升redis性能可以关闭。 dbfilename dump.rdb：存储的rdb快照文件名。 dir ./：设置快照存放路径，必须是目录，默认和当前配置文件在同一目录。 手动触发rdb快照保存可以使用save和bgsave命令。save会阻塞当前redis，redis不能处理其他命令直到rdb过程完成，而bgsave会在后台异步进行保存（redis会执行fork操作创建一个子进程），阻塞只会在fork短时间内，redis内部rdb自动保存都是采用bgsave命令。 将备份文件dump.rdb放到配置文件指定的目录（默认是和redis配置文件同一目录）下，启动redis就会自动将数据加载到内存中。 （2）AOF 持久化是通过保存Redis服务器所执行的写命令来记录数据库状态。在redis的配置文件中APPEND ONLY MODE的下有关于AOF持久化的相关配置。 appendonly：表示是否开启AOF持久化，因为redis默认的是rdb方式，打开aof需要改为yes。 appendfilename：aof文件名。 appendsync：aof持久化策略配置。no表示不执行fsync，有系统保证数据同步到磁盘，速度最快但不安全；always表示每次写入都要执行fsync，以保证数据完全同步到磁盘，效率低；everysec则是每秒保存一次，可能会丢失者1s数据，兼顾安全和效率。 no-appendfsync-on-rewrite：设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据。默认值为no。 auto-aof-rewrite-percentage：默认值为100。aof自动重写配置，当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候，Redis能够调用bgrewriteaof对日志文件进行重写。 auto-aof-rewrite-min-size：64mb。设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写。 aof-load-truncated：aof文件可能在尾部是不完整的（宕机或者断电等），如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以。默认值为 yes AOF文件不完整需要恢复可以使用命令：redis-check-aof –fix 进行修复。aof文件过大的时候也需要重写，和rdb的bgsave模式相似，都是创建子进程，设置重写缓冲区，在重写完成之后再将缓冲区文件写入aof文件。 总结AOF 持久化的方法提供了多种的同步频率，即使使用默认的同步频率每秒同步一次，Redis 最多也就丢失 1 秒的数据而已。 AOF 文件使用 Redis 命令追加的形式来构造，因此，即使 Redis 只能向 AOF 文件写入命令的片断，使用 redis-check-aof 工具也很容易修正 AOF 文件。 AOF 文件的格式可读性较强，这也为使用者提供了更灵活的处理方式。例如，如果我们不小心错用了 FLUSHALL 命令，在重写还没进行时，我们可以手工将最后的 FLUSHALL 命令去掉，然后再使用 AOF 来恢复数据。 对于具有相同数据的的 Redis，AOF 文件通常会比 RDB文件体积更大。 虽然 AOF 提供了多种同步的频率，默认情况下，每秒同步一次的频率也具有较高的性能。但在 Redis 的负载较高时，RDB 比 AOF 具好更好的性能保证。 RDB 使用快照的形式来持久化整个 Redis 数据，而 AOF 只是将每次执行的命令追加到 AOF 文件中，因此从理论上说，RDB 比 AOF 方式更健壮。官方文档也指出，AOF 的确也存在一些 BUG，这些 BUG 在 RDB 没有存在。 主从复制复制三份配置文件，分别更改端口号，并且配置文件的名字以端口号区分。之后再更改每份配置文件：rdb文件名（dbfilename）、log日志文件名（logfile），之后使用下面三个命令启动三个redis服务端。123redis-server.exe redis.windows.confredis-server.exe redis.windows-10087.conf redis-server.exe redis.windows-10088.conf 通过info replication查看各个节点信息。此时都是master节点，接着设置slave节点。使用slaveof命令把10087和10088设为slave。此时设为slave节点之后再使用info replication命令查看就发现role已经变为了slave了。现再在master节点写，在slave读。可以看见现在主从关系已经成功建立了。注： （1）如果master以前还存在一些key，那么slave节点也是会有的，因为master会全量复制到slave。 （2）默认从节点是不能够执行写命令的，配置文件中slave-read-only默认是yes。 （3）主节点down掉之后，另外两个slave角色依然不变，并且在master恢复之后，仍然是master并且有两个slave节点。 哨兵模式哨兵模式就是不时地监控redis是否按照预期良好地运行（至少是保证主节点是存在的），若一台主机出现问题时，哨兵会自动将该主机下的某一个从机设置为新的主机，并让其他从机和新主机建立主从关系（如果监控主机发生故障，就根据投票数自动将从库转化为主库）。首先启动多个redis，并配置主从关系，下面再配置哨兵监控master。 （1）在配置文件目录下面使用touch命令新建sentinel.conf文件，然后配置内容： sentinel monitor 被监控主机名（自己起） ip地址 端口 得票数 如：sentinel monitor my6379 127.0.0.1 6379 1。1表示当主机挂掉之后得票数&gt;=1便成为主机。 （2）启动哨兵监控 使用命令：./redis-sentinel /mrliu_project/redis/sentinel.conf 注：/mrliu_project/redis/sentinel.conf 是配置文件所在目录 （3）exit退出master主机，之后查看哨兵控制台打印的日志，会发现在重新选择master。 在redis稳定版之后，挂掉的主机在选举之后重新连接上，会设置为新选举的msater的从节点。 启动三台带有redis的服务器133，132，130分别更改redis.conf文件，并指定配置启动redis-server和redis-sentinel 进入redis的src目录：./redis-server ../redis.config ./redis-sentinel ../sentinel.conf(哨兵配置需要自己touch) 133启动一个master和哨兵的服务器， 132启动两个redis服务(两份配置文件)，分别设为133的slave 130启动一个redis服务，设为133的slave redis-config更改了一些目录和端口等，我大概改了如下内容：12345daemonize yeslogfile port #bind.1 注释掉了protected-mode no //关闭了 注意（出现设置了slaveof之后发现主机一直未down可能是如下原因）： （1）每个启动的redis服务需要注释掉bind(代表可以访问的主机)，不然其他redis服务器不能感知到该redis服务的存在 (2)每个redis服务需要更改protected-mode 为no， （3）每台linux服务器需要打开端口，不然直接关闭firewall或者是iptables也行，命令systemctl stop firewalld和service iptables stop。 永久关闭防火墙使用disable。 （4）建议redis-server都配置为守护进程，daemon设为yes即可。 哨兵需要自建配置文件，在redis的src目录下使用 ./redis-sentinel ../sentinel_liu.conf 启动，其中后面的是自己的哨兵配置文件，简易配置如下:12345port 26379 sentinel monitor liu_master 192.168.15.130 6379 1//监控的主机，后面代表超过机票就成为leadersentinel down-after-milliseconds liu_master 10000//可选，多久没心跳就认为downsentinel failover-timeout liu_master 10000//可选，代表每次选举间隔 几台服务器如下:之后进入133使用info确认从节点有三个， 之后查看哨兵启动日志注：sdown代表哨兵主观任务下线，（后面是master断开之后的日志）odown是客观下线，当出现odown的时候，哨兵将不会监控该服务，任务确实下线了，然后开始选举。 断开133的master，观察哨兵日志可以进入133的客户端，使用shutdown关掉，也可以在redis的src目录下使用./redis-cli shutdown关，也可以杀redis进程关。 哨兵日志如下（我这儿选了这么多次原因是其他机器防火墙开着，所以关了就选举成功了）: 出现failover-end即是选举成功了，switch代表切换master到了130服务器节点，随后发现 +fix-slave-config日志，代表将132的6379redis服务和132的6380redis服务设为了130的slave节点，这时候130成为master，132的两个redis服务是slave节点。 重新上线之前断开的133master，查看哨兵日志 发现新上线的133设为了130redis服务的slave，下面去130服务器登上redis客户端输入info验证 发现回归后的master变为了新选举的master的slave节点。 哨兵机制、选举算法Redis Sentinel是一个分布式系统，为Redis提供高可用性解决方案。可以在一个架构中运行多个 Sentinel 进程(progress)， 这些进程使用流言协议(gossip protocols)来 接收关于主服务器是否下线的信息， 并使用投票协议(agreement protocols)来决定是否执行自动故 障迁移， 以及选择哪个从服务器作为新的主服务器。 Redis 的 Sentinel 系统用于管理多个 Redis 服务器(instance) 该系统执行以下三个任务: 监控(Monitoring): Sentinel 会不断地定期检查你的主服务器和从服务器是否运作正常。 提醒(Notification): 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。 自动故障迁移(Automaticfailover): 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效主服务器的其中 一个从服务器升级为新的主服务器， 并让失效主服务器的其他从服务器改为复制新的主服务器; 当客 户端试图连接失效的主服务器时， 集群也会向客户端返回新主服务器的地址， 使得集群可以使用新主 服务器代替失效服务器。 Sentinel 工作原理分析（1）哨兵文件详解 配置一：sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt; 这个配置表达的是 哨兵节点定期监控 名字叫做 &lt;master-name&gt; 并且 IP 为 &lt;ip&gt; 端口号为 &lt;port&gt; 的主节点。&lt;quorum&gt; 表示的是哨兵判断主节点是否发生故障的票数。也就是说如果我们将&lt;quorum&gt;设置为2就代表至少要有两个哨兵认为主节点故障了，才算这个主节点是客观下线的了，一般是设置为sentinel节点数的一半加一。 配置二：sentinel down-after-milliseconds &lt;master-name&gt; &lt;times&gt; 每个哨兵节点会定期发送ping命令来判断Redis节点和其余的哨兵节点是否是可达的，如果超过了配置的&lt;times&gt;时间没有收到pong回复，就主观判断节点是不可达的,&lt;times&gt;的单位为毫秒。 配置三：sentinel parallel-syncs &lt;master-name&gt; &lt;nums&gt; 当哨兵节点都认为主节点故障时，哨兵投票选出的leader会进行故障转移，选出新的主节点，原来的从节点们会向新的主节点发起复制，这个配置就是控制在故障转移之后，每次可以向新的主节点发起复制的节点的个数，最多为&lt;nums&gt;个，因为如果不加控制会对主节点的网络和磁盘IO资源很大的开销。 配置四：sentinel failover-timeout &lt;master-name&gt; &lt;times&gt; 这个代表哨兵进行故障转移时如果超过了配置的&lt;times&gt;时间就表示故障转移超时失败。 配置五： sentinel auth-pass &lt;master-name&gt; &lt;password&gt; 如果主节点设置了密码，则需要这个配置，否则哨兵无法对主节点进行监控。 （2）为什么要用到哨兵 哨兵(Sentinel)主要是为了解决在主从复制架构中出现宕机的情况,主要分为两种情况: 1).从Redis宕机 这个相对而言比较简单,在Redis中从库重新启动后会自动加入到主从架构中,自动完成同步数据。在Redis2.8版本后,主从断线后恢复的情况下实现增量复制。 2).主Redis宕机 这个相对而言就会复杂一些,需要以下2步才能完成 a. 在从数据库中执行SLAVEOF NO ONE命令,断开主从关系并且提升为主库继续服务 b. 第二步,将主库重新启动后,执行SLAVEOF命令,将其设置为其他库的从库,这时数据就能更新回来 由于这个手动完成恢复的过程其实是比较麻烦的并且容易出错,所以Redis提供的哨兵(sentinel)的功能来解决 （3）哨兵机制（sentinel）的高可用Sentinel（哨兵）是Redis 的高可用性解决方案：由一个或多个Sentinel 实例 组成的Sentinel 系统可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器属下的某个从服务器升级为新的主服务器。 在Server1 掉线后： 升级Server2 为新的主服务器： （4）哨兵的定时监控 任务1：每个哨兵节点每10秒会向主节点和从节点发送info命令获取最拓扑结构图，哨兵配置时只要配置对主节点的监控即可，通过向主节点发送info，获取从节点的信息，并当有新的从节点加入时可以马上感知到 任务2：每个哨兵节点每隔2秒会向redis数据节点的指定频道上发送该哨兵节点对于主节点的判断以及当前哨兵节点的信息，同时每个哨兵节点也会订阅该频道，来了解其它哨兵节点的信息及对主节点的判断，其实就是通过消息publish和subscribe来完成的 任务3：每隔1秒每个哨兵会向主节点、从节点及其余哨兵节点发送一次ping命令做一次心跳检测，这个也是哨兵用来判断节点是否正常的重要依据 主观下线：所谓主观下线，就是单个sentinel认为某个服务下线（有可能是接收不到订阅，之间的网络不通等等原因）。 sentinel会以每秒一次的频率向所有与其建立了命令连接的实例（master，从服务，其他sentinel）发ping命令，通过判断ping回复是有效回复，还是无效回复来判断实例时候在线（对该sentinel来说是“主观在线”）。 sentinel配置文件中的down-after-milliseconds设置了判断主观下线的时间长度，如果实例在down-after-milliseconds毫秒内，返回的都是无效回复，那么sentinel回认为该实例已（主观）下线，修改其flags状态为SRI_S_DOWN。如果多个sentinel监视一个服务，有可能存在多个sentinel的down-after-milliseconds配置不同，这个在实际生产中要注意。 客观下线：当主观下线的节点是主节点时，此时该哨兵3节点会通过指令sentinel is-masterdown-by-addr寻求其它哨兵节点对主节点的判断，如果其他的哨兵也认为主节点主观线下了，则当认为主观下线的票数超过了quorum（选举）个数，此时哨兵节点则认为该主节点确实有问题，这样就客观下线了，大部分哨兵节点都同意下线操作，也就说是客观下线 （5）哨兵lerder选举流程 如果主节点被判定为客观下线之后，就要选取一个哨兵节点来完成后面的故障转移工作，选举出一个leader的流程如下: a)每个在线的哨兵节点都可以成为领导者，当它确认（比如哨兵3）主节点下线时，会向其它哨兵发is-master-down-by-addr命令，征求判断并要求将自己设置为领导者，由领导者处理故障转移； b)当其它哨兵收到此命令时，可以同意或者拒绝它成为领导者； c)如果哨兵3发现自己在选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举………… （6）自动故障转移机制 在从节点中选择新的主节点 sentinel状态数据结构中保存了主服务的所有从服务信息，领头sentinel按照如下的规则从从服务列表中挑选出新的主服务 过滤掉主观下线的节点 选择slave-priority最高的节点，如果由则返回没有就继续选择 选择出复制偏移量最大的系节点，因为复制便宜量越大则数据复制的越完整，如果由就返回了，没有就继续 选择run_id最小的节点 更新主从状态 通过slaveof no one命令，让选出来的从节点成为主节点；并通过slaveof命令让其他节点成为其从节点。 将已下线的主节点设置成新的主节点的从节点，当其回复正常时，复制新的主节点，变成新的主节点的从节点同理，当已下线的服务重新上线时，sentinel会向其发送slaveof命令，让其成为新主的从 Sentinel获取服务器信息（1） Sentinel获取主服务器信息 Sentinel默认会以每10秒一次的频率，通过命令连接向主服务器发送info命令，通过分析info命令的回复来获取主服务器的当前信息，就像在上篇讲到的复制功能，在客户端输入info replication 命令一样，Sentinel可以获取以下两方面的信息： (1) 关于主服务器本身的信息，包括服务器run_id，role的服务器角色。 (2) 关于所有从服务器的信息，每个从服务器都由一个slave字符串开头的行记录，记录了从服务器IP和端口(主服务器中有从库的配置信息)。 （2）Sentinel获取从服务器信息 当Sentinel发现主服务器有新的从服务器出现时，Sentinel除了会为这个新的从服务器创建相应的实例结构(sentinelRedisInstance)之外，Sentinel还会创建连接到从服务器的命令连接和订阅连接。Sentinel默认会以每10秒一次的频率通过命令连接从服务器发送info命令，通过分析info命令的回复来获取从服务器的当前信息。包括:从服务器运行run_ID、从服务器角色role、主服务器的ip及端口、主从服务器的连接状态master_link_status、从服务器的优先级slave_priority。 （3）Sentinel向主从服务器发送信息 在默认情况下, Sentinel会以每2秒一次的频率，通过命令连接向所有被监视的主服务器和从服务器发送以下格式的命令： 这条命令向服务器的sentinel:hello频道发送了一条信息，信息的内容由多个参数组成： (1) 以s_开头以参数记录的是sentinel本身的信息。 (2) 而m_开头的参数记录的则是主服务器的信息，如果sentinel正在监视的是主服务器，那么这些参数就是主服务器的信息，如果sentinel正在监视的是从服务器，那么这些参数记录就是从服务器正在复制的主服务器的信息。 参数 描述 S_ip Sentinel的ip地址 S_port Sentinel的端口号 S_runid Sentinel的运行ID S_epoch Sentinel 的当前配置纪元 m_name 主服务器的名字 M_ip 主服务器的IP地址 M_port 主服务器的端口号 M_epoch 主服务器的当前配置纪元 以下是一条sentinel通过publish命令向主服务器发送的信息示例： 这个示例中sentinel的ip地址为172.0.0.1端口号为26379, 运行ID为后面一串，当前纪元为0。主服务器的名字为mymaster,ip地址为127.0.0.1,端口号为6379, 当前纪元为0。 4）sentinel接收来自主服务器和从服务器的频道信息 当sentinel与一个主服务器或者从服务器建立起订阅连接之后,Sentinel就会通过订阅连接，向服务器发送以下命令：subscribe_sentinel_:hello 。对于每个与Sentinel连接的服务器，Sentinel既通过命令连向服务器的_sentinel_:hello频道发送信息，又通过订阅连接从服务器的_sentinel_:hello频道接收信息。 当有三个sentinel，分别是sentinel1、sentinel2 、sentinel3。三个sentinel在监视同一个服务器，那么当sentinel1向服务器的_sentinel_:hello频道发送一条信息时，所有订阅了_sentinel_:hello频道的sentinel(包括sentinel1自己在内)都会收到这条信息。 当一个sentinel从_sentinel_:hello频道收到一条信息时，sentinel会对这条信息进行分析，提取出信息中sentinel 的 ip 、port、runID等8个参数，并进行以下检查： (1) 如果信息中记录的sentinel运行ID和接收信息的sentinel运行ID相同，那么说明这条信息是sentinel自己发送的，sentinel将丢弃这条信息，不做进一步处理。 (2) 相反地，如果信息中记录的sentinel运行ID和接收信息的sentinel运行ID不相同，那说明这条信息监视同一个服务器的其它sentinel发来的，接收信息的sentinel将根据信息中的参数，对相应主服务器的实例结构进行更新。 （5）sentinel更新自己的sentinels字典 sentinel为主服务器创建实例结构中的sentinels字典，保存了sentinel本身，还监视这个主服务器的其他sentinel的资料。当一个sentinel接收到其他sentinels发来的信息时，接收的sentinel会从信息中分析并提取出两方面参数: (1)与sentinel有关的参数，包括sentinel的ip、port、runid、配置纪元。 (2)与主服务器有关的参数, 包括监视主服务器的ip、port、runid、配置纪元。 假设分别有三个sentinel: 127.0.0.1:26379、127.0.0.1:26380、127.0.0.1:26381。三个sentinel正在监视主服务器127.0.0.1:6379, 那么当127.0.0.1:26379这个sentinel接收到以下消息时： 这个sentinel将执行以下动作： (1) 第一条信息发送者为自己，信息忽略。 (2) 第二条信息发送者为26381, sentinel会根据信息提取出内容，对sentinels字典中26381对应的实例结构进行更新。 (3) 第三条信息发送者为23680，同样更新字典中的23680对应的实例结构。 每个sentinel都有自己的一个sentinels字典， 对于26379的sentinel它的sentinels字典信息保存了26380和26381两个sentinel信息。其它sentinel也一样。 （6）sentinel创建连向其他sentinel的命令连接 当sentinel通过频道信息发现一个新的sentinel时，不仅更新sentinels字典，还会创建一个连向sentinel命令连接，而新的sentinel也会创建连向这个sentinel的命令连接，最终监视同一个主服务器的多个sentinel将形成相互连接的网络。如下图所示： 4.Sentinel的工作原理总结 1)：每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他 Sentinel 实例发送一个 PING 命令。 2)：如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel 标记为主观下线。 3)：如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。 4)：当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线 。 5)：在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有Master，Slave发送 INFO 命令 。 6)：当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 。 7)：若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会被移除。 若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。 消息中间件如何保证RocketMQ 消息的顺序性，如何解决重复消费问题。分布式消息系统作为实现分布式系统可扩展、可伸缩性的关键组件，需要具有高吞吐量、高可用等特点。而谈到消息系统的设计，就回避不了两个问题： 消息的顺序问题 消息的重复问题 RocketMQ作为阿里开源的一款高性能、高吞吐量的消息中间件，它是怎样来解决这两个问题的？RocketMQ有哪些关键特性？其实现原理是怎样的？ 关键特性及其实现原理 顺序消息消息有序指的是可以按照消息的发送顺序来消费。例如：一笔订单产生了 3 条消息，分别是订单创建、订单付款、订单完成。消费时，要按照顺序依次消费才有意义。与此同时多笔订单之间又是可以并行消费的。首先来看如下示例： 假如生产者产生了2条消息：M1、M2，要保证这两条消息的顺序，应该怎样做？你脑中想到的可能是这样： 你可能会采用这种方式保证消息顺序 假定M1发送到S1，M2发送到S2，如果要保证M1先于M2被消费，那么需要M1到达消费端被消费后，通知S2，然后S2再将M2发送到消费端。 这个模型存在的问题是，如果M1和M2分别发送到两台Server上，就不能保证M1先达到MQ集群，也不能保证M1被先消费。换个角度看，如果M2先于M1达到MQ集群，甚至M2被消费后，M1才达到消费端，这时消息也就乱序了，说明以上模型是不能保证消息的顺序的。如何才能在MQ集群保证消息的顺序？一种简单的方式就是将M1、M2发送到同一个Server上： 保证消息顺序，你改进后的方法 这样可以保证M1先于M2到达MQServer（生产者等待M1发送成功后再发送M2），根据先达到先被消费的原则，M1会先于M2被消费，这样就保证了消息的顺序。 这个模型也仅仅是理论上可以保证消息的顺序，在实际场景中可能会遇到下面的问题： 网络延迟问题 只要将消息从一台服务器发往另一台服务器，就会存在网络延迟问题。如上图所示，如果发送M1耗时大于发送M2的耗时，那么M2就仍将被先消费，仍然不能保证消息的顺序。即使M1和M2同时到达消费端，由于不清楚消费端1和消费端2的负载情况，仍然有可能出现M2先于M1被消费的情况。 那如何解决这个问题？将M1和M2发往同一个消费者，且发送M1后，需要消费端响应成功后才能发送M2。 聪明的你可能已经想到另外的问题：如果M1被发送到消费端后，消费端1没有响应，那是继续发送M2呢，还是重新发送M1？一般为了保证消息一定被消费，肯定会选择重发M1到另外一个消费端2，就如下图所示。 保证消息顺序的正确姿势 这样的模型就严格保证消息的顺序，细心的你仍然会发现问题，消费端1没有响应Server时有两种情况，一种是M1确实没有到达(数据在网络传送中丢失)，另外一种消费端已经消费M1且已经发送响应消息，只是MQ Server端没有收到。如果是第二种情况，重发M1，就会造成M1被重复消费。也就引入了我们要说的第二个问题，消息重复问题，这个后文会详细讲解。 回过头来看消息顺序问题，严格的顺序消息非常容易理解，也可以通过文中所描述的方式来简单处理。总结起来，要实现严格的顺序消息，简单且可行的办法就是： 保证生产者 - MQServer - 消费者是一对一对一的关系 这样的设计虽然简单易行，但也会存在一些很严重的问题，比如： 并行度就会成为消息系统的瓶颈（吞吐量不够） 更多的异常处理，比如：只要消费端出现问题，就会导致整个处理流程阻塞，我们不得不花费更多的精力来解决阻塞的问题。 但我们的最终目标是要集群的高容错性和高吞吐量。这似乎是一对不可调和的矛盾，那么阿里是如何解决的？ 世界上解决一个计算机问题最简单的方法：“恰好”不需要解决它！ 有些问题，看起来很重要，但实际上我们可以通过合理的设计或者将问题分解来规避。如果硬要把时间花在解决问题本身，实际上不仅效率低下，而且也是一种浪费。从这个角度来看消息的顺序问题，我们可以得出两个结论： 不关注乱序的应用实际大量存在 队列无序并不意味着消息无序 所以从业务层面来保证消息的顺序而不仅仅是依赖于消息系统，是不是我们应该寻求的一种更合理的方式？ 最后我们从源码角度分析RocketMQ怎么实现发送顺序消息的。 RocketMQ通过轮询所有队列的方式来确定消息被发送到哪一个队列（负载均衡策略）。比如下面的示例中，订单号相同的消息会被先后发送到同一个队列中： 在获取到路由信息以后，会根据MessageQueueSelector实现的算法来选择一个队列，同一个OrderId获取到的肯定是同一个队列。 消息重复上面在解决消息顺序问题时，引入了一个新的问题，就是消息重复。那么RocketMQ是怎样解决消息重复的问题呢？还是“恰好”不解决。 造成消息重复的根本原因是：网络不可达。只要通过网络交换数据，就无法避免这个问题。所以解决这个问题的办法就是绕过这个问题。那么问题就变成了：如果消费端收到两条一样的消息，应该怎样处理？ 消费端处理消息的业务逻辑保持幂等性 保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现 第1条很好理解，只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。第2条原理就是利用一张日志表来记录已经处理成功的消息的ID，如果新到的消息ID已经在日志表中，那么就不再处理这条消息。 第1条解决方案，很明显应该在消费端实现，不属于消息系统要实现的功能。第2条可以消息系统实现，也可以业务端实现。正常情况下出现重复消息的概率其实很小，如果由消息系统来实现的话，肯定会对消息系统的吞吐量和高可用有影响，所以最好还是由业务端自己处理消息重复的问题，这也是RocketMQ不解决消息重复的问题的原因。 那么如何解决消息重复投递的问题？以我们支付宝转账到余额宝为例，如果相同的消息被重复投递两次，那么我们余额宝账户将会增加2万而不是1万了(上面讲顺序消费是讲过，这里再提一下)。 为什么相同的消息会被重复投递？比如余额宝处理完消息msg后，发送了处理成功的消息给支付宝，正常情况下支付宝应该要删除消息msg，但如果支付宝这时候悲剧的挂了，重启后一看消息msg还在，就会继续发送消息msg。 解决方法很简单，在余额宝这边增加消息应用状态表（message_apply）（这就是上文说的去重表吧），通俗来说就是个账本，用于记录消息的消费情况，每次来一个消息，在真正执行之前，先去消息应用状态表中查询一遍，如果找到说明是重复消息，丢弃即可，如果没找到才执行，同时插入到消息应用状态表（同一事务） 。123456789101112131415for each msg in queue Begin transaction select count(*) as cnt from message_apply where msg_id=msg.msg_id; if cnt==0 then update B set amount=amount+10000 where userId=1; insert into message_apply(msg_id) values(msg.msg_id); End transaction commit; 事务消息RocketMQ除了支持普通消息，顺序消息，另外还支持事务消息。首先讨论一下什么是事务消息以及支持事务消息的必要性。我们以一个转帐的场景为例来说明这个问题：Bob向Smith转账100块。 在单机环境下，执行事务的情况，大概是下面这个样子： 单机环境下转账事务示意图 当用户增长到一定程度，Bob和Smith的账户及余额信息已经不在同一台服务器上了，那么上面的流程就变成了这样：集群环境下转账事务示意图 这时候你会发现，同样是一个转账的业务，在集群环境下，耗时居然成倍的增长，这显然是不能够接受的。那如何来规避这个问题？ 大事务 = 小事务 + 异步 将大事务拆分成多个小事务异步执行。这样基本上能够将跨机事务的执行效率优化到与单机一致。转账的事务就可以分解成如下两个小事务：小事务+异步消息 图中执行本地事务（Bob账户扣款）和发送异步消息应该保证同时成功或者同时失败，也就是扣款成功了，发送消息一定要成功，如果扣款失败了，就不能再发送消息。那问题是：我们是先扣款还是先发送消息呢？ 首先看下先发送消息的情况，大致的示意图如下： 事务消息：先发送消息 存在的问题是：如果消息发送成功，但是扣款失败，消费端就会消费此消息，进而向Smith账户加钱。 先发消息不行，那就先扣款吧，大致的示意图如下： 事务消息-先扣款 存在的问题跟上面类似：如果扣款成功，发送消息失败，就会出现Bob扣钱了，但是Smith账户未加钱。 可能大家会有很多的方法来解决这个问题，比如：直接将发消息放到Bob扣款的事务中去，如果发送失败，抛出异常，事务回滚。这样的处理方式也符合“恰好”不需要解决的原则。在https://blog.csdn.net/yinni11/article/details/81122093中的非事务消息中间件就是采用的这种方法 这里需要说明一下：如果使用Spring来管理事物的话，大可以将发送消息的逻辑放到本地事物中去，发送消息失败抛出异常，Spring捕捉到异常后就会回滚此事物，以此来保证本地事物与发送消息的原子性。 RocketMQ支持事务消息，下面来看看RocketMQ是怎样来实现的。RocketMQ实现发送事务消息 RocketMQ第一阶段发送Prepared消息时，会拿到消息的地址，第二阶段执行本地事物，第三阶段通过第一阶段拿到的地址去访问消息，并修改消息的状态。 细心的你可能又发现问题了，如果确认消息发送失败了怎么办？RocketMQ会定期扫描消息集群中的事物消息，如果发现了Prepared消息，它会向消息发送端(生产者)确认，Bob的钱到底是减了还是没减呢？如果减了是回滚还是继续发送确认消息呢？RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。 那我们来看下RocketMQ源码，是如何处理事务消息的。客户端发送事务消息的部分（完整代码请查看：rocketmq-example工程下的com.alibaba.rocketmq.example.transaction.TransactionProducer）：接着查看sendMessageInTransaction方法的源码，总共分为3个阶段：发送Prepared消息、执行本地事务、发送确认消息。endTransaction方法会将请求发往broker(mq server)去更新事务消息的最终状态： 根据sendResult找到Prepared消息 ，sendResult包含事务消息的ID 根据localTransaction更新消息的最终状态 如果endTransaction方法执行失败，数据没有发送到broker，导致事务消息的 状态更新失败，broker会有回查线程定时（默认1分钟）扫描每个存储事务状态的表格文件，如果是已经提交或者回滚的消息直接跳过，如果是prepared状态则会向Producer发起CheckTransaction请求，Producer会调用DefaultMQProducerImpl.checkTransactionState()方法来处理broker的定时回调请求，而checkTransactionState会调用我们的事务设置的决断方法来决定是回滚事务还是继续执行，最后调用endTransactionOneway让broker来更新消息的最终状态。 再回到转账的例子，如果Bob的账户的余额已经减少，且消息已经发送成功，Smith端开始消费这条消息，这个时候就会出现消费失败和消费超时两个问题，解决超时问题的思路就是一直重试，直到消费端消费消息成功，整个过程中有可能会出现消息重复的问题，按照前面的思路解决即可。消费事务消息 这样基本上可以解决消费端超时问题，但是如果消费失败怎么办？阿里提供给我们的解决方法是：人工解决。大家可以考虑一下，按照事务的流程，因为某种原因Smith加款失败，那么需要回滚整个流程。如果消息系统要实现这个回滚流程的话，系统复杂度将大大提升，且很容易出现Bug，估计出现Bug的概率会比消费失败的概率大很多。这也是RocketMQ目前暂时没有解决这个问题的原因，在设计实现消息系统时，我们需要衡量是否值得花这么大的代价来解决这样一个出现概率非常小的问题，这也是大家在解决疑难问题时需要多多思考的地方。 20160321补充：在3.2.6版本中移除了事务消息的实现，所以此版本不支持事务消息，具体情况请参考rocketmq的issues： Producer如何发送消息Producer轮询某topic下的所有队列的方式来实现发送方的负载均衡，如下图所示： producer发送消息负载均衡 首先分析一下RocketMQ的客户端发送消息的源码：在整个应用生命周期内，生产者需要调用一次start方法来初始化，初始化主要完成的任务有： 如果没有指定namesrv地址，将会自动寻址 启动定时任务：更新namesrv地址、从namsrv更新topic路由信息、清理已经挂掉的broker、向所有broker发送心跳… 启动负载均衡的服务 初始化完成后，开始发送消息，发送消息的主要代码如下： 代码中需要关注的两个方法tryToFindTopicPublishInfo和selectOneMessageQueue。前面说过在producer初始化时，会启动定时任务获取路由信息并更新到本地缓存，所以tryToFindTopicPublishInfo会首先从缓存中获取topic路由信息，如果没有获取到，则会自己去namesrv获取路由信息。selectOneMessageQueue方法通过轮询的方式，返回一个队列，以达到负载均衡的目的。 如果Producer发送消息失败，会自动重试，重试的策略： 重试次数 &lt; retryTimesWhenSendFailed（可配置） 总的耗时（包含重试n次的耗时） &lt; sendMsgTimeout（发送消息时传入的参数） 同时满足上面两个条件后，Producer会选择另外一个队列发送消息 消息存储RocketMQ的消息存储是由consume queue和commit log配合完成的。 Consume Queueconsume queue是消息的逻辑队列，相当于字典的目录，用来指定消息在物理文件commit log上的位置。 我们可以在配置中指定consumequeue与commitlog存储的目录 每个topic下的每个queue都有一个对应的consumequeue文件，比如： Consume Queue文件组织，如图所示： Consume Queue文件组织示意图 根据topic和queueId来组织文件，图中TopicA有两个队列0,1，那么TopicA和QueueId=0组成一个ConsumeQueue，TopicA和QueueId=1组成另一个ConsumeQueue。 按照消费端的GroupName来分组重试队列，如果消费端消费失败，消息将被发往重试队列中，比如图中的%RETRY%ConsumerGroupA。 按照消费端的GroupName来分组死信队列，如果消费端消费失败，并重试指定次数后，仍然失败，则发往死信队列，比如图中的%DLQ%ConsumerGroupA。 死信队列（Dead Letter Queue）一般用于存放由于某种原因无法传递的消息，比如处理失败或者已经过期的消息。 Consume Queue中存储单元是一个20字节定长的二进制数据，顺序写顺序读，如下图所示： consumequeue文件存储单元格式 CommitLog Offset是指这条消息在Commit Log文件中的实际偏移量 Size存储中消息的大小 Message Tag HashCode存储消息的Tag的哈希值：主要用于订阅时消息过滤（订阅时如果指定了Tag，会根据HashCode来快速查找到订阅的消息） Commit LogCommitLog：消息存放的物理文件，每台broker上的commitlog被本机所有的queue共享，不做任何区分。 文件的默认位置如下，仍然可通过配置文件修改： ${user.home} store${commitlog}${fileName} CommitLog的消息存储单元长度不固定，文件顺序写，随机读。消息的存储结构如下表所示，按照编号顺序以及编号对应的内容依次存储。 Commit Log存储单元结构图 消息存储实现消息存储实现，比较复杂，也值得大家深入了解，后面会单独成文来分析(目前正在收集素材)，这小节只以代码说明一下具体的流程。 消息的索引文件如果一个消息包含key值的话，会使用IndexFile存储消息索引，文件的内容结构如图： 消息索引 索引文件主要用于根据key来查询消息的，流程主要是： 根据查询的 key 的 hashcode%slotNum 得到具体的槽的位置(slotNum 是一个索引文件里面包含的最大槽的数目，例如图中所示 slotNum=5000000) 根据 slotValue(slot 位置对应的值)查找到索引项列表的最后一项(倒序排列,slotValue 总是指向最新的一个索引项) 遍历索引项列表返回查询时间范围内的结果集(默认一次最大返回的 32 条记录) 消息订阅RocketMQ消息订阅有两种模式，一种是Push模式，即MQServer主动向消费端推送；另外一种是Pull模式，即消费端在需要时，主动到MQServer拉取。但在具体实现时，Push和Pull模式都是采用消费端主动拉取的方式。 首先看下消费端的负载均衡：消费端负载均衡 消费端会通过RebalanceService线程，10秒钟做一次基于topic下的所有队列负载： 遍历Consumer下的所有topic，然后根据topic订阅所有的消息 获取同一topic和Consumer Group下的所有Consumer 然后根据具体的分配策略来分配消费队列，分配的策略包含：平均分配、消费端配置等 如同上图所示：如果有 5 个队列，2 个 consumer，那么第一个 Consumer 消费 3 个队列，第二 consumer 消费 2 个队列。这里采用的就是平均分配策略，它类似于分页的过程，TOPIC下面的所有queue就是记录，Consumer的个数就相当于总的页数，那么每页有多少条记录，就类似于某个Consumer会消费哪些队列。 通过这样的策略来达到大体上的平均消费，这样的设计也可以很方便的水平扩展Consumer来提高消费能力。 消费端的Push模式是通过长轮询的模式来实现的，就如同下图： Push模式示意图 Consumer端每隔一段时间主动向broker发送拉消息请求，broker在收到Pull请求后，如果有消息就立即返回数据，Consumer端收到返回的消息后，再回调消费者设置的Listener方法。如果broker在收到Pull请求时，消息队列里没有数据，broker端会阻塞请求直到有数据传递或超时才返回。 当然，Consumer端是通过一个线程将阻塞队列LinkedBlockingQueue&lt;PullRequest&gt;中的PullRequest发送到broker拉取消息，以防止Consumer一致被阻塞。而Broker端，在接收到Consumer的PullRequest时，如果发现没有消息，就会把PullRequest扔到ConcurrentHashMap中缓存起来。broker在启动时，会启动一个线程不停的从ConcurrentHashMap取出PullRequest检查，直到有数据返回。 RocketMQ的其他特性前面的6个特性都是基本上都是点到为止，想要深入了解，还需要大家多多查看源码，多多在实际中运用。当然除了已经提到的特性外，RocketMQ还支持： 定时消息 消息的刷盘策略 主动同步策略：同步双写、异步复制 海量消息堆积能力 高效通信 ……. 其中涉及到的很多设计思路和解决方法都值得我们深入研究： 消息的存储设计：既要满足海量消息的堆积能力，又要满足极快的查询效率，还要保证写入的效率。 高效的通信组件设计：高吞吐量，毫秒级的消息投递能力都离不开高效的通信。 ……. RocketMQ最佳实践 一、Producer最佳实践 一个应用尽可能用一个 Topic，消息子类型用 tags 来标识，tags 可以由应用自由设置。只有发送消息设置了tags，消费方在订阅消息时，才可以利用 tags 在 broker 做消息过滤。 每个消息在业务层面的唯一标识码，要设置到 keys 字段，方便将来定位消息丢失问题。由于是哈希索引，请务必保证 key 尽可能唯一，这样可以避免潜在的哈希冲突。 消息发送成功或者失败，要打印消息日志，务必要打印 sendresult 和 key 字段。 对于消息不可丢失应用，务必要有消息重发机制。例如：消息发送失败，存储到数据库，能有定时程序尝试重发或者人工触发重发。 某些应用如果不关注消息是否发送成功，请直接使用sendOneWay方法发送消息。 二、Consumer最佳实践 消费过程要做到幂等（即消费端去重） 尽量使用批量方式消费方式，可以很大程度上提高消费吞吐量。 优化每条消息消费过程 三、其他配置 线上应该关闭autoCreateTopicEnable，即在配置文件中将其设置为false。 RocketMQ在发送消息时，会首先获取路由信息。如果是新的消息，由于MQServer上面还没有创建对应的Topic，这个时候，如果上面的配置打开的话，会返回默认TOPIC的（RocketMQ会在每台broker上面创建名为TBW102的TOPIC）路由信息，然后Producer会选择一台Broker发送消息，选中的broker在存储消息时，发现消息的topic还没有创建，就会自动创建topic。后果就是：以后所有该TOPIC的消息，都将发送到这台broker上，达不到负载均衡的目的。 所以基于目前RocketMQ的设计，建议关闭自动创建TOPIC的功能，然后根据消息量的大小，手动创建TOPIC。 RocketMQ设计相关 RocketMQ的设计假定： 每台PC机器都可能宕机不可服务 任意集群都有可能处理能力不足 最坏的情况一定会发生 内网环境需要低延迟来提供最佳用户体验 RocketMQ的关键设计： 分布式集群化 强数据安全 海量数据堆积 毫秒级投递延迟（推拉模式） 这是RocketMQ在设计时的假定前提以及需要到达的效果。我想这些假定适用于所有的系统设计。随着我们系统的服务的增多，每位开发者都要注意自己的程序是否存在单点故障，如果挂了应该怎么恢复、能不能很好的水平扩展、对外的接口是否足够高效、自己管理的数据是否足够安全…… 多多规范自己的设计，才能开发出高效健壮的程序。 Kafka 如何保证消息顺序消费、在consumer group 中新增一个consumer 会提高消费消息的速度吗、那如果我想提高消息消费的速度，我要怎么办？Kafka是一种分布式的，基于发布/订阅的消息系统。主要设计目标如下： 以时间复杂度为O(1)的方式提供消息持久化能力，并保证即使对TB级以上数据也能保证常数时间的访问性能 高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输 支持Kafka Server间的消息分区，及分布式消息消费，同时保证每个partition内的消息顺序传输 同时支持离线数据处理和实时数据处理 为什么要用Message Queue 解耦 在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。消息队列在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口。这允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束 冗余 有时在处理数据的时候处理过程会失败。除非数据被持久化，否则将永远丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。在被许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理过程明确的指出该消息已经被处理完毕，确保你的数据被安全的保存直到你使用完毕。 扩展性 因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的；只要另外增加处理过程即可。不需要改变代码、不需要调节参数。扩展就像调大电力按钮一样简单。 灵活性 &amp; 峰值处理能力 在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住增长的访问压力，而不是因为超出负荷的请求而完全崩溃。 可恢复性 当体系的一部分组件失效，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。而这种允许重试或者延后处理请求的能力通常是造就一个略感不便的用户和一个沮丧透顶的用户之间的区别。 送达保证 消息队列提供的冗余机制保证了消息能被实际的处理，只要一个进程读取了该队列即可。在此基础上，IronMQ提供了一个”只送达一次”保证。无论有多少进程在从队列中领取数据，每一个消息只能被处理一次。这之所以成为可能，是因为获取一个消息只是”预定”了这个消息，暂时把它移出了队列。除非客户端明确的表示已经处理完了这个消息，否则这个消息会被放回队列中去，在一段可配置的时间之后可再次被处理。 顺序保证 在许多情况下，数据处理的顺序都很重要。消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。IronMO保证消息浆糊通过FIFO（先进先出）的顺序来处理，因此消息在队列中的位置就是从队列中检索他们的位置。 缓冲 在任何重要的系统中，都会有需要不同的处理时间的元素。例如,加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行—写入队列的处理会尽可能的快速，而不受从队列读的预备处理的约束。该缓冲有助于控制和优化数据流经过系统的速度。 理解数据流 在一个分布式系统里，要得到一个关于用户操作会用多长时间及其原因的总体印象，是个巨大的挑战。消息系列通过消息被处理的频率，来方便的辅助确定那些表现不佳的处理过程或领域，这些地方的数据流都不够优化。 异步通信 很多时候，你不想也不需要立即处理消息。消息队列提供了异步处理机制，允许你把一个消息放入队列，但并不立即处理它。你想向队列中放入多少消息就放多少，然后在你乐意的时候再去处理它们。 常用Message Queue对比 RabbitMQ RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP，也正因如此，它非常重量级，更适合于企业级的开发。同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。对路由，负载均衡或者数据持久化都有很好的支持。 Redis Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。测试数据分为128Bytes、512Bytes、1K和10K四个不同大小的数据。实验表明：入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。 ZeroMQ ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。ZMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，技术上的复杂度是对这MQ能够应用成功的挑战。ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演了这个服务角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果down机，数据将会丢失。其中，Twitter的Storm中默认使用ZeroMQ作为数据流的传输。 ActiveMQ ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。 Kafka/Jafka Kafka是Apache下的一个子项目，是一个高性能跨语言分布式Publish/Subscribe消息队列系统，而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。具有以下特性：快速持久化，可以在O(1)的系统开销下进行消息持久化；高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现复杂均衡；支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。Kafka通过Hadoop的并行加载机制来统一了在线和离线的消息处理，这一点也是本课题所研究系统所看重的。Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。 Kafka解析Terminology Broker Kafka集群包含一个或多个服务器，这种服务器被称为broker Topic 每条发布到Kafka集群的消息都有一个类别，这个类别被称为topic。（物理上不同topic的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上但用户只需指定消息的topic即可生产或消费数据而不必关心数据存于何处） Partition parition是物理上的概念，每个topic包含一个或多个partition，创建topic时可指定parition数量。每个partition对应于一个文件夹，该文件夹下存储该partition的数据和索引文件 Producer 负责发布消息到Kafka broker Consumer 消费消息。每个consumer属于一个特定的consuer group（可为每个consumer指定group name，若不指定group name则属于默认的group）。使用consumer high level API时，同一topic的一条消息只能被同一个consumer group内的一个consumer消费，但多个consumer group可同时消费这一消息。 Kafka架构 如上图所示，一个典型的kafka集群中包含若干producer（可以是web前端产生的page view，或者是服务器日志，系统CPU、memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干consumer group，以及一个Zookeeper 集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。producer使用push模式将消息发布到broker，consumer使用pull模式从broker订阅并消费消息。 Push vs. Pull作为一个messaging system，Kafka遵循了传统的方式，选择由producer向broker push消息并由consumer从broker pull消息。一些logging-centric system，比如Facebook的 Scribe 和Cloudera的 Flume ,采用非常不同的push模式。事实上，push模式和pull模式各有优劣。 push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而pull模式则可以根据consumer的消费能力以适当的速率消费消息。 Topic &amp; PartitionTopic在逻辑上可以被认为是一个在的queue，每条消费都必须指定它的topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以水平扩展，物理上把topic分成一个或多个partition，每个partition在物理上对应一个文件夹，该文件夹下存储这个partition的所有消息和索引文件。 每个日志文件都是“log entries”序列，每一个 log entry 包含一个4字节整型数（值为N），其后跟N个字节的消息体。每条消息都有一个当前partition下唯一的64字节的offset，它指明了这条消息的起始位置。磁盘上存储的消费格式如下： 1234567message length ： 4 bytes (value: 1+4+n)“magic” value ： 1 bytecrc ： 4 bytespayload ： n bytes 这个“log entries”并非由一个文件构成，而是分成多个segment，每个segment名为该segment第一条消息的offset和“.kafka”组成。另外会有一个索引文件，它标明了每个segment下包含的 log entry 的offset范围，如下图所示。 因为每条消息都被append到该partition中，是顺序写磁盘，因此效率非常高（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。 每一条消息被发送到broker时，会根据paritition规则选择被存储到哪一个partition。如果partition规则设置的合理，所有消息可以均匀分布到不同的partition里，这样就实现了水平扩展。（如果一个topic对应一个文件，那这个文件所在的机器I/O将会成为这个topic的性能瓶颈，而partition解决了这个问题）。在创建topic时可以在$KAFKA_HOME/config/server.properties 中指定这个partition的数量(如下所示)，当然也可以在topic创建之后去修改parition数量。 1234#The default number of log partitions per topic. More partitions allow greater#parallelism for consumption, but this will also result in more files across#the brokers.num.partitions=3 在发送一条消息时，可以指定这条消息的key，producer根据这个key和partition机制来判断将这条消息发送到哪个parition。paritition机制可以通过指定producer的paritition. class这一参数来指定，该class必须实现 kafka.producer.Partitioner 接口。本例中如果key可以被解析为整数则将对应的整数与partition总数取余，该消息会被发送到该数对应的partition。（每个parition都会有个序号）1234567891011121314import kafka.producer.Partitioner;import kafka.utils.VerifiableProperties;public class JasonPartitioner&lt;T&gt; implements Partitioner &#123; public JasonPartitioner(VerifiableProperties verifiableProperties) &#123;&#125; @Override public int partition(Object key, int numPartitions) &#123; try &#123; int partitionNum = Integer.parseInt((String) key); return Math.abs(Integer.parseInt((String) key) % numPartitions); &#125; catch (Exception e) &#123; return Math.abs(key.hashCode() % numPartitions); &#125; &#125;&#125; 如果将上例中的class作为partition.class，并通过如下代码发送20条消息（key分别为0，1，2，3）至topic2（包含4个partition）。12345678910public void sendMessage() throws InterruptedException&#123; for(int i = 1; i &lt;= 5; i++)&#123; List messageList = new ArrayList&lt;KeyedMessage&lt;String, String&gt;&gt;(); for(int j = 0; j &lt; 4; j++）&#123; messageList.add(new KeyedMessage&lt;String, String&gt;("topic2", j+"", "The " + i + " message for key " + j)); &#125; producer.send(messageList); &#125; producer.close();&#125; 则key相同的消息会被发送并存储到同一个partition里，而且key的序号正好和partition序号相同。（partition序号从0开始，本例中的key也正好从0开始）。如下图所示。 对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略去删除旧数据。一是基于时间，二是基于partition文件大小。例如可以通过配置$KAFKA_HOME/config/server.properties ，让Kafka删除一周前的数据，也可通过配置让Kafka在partition文件超过1GB时删除旧数据，如下所示。 12345678910111213141516171819202122232425#############################Log Retention Policy############################# #he following configurations control the disposal of log segments. The policy can#be set to delete segments after a period of time, or after a given size has accumulated.#A segment will be deleted whenever *either* of these criteria are met. Deletion always happens#from the end of the log. #The minimum age of a log file to be eligible for deletionlog.retention.hours=168 #A size-based retention policy for logs. Segments are pruned from the log as long as the remaininsegments don't drop below log.retention.bytes.#log.retention.bytes=1073741824 #The maximum size of a log segment file. When this size is reached a new log segment will be created.log.segment.bytes=1073741824 #The interval at which log segments are checked to see if they can be deleted according#to the retention policieslog.retention.check.interval.ms=300000 #By default the log cleaner is disabled and the log retention policy will default to #just delete segments after their retention expires.#If log.cleaner.enable=true is set the cleaner will be enabled and individual logs #can then be marked for log compaction.log.cleaner.enable=false 这里要注意，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除文件与Kafka性能无关，选择怎样的删除策略只与磁盘以及具体的需求有关。另外，Kafka会为每一个consumer group保留一些metadata信息—当前消费的消息的position，也即offset。这个offset由consumer控制。正常情况下consumer会在消费完一条消息后线性增加这个offset。当然，consumer也可将offset设成一个较小的值，重新消费一些消息。因为offet由consumer控制，所以Kafka broker是无状态的，它不需要标记哪些消息被哪些consumer过，不需要通过broker去保证同一个consumer group只有一个consumer能消费某一条消息，因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。 Replication &amp; Leader electionKafka从0.8开始提供partition级别的replication，replication的数量可在$KAFKA_HOME/config/server.properties中配置。1default.replication.factor = 1 该 Replication与leader election配合提供了自动的failover机制。replication对Kafka的吞吐率是有一定影响的，但极大的增强了可用性。默认情况下，Kafka的replication数量为1。 每个partition都有一个唯一的leader，所有的读写操作都在leader上完成，leader批量从leader上pull数据。一般情况下partition的数量大于等于broker的数量，并且所有partition的leader均匀分布在broker上。follower上的日志和其leader上的完全一样。 和大部分分布式系统一样，Kakfa处理失败需要明确定义一个broker是否alive。对于Kafka而言，Kafka存活包含两个条件，一是它必须维护与Zookeeper的session(这个通过Zookeeper的heartbeat机制来实现)。二是follower必须能够及时将leader的writing复制过来，不能“落后太多”。 leader会track“in sync”的node list。如果一个follower宕机，或者落后太多，leader将把它从”in sync” list中移除。这里所描述的“落后太多”指follower复制的消息落后于leader后的条数超过预定值，该值可在 $KAFKA_HOME/config/server.properties 中配置12345#If a replica falls more than this many messages behind the leader, the leader will remove the follower from ISR and treat it as deadreplica.lag.max.messages=4000 #If a follower hasn't sent any fetch requests for this window of time, the leader will remove the follower from ISR (in-sync replicas) and treat it as deadreplica.lag.time.max.ms=10000 需要说明的是，Kafka只解决”fail/recover”，不处理“Byzantine”（“拜占庭”）问题。 一条消息只有被“in sync” list里的所有follower都从leader复制过去才会被认为已提交。这样就避免了部分数据被写进了leader，还没来得及被任何follower复制就宕机了，而造成数据丢失（consumer无法消费这些数据）。而对于producer而言，它可以选择是否等待消息commit，这可以通过request.required.acks 来设置。这种机制确保了只要“in sync” list有一个或以上的flollower，一条被commit的消息就不会丢失。 这里的复制机制即不是同步复制，也不是单纯的异步复制。事实上，同步复制要求“活着的”follower都复制完，这条消息才会被认为commit，这种复制方式极大的影响了吞吐率（高吞吐率是Kafka非常重要的一个特性）。而异步复制方式下，follower异步的从leader复制数据，数据只要被leader写入log就被认为已经commit，这种情况下如果follwer都落后于leader，而leader突然宕机，则会丢失数据。而Kafka的这种使用“in sync” list的方式则很好的均衡了确保数据不丢失以及吞吐率。follower可以批量的从leader复制数据，这样极大的提高复制性能（批量写磁盘），极大减少了follower与leader的差距（前文有说到，只要follower落后leader不太远，则被认为在“in sync” list里）。 上文说明了Kafka是如何做replication的，另外一个很重要的问题是当leader宕机了，怎样在follower中选举出新的leader。因为follower可能落后许多或者crash了，所以必须确保选择“最新”的follower作为新的leader。一个基本的原则就是，如果leader不在了，新的leader必须拥有原来的leader commit的所有消息。这就需要作一个折衷，如果leader在标明一条消息被commit前等待更多的follower确认，那在它die之后就有更多的follower可以作为新的leader，但这也会造成吞吐率的下降。 一种非常常用的选举leader的方式是“majority 灵秀”（“少数服从多数”），但Kafka并未采用这种方式。这种模式下，如果我们有2f+1个replica（包含leader和follower），那在commit之前必须保证有f+1个replica复制完消息，为了保证正确选出新的leader，fail的replica不能超过f个。因为在剩下的任意f+1个replica里，至少有一个replica包含有最新的所有消息。这种方式有个很大的优势，系统的latency只取决于最快的几台server，也就是说，如果replication factor是3，那latency就取决于最快的那个follower而非最慢那个。majority vote也有一些劣势，为了保证leader election的正常进行，它所能容忍的fail的follower个数比较少。如果要容忍1个follower挂掉，必须要有3个以上的replica，如果要容忍2个follower挂掉，必须要有5个以上的replica。也就是说，在生产环境下为了保证较高的容错程度，必须要有大量的replica，而大量的replica又会在大数据量下导致性能的急剧下降。这就是这种算法更多用在 Zookeeper 这种共享集群配置的系统中而很少在需要存储大量数据的系统中使用的原因。例如HDFS的HA feature是基于 majority-vote-based journal ，但是它的数据存储并没有使用这种expensive的方式。 实际上，leader election算法非常多，比如Zookeper的 Zab , Raft 和 Viewstamped Replication 。而Kafka所使用的leader election算法更像微软的 PacificA 算法。 Kafka在Zookeeper中动态维护了一个ISR（in-sync replicas） set，这个set里的所有replica都跟上了leader，只有ISR里的成员才有被选为leader的可能。在这种模式下，对于f+1个replica，一个Kafka topic能在保证不丢失已经ommit的消息的前提下容忍f个replica的失败。在大多数使用场景中，这种模式是非常有利的。事实上，为了容忍f个replica的失败，majority vote和ISR在commit前需要等待的replica数量是一样的，但是ISR需要的总的replica的个数几乎是majority vote的一半。 虽然majority vote与ISR相比有不需等待最慢的server这一优势，但是Kafka作者认为Kafka可以通过producer选择是否被commit阻塞来改善这一问题，并且节省下来的replica和磁盘使得ISR模式仍然值得。 上文提到，在ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，但如果某一个partition的所有replica都挂了，就无法保证数据不丢失了。这种情况下有两种可行的方案： 等待ISR中的任一个replica“活”过来，并且选它作为leader 选择第一个“活”过来的replica（不一定是ISR中的）作为leader 这就需要在可用性和一致性当中作出一个简单的平衡。如果一定要等待ISR中的replica“活”过来，那不可用的时间就可能会相对较长。而且如果ISR中的所有replica都无法“活”过来了，或者数据都丢失了，这个partition将永远不可用。选择第一个“活”过来的replica作为leader，而这个replica不是ISR中的replica，那即使它并不保证已经包含了所有已commit的消息，它也会成为leader而作为consumer的数据源（前文有说明，所有读写都由leader完成）。Kafka0.8.*使用了第二种方式。根据Kafka的文档，在以后的版本中，Kafka支持用户通过配置选择这两种方式中的一种，从而根据不同的使用场景选择高可用性还是强一致性。 上文说明了一个parition的replication过程，然尔Kafka集群需要管理成百上千个partition，Kafka通过round-robin的方式来平衡partition从而避免大量partition集中在了少数几个节点上。同时Kafka也需要平衡leader的分布，尽可能的让所有partition的leader均匀分布在不同broker上。另一方面，优化leadership election的过程也是很重要的，毕竟这段时间相应的partition处于不可用状态。一种简单的实现是暂停宕机的broker上的所有partition，并为之选举leader。实际上，Kafka选举一个broker作为controller，这个controller通过watch Zookeeper检测所有的broker failure，并负责为所有受影响的parition选举leader，再将相应的leader调整命令发送至受影响的broker，过程如下图所示。 这样做的好处是，可以批量的通知leadership的变化，从而使得选举过程成本更低，尤其对大量的partition而言。如果controller失败了，幸存的所有broker都会尝试在Zookeeper中创建/controller-&gt;{this broker id}，如果创建成功（只可能有一个创建成功），则该broker会成为controller，若创建不成功，则该broker会等待新controller的命令。 Consumer group（本节所有描述都是基于consumer hight level API而非low level API）。 每一个consumer实例都属于一个consumer group，每一条消息只会被同一个consumer group里的一个consumer实例消费。（不同consumer group可以同时消费同一条消息） 很多传统的message queue都会在消息被消费完后将消息删除，一方面避免重复消费，另一方面可以保证queue的长度比较少，提高效率。而如上文所将，Kafka并不删除已消费的消息，为了实现传统message queue消息只被消费一次的语义，Kafka保证保证同一个consumer group里只有一个consumer会消费一条消息。与传统message queue不同的是，Kafka还允许不同consumer group同时消费同一条消息，这一特性可以为消息的多元化处理提供了支持。实际上，Kafka的设计理念之一就是同时提供离线处理和实时处理。根据这一特性，可以使用Storm这种实时流处理系统对消息进行实时在线处理，同时使用Hadoop这种批处理系统进行离线处理，还可以同时将数据实时备份到另一个数据中心，只需要保证这三个操作所使用的consumer在不同的consumer group即可。下图展示了Kafka在Linkedin的一种简化部署。 为了更清晰展示Kafka consumer group的特性，笔者作了一项测试。创建一个topic (名为topic1)，创建一个属于group1的consumer实例，并创建三个属于group2的consumer实例，然后通过producer向topic1发送key分别为1，2，3r的消息。结果发现属于group1的consumer收到了所有的这三条消息，同时group2中的3个consumer分别收到了key为1，2，3的消息。如下图所示。 Consumer Rebalance（本节所讲述内容均基于Kafka consumer high level API） Kafka保证同一consumer group中只有一个consumer会消息某条消息，实际上，Kafka保证的是稳定状态下每一个consumer实例只会消费某一个或多个特定partition的数据，而某个partition的数据只会被某一个特定的consumer实例所消费。这样设计的劣势是无法让同一个consumer group里的consumer均匀消费数据，优势是每个consumer不用都跟大量的broker通信，减少通信开销，同时也降低了分配难度，实现也更简单。另外，因为同一个partition里的数据是有序的，这种设计可以保证每个partition里的数据也是有序被消费。 如果某consumer group中consumer数量少于partition数量，则至少有一个consumer会消费多个partition的数据，如果consumer的数量与partition数量相同，则正好一个consumer消费一个partition的数据，而如果consumer的数量多于partition的数量时，会有部分consumer无法消费该topic下任何一条消息。 如下例所示，如果topic1有0，1，2共三个partition，当group1只有一个consumer(名为consumer1)时，该 consumer可消费这3个partition的所有数据。 增加一个consumer(consumer2)后，其中一个consumer（consumer1）可消费2个partition的数据，另外一个consumer(consumer2)可消费另外一个partition的数据。 再增加一个consumer(consumer3)后，每个consumer可消费一个partition的数据。consumer1消费partition0，consumer2消费partition1，consumer3消费partition2 再增加一个consumer（consumer4）后，其中3个consumer可分别消费一个partition的数据，另外一个consumer（consumer4）不能消费topic1任何数据。 此时关闭consumer1，剩下的consumer可分别消费一个partition的数据。 接着关闭consumer2，剩下的consumer3可消费2个partition，consumer4可消费1个partition。 再关闭consumer3，剩下的consumer4可同时消费topic1的3个partition。 consumer rebalance算法如下： Sort PT (all partitions in topic T) Sort CG(all consumers in consumer group G) Let i be the index position of Ci in CG and let N=size(PT)/size(CG) Remove current entries owned by Ci from the partition owner registry Assign partitions from i N to (i+1) N-1 to consumer Ci Add newly assigned partitions to the partition owner registry 目前consumer rebalance的控制策略是由每一个consumer通过Zookeeper完成的。具体的控制方式如下： Register itself in the consumer id registry under its group. Register a watch on changes under the consumer id registry. Register a watch on changes under the broker id registry. If the consumer creates a message stream using a topic filter, it also registers a watch on changes under the broker topic registry. Force itself to rebalance within in its consumer group. 在这种策略下，每一个consumer或者broker的增加或者减少都会触发consumer rebalance。因为每个consumer只负责调整自己所消费的partition，为了保证整个consumer group的一致性，所以当一个consumer触发了rebalance时，该consumer group内的其它所有consumer也应该同时触发rebalance。 目前（2015-01-19）最新版（0.8.2）Kafka采用的是上述方式。但该方式有不利的方面： Herd effect 任何broker或者consumer的增减都会触发所有的consumer的rebalance Split Brain 每个consumer分别单独通过Zookeeper判断哪些partition down了，那么不同consumer从Zookeeper“看”到的view就可能不一样，这就会造成错误的reblance尝试。而且有可能所有的consumer都认为rebalance已经完成了，但实际上可能并非如此。 根据Kafka官方文档，Kafka作者正在考虑在还未发布的 0.9.x版本中使用中心协调器(coordinator) 。大体思想是选举出一个broker作为coordinator，由它watch Zookeeper，从而判断是否有partition或者consumer的增减，然后生成rebalance命令，并检查是否这些rebalance在所有相关的consumer中被执行成功，如果不成功则重试，若成功则认为此次rebalance成功（这个过程跟replication controller非常类似，所以我很奇怪为什么当初设计replication controller时没有使用类似方式来解决consumer rebalance的问题）。 消息Deliver guarantee通过上文介绍，想必读者已经明天了producer和consumer是如何工作的，以及Kafka是如何做replication的，接下来要讨论的是Kafka如何确保消息在producer和consumer之间传输。有这么几种可能的delivery guarantee： At most once 消息可能会丢，但绝不会重复传输 At least one 消息绝不会丢，但可能会重复传输 Exactly once 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。 Kafka的delivery guarantee semantic非常直接。当producer向broker发送消息时，一旦这条消息被commit，因数replication的存在，它就不会丢。但是如果producer发送数据给broker后，遇到的网络问题而造成通信中断，那producer就无法判断该条消息是否已经commit。这一点有点像向一个自动生成primary key的数据库表中插入数据。虽然Kafka无法确定网络故障期间发生了什么，但是producer可以生成一种类似于primary key的东西，发生故障时幂等性的retry多次，这样就做到了Exactly one 。截止到目前(Kafka 0.8.2版本，2015-01-25)，这一feature还并未实现，有希望在Kafka未来的版本中实现。（所以目前默认情况下一条消息从producer和broker是确保了 At least once ，但可通过设置producer异步发送实现 At most once ）。 接下来讨论的是消息从broker到consumer的delivery guarantee semantic。（仅针对Kafka consumer high level API）。consumer在从broker读取消息后，可以选择commit，该操作会在Zookeeper中存下该consumer在该partition下读取的消息的offset。该consumer下一次再读该partition时会从下一条开始读取。如未commit，下一次读取的开始位置会跟上一次commit之后的开始位置相同。当然可以将consumer设置为autocommit，即consumer一旦读到数据立即自动commit。如果只讨论这一读取消息的过程，那Kafka是确保了 Exactly once 。但实际上实际使用中consumer并非读取完数据就结束了，而是要进行进一步处理，而数据处理与commit的顺序在很大程度上决定了消息从broker和consumer的delivery guarantee semantic。 读完消息先commit再处理消息。这种模式下，如果consumer在commit后还没来得及处理消息就crash了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于 At most once 读完消息先处理再commit。这种模式下，如果处理完了消息在commit之前consumer crash了，下次重新开始工作时还会处理刚刚未commit的消息，实际上该消息已经被处理过了。这就对应于 At least once 。在很多情况使用场景下，消息都有一个primary key，所以消息的处理往往具有幂等性，即多次处理这一条消息跟只处理一次是等效的，那就可以认为是 Exactly once 。（人个感觉这种说法有些牵强，毕竟它不是Kafka本身提供的机制，而且primary key本身不保证操作的幂等性。而且实际上我们说delivery guarantee semantic是讨论被处理多少次，而非处理结果怎样，因为处理方式多种多样，我们的系统不应该把处理过程的特性—如是否幂等性，当成Kafka本身的feature） 如果一定要做到 Exactly once ，就需要协调offset和实际操作的输出。精典的做法是引入两阶段提交。如果能让offset和操作输入存在同一个地方，会更简洁和通用。这种方式可能更好，因为许多输出系统可能不支持两阶段提交。比如，consumer拿到数据后可能把数据放到HDFS，如果把最新的offset和数据本身一起写到HDFS，那就可以保证数据的输出和offset的更新要么都完成，要么都不完成，间接实现 Exactly once 。（目前就high level API而言，offset是存于Zookeeper中的，无法存于HDFS，而low level API的offset是由自己去维护的，可以将之存于HDFS中） 总之，Kafka默认保证 At least once ，并且允许通过设置producer异步提交来实现 At most once 。而 Exactly once 要求与目标存储系统协作，幸运的是Kafka提供的offset可以使用这种方式非常直接非常容易。 Benchmark纸上得来终觉浅，绝知些事要躬行。笔者希望能亲自测一下Kafka的性能，而非从网上找一些测试数据。所以笔者曾在0.8发布前两个月做过详细的Kafka0.8性能测试，不过很可惜测试报告不慎丢失。所幸在网上找到了Kafka的创始人之一的 Jay Kreps的bechmark 。以下描述皆基于该benchmark。（该benchmark基于Kafka0.8.1） 测试环境producer吞吐率该项测试只测producer的吞吐率，也就是数据只被持久化，没有consumer读数据。 1个producer线程，无replication在这一测试中，创建了一个包含6个partition且没有replication的topic。然后通过一个线程尽可能快的生成50 million条比较短（payload100字节长）的消息。测试结果是821,557 records/second （ 78.3MB/second ）。 之所以使用短消息，是因为对于消息系统来说这种使用场景更难。因为如果使用MB/second来表征吞吐率，那发送长消息无疑能使得测试结果更好。 整个测试中，都是用每秒钟delivery的消息的数量乘以payload的长度来计算MB/second的，没有把消息的元信息算在内，所以实际的网络使用量会比这个大。对于本测试来说，每次还需传输额外的22个字节，包括一个可选的key，消息长度描述，CRC等。另外，还包含一些请求相关的overhead，比如topic，partition，acknowledgement等。这就导致我们比较难判断是否已经达到网卡极限，但是把这些overhead都算在吞吐率里面应该更合理一些。因此，我们已经基本达到了网卡的极限。 初步观察此结果会认为它比人们所预期的要高很多，尤其当考虑到Kafka要把数据持久化到磁盘当中。实际上，如果使用随机访问数据系统，比如RDBMS，或者key-velue store，可预期的最高访问频率大概是5000到50000个请求每秒，这和一个好的RPC层所能接受的远程请求量差不多。而该测试中远超于此的原因有两个。 Kafka确保写磁盘的过程是线性磁盘I/O，测试中使用的6块廉价磁盘线性I/O的最大吞吐量是822MB/second，这已经远大于1Gb网卡所能带来的吞吐量了。许多消息系统把数据持久化到磁盘当成是一个开销很大的事情，这是因为他们对磁盘的操作都不是线性I/O。 在每一个阶段，Kafka都尽量使用批量处理。如果想了解批处理在I/O操作中的重要性，可以参考David Patterson的” Latency Lags Bandwidth “ 1个producer线程，3个异步replication该项测试与上一测试基本一样，唯一的区别是每个partition有3个replica（所以网络传输的和写入磁盘的总的数据量增加了3倍）。每一个broker即要写作为leader的partition，也要读（从leader读数据）写（将数据写到磁盘）作为follower的partition。测试结果为 786,980 records/second （ 75.1MB/second ）。 该项测试中replication是异步的，也就是说broker收到数据并写入本地磁盘后就acknowledge producer，而不必等所有replica都完成replication。也就是说，如果leader crash了，可能会丢掉一些最新的还未备份的数据。但这也会让message acknowledgement延迟更少，实时性更好。 这项测试说明，replication可以很快。整个集群的写能力可能会由于3倍的replication而只有原来的三分之一，但是对于每一个producer来说吞吐率依然足够好。 1个producer线程，3个同步replication该项测试与上一测试的唯一区别是replication是同步的，每条消息只有在被 in sync 集合里的所有replica都复制过去后才会被置为committed（此时broker会向producer发送acknowledgement）。在这种模式下，Kafka可以保证即使leader crash了，也不会有数据丢失。测试结果为 421,823 records/second （ 40.2MB/second）。 Kafka同步复制与异步复制并没有本质的不同。leader会始终track follower replica从而监控它们是否还alive，只有所有 in sync 集合里的replica都acknowledge的消息才可能被consumer所消费。而对follower的等待影响了吞吐率。可以通过增大batch size来改善这种情况，但为了避免特定的优化而影响测试结果的可比性，本次测试并没有做这种调整。 3个producer,3个异步replication该测试相当于把上文中的1个producer,复制到了3台不同的机器上（在1台机器上跑多个实例对吞吐率的增加不会有太大帮忙，因为网卡已经基本饱和了），这3个producer同时发送数据。整个集群的吞吐率为 2,024,032 records/second （ 193,0MB/second）。 Producer Throughput Vs. Stored Data消息系统的一个潜在的危险是当数据能都存于内存时性能很好，但当数据量太大无法完全存于内存中时（然后很多消息系统都会删除已经被消费的数据，但当消费速度比生产速度慢时，仍会造成数据的堆积），数据会被转移到磁盘，从而使得吞吐率下降，这又反过来造成系统无法及时接收数据。这样就非常糟糕，而实际上很多情景下使用queue的目的就是解决数据消费速度和生产速度不一致的问题。 但Kafka不存在这一问题，因为Kafka始终以O（1）的时间复杂度将数据持久化到磁盘，所以其吞吐率不受磁盘上所存储的数据量的影响。为了验证这一特性，做了一个长时间的大数据量的测试，下图是吞吐率与数据量大小的关系图。 上图中有一些variance的存在，并可以明显看到，吞吐率并不受磁盘上所存数据量大小的影响。实际上从上图可以看到，当磁盘数据量达到1TB时，吞吐率和磁盘数据只有几百MB时没有明显区别。 这个variance是由Linux I/O管理造成的，它会把数据缓存起来再批量flush。上图的测试结果是在生产环境中对Kafka集群做了些tuning后得到的，这些tuning方法可参考 这里 。 consumer吞吐率需要注意的是，replication factor并不会影响consumer的吞吐率测试，因为consumer只会从每个partition的leader读数据，而与replicaiton factor无关。同样，consumer吞吐率也与同步复制还是异步复制无关。 1个consumer 该测试从有6个partition，3个replication的topic消费50 million的消息。测试结果为940,521 records/second （ 89.7MB/second ）。 可以看到，Kafkar的consumer是非常高效的。它直接从broker的文件系统里读取文件块。Kafka使用 sendfile API 来直接通过操作系统直接传输，而不用把数据拷贝到用户空间。该项测试实际上从log的起始处开始读数据，所以它做了真实的I/O。在生产环境下，consumer可以直接读取producer刚刚写下的数据（它可能还在缓存中）。实际上，如果在生产环境下跑 I/O stat ，你可以看到基本上没有物理“读”。也就是说生产环境下consumer的吞吐率会比该项测试中的要高。 3个consumer 将上面的consumer复制到3台不同的机器上，并且并行运行它们（从同一个topic上消费数据）。测试结果为 2,615,968 records/second （ 249.5MB/second ）。 正如所预期的那样，consumer的吞吐率几乎线性增涨。 Producer and Consumer上面的测试只是把producer和consumer分开测试，而该项测试同时运行producer和consumer，这更接近使用场景。实际上目前的replication系统中follower就相当于consumer在工作。 该项测试，在具有6个partition和3个replica的topic上同时使用1个producer和1个consumer，并且使用异步复制。测试结果为 795,064 records/second （75.8MB/second ）。 可以看到，该项测试结果与单独测试1个producer时的结果几乎一致。所以说consumer非常轻量级。 消息长度对吞吐率的影响上面的所有测试都基于短消息（payload 100字节），而正如上文所说，短消息对Kafka来说是更难处理的使用方式，可以预期，随着消息长度的增大，records/second会减小，但MB/second会有所提高。下图是records/second与消息长度的关系图。 正如我们所预期的那样，随着消息长度的增加，每秒钟所能发送的消息的数量逐渐减小。但是如果看每秒钟发送的消息的总大小，它会随着消息长度的增加而增加，如下图所示。 从上图可以看出，当消息长度为10字节时，因为要频繁入队，花了太多时间获取锁，CPU成了瓶颈，并不能充分利用带宽。但从100字节开始，我们可以看到带宽的使用逐渐趋于饱和（虽然MB/second还是会随着消息长度的增加而增加，但增加的幅度也越来越小）。 端到端的Latency上文中讨论了吞吐率，那消息传输的latency如何呢？也就是说消息从producer到consumer需要多少时间呢？该项测试创建1个producer和1个consumer并反复计时。结果是， 2 ms (median), 3ms (99th percentile, 14ms (99.9th percentile) 。 （这里并没有说明topic有多少个partition，也没有说明有多少个replica，replication是同步还是异步。实际上这会极大影响producer发送的消息被commit的latency，而只有committed的消息才能被consumer所消费，所以它会最终影响端到端的latency） Kafka 如何保证消息顺序消费两种方案： 方案一，kafka topic 只设置一个partition分区 方案二，producer将消息发送到指定partition分区 解析： 方案一：kafka默认保证同一个partition分区内的消息是有序的，则可以设置topic只使用一个分区，这样消息就是全局有序，缺点是只能被consumer group里的一个消费者消费，降低了性能，不适用高并发的情况 方案二：既然kafka默认保证同一个partition分区内的消息是有序的，则producer可以在发送消息时可以指定需要保证顺序的几条消息发送到同一个分区，这样消费者消费时，消息就是有序。 producer发送消息时具体到topic的哪一个partition分区，提供了三种方式 1）指定分区 2）不指定分区，有指定key 则根据key的hash值与分区数进行运算后确定发送到哪个partition分区 3）不指定分区，不指定key，则轮询各分区发送 提高消费者速度一般来说有几类 1.增加分区（题上不让） 2.关闭autocommit（偏移量手工提交可以按需减少分区偏移量的更新，有利于提升消费速度） 3.增加单次拉取消息的大小（大量消息的场景下可减少拉取消息的次数） 比较另类的： 1.如果不考虑数据一致性，可以将key值平均一下，这样每个分区的消息大小都差不多，有利于负载均衡 2.如果没有开启压缩，最好开启压缩（需要重启集群），可大大提高通信效率，有得消费速度提升 其他 JUC有研究没有，讲一讲？]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>其他</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试分享(四).项目相关]]></title>
    <url>%2F2019%2F06%2F18%2F%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB(%E5%9B%9B).%E9%A1%B9%E7%9B%AE%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[项目相关聊项目，画项目架构图，画一个用户从发起请求到接收到响应，中间经过哪些服务，每个服务做什么事情的流程图。你个人有什么优势讲项目中的难点、挑战，如何解决的，项目这一块会问的特别细线上有没有遇到其他问题，如何处理的说一个你了解最多的框架，说出你的理解项目中监控报警机制如何做的，说说你的了解服务A调用服务B，用户请求服务A，发现返回较慢，如何定位这个问题防止服务器雪崩服务雪崩效应是一种因 服务提供者 的不可用导致 服务调用者 的不可用,并将不可用 逐渐放大 的过程.如果所示: 上图中, A为服务提供者, B为A的服务调用者, C和D是B的服务调用者. 当A的不可用,引起B的不可用,并将不可用逐渐放大C和D时, 服务雪崩就形成了. 服务雪崩效应形成的原因我把服务雪崩的参与者简化为 服务提供者 和 服务调用者, 并将服务雪崩产生的过程分为以下三个阶段来分析形成的原因: 服务提供者不可用 重试加大流量 服务调用者不可用 服务雪崩的每个阶段都可能由不同的原因造成, 比如造成 服务不可用 的原因有: 硬件故障 程序Bug 缓存击穿 用户大量请求 硬件故障可能为硬件损坏造成的服务器主机宕机, 网络硬件故障造成的服务提供者的不可访问.缓存击穿一般发生在缓存应用重启, 所有缓存被清空时,以及短时间内大量缓存失效时. 大量的缓存不命中, 使请求直击后端,造成服务提供者超负荷运行,引起服务不可用.在秒杀和大促开始前,如果准备不充分,用户发起大量请求也会造成服务提供者的不可用. 而形成 重试加大流量 的原因有: 用户重试 代码逻辑重试 在服务提供者不可用后, 用户由于忍受不了界面上长时间的等待,而不断刷新页面甚至提交表单.服务调用端的会存在大量服务异常后的重试逻辑.这些重试都会进一步加大请求流量. 最后, 服务调用者不可用 产生的主要原因是: 同步等待造成的资源耗尽 当服务调用者使用 同步调用 时, 会产生大量的等待线程占用系统资源. 一旦线程资源被耗尽,服务调用者提供的服务也将处于不可用状态, 于是服务雪崩效应产生了. 服务雪崩的应对策略针对造成服务雪崩的不同原因, 可以使用不同的应对策略: 流量控制 改进缓存模式 服务自动扩容 服务调用者降级服务 流量控制 的具体措施包括: 网关限流 用户交互限流 关闭重试 因为Nginx的高性能, 目前一线互联网公司大量采用Nginx+Lua的网关进行流量控制, 由此而来的OpenResty也越来越热门. 用户交互限流的具体措施有: 采用加载动画,提高用户的忍耐等待时间. 提交按钮添加强制等待时间机制. 改进缓存模式 的措施包括: 缓存预加载 同步改为异步刷新 服务自动扩容 的措施主要有: AWS的auto scaling 服务调用者降级服务 的措施包括:资源隔离 对依赖服务进行分类 不可用服务的调用快速失败 资源隔离主要是对调用服务的线程池进行隔离. 我们根据具体业务,将依赖服务分为: 强依赖和若依赖. 强依赖服务不可用会导致当前业务中止,而弱依赖服务的不可用不会导致当前业务的中止. 不可用服务的调用快速失败一般通过 超时机制, 熔断器 和熔断后的 降级方法 来实现. 缓存穿透，缓存击穿，缓存雪崩解决方案分析缓存穿透缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。 解决方案有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 缓存雪崩缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。 解决方案缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 缓存击穿对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。 缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 解决方案使用互斥锁(mutex key)业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。 SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。在redis2.6.1之前版本未实现setnx的过期时间，所以这里给出两种版本代码参考：123456789101112131415161718//2.6.1前单机版本锁String get(String key) &#123; String value = redis.get(key); if (value == null) &#123; if (redis.setnx(key_mutex, "1")) &#123; // 3 min timeout to avoid mutex holder crash redis.expire(key_mutex, 3 * 60) value = db.get(key); redis.set(key, value); redis.delete(key_mutex); &#125; else &#123; //其他线程休息50毫秒后重试 Thread.sleep(50); get(key); &#125; &#125; &#125; 最新版本代码：1234567891011121314151617public String get(key) &#123; String value = redis.get(key); if (value == null) &#123; //代表缓存值过期 //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db if (redis.setnx(key_mutex, 1, 3 * 60) == 1) &#123; //代表设置成功 value = db.get(key); redis.set(key, value, expire_secs); redis.del(key_mutex); &#125; else &#123; //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可 sleep(50); get(key); //重试 &#125; &#125; else &#123; return value; &#125; &#125; memcache代码1234567891011if (memcache.get(key) == null) &#123; // 3 min timeout to avoid mutex holder crash if (memcache.add(key_mutex, 3 * 60 * 1000) == true) &#123; value = db.get(key); memcache.set(key, value); memcache.delete(key_mutex); &#125; else &#123; sleep(50); retry(); &#125; &#125; “提前”使用互斥锁(mutex key)在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。伪代码如下：12345678910111213141516171819202122232425262728v = memcache.get(key); if (v == null) &#123; if (memcache.add(key_mutex, 3 * 60 * 1000) == true) &#123; value = db.get(key); memcache.set(key, value); memcache.delete(key_mutex); &#125; else &#123; sleep(50); retry(); &#125; &#125; else &#123; if (v.timeout &lt;= now()) &#123; if (memcache.add(key_mutex, 3 * 60 * 1000) == true) &#123; // extend the timeout for other threads v.timeout += 3 * 60 * 1000; memcache.set(key, v, KEY_TIMEOUT * 2); // load the latest value from db v = db.get(key); v.timeout = KEY_TIMEOUT; memcache.set(key, value, KEY_TIMEOUT * 2); memcache.delete(key_mutex); &#125; else &#123; sleep(50); retry(); &#125; &#125; &#125; “永远不过期”这里的“永远不过期”包含两层意思： (1) 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。 (2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期 从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。123456789101112131415161718192021String get(final String key) &#123; V v = redis.get(key); String value = v.getValue(); long timeout = v.getTimeout(); if (v.timeout &lt;= System.currentTimeMillis()) &#123; // 异步更新后台异常执行 threadPool.execute(new Runnable() &#123; public void run() &#123; String keyMutex = "mutex:" + key; if (redis.setnx(keyMutex, "1")) &#123; // 3 min timeout to avoid mutex holder crash redis.expire(keyMutex, 3 * 60); String dbValue = db.get(key); redis.set(key, dbValue); redis.delete(keyMutex); &#125; &#125; &#125;); &#125; return value; &#125; 资源保护采用netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。 四种解决方案：没有最佳只有最合适 解决方案 优点 缺点 简单分布式互斥锁（mutex key） 1. 思路简单2. 保证一致性 1. 代码复杂度增大2. 存在死锁的风险3. 存在线程池阻塞的风险 “提前”使用互斥锁 保证一致性 同上 不过期(本文) 异步构建缓存，不会阻塞线程池 1.不保证一致性。2. 代码复杂度增大(每个value都要维护一个timekey)。3. 占用一定的内存空间(每个value都要维护一个timekey)。 资源隔离组件hystrix(本文) 1.hystrix技术成熟，有效保证后端。2. hystrix监控强大。 部分访问存在降级策略。 怎么理解微服务，服务如何划分，可以从哪几个方面去划分，为什么这样划分，微服务带来了哪些好处，哪些坏处，如何看待这个问题？优点 1:提升开发交流，每个服务足够内聚，足够小，代码容易理解； 2:服务独立测试、部署、升级、发布； 3:按需定制的DFX，资源利用率，每个服务可以各自进行x扩展和z扩展，而且，每个服务可以根据自己的需要部署到合适的硬件服务器上；每个服务按4:需要选择HA的模式，选择接受服务的实例个数； 5:容易扩大开发团队，可以针对每个服务（service）组件开发团队； 6:提高容错性（fault isolation），一个服务的内存泄露并不会让整个系统瘫痪； 7:新技术的应用，系统不会被长期限制在某个技术栈上； 缺点 没有银弹，微服务提高了系统的复杂度；开发人员要处理分布式系统的复杂性；服务之间的分布式通信问题；服务的注册与发现问题；服务之间的分布式事务问题；数据隔离再来的报表处理问题；服务之间的分布式一致性问题；服务管理的复杂性，服务的编排；不同服务实例的管理。 Chris Richardson提出的微服务的三维扩展模型： X轴，服务实例水平扩展，保证可靠性与性能； Y轴，功能的扩展，服务单一职责，功能独立； Z轴，数据分区，数据独立，可靠性保证； 拆分例子姿势一新浪微博微服务专家胡忠想从纵横两个维度来划分，简单粗暴： 1.1 纵向拆分 从业务维度进行拆分。标准是按照业务的关联程度来决定，关联比较密切的业务适合拆分为一个微服务，而功能相对比较独立的业务适合单独拆分为一个微服务。 1.2 横向拆分 从公共且独立功能维度拆分。标准是按照是否有公共的被多个其他服务调用，且依赖的资源独立不与其他业务耦合。 纵向以业务为基准，关系铁的在一起；横向功能独立的在一起。我想如果拆分这么简单，你有底气拆，敢拆吗？所以我们又继续比对一下其他专家的言论。 姿势二阿里的小伙伴从综合的维度来看，部分维度和上面会有重合。 2.1 服务拆分要迎合业务的需要 充分考虑业务独立性和专业性，避免以团队来定义服务边界，从而出现“土匪”抢地盘，影响团队信任。 这个维度和上面的类似，但是强调的是业务和团队成员的各自独立性，对上面是一种很好的补充。 2.2 拆分后的维护成本要低于拆分前 这里的维护成本包括：人力、物力、时间。 这里的成本对大部分中小团队来说都是必须要考虑的重要环节，如果投入和收益不能成正比，或者超出领导的预算或者市场窗口，那么先进的技术就是绊脚石，千万不要迷恋技术，所谓工程师思维千万要不得。 2.3 拆分不仅仅是架构的调整，组织结构上也要做响应的适应性优化 确保拆分后的服务由相对独立的团队负责维护。 这句话怎么理解呢？传统的团队划分是按照产品部、前端、后端横向划分，微服务化以后的团队可能就会是吃一张披萨饼的人数，产品、前端、后端被归类到服务里面，以服务为中心来分配人数。 2.4 拆分最有价值的结果是提高了系统的可扩展性 把具有不同扩展性要求的服务拆分出来，分别进行部署，降低成本，提高效率。比如全文搜索服务。 这点和上面的按功能独立性来拆分有点类似，功能独立其实就是面向可扩展性。 2.5 考虑软件发布频率 比如把20%经常变动的部分进行抽离，80%不经常变动的单独部署和管理。说白了就是按照8/2原则进行拆分。这个拆分的好处很明显，可以尽可能的减少发布产生的后遗症，比如用户体验、服务相互干扰等。 但是这里有一个问题，假如20%的服务分属于不同的业务层面，那该怎么办？所以这里的拆分应该有个优先级，在拆分相互冲突的时候应该要优先考虑权重比较高的那个。 姿势三资深技术专家李运华在他的架构书中给出的拆分： 3.1 基于业务逻辑 将系统中的业务按照职责范围进行识别，职责相同的划分为一个单独的服务。这种业务优先的方式在前面两种姿势当中都出现过，可见是最基本，最重要的划分方式（没有之一）。 3.2 基于稳定性 将系统中的业务模块按照稳定性进行排序。稳定的、不经常修改的划分一块；将不稳定的，经常修改的划分为一个独立服务。比如日志服务、监控服务都是相对稳定的服务，可以归到一起。这个很类似上面提到的2/8原则，80%的业务是稳定的。 至此你会发现服务的拆分真的没有绝对的标准，只有合理才是标准。 3.3 基于可靠性 同样，将系统中的业务模块按照可靠性进行排序。对可靠性要求比较高的核心模块归在一起，对可靠性要求不高的非核心模块归在一块。 这种拆分的高明可以很好的规避因为一颗老鼠屎坏了一锅粥的单体弊端，同时将来要做高可用方案也能很好的节省机器或带宽的成本。 3.4 基于高性能 同上，将系统中的业务模块按照对性能的要求进行优先级排序。把对性能要求较高的模块独立成一个服务，对性能要求不高的放在一起。比如全文搜索，商品查询和分类，秒杀就属于高性能的核心模块。 如何理解网关，网关带来的好处和坏处，如何解决API网关我的分析中会用到以下三种场景。 Open API。企业需要将自身数据、能力等作为开发平台向外开放，通常会以rest的方式向外提供，最好的例子就是淘宝开放平台、腾讯公司的QQ开放平台、微信开放平台。 Open API开放平台必然涉及到客户应用的接入、API权限的管理、调用次数管理等，必然会有一个统一的入口进行管理，这正是API网关可以发挥作用的时候。 微服务网关。微服务的概念最早在2012年提出，在Martin Fowler的大力推广下，微服务在2014年后得到了大力发展。 在微服务架构中，有一个组件可以说是必不可少的，那就是微服务网关，微服务网关处理了负载均衡，缓存，路由，访问控制，服务代理，监控，日志等。API网关在微服务架构中正是以微服务网关的身份存在。 API服务管理平台。上述的微服务架构对企业来说有可能实施上是困难的，企业有很多遗留系统，要全部抽取为微服务器改动太大，对企业来说成本太高。但是由于不同系统间存在大量的API服务互相调用，因此需要对系统间服务调用进行管理，清晰地看到各系统调用关系，对系统间调用进行监控等。 API网关可以解决这些问题，我们可以认为如果没有大规模的实施微服务架构，那么对企业来说微服务网关就是企业的API服务管理平台。 一个企业随着信息系统复杂度的提高，必然出现外部合作伙伴应用、企业自身的公网应用、企业内网应用等，在架构上应该将这三种应用区别开，三种应用的安排级别、访问方式也不一样。 因此在我的设计中将这三种应用分别用不同的网关进行API管理，分别是：API网关（OpenAPI合伙伙伴应用）、API网关（内部应用）、API网关（内部公网应用）。 对于OpenAPI使用的API网关来说，一般合作伙伴要以应用的形式接入到OpenAPI平台，合作伙伴需要到 OpenAPI平台申请应用。 因此在OpenAPI网关之外，需要有一个面向合作伙伴的使用的平台用于合作伙伴，这就要求OpenAPI网关需要提供API给这个用户平台进行访问。 如下架构: 对于内网的API网关，在起到的作用上来说可以认为是微服务网关，也可以认为是内网的API服务治理平台。 当企业将所有的应用使用微服务的架构管理起来，那么API网关就起到了微服务网关的作用。 而当企业只是将系统与系统之间的调用使用rest api的方式进行访问时使用API网关对调用进行管理，那么API网关起到的就是API服务治理的作用。 对于公司内部公网应用（如APP、公司的网站），如果管理上比较细致，在架构上是可能由独立的API网关来处理这部分内部公网应用，如果想比较简单的处理，也可以是使用面向合作伙伴的API网关。 如果使用独立的API网关，有以下的好处： 面向合作伙伴和面向公司主体业务的优先级不一样，不同的API网关可以做到业务影响的隔离。 内部API使用的管理流程和面向合作伙伴的管理流程可能不一样。 内部的API在功能扩展等方面的需求一般会大于OpenAPI对于功能的要求。基于以上的分析，如果公司有能力，那么还是建议分开使用合作伙伴OPEN API网关和内部公网应用网关 API网关有哪些竞争方案1、对于Open API平台的API网关，我分析只能选择API网关作为解决方案，业界没有发现比较好的可以用来作为Open API平台的入口的其他方案。 2、对于作为微服务网关的API网关，业界的选择可以选择的解决方案比较多，也取决于微服务器的实现方案，有一些微服务架构的实现方案是不需要微服务网关的。 Service Mesh，这是新兴的基于无API网关的架构，通过在客户端上的代理完成屏蔽网络层的访问，这样达到对应用层最小的改动，当前Service Mesh的产品还正在开发中，并没有非常成熟可直接应用的产品。 发展最迅速的产品是Istio。 建议大家密切关注相关产品的研发、业务使用进展。 基于duboo架构，在这个架构中通常是不需要网关的，是由客户端直接访问服务提供方，由注册中心向客户端返回服务方的地址。 API网关解决方案私有云开源解决方案如下： Kong kong是基于Nginx+Lua进行二次开发的方案， https://konghq.com/ Netflix Zuul，zuul是spring cloud的一个推荐组件，https://github.com/Netflix/zuul orange,这个开源程序是国人开发的， http://orange.sumory.com/ 公有云解决方案： Amazon API Gateway，https://aws.amazon.com/cn/api-gateway/ 阿里云API网关，https://www.aliyun.com/product/apigateway/ 腾讯云API网关， https://cloud.tencent.com/product/apigateway 自开发解决方案： 基于Nginx+Lua+ OpenResty的方案，可以看到Kong,orange都是基于这个方案 基于Netty、非阻塞IO模型。 通过网上搜索可以看到国内的宜人贷等一些公司是基于这种方案，是一种成熟的方案。 基于Node.js的方案。 这种方案是应用了Node.js天生的非阻塞的特性。 基于java Servlet的方案。 zuul基于的就是这种方案，这种方案的效率不高，这也是zuul总是被诟病的原因。 怎么选择API网关如果是要选择一款已有的API网关，那么需要从以下几个方面去考虑。 1、性能与可用性如果一旦采用了API网关，那么API网关就会作为企业应用核心，因此性能和可用性是必须要求的。 从性能上来说，需要让网关增加的时间消耗越短越好，个人觉得需要10ms以下。 系统需要采用非阻塞的IO，如epoll，NIO等。网关和各种依赖的交互也需要是非阻塞的，这样才能保证整体系统的高可用性，如：Node.js的响应式编程和基于java体现的RxJava和Future。网关必须支持集群部署，任务一台服务器的crash都应该不影响整体系统的可用性。 多套网关应该支持同一管理平台和同一监控中心。 如： 一个企业的OpenAPI网关和内部应用的多个系统群的不同的微服务网关可以在同一监控中心进行监控。 2、可扩展性、可维护性 一款产品总有不能满足生产需求的地方，因此需求思考产品在如何进行二次开发和维护，是否方便公司团队接手维护产品。 3、需求匹配度 需要评估各API网关在需求上是否能满足，如： 如果是OpenAPI平台需要使用API网关，那么需要看API网关在合作伙伴应用接入、合作伙伴门户集成、访问次数限额等OpenAPI核心需求上去思考产品是否能满足要求。 如果是微服务网关，那么要从微服务的运维、监控、管理等方面去思考产品是否足够强大。 4、是否开源？公司是否有自开发的能力？ 现有的开源产品如kong，zuul，orange都有基础的API网关的核心功能，这些开源产品大多离很好的使用有一定的距离，如：没有提供管理功能的UI界面、监控功能弱小，不支持OpenAPI平台，没有公司运营与运维的功能等。 当然开源产品能获取源代码，如果公司有比较强的研发能力，能hold住这些开源产品，经过二次开发kong、zuul应该还是适应一些公司，不过需求注意以下一些点： kong是基于ngnix+lua的，从公司的角度比较难于找到能去维护这种架构产品的人。 需求评估当前公司是否有这个能力去维护这个产品。 zuul因为架构的原因在高并发的情况下性能不高，同时需要去基于研究整合开源的适配zuul的监控和管理系统。orange由于没有被大量使用，同时是国内个人在开源，在可持续性和社区资源上不够丰富，出了问题后可能不容易找到人问。另外kong提供企业版本的API网关，当然也是基于ngnix+lua的，企业版本可以购买他们的技术支持、培训等服务、以及拥有界面的管理、监控等功能。 5、公有云还是私有云 现在的亚马逊、阿里、腾讯云都在提供基础公有云的API网关，当然这些网关的基础功能肯定是没有问题，但是二次开发，扩展功能、监控功能可能就不能满足部分用户的定制需求了。另外很多企业因为自身信息安全的原因，不能使用外网公有网的API网关服务，这样就只有选择私有云的方案了。在需求上如果基于公有云的API网关只能做到由内部人员为外网人员申请应用，无法做到定制的合作伙伴门户，这也不适合于部分企业的需求。如果作为微服务网关，大多数情况下是希望网关服务器和服务提供方服务器是要在内网的，在这里情况下也只有私有云的API网关才能满足需求。 综合上面的分析，基础公有云的API网关只有满足一部分简单客户的需求，对于很多企业来说私有云的API网关才是正确的选择。 项目中如何保证接口的幂等操作 调用者给消息一个唯一请求ID标识。ID标识一个工作单元，这个工作单元只应执行一次，工作单元ID可以是Schema的一部分，也可以是一个定制的SOAP Header，服务的Contract 可以说明这个唯一请求ID标识是必须的 接收者在执行一个工作单元必须先检验该工作单元是否已经执行过。检查是否执行的逻辑通常是根据唯一请求ID ，在服务端查询请求是否有记录，是否有对应的响应信息，如果有，直接把响应信息查询后返回；如果没有，那么就当做新请求去处理 遇到过线上服务器CPU飙高的情况没有，如何处理的？ 登录服务器，执行top命令，查看CPU占用情况（top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器，通过以上命令，我们可以看到，进程ID为1893的Java进程的CPU占用率达到了181%，基本可以定位到是我们的Java应用导致整个服务器的CPU占用率飙升） 123$topPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND1893 admin 20 0 7127m 2.6g 38m S 181.7 32.6 10:20.26 java Java是单进程多线程的，那么，我们接下来看看PID=1893的这个Java进程中的各个线程的CPU使用情况，同样是用top命令,通过top -Hp 1893命令，我们可以发现，当前1893这个进程中，ID为4519的线程占用CPU最高。 123$top -Hp 1893PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND4519 admin 20 0 7127m 2.6g 38m R 18.6 32.6 0:40.11 java 通过top命令，我们目前已经定位到导致CPU使用率较高的具体线程， 那么我么接下来就定位下到底是哪一行代码存在问题。首先，我们需要把4519这个线程转成16进制 12$printf %x 451911a7 接下来，通过jstack命令，查看栈信息(通过以上代码，我们可以清楚的看到，BeanValidator.java的第30行是有可能存在问题的)： 123456789101112131415161718$sudo -u admin jstack 1893 |grep -A 200 11a7"HSFBizProcessor-DEFAULT-8-thread-5" #500 daemon prio=10 os_prio=0 tid=0x00007f632314a800 nid=0x11a2 runnable [0x000000005442a000] java.lang.Thread.State: RUNNABLE at sun.misc.URLClassPath$Loader.findResource(URLClassPath.java:684) at sun.misc.URLClassPath.findResource(URLClassPath.java:188) at java.net.URLClassLoader$2.run(URLClassLoader.java:569) at java.net.URLClassLoader$2.run(URLClassLoader.java:567) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findResource(URLClassLoader.java:566) at java.lang.ClassLoader.getResource(ClassLoader.java:1093) at java.net.URLClassLoader.getResourceAsStream(URLClassLoader.java:232) at org.hibernate.validator.internal.xml.ValidationXmlParser.getInputStreamForPath(ValidationXmlParser.java:248) at org.hibernate.validator.internal.xml.ValidationXmlParser.getValidationConfig(ValidationXmlParser.java:191) at org.hibernate.validator.internal.xml.ValidationXmlParser.parseValidationXml(ValidationXmlParser.java:65) at org.hibernate.validator.internal.engine.ConfigurationImpl.parseValidationXml(ConfigurationImpl.java:287) at org.hibernate.validator.internal.engine.ConfigurationImpl.buildValidatorFactory(ConfigurationImpl.java:174) at javax.validation.Validation.buildDefaultValidatorFactory(Validation.java:111) at com.test.common.util.BeanValidator.validate(BeanValidator.java:30) 线上问题排查还可以使用Alibaba开源的工具Arthas进行排查，以上问题，可以使用一下命令定位thread -n 3。 如果线上一个功能是用栈结构实现的，使用过程中要注意哪些问题，为什么？ stack栈：是自动分配变量，以及函数调用的时候所使用的一些空间。地址是由高向低减少的。由编译器自动分配内存空间，代码结束，自动释放内存空间。它的内部结构是一个容器式，只有一个进口，并且也作为出口。这就是导致，先进来的数据在“容器”底部，后进来的数据在“容器顶部”，出栈的时候，就应验了“后进先出，先进后出”的这句话。 对于栈来说，理论上线性表的操作特性它都具备，可由于它的特殊性，所以针对它的操作上会有些变化。特别是插入和删除操作，我们改名为push和pop，进栈和出栈。 主要用途：函数调用和返回，数字转字符，表达式求值，走迷宫等等。只要数据的保存满足先进后出的原理，都优先考虑使用栈，所以栈是计算机中不可缺的机制。 建立Stack数组时需要为每一个Stack元素初始化一个对象分布式锁的实现、对比Redis分布式锁 &amp; ZK分布式锁 redis分布式锁 简单算法：是redis官方支持的分布式锁算法。这个分布式锁有3个重要的考量点，互斥（只能有一个客户端获取锁），不能死锁，容错（大部分redis节点或者这个锁就可以加可以释放），第一个最普通的实现方式，如果就是在redis里创建一个key算加锁。SET my:lock 随机值 NX PX 30000，这个命令就ok，这个的NX的意思就是只有key不存在的时候才会设置成功，PX 30000的意思是30秒后锁自动释放。别人创建的时候如果发现已经有了就不能加锁了。为啥要用随机值呢？因为如果某个客户端获取到了锁，但是阻塞了很长时间才执行完，此时可能已经自动释放锁了，此时可能别的客户端已经获取到了这个锁，要是你这个时候直接删除key的话会有问题，所以得用随机值加上面的lua脚本来释放锁。但是这样是肯定不行的。因为如果是普通的redis单实例，那就是单点故障。或者是redis普通主从，那redis主从异步复制，如果主节点挂了，key还没同步到从节点，此时从节点切换为主节点，别人就会拿到锁。 RedLock算法：这个场景是假设有一个redis cluster，有5个redis master实例。然后执行如下步骤获取一把锁1. 获取当前时间戳，单位是毫秒； 2. 跟上面类似，轮流尝试在每个master节点上创建锁，过期时间较短，一般就几十毫秒； 3. 尝试在大多数节点上建立一个锁，比如5个节点就要求是3个节点（n / 2 +1）； 4. 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了； 5. 要是锁建立失败了，那么就依次删除这个锁； 6. 只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。 zk分布式锁 zk分布式锁，其实可以做的比较简单，就是某个节点尝试创建临时znode，此时创建成功了就获取了这个锁；这个时候别的客户端来创建锁会失败，只能注册个监听器监听这个锁。释放锁就是删除这个znode，一旦释放掉就会通知客户端，然后有一个等待着的客户端就可以再次重新枷锁。 redis分布式锁和zk分布式锁的对比：redis分布式锁，其实需要自己不断去尝试获取锁，比较消耗性能；zk分布式锁，获取不到锁，注册个监听器即可，不需要不断主动尝试获取锁，性能开销较小。另外一点就是，如果是redis获取锁的那个客户端bug了或者挂了，那么只能等待超时时间之后才能释放锁；而zk的话，因为创建的是临时znode，只要客户端挂了，znode就没了，此时就自动释放锁。redis分布式锁大家每发现好麻烦吗？遍历上锁，计算时间等等。zk的分布式锁语义清晰实现简单。所以先不分析太多的东西，就说这两点，我个人实践认为zk的分布式锁比redis的分布式锁牢靠、而且模型简单易用。 项目中系统监控怎么做的 集中式日志系统 Elasticsearch Logstash Kibana Beats 集中式度量系统 Prometheus Cat 分布式追踪系统 Zipkin Pinpoint Skywalking Jaeger 如何实现的，Snowflake实现原理，Snowflake有哪些问题，如何避免根据订单号可以推算出今天的订单量 正数位（占1比特）+时间戳（占41比特）+机械id（占5比特）+数据中心（占5比特）+自增值（占12比特），总共64比特组成的一个Long类型。 时间戳（占41个比特）：毫秒数，大约可以使使用69年 机械id（占5个比特）：即2的5次方等于32个机器 数据中心id（占5个比特）：即2的5次方等于32个数据中心 自增值（占12比特）：2的12次方等于4096。也就是说每毫秒最多可以生成4096个id，如果cpu生产id的速度大于每毫秒4096个，那么需要使线程进行等待到下一毫秒，重新计数获取自增值。 好处 生成的id是一个数字的Long类型 无需链接数据库或者redis，超高性能 弊端 每毫秒只能生成4096个id。随着cpu不断的进步，每毫秒4096个id将不能满足。可以不用担心，即便cpu性能超过了这个值，那么只需等待到下一个毫秒 只能使用69年 每毫秒重新计数，空闲时间会浪费很多id空间 系统时间不可回退，回退将会导致id重复。另：系统时间可以前进，不受影响 如何设计一个秒杀系统？ 同样是高并发场景，三类业务的架构挑战不一样 QQ类业务，用户主要读写自己的数据，访问基本带有uid属性，数据访问锁冲突较小 微博类业务，用户的feed主页由别人发布的消息构成，数据读写有一定锁冲突 12306类业务，并发量很高，几乎所有的读写锁冲突都集中在少量数据上，难度最大 将请求尽量拦截在系统上游，而不要让锁冲突落到数据库。传统秒杀系统之所以挂，是因为请求都压到了后端数据层，数据读写锁冲突严重，并发高响应慢，几乎所有请求都超时，访问流量大，下单成功的有效流量小。一趟火车2000张票，200w个人同时来买，没有人能买成功，请求有效率为0。画外音：此时系统的效率，还不如线下售票窗口。 充分利用缓存,秒杀买票，这是一个典型的读多写少的业务场景： 车次查询，读，量大 余票查询，读，量大 下单和支付，写，量小一趟火车2000张票，200w个人同时来买，最多2000个人下单成功，其他人都是查询库存，写比例只有0.1%，读比例占99.9%，非常适合使用缓存来优化。 秒杀业务，常见的系统分层架构 秒杀业务，可以使用典型的服务化分层架构 端（浏览器/APP），最上层，面向用户 JS层面，可以限制用户在x秒之内只能提交一次请求，从而降低系统负载。 APP层面，可以做类似的事情，虽然用户疯狂的在摇微信抢红包，但其实x秒才向后端发起一次请求。 不过，端上的拦截只能挡住普通用户（99%的用户是普通用户），程序员firebug一抓包，写个for循环直接调用后端http接口，js拦截根本不起作用，这下怎么办？ 站点层，访问后端数据，拼装html/json返回，如何抗住程序员写for循环调用http接口，首先要确定用户的唯一标识，对于频繁访问的用户予以拦截。 购票类业务都需要登录，用uid就能标识用户，在站点层，对同一个uid的请求进行计数和限速，例如：一个uid，5秒只准透过1个请求，这样又能拦住99%的for循环请求。 一个uid，5s只透过一个请求，其余的请求怎么办，缓存，页面缓存，5秒内到达站点层的其他请求，均返回上次返回的页面。 OK，通过计数、限速、页面缓存拦住了99%的普通程序员，但仍有些高端程序员，例如黑客，控制了10w个肉鸡，手里有10w个uid，同时发请求，这下怎么办 服务层的请求拦截 服务层非常清楚业务的库存，非常清楚数据库的抗压能力，可以根据这两者进行削峰限速。例如，业务服务很清楚的知道，一列火车只有2000张车票，此时透传10w个请求去数据库，是没有意义的。用什么削峰？请求队，对于写请求，做请求队列，每次只透传有限的写请求去数据层（下订单，支付这样的写业务）。只有2000张火车票，即使10w个请求过来，也只透传2000个去访问数据库： 如果前一批请求均成功，再放下一批 如果前一批请求库存已经不足，则后续请求全部返回“已售罄” 对于读请求，怎么优化？cache抗，不管是memcached还是redis，单机抗个每秒10w应该都是没什么问题的。如此削峰限流，只有非常少的写请求，和非常少的读缓存mis的请求会透到数据层去，又有99%的请求被拦住了。 数据库层,经过前三层的优化： 浏览器拦截了80%请求 站点层拦截了99%请求，并做了页面缓存 服务层根据业务库存，以及数据库抗压能力，做了写请求队列与数据缓存 你会发现，每次透到数据库层的请求都是可控的。db基本就没什么压力了，闲庭信步。此时，透2000个到数据库，全部成功，请求有效率100%。 按照上面的优化方案，其实压力最大的反而是站点层，假设真实有效的请求数是每秒100w，这部分的压力怎么处理？ 站点层水平扩展，通过加机器扩容，一台抗5000，200台搞定； 服务降级，抛弃请求，例如抛弃50%； 原则是要保护系统，不能让所有用户都失败。 站点层限速，是个每个uid的请求计数放到redis里么？吞吐量很大情况下，高并发访问redis，网络带宽会不会成为瓶颈？ 同一个uid计数与限速，如果担心访问redis带宽成为瓶颈，可以这么优化 计数直接放在内存，这样就省去了网络请求； 在nginx层做7层均衡，让一个uid的请求落到同一个机器上； 除了系统上的优化，产品与业务还能够做一些折衷，降低架构难度。 业务折衷一,一般来说，下单和支付放在同一个流程里，能够提高转化率。对于秒杀场景，产品上，下单流程和支付流程异步，放在两个环节里，能够降低数据库写压力。以12306为例，下单成功后，系统占住库存，45分钟之内支付即可。 业务折衷二,一般来说，所有用户规则相同，体验会更好。对于秒杀场景，产品上，不同地域分时售票，虽然不是所有用户规则相同，但能够极大降低系统压力。北京9:00开始售票，上海9:30开始售票，广州XX开始售票，能够分担系统压力。 业务折衷三,秒杀场景，由于短时间内并发较大，系统返回较慢，用户心情十分焦急，可能会频繁点击按钮，对系统造成压力。产品上可以优化为，一旦点击，不管系统是否返回，按钮立刻置灰，不给用户机会频繁点击。 业务折衷四,一般来说，显示具体的库存数量，能够加强用户体验。对于秒杀场景，产品上，只显示有/无车票，而不是显示具体票数目，能够降低缓存淘汰率。画外音：显示库存会淘汰N次，显示有无只会淘汰1次。更多的，用户关注是否有票，而不是票有几张。 总结,对于秒杀系统，除了产品和业务上的折衷，架构设计上主要有两大优化方向 尽量将请求拦截在系统上游； 读多写少用缓存； 如果我现在就是要实现每秒10w请求，不能熔断限流，如何去设计？ Cache住所有查询，两层cache：除了使用ckv做全量缓存，还在数据访问层dao中增加本机内存cache做二级缓存，cache住所有读请求。查询失败或者查询不存在时，降级内存cache；内存cache查询失败或记录不存在时降级DB。DB本身不做读写分离。 DB写同步cache，容忍少量不一致。DB写操作完成后，dao中同步内存cache，业务服务层同步ckv，失败由异步队列补偿，定时的ckv与DB备机对账，保证最终数据一致。 服务A调用服务B中一个接口，服务B调用服务C中一个接口，如何实现若服务B响应服务A成功，则服务C一定响应服务B成功，需要考虑系统性能问题？欢迎补充。。。。。 一致性hash一致性哈希（Consistent hashing）算法是由 MIT 的Karger 等人与1997年在一篇学术论文（《Consistent hashing and random trees: distributed caching protocols for relieving hot spots on the World Wide Web》）中提出来的，用于解决分布式缓存数据分布问题。在传统的哈希算法下，每条缓存数据落在那个节点是通过哈希算法和服务器节点数量计算出来的，一旦服务器节点数量发生增加或者介绍，哈希值需要重新计算，此时几乎所有的数据和服务器节点的对应关系也会随之发生变化，进而会造成绝大多数缓存的失效。一致性哈希算法通过环形结构和虚拟节点的概念，确保了在缓存服务器节点数量发生变化时大部分数据保持原地不动，从而大幅提高了缓存的有效性。下面我们通过例子来解释一致性哈希的原理。 比如有 n 个节点，对于缓存 数据（k，v）具体存在哪个节点往往 hash(k) % n 来计算处理，举一个例子如下表所示，一共有个3个节点，hash函数采用 md5 。 缓存key hash(k) % n 服务器节点 user_nick_rommel 1 192.168.56.101 user_nick_pandy 0 192.168.56.100 user_nick_sam 2 192.168.56.102 Md5 的计算结果一般是一串32位的16进制字符串，做取模运算时原始数字较长，实际使用时，可以只截取最后4位或者8位使用，因为hash函数具有随机性，当数据量足球大时，截取部分数据也能保证数据的均匀分布。比如 md5(‘user_nick_rommel’)，对应字符串为 29e4fd2a0f05bd63343ae2276ca5038e，取最后4位 038e 转成10进制整数在进行取模运算，038e 对应的10进制数为 910，取模计算得 1 (9102 % 3 = 1)。 如果此时对缓存服务器进行扩容，添加一个新节点如 192.168.56.103，那么按照上面的计算方式，n 变为4， 得到的结果如下： 缓存key hash(k) % n 服务器节点 user_nick_rommel 2 192.168.56.102 user_nick_pandy 2 192.168.56.102 user_nick_sam 3 192.168.56.103 从结果中可见，缓存对应关系完全发生改变，比如 user_nick_rommel 这个可以，添加节点钱可以从 192.168.56.101 中读到，添加节点后却读不到了，。一般缓存失效时应用程序都会重新从后端服务加载数据（比如数据库），以这种这种方式分配缓存，当缓节点数量发生改变时，会造成大面积的缓存失效，这回造成后端服务瞬间压力上升，压力过大会造成服务不可以用，如果服务出于关键节点，甚至还会引发雪崩效应（TODO）。 在实际应用中，缓存节点由于故障挂掉，或者空间不足而进行扩容，缓存节点的增减是比较常见的事情，但上面传统方式会使服务的不可靠，下面看下一致性哈希是如何解决这个问题的。 在一致性哈希算法中，首先将哈希空间映射到一个虚拟的环上，环上的数值分从 0 到 2^32-1（哈希值的范围），如下图： 在一致性哈希算法刚提出来的时候，32位系统还是主流，2^32-1 相当于最大Integer，现在的应用服务器普遍都是64位系统，在使用使用一致性哈希算法时可以根据实际情况适当变通，比如将哈希值空间放大到 2^64-1。 然后使用同样的哈希算法将缓存服务节点（通常通过服务器IP+端口作为节点的key）和数据键映射到环上的位置。再决定数据落在那台服务器上时，使用一致的方向（比如顺时针方向）沿环查找，遇到的第一个有效服务器就是缓存保存的地方，如图： 当有新的服务器节点加入时，按照同样的哈希算法将新节点映射到环上的某处位置，和新节点相邻的数据逆时针节点会进行迁移，其他节点保持不变。如下图，当新加入一台新服务器 192.168.56.104 时，user_nick_pandy 这条缓存数据的请求根据算法会落在192.168.56.104 这台及其上，其他节点不受任何影响。 另外，由于哈希计算的记过通常都比较随机，如果缓存服务器比较少的话，可能会出现数据分配冷热不均的问题，如下图所示，大部分数据都会存储在 node3 节点上。 为了解决这个问题，我们引入虚拟节点的概念，在实体服务器不增加的情况下，用多个虚拟节点替代原来的单个实体节点，一台服务服务器在环上就对应多个位置，这样可以让数据存储更加均匀，各服务器的负载页更加平衡，如图： 使用 Java 代码实现一致性哈希的例子如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.util.SortedMap;import java.util.TreeMap;import org.apache.commons.codec.digest.DigestUtils;public class ConsistentHashingTest &#123; // 真实缓存地址 private final String[] cacheServers = &#123; "192.168.56.101:11211", "192.168.56.102:11211", "192.168.56.103:11211" &#125;; // 保存虚拟节点 private final SortedMap&lt;Long, String&gt; nodes = new TreeMap&lt;Long, String&gt;(); // 每个虚拟节点的数量 private final int VIRTUAL_NODE_NUM = 3; public ConsistentHashingTest()&#123; //初始化 for(String eachServer : cacheServers) &#123; this.addNode(eachServer); &#125; &#125; // 创建虚拟节点 public void addNode(String nodeKey) &#123; //为每一个实体节点创建3个虚拟节点 for (int i = 0; i &lt; VIRTUAL_NODE_NUM; i++) &#123; long eachHashCode = this.hash(nodeKey + ":" + i); nodes.put(eachHashCode, nodeKey); &#125; &#125; // hash 函数 可以使用 md5, sha-1, sha-256 等 // 虽然 md5, sha-1 哈希算法在签名领域已经不再安全，但运算速度比较快，在非安全领域是可以使用的。 // DigestUtils 是来自于 apache 中的 org.apache.commons.codec.digest 中的工具类 private long hash(String key) &#123; Stringmd5key = DigestUtils.md5Hex(key); return Long.parseLong(md5key.substring(0, 15), 16) % ((long) Math.pow(2, 32)); &#125; //按照同一个方向寻找 public String getRealServer(String key) &#123; long hashCode = this.hash(key); SortedMap&lt;Long,String&gt; tailMap = nodes.tailMap(hashCode); long serverKey = tailMap.isEmpty() ? nodes.firstKey() : tailMap.firstKey(); return nodes.get(serverKey); &#125; public static void main(String[] args) &#123; ConsistentHashingTestt = new ConsistentHashingTest(); System.out.println(t.getRealServer("my-cache-key")); &#125;&#125; 另外，前文提到的（TODO 章节）Guava Cache 框架支持一致性哈希，实例代码如下：1234567891011//实体缓存服务器String[]cacheServers = &#123; "192.168.56.101:11211", "192.168.56.102:11211", "192.168.56.103:11211" &#125;;// 缓存数据的keyString key = "my-test-cache-key";// 计算缓存 key 对应的 hash 值，这里使用 MurmurHash 算法，MurmurHash 是一种高性能低碰撞的算法。此外，还支持 md5、sha1/sha256/sha512、orc32、adler32 等哈希算法。 HashCode hashCode = Hashing.murmur3_32().newHasher().putString(key, Charsets.UTF_8).hash();// 通过一致性哈希方式计算，缓存key对应的服务器主机是那一台，bucket 的范围在 0 ~ cacheServers.length -1int bucket = Hashing.consistentHash(hashCode, cacheServers.length); 多路复用的几种方式以及区别？ select的优缺点 优点 select的可移植性好，在某些unix下不支持poll。 select对超时值提供了很好的精度，精确到微秒，而poll式毫秒。 缺点 单个进程可监视的fd数量被限制，默认是1024。 需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。 对fd进行扫描时是线性扫描，fd剧增后，IO效率降低，每次调用都对fd进行线性扫描遍历，随着fd的增加会造成遍历速度慢的问题。 select函数超时参数在返回时也是未定义的，考虑到可移植性，每次超时之后进入下一个select之前都要重新设置超时参数。 poll的优缺点 优点 不要求计算最大文件描述符+1的大小。 应付大数量的文件描述符时比select要快。 没有最大连接数的限制是基于链表存储的。 缺点 大量的fd数组被整体复制于内核态和用户态之间，而不管这样的复制是不是有意义。 同select相同的是调用结束后需要轮询来获取就绪描述符。 epoll的优缺点（epoll详解） 支持一个进程打开大数目的socket描述符(FD) select 最不能忍受的是一个进程所打开的FD是有一定限制的，由FD_SETSIZE设置，默认值是2048。对于那些需要支持的上万连接数目的IM服务器来说显 然太少了。这时候你一是可以选择修改这个宏然后重新编译内核，不过资料也同时指出这样会带来网络效率的下降，二是可以选择多进程的解决方案(传统的 Apache方案)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完 美的方案。不过 epoll则没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。 IO效率不随FD数目增加而线性下降 传统的select/poll另一个致命弱点就是当你拥有一个很大的socket集合，不过由于网络延时，任一时间只有部分的socket是”活跃”的， 但是select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。但是epoll不存在这个问题，它只会对”活跃”的socket进行 操作—这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。那么，只有”活跃”的socket才会主动的去调用 callback函数，其他idle状态socket则不会，在这点上，epoll实现了一个”伪”AIO，因为这时候推动力在os内核。在一些 benchmark中，如果所有的socket基本上都是活跃的—比如一个高速LAN环境，epoll并不比select/poll有什么效率，相 反，如果过多使用epoll_ctl,效率相比还有稍微的下降。但是一旦使用idle connections模拟WAN环境,epoll的效率就远在select/poll之上了。 epoll工作的两种模式 EPOLL事件分发系统可以运转在两种模式下：边缘触发Edge Triggered (ET)、水平触发Level Triggered (LT)。 LT 是缺省的工作方式：同时支持block和no-block socket；在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表。 ET是高速工作方式：它只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述 符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知。 对于LT模式epoll_wait清空就绪链表之后会检查该文件描述符是哪一种模式，如果为LT模式，且必须该节点确实有事件未处理，那么就会把该节点重新放入到刚刚删除掉的且刚准备好的就绪链表，epoll_wait马上返回。而ET模式不会检查，只会调用一次，只通知就绪通知一次 。 epoll函数底层实现过程 首先epoll_create创建一个epoll文件描述符，底层同时创建一个红黑树，和一个就绪链表；红黑树存储所监控的文件描述符的节点数据，就绪链表存储就绪的文件描述符的节点数据；epoll_ctl将会添加新的描述符，首先判断是红黑树上是否有此文件描述符节点，如果有，则立即返回。如果没有， 则在树干上插入新的节点，并且告知内核注册回调函数。当接收到某个文件描述符过来数据时，那么内核将该节点插入到就绪链表里面。epoll_wait将会接收到消息，并且将数据拷贝到用户空间，清空链表。对于LT模式epoll_ctl清空就绪链表之后会检查该文件描述符是哪一种模式，如果为LT模式，且必须该节点确实有事件未处理，那么就会把该节点重新放入到刚刚删除掉的且刚准备好的就绪链表，epoll_wait马上返回。ET模式不会检查，只会调用一次]]></content>
      <categories>
        <category>项目</category>
      </categories>
      <tags>
        <tag>项目</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试分享(三).数据库相关]]></title>
    <url>%2F2019%2F06%2F01%2F%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB(%E4%B8%89).%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[数据库相关读过MyBatis源码没有？可以参考本文 聊一聊对分库分表的理解大众点评设计案例原大众点评的订单单表早就已经突破两百G，由于查询维度较多，即使加了两个从库，优化索引，仍然存在很多查询不理想的情况。去年大量抢购活动的开展，使数据库达到瓶颈，应用只能通过限速、异步队列等对其进行保护；业务需求层出不穷，原有的订单模型很难满足业务需求，但是基于原订单表的DDL又非常吃力，无法达到业务要求。随着这些问题越来越突出，订单数据库的切分就愈发急迫了。这次切分，我们的目标是未来十年内不需要担心订单容量的问题。先对订单库进行垂直切分，将原有的订单库分为基础订单库、订单流程库等。垂直切分缓解了原来单集群的压力，但是在抢购时依然捉襟见肘。原有的订单模型已经无法满足业务需求，于是我们设计了一套新的统一订单模型，为同时满足C端用户、B端商户、客服、运营等的需求，我们分别通过用户ID和商户ID进行切分，并通过PUMA（我们内部开发的MySQL binlog实时解析服务）同步到一个运营库。 切分策略 查询切分：将ID和库的Mapping关系记录在一个单独的库中。优点：ID和库的Mapping算法可以随意更改。缺点：引入额外的单点。 范围切分：比如按照时间区间或ID区间来切分。优点：单表大小可控，天然水平扩展。缺点：无法解决集中写入瓶颈的问题。 Hash切分：一般采用Mod来切分，下面着重讲一下Mod的策略。数据水平切分后我们希望是一劳永逸或者是易于水平扩展的，所以推荐采用mod 2^n这种一致性Hash。以统一订单库为例，我们分库分表的方案是32*32的，即通过UserId后四位mod 32分到32个库中，同时再将UserId后四位Div 32 Mod 32将每个库分为32个表，共计分为1024张表。线上部署情况为8个集群(主从)，每个集群4个库。为什么说这种方式是易于水平扩展的呢？我们分析如下两个场景。 场景一：数据库性能达到瓶颈 方法一：按照现有规则不变，可以直接扩展到32个数据库集群。 方法二：如果32个集群也无法满足需求，那么将分库分表规则调整为(322^n)(32⁄2^n)，可以达到最多1024个集群。 场景二：单表容量达到瓶颈（或者1024已经无法满足你） 方法：假如单表都已突破200G，2001024=200T（按照现有的订单模型算了算，大概一万千亿订单，相信这一天，嗯，指日可待！），没关系，32 (32 2^n)，这时分库规则不变，单库里的表再进行裂变，当然，在目前订单这种规则下（用userId后四位 mod）还是有极限的，因为只有四位，所以最多拆8192个表，至于为什么只取后四位，后面会有篇幅讲到。另外一个维度是通过ShopID进行切分，规则8 8和UserID比较类似，就不再赘述，需要注意的是Shop库我们仅存储了订单主表，用来满足Shop维度的查询。 唯一ID方案：这个方案也很多，主流的有那么几种: 利用数据库自增ID：优点：最简单。 缺点：单点风险、单机性能瓶颈。 利用数据库集群并设置相应的步长（Flickr方案）：优点：高可用、ID较简洁。 缺点：需要单独的数据库集群。 Twitter Snowflake：优点：高性能高可用、易拓展。 缺点：需要独立的集群以及ZK。 一大波GUID、Random算法：优点：简单。 缺点：生成ID较长，有重复几率。 我们的方案：为了减少运营成本并减少额外的风险我们排除了所有需要独立集群的方案，采用了带有业务属性的方案： &gt; 时间戳+用户标识码+随机数有下面几个好处： 方便、成本低。 基本无重复的可能。 自带分库规则，这里的用户标识码即为用户ID的后四位，在查询的场景下，只需要订单号就可以匹配到相应的库表而无需用户ID，只取四位是希望订单号尽可能的短一些，并且评估下来四位已经足够。 可排序，因为时间戳在最前面。 当然也有一些缺点，比如长度稍长，性能要比int/bigint的稍差等。 其他问题 事务支持：我们是将整个订单领域聚合体切分，维度一致，所以对聚合体的事务是支持的。 复杂查询：垂直切分后，就跟join说拜拜了；水平切分后，查询的条件一定要在切分的维度内，比如查询具体某个用户下的各位订单等；禁止不带切分的维度的查询，即使中间件可以支持这种查询，可以在内存中组装，但是这种需求往往不应该在 在线库查询，或者可以通过其他方法转换到切分的维度来实现。 数据迁移 数据库拆分一般是业务发展到一定规模后的优化和重构，为了支持业务快速上线，很难一开始就分库分表，垂直拆分还好办，改改数据源就搞定了，一旦开始水平拆分，数据清洗就是个大问题，为此，我们经历了以下几个阶段。 第一阶段 数据库双写（事务成功以老模型为准），查询走老模型。 每日job数据对账（通过DW），并将差异补平。 通过job导历史数据。 第二阶段 历史数据导入完毕并且数据对账无误。 依然是数据库双写，但是事务成功与否以新模型为准，在线查询切新模型。 每日job数据对账，将差异补平。 第三阶段 老模型不再同步写入，仅当订单有终态时才会异步补上。 此阶段只有离线数据依然依赖老的模型，并且下游的依赖非常多，待DW改造完就可以完全废除老模型了。 总结并非所有表都需要水平拆分，要看增长的类型和速度，水平拆分是大招，拆分后会增加开发的复杂度，不到万不得已不使用。在大规模并发的业务上，尽量做到在线查询和离线查询隔离，交易查询和运营/客服查询隔离。拆分维度的选择很重要，要尽可能在解决拆分前问题的基础上，便于开发。数据库没你想象的那么坚强，需要保护，尽量使用简单的、良好索引的查询，这样数据库整体可控，也易于长期容量规划以及水平扩展。 亿级数据下的分库分表方案分区分区表是由多个相关的底层表实现，这些底层表也是由句柄对象表示，所以我们也可以直接访问各个分区，存储引擎管理分区的各个底层表和管理普通表一样（所有的底层表都必须使用相同的存储引擎），分区表的索引只是在各个底层表上各自加上一个相同的索引，从存储引擎的角度来看，底层表和一个普通表没有任何不同，存储引擎也无须知道这是一个普通表还是一个分区表的一部分。这个方案也不错，它对用户屏蔽了sharding的细节，即使查询条件没有sharding column，它也能正常工作（只是这时候性能一般）。不过它的缺点很明显：很多的资源都受到单机的限制，例如连接数，网络吞吐等。如何进行分区，在实际应用中是一个非常关键的要素之一。在我们的项目中，以客户信息为例，客户数据量5000万加，项目背景要求保存客户的银行卡绑定关系，客户的证件绑定关系，以及客户绑定的业务信息。此业务背景下，该如何设计数据库呢。项目一期的时候，我们建立了一张客户业务绑定关系表，里面冗余了每一位客户绑定的业务信息。基本结构大致如下：查询时，对银行卡做索引，业务编号做索引，证件号做索引。随着需求大增多，这张表的索引会达到10个以上。而且客户解约再签约，里面会保存两条数据，只是绑定的状态不同。假设我们有5千万的客户，5个业务类型，每位客户平均2张卡，那么这张表的数据量将会达到惊人的5亿，事实上我们系统用户量还没有过百万时就已经不行了。mysql数据库中的数据是以文件的形势存在磁盘上的，默认放在/mysql/data下面（可以通过my.cnf中的datadir来查看）， 一张表主要对应着三个文件，一个是frm存放表结构的，一个是myd存放表数据的，一个是myi存表索引的。这三个文件都非常的庞大，尤其是.myd文件，快5个G了。 下面进行第一次分区优化 ，Mysql支持的分区方式有四种：在我们的项目中，range分区和list分区没有使用场景，如果基于绑定编号做range或者list分区，绑定编号没有实际的业务含义，无法通过它进行查询，因此，我们就剩下 HASH 分区和 KEY 分区了， HASH 分区仅支持int类型列的分区，且是其中的一列。看看我们的库表结构，发现没有哪一列是int类型的，如何做分区呢？可以增加一列，绑定时间列，将此列设置为int类型，然后按照绑定时间进行分区，将每一天绑定的用户分到同一个区里面去。这次优化之后，我们的插入快了许多，但是查询依然很慢，为什么，因为在做查询的时候，我们也只是根据银行卡或者证件号进行查询，并没有根据时间查询，相当于每次查询，mysql都会将所有的分区表查询一遍。 然后进行第二次方案优化，既然hash分区和key分区要求其中的一列必须是int类型的，那么创造出一个int类型的列出来分区是否可以。分析发现，银行卡的那串数字有秘密。银行卡一般是16位到19位不等的数字串，我们取其中的某一位拿出来作为表分区是否可行呢，通过分析发现，在这串数字中，其中确实有一位是0到9随机生成的，不同的卡串长度，这一位不同，绝不是最后一位，最后位数字一般都是校验位，不具有随机性。我们新设计的方案，基于银行卡号+随机位进行KEY分区，每次查询的时候，通过计算截取出这位随机位数字，再加上卡号，联合查询，达到了分区查询的目的，需要说明的是，分区后，建立的索引，也必须是分区列，否则的话，Mysql还是会在所有的分区表中查询数据。那么通过银行卡号查询绑定关系的问题解决了，那么证件号呢，如何通过证件号来查询绑定关系。前面已经讲过，做索引一定是要在分区健上进行，否则会引起全表扫描。我们再创建了一张新表，保存客户的证件号绑定关系，每位客户的证件号都是唯一的，新的证件号绑定关系表里，证件号作为了主键，那么如何来计算这个分区健呢，客户的证件信息比较庞杂，有身份证号，港澳台通行证，机动车驾驶证等等，如何在无序的证件号里找到分区健。为了解决这个问题，我们将证件号绑定关系表一分为二，其中的一张表专用于保存身份证类型的证件号，另一张表则保存其他证件类型的证件号，在身份证类型的证件绑定关系表中，我们将身份证号中的月数拆分出来作为了分区健，将同一个月出生的客户证件号保存在同一个区，这样分成了12个区，其他证件类型的证件号，数据量不超过10万，就没有必要进行分区了。这样每次查询时，首先通过证件类型确定要去查询哪张表，再计算分区健进行查询。 作了分区设计之后，保存2000万用户数据的时候，银行卡表的数据保存文件就分成了10个小文件，证件表的数据保存文件分成了12个小文件，解决了这两个查询的问题，还剩下一个问题就是，业务编号呢，怎么办，一个客户有多个签约业务，如何进行保存，这时候，采用分区的方案就不太合适了，它需要用到分表的方案。 分库分表如何进行分库分表，目前互联网上有许多的版本，比较知名的一些方案： 阿里的TDDL，DRDS和cobar 京东金融的sharding-jdbc 民间组织的MyCAT 360的Atlas 美团的zebra 其他比如网易，58，京东等公司都有自研的中间件。 百花齐放的景象。但是这么多的分库分表中间件方案，归总起来，就两类： client模式和proxy模式 。 client模式 和proxy模式 无论是client模式，还是proxy模式，几个核心的步骤是一样的：SQL解析，重写，路由，执行，结果归并。个人比较倾向于采用client模式，它架构简单，性能损耗也比较小，运维成本低。如果在项目中引入mycat或者cobar，他们的单机模式无法保证可靠性，一旦宕机则服务就变得不可用，你又不得不引入HAProxy来实现它的高可用集群部署方案， 为了解决HAProxy的高可用问题，又需要采用Keepalived来实现。 我们在项目中放弃了这个方案，采用了shardingjdbc的方式。回到刚才的业务问题，如何对业务类型进行分库分表。分库分表第一步也是最重要的一步，即sharding column的选取，sharding column选择的好坏将直接决定整个分库分表方案最终是否成功。而sharding column的选取跟业务强相关。在我们的项目场景中，sharding column无疑最好的选择是业务编号。通过业务编号，将客户不同的绑定签约业务保存到不同的表里面去，查询时，根据业务编号路由到相应的表中进行查询，达到进一步优化sql的目的。 前面我们讲到了基于客户签约绑定业务场景的数据库优化，下面我们再聊一聊，对于海量数据的保存方案。 垂直拆分垂直分表也就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将不常用的， 数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。 垂直分库垂直分库在“微服务”盛行的今天已经非常普及了。基本的思路就是按照业务模块来划分出不同的数据库，而不是像早期一样将所有的数据表都放到同一个数据库中。如下图： 优点 数据库往往最容易成为应用系统的瓶颈，而数据库本身属于“有状态”的，相对于 Web 和应用服务器来讲，是比较难实现“横向扩展”的。数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破 IO、连接数及单机硬件资源的瓶颈，是大型分布式系统中优化数据库架构的重要手段。 缺点 跨库 join 的问题 跨库事务（分布式事务）的问题 解决方式 全局表 所谓全局表，就是有可能系统中所有模块都可能会依赖到的一些表。比较类似我们理解的“数据字典”。为了避免跨库 join 查询，我们可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改（甚至几乎不会），所以也不用太担心“一致性”问题。 字段冗余 这是一种典型的反范式设计，在互联网行业中比较常见，通常是为了性能来避免 join 查询。 数据同步 定时 A 库中的 tab_a 表和 B 库中 tbl_b 有关联，可以定时将指定的表做同步。当然，同步本来会对数据库带来一定的影响，需要性能影响和数据时效性中取得一个平衡。这样来避免复杂的跨库查询。例如ETL工具。 系统层组装 在系统层面，通过调用不同模块的组件或者服务，获取到数据并进行字段拼装。说起来很容易，但实践起来可真没有这么简单，尤其是数据库设计上存在问题但又无法轻易调整的时候。 对于每分钟要处理近1000万的流水，每天流水近1亿的量，如何高效的写入和查询，是一项比较大的挑战。还是老办法，分库分表分区，读写分离，只不过这一次，我们先分表，再分库，最后分区。我们将消息流水按照不同的业务类型进行分表，相同业务的消息流水进入同一张表，分表完成之后，再进行分库。我们将流水相关的数据单独保存到一个库里面去，这些数据，写入要求高，查询和更新到要求低，将它们和那些更新频繁的数据区分开。分库之后，再进行分区。 这是基于业务垂直度进行的分库操作，垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库，以达到系统资源的饱和利用率。这样的分库方案结合应用的微服务治理，每个微服务系统使用独立的一个数据库。将不同模块的数据分库存储，模块间不能进行相互关联查询，如果有，要么通过数据冗余解决，要么通过应用代码进行二次加工进行解决。若不能杜绝跨库关联查询，则将小表到数据冗余到大数据量大库里去。假如，流水大表中查询需要关联获得渠道信息，渠道信息在基础管理库里面，那么，要么在查询时，代码里二次查询基础管理库中的渠道信息表，要么将渠道信息表冗余到流水大表中。 将每天过亿的流水数据分离出去之后，流水库中单表的数据量还是太庞大，我们将单张流水表继续分区，按照一定的业务规则，（一般是查询索引列）将单表进行分区，一个表编程N个表，当然这些变化对应用层是无法感知的。 分区表的设置，一般是以查询索引列进行分区，例如，对于流水表A，查询需要根据手机号和批次号进行查询，所以我们在创建分区的时候，就选择以手机号和批次号进行分区，这样设置后，查询都会走索引，每次查询Mysql都会根据查询条件计算出来，数据会落在那个分区里面，直接到对应的分区表中检索即可，避免了全表扫描。 对于每天流水过亿的数据，当然是要做历史表进行数据迁移的工作了。客户要求流水数据需要保存半年的时间，有的关键流水需要保存一年。删数据是不可能的了，也跑不了路，虽然当时非常有想删数据跑路的冲动。其实即使是删数据也是不太可能的了，delete的拙劣表演先淘汰了，truncate也快不了多少，我们采用了一种比较巧妙方法，具体步骤如下： 创建一个原表一模一样的临时表1 create table test_a_serial_1 like test_a_serial; 将原表命名为临时表2 alter table test_a_serial rename test_a_serial_{date}; 将临时表1改为原表 alter table able test_a_serial_1 rename able test_a_serial; 此时，当日流水表就是一张新的空表了，继续保存当日的流水，而临时表2则保存的是昨天的数据和部分今天的数据，临时表2到名字中的date时间是通过计算获得的昨日的日期；每天会产生一张带有昨日日期的临时表2，每个表内的数据大约是有1000万。 将当日表中的历史数据迁移到昨日流水表中去 这样的操作都是用的定时任务进行处理，定时任务触发一般会选择凌晨12点以后，这个操作即使是几秒内完成，也有可能会有几条数据落入到当日表中去。因此我们最后还需要将当日表内的历史流水数据插入到昨日表内； insert into test_a_serial_{date}(cloumn1,cloumn2….) select(cloumn1,cloumn2….) from test_a_serial where LEFT(create_time,8) &gt; CONCAT(date); commit; 如此，便完成了流水数据的迁移；根据业务需要，有些业务数据需要保存半年，超过半年的进行删除,在进行删除的时候，就可以根据表名中的_{date}筛选出大于半年的流水直接删表； 半年的时间，对于一个业务流水表大约就会有180多张表，每张表又有20个分区表，那么如何进实时计算统计行查询呢？由于我们的项目对于流水的查询实时性要求不是特别高，因此我们在做查询时，进行了根据查询时间区间段进行路由查询的做法。大致做法时，根据客户选择的时间区间段，带上查询条件，分别去时间区间段内的每一张表内查询，将查询结果保存到一张临时表内，然后，再去查询临时表获得最终的查询结果。 半年的时间，对于一个业务流水表大约就会有180多张表，每张表又有20个分区表，那么如何进行查询呢？由于我们的项目对于流水的查询实时性要求不是特别高，因此我们在做查询时，进行了根据查询时间区间段进行路由查询的做法。大致做法时，根据客户选择的时间区间段，带上查询条件，分别去时间区间段内的每一张表内查询，将查询结果保存到一张临时表内，然后，再去查询临时表获得最终的查询结果。 以上便是我们面对大数据量的场景下，数据库层面做的相应的优化，一张每天一亿的表，经过拆分后，每个表分区内的数据在500万左右。 水平拆分 水平分表 针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表里面去。 但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用。 某种意义上来讲，有些系统中使用的“冷热数据分离”（将一些使用较少的历史数据迁移到其他的数据库中。而在业务功能上，通常默认只提供热点数据的查询），也是类似的实践。在高并发和海量数据的场景下，分库分表能够有效缓解单机和单库的性能瓶颈和压力，突破 IO、连接数、硬件资源的瓶颈。当然，投入的硬件成本也会更高。同时，这也会带来一些复杂的技术问题和挑战（例如：跨分片的复杂查询，跨分片事务等）。 水平分库分表 将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。 水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。 水平分库分表切分规则 RANGE 从0到10000一个表，10001到20000一个表； HASH取模 一个商场系统，一般都是将用户，订单作为主表，然后将和它们相关的作为附表，这样不会造成跨库事务之类的问题。 取用户id，然后hash取模，分配到不同的数据库上。 地理区域 比如按照华东，华南，华北这样来区分业务，七牛云应该就是如此。 时间 按照时间切分，就是将6个月前，甚至一年前的数据切出去放到另外的一张表，因为随着时间流逝，这些表的数据 被查询的概率变小，所以没必要和“热数据”放在一起，这个也是“冷热数据分离”。 MySQL主从同步与主主同步MySQL复制 MySQL内建的复制功能是构建大型，高性能应用程序的基础。将MySQL的数据分布到多个系统上去，这种分布的机制，是通过将mysql的某一台主机的数据复制到其它主机（slave）上，并重新执行一遍来实现。 复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。主服务器将更新写入二进制日志文件，并维护文件的一个索引以跟踪日志循坏，这些日志可以记录发送到从服务器的更新。当一个从服务器 连接主服务器时，它通知主服务器从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，然后封锁并等待主服务器通知的更新。 需注意的是： 在进行mysql复制时，所有对复制中的表的更新必须在主服务器上进行。否则必须要小心，以避免用户对主服器上的表进行更新与对从服务器上的表所进行更新之间的冲突。 mysql支持哪些复制 a.基于语句的复制：在主服务器上执行的sql语句，在从服务器上执行同样的语句。mysql默认采用基于语句的复制，效率边角高。一旦发现没法精确复制时，会自动选着基于行的复制。 b.基于行的复制：把改变的内容复制过去，而不是把命令在从服务器上执行一遍。从mysql 5.0开始支持 c.混合类型的复制：默认采用基于语句的复制，一旦发现基于语句的无法精确复制时，就会采用基于行的复制。 mysql复制解决的问题a.数据分布（data distribution） b.负载平衡（load balancing） c.数据备份（backup），保证数据安全 d.高可用性与容错行（high availability and failover） e.实现读写分离，缓解数据库压力 mysql主从复制原理master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变， 如果发生改变，则开始一个I/O Thread请求master二进制事件，同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志 中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/O Thread和SQL Thread将进入睡眠状态，等待下一次被唤醒。 注意几点： 1–master将操作语句记录到binlog日志中，然后授予slave远程连接的权限（master一定要开启binlog二进制日志功能；通常为了数据安全考虑，slave也开启binlog功能）。 2–slave开启两个线程：IO线程和SQL线程。其中：IO线程负责读取master的binlog内容到中继日志relay log里；SQL线程负责从relay log日志里读出binlog内容，并更新到slave的数据库里，这样就能保证slave数据和 master数据保持一致了。 3–Mysql复制至少需要两个Mysql的服务，当然Mysql服务可以分布在不同的服务器上，也可以在一台服务器上启动多个服务。 4–Mysql复制最好确保master和slave服务器上的Mysql版本相同（如果不能满足版本一致，那么要保证master主节点的版本低于slave从节点的版本） 5–master和slave两节点间时间需同步 Mysql复制的流程图如下： 如上图所示： Mysql复制过程的第一部分就是master记录二进制日志。在每个事务更新数据完成之前，master在二日志记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。 第二部分就是slave将master的binary log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。 SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。 此外，在master中也有一个工作线程：和其它MySQL的连接一样，slave在master中打开一个连接也会使得master开始一个线程。复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。 mysql复制的模式 1–主从复制：主库授权从库远程连接，读取binlog日志并更新到本地数据库的过程；主库写数据后，从库会自动同步过来（从库跟着主库变）； 2–主主复制：主从相互授权连接，读取对方binlog日志并更新到本地数据库的过程；只要对方数据改变，自己就跟着改变； mysql主从复制优点 1–在从服务器可以执行查询工作(即我们常说的读功能)，降低主服务器压力;（主库写，从库读，降压） 2–在从主服务器进行备份，避免备份期间影响主服务器服务;（确保数据安全） 3–当主服务器出现问题时，可以切换到从服务器。（提升性能） mysql主从复制工作流程细节a. MySQL支持单向、异步复制，复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。MySQL复制基于主服务器在二进制日志中跟踪所有对数据库的更改(更新、删除等等)。因此，要进行复制，必须在主服务器上启用二进制日志。每个从服务器从主服务器接收主服务器上已经记录到其二进制日志的保存的更新。当一个从服务器连接主服务器时，它通知主服务器定位到从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，并在本机上执行相同的更新。然后封锁并等待主服务器通知新的更新。从服务器执行备份不会干扰主服务器，在备份过程中主服务器可以继续处理更新。 b. MySQL使用3个线程来执行复制功能，其中两个线程(Sql线程和IO线程)在从服务器，另外一个线程(IO线程)在主服务器。当发出START SLAVE时，从服务器创建一个I/O线程，以连接主服务器并让它发送记录在其二进制日志中的语句。主服务器创建一个线程将二进制日志中的内容发送到从服务器。该线程可以即为主服务器上SHOW PROCESSLIST的输出中的Binlog Dump线程。从服务器I/O线程读取主服务器Binlog Dump线程发送的内容并将该数据拷贝到从服务器数据目录中的本地文件中，即中继日志。第3个线程是SQL线程，由从服务器创建，用于读取中继日志并执行日志中包含的更新。在从服务器上，读取和执行更新语句被分成两个独立的任务。当从服务器启动时，其I/O线程可以很快地从主服务器索取所有二进制日志内容，即使SQL线程执行更新的远远滞后。 总结主从数据完成同步的过程： 1）在Slave 服务器上执行sartslave命令开启主从复制开关，开始进行主从复制。 2）此时，Slave服务器的IO线程会通过在master上已经授权的复制用户权限请求连接master服务器，并请求从执行binlog日志文件的指定位置（日志文件名和位置就是在配置主从复制服务时执行change master命令指定的）之后开始发送binlog日志内容 3）Master服务器接收到来自Slave服务器的IO线程的请求后，其上负责复制的IO线程会根据Slave服务器的IO线程请求的信息分批读取指定binlog日志文件指定位置之后的binlog日志信息，然后返回给Slave端的IO线程。返回的信息中除了binlog日志内容外，还有在Master服务器端记录的IO线程。返回的信息中除了binlog中的下一个指定更新位置。 4）当Slave服务器的IO线程获取到Master服务器上IO线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到Slave端自身的Relay Log（即中继日志）文件（Mysql-relay-bin.xxx）的最末端，并将新的binlog文件名和位置记录到master-info文件中，以便下一次读取master端新binlog日志时能告诉Master服务器从新binlog日志的指定文件及位置开始读取新的binlog日志内容 5）Slave服务器端的SQL线程会实时检测本地Relay Log 中IO线程新增的日志内容，然后及时把Relay LOG 文件中的内容解析成sql语句，并在自身Slave服务器上按解析SQL语句的位置顺序执行应用这样sql语句，并在relay-log.info中记录当前应用中继日志的文件名和位置点 主从复制条件1）开启Binlog功能 2）主库要建立账号 3）从库要配置master.info（CHANGE MASTER to…相当于配置密码文件和Master的相关信息） 4）start slave 开启复制功能 需要了解的1）3个线程，主库IO，从库IO和SQL及作用 2）master.info（从库）作用 3）relay-log 作用 4）异步复制 5）binlog作用（如果需要级联需要开启Binlog） 需要注意1）主从复制是异步的逻辑的SQL语句级的复制 2）复制时，主库有一个I/O线程，从库有两个线程，I/O和SQL线程 3）实现主从复制的必要条件是主库要开启记录binlog功能 4）作为复制的所有Mysql节点的server-id都不能相同 5）binlog文件只记录对数据库有更改的SQL语句（来自主库内容的变更），不记录任何查询（select，show）语句 彻底解除主从复制关系1)stop slave; 2)reset slave; 或直接删除master.info和relay-log.info这两个文件； 3)修改my.cnf删除主从相关配置参数。 让slave不随MySQL自动启动 修改my.cnf 在[mysqld]中增加 skip-slave-start 选项。 做了MySQL主从复制以后，使用mysqldump对数据备份时，一定要注意按照如下方式： mysqldump --master-data --single-transaction --user=username --password=password dbname&gt; dumpfilename 这样就可以保留 file 和 position 的信息，在新搭建一个slave的时候，还原完数据库， file 和 position 的信息也随之更新，接着再start slave 就可以很迅速 的完成增量同步！ 需要限定同步哪些数据库，有3个思路： 1）在执行grant授权的时候就限定数据库； 2）在主服务器上限定binlog_do_db = 数据库名； 3）主服务器上不限定数据库，在从服务器上限定replicate-do-db = 数据库名； 如果想实现 主-从（主）-从 这样的链条式结构，需要设置： log-slave-updates 只有加上它，从前一台机器上同步过来的数据才能同步到下一台机器。 当然，二进制日志也是必须开启的： log-bin=/opt/mysql/binlogs/bin-log log-bin-index=/opt/mysql/binlogs/bin-log.index 还可以设置一个log保存周期： expire_logs_days=14 下面记录下mysql主从／主主同步环境的实施过程环境描述1234567mysqlcentos 7.4master：192.168.0.103slave： 192.168.0.104 注意下面几点： 1）要保证同步服务期间之间的网络联通。即能相互ping通，能使用对方授权信息连接到对方数据库（防火墙开放3306端口）。 2）关闭selinux。 3）同步前，双方数据库中需要同步的数据要保持一致。这样，同步环境实现后，再次更新的数据就会如期同步了。 主从复制实现过程(1)设置master数据库的my.cnf文件（my.cnf 查找顺序 /etc/my.cnf ---&gt; $basedir/my.cnf,在[mysqld]配置区域添加下面内容） 12345678910[root@master ~]# vim /etc/my.cnf .......... [mysqld] server-id=1 #数据库唯一ID，主从的标识号绝对不能重复。log-bin=mysql-bin #开启bin-log，并指定文件目录和文件名前缀binlog-do-db=liting #需要同步liting数据库。如果是多个同步库，就以此格式另写几行即可。如果不指明对某个具体库同步，就去掉此行，表示同步所有库（除了ignore忽略的库）。binlog-ignore-db=mysql #不同步mysql系统数据库。如果是多个不同步库，就以此格式另写几行；也可以在一行，中间逗号隔开。sync_binlog = 1 ＃确保binlog日志写入后与硬盘同步binlog_checksum = none ＃跳过现有的采用checksum的事件，mysql5.6.5以后的版本中binlog_checksum=crc32,而低版本都是binlog_checksum=nonebinlog_format = mixed ＃bin-log日志文件格式，设置为MIXED可以防止主键重复。 温馨提示：在主服务器上最重要的二进制日志设置是sync_binlog，这使得mysql在每次提交事务的时候把二进制日志的内容同步到磁盘上，即使服务器崩溃也会把事件写入日志中。sync_binlog这个参数是对于MySQL系统来说是至关重要的，他不仅影响到Binlog对MySQL所带来的性能损耗，而且还影响到MySQL中数据的完整性。对于”sync_binlog”参数的各种设置的说明如下：sync_binlog=0，当事务提交之后，MySQL不做fsync之类的磁盘同步指令刷新binlog_cache中的信息到磁盘，而让Filesystem自行决定什么时候来做同步，或者cache满了之后才同步到磁盘。sync_binlog=n，当每进行n次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘。 在MySQL中系统默认的设置是sync_binlog=0，也就是不做任何强制性的磁盘刷新指令，这时候的性能是最好的，但是风险也是最大的。因为一旦系统Crash，在binlog_cache中的所有binlog信息都会被丢失。而当设置为“1”的时候，是最安全但是性能损耗最大的设置。因为当设置为1的时候，即使系统Crash，也最多丢失binlog_cache中未完成的一个事务，对实际数据没有任何实质性影响。 从以往经验和相关测试来看，对于高并发事务的系统来说，“sync_binlog”设置为0和设置为1的系统写入性能差距可能高达5倍甚至更多。 (2)导出master数据库多余slave数据库中的数据，然后导入到slave数据库中。保证双方在同步环境实现前的数据一致。[新建环境可忽略次步骤] 导出数据库之前先锁定数据库12345mysql&gt; flush tables with read lock; #数据库只读锁定命令，防止导出数据库的时候有数据写入。unlock tables命令解除锁定 导出master数据库中需要同步的库(master数据库的root用户登陆密码：123456)[root@master ~]#mysqldump -uroot liting -p123456 &gt;/opt/liting.sql[root@master ~]#rsync -e "ssh -p22" -avpgolr /opt/liting.sql 192.168.0.104:/opt/ ＃将导出的sql文件上传到slave机器上 (3)在master上设置数据同步权限1234mysql&gt; grant replication slave,replication client on *.* to repl@'192.168.0.104' identified by "repl123"; #只允许192.168.0.104使用repl，且密码为"repl123"连接主库做数据同步 Query OK, 0 rows affected (0.02 sec) #若要所有网段则设置repl@'%' ；部分网段：repl@'192.168.0.%' mysql&gt; flush privileges; Query OK, 0 rows affected (0.00 sec) 温馨提示：权限查看方式12mysql&gt; show grants;mysql&gt; show grants for repl@'192.168.0.104'; (4)查看主服务器master状态(注意File与Position项，从服务器需要这两项参数)1234567mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000007 | 120 | liting | mysql | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 下面是slave数据库上的操作 (1)设置slave数据库的my.cnf配置文件12345678root@master ~]# vim /etc/my.cnf.......[mysqld]server-id=2 #设置从服务器id，必须于主服务器不同log-bin=mysql-bin #启动MySQ二进制日志系统replicate-do-db=liting #需要同步的数据库名。如果不指明同步哪些库，就去掉这行，表示所有库的同步（除了ignore忽略的库）。replicate-ignore-db=mysql #不同步test数据库slave-skip-errors = all #跳过所有的错误，继续执行复制操作 温馨提示：当只针对某些库的某张表进行同步时，如下，只同步liting库的haha表和test库的heihei表：1234replicate-do-db = litingreplicate-wild-do-table = liting.haha //当只同步几个或少数表时，可以这样设置。注意这要跟上面的库指定配合使用；replicate-do-db = testreplicate-wild-do-table = test.heihei //如果同步的库的表比较多时，就不能这样一一指定了，就把这个选项配置去掉，直接根据指定的库进行同步。 (2)在slave数据库中导入从master传过来的数据。1234mysql&gt; CREATE DATABASE liting CHARACTER SET utf8 COLLATE utf8_general_ci; #先创建一个liting空库，否则下面导入数据时会报错说此库不存在。mysql&gt; use liting;mysql&gt; source /opt/liting.sql; ＃导入master中多余的数据。....... (3）配置主从同步指令1234567891011121314151617181920212223mysql&gt; stop slave; ＃执行同步前，要先关闭slavemysql&gt; change master to master_host='192.168.0.103',master_user='repl',master_password='repl123',master_log_file='mysql-bin.000007',master_log_pos=120; mysql&gt; start slave;mysql&gt; show slave status \G;.......*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.0.103 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000007 Read_Master_Log_Pos: 120 Relay_Log_File: mysql-relay-bin.000002 Relay_Log_Pos: 279 Relay_Master_Log_File: mysql-bin.000007 Slave_IO_Running: Yes Slave_SQL_Running: Yes Replicate_Do_DB: liting Replicate_Ignore_DB: mysql ............. Seconds_Behind_Master: 0 如上，当IO和SQL线程的状态均为Yes，则表示主从已实现同步了！ 下面测试下Mysql主从同步的效果在master主数据库上写入新数据12345mysql&gt; use liting; mysql&gt;create table if not exists haha (id int(10) PRIMARY KEY AUTO_INCREMENT,name varchar(50) NOT NULL);Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into huanqiu.haha values(100,"anhui");Query OK, 1 row affected (0.00 sec) 然后在slave数据库上查看，发现master上新写入的数据已经同步过来了1234567mysql&gt; select * from liting.haha;+-----+-----------+| id | name |+-----+-----------+| 100 | anhui |+-----+-----------+1 rows in set (0.00 sec) 至此，主从同步环境已经实现！ 注意：Mysql主从环境部署一段时间后，发现主从不同步时，如何进行数据同步至一致？有以下两种做法：1）参考：mysql主从同步(2)-问题梳理 中的第（4）步的第二种方法2）参考：mysql主从同步(3)-percona-toolkit工具（数据一致性监测、延迟监控）使用梳理 主主复制实现过程根据上面的主从环境部署，master和slave已经实现同步，即在master上写入新数据，自动同步到slave。而从库只能读不能写，一旦从库有写入数据，就会造成主从数据不一致！下面就说下Mysql主主复制环境，在slave上更新数据时，master也能自动同步过来。 温馨提示： 在做主主同步前，提醒下需要特别注意的一个问题： 主主复制和主从复制有一些区别，因为多主中都可以对服务器有写权限，所以设计到自增长重复问题，例如： 出现的问题（多主自增长ID重复） 1）首先在A和B两个库上创建test表结构; 2）停掉A，在B上对数据表test(存在自增长属性的ID字段)执行插入操作，返回插入ID为1; 3）然后停掉B，在A上对数据表test(存在自增长属性的ID字段)执行插入操作，返回的插入ID也是1; 4）然后 同时启动A,B，就会出现主键ID重复 解决方法： 只要保证两台服务器上的数据库里插入的自增长数据不同就可以了如：A插入奇数ID，B插入偶数ID，当然如果服务器多的话，还可以自定义算法，只要不同就可以了在下面例子中，在两台主主服务器上加入参数，以实现奇偶插入！记住:在做主主同步时需要设置自增长的两个相关配置，如下：12auto_increment_offset 表示自增长字段从那个数开始，取值范围是1 .. 65535。这个就是序号。如果有n台mysql机器，则从第一台开始分为设1，2...nauto_increment_increment 表示自增长字段每次递增的量，其默认值是1，取值范围是1 .. 65535。如果有n台mysql机器，这个值就设置为n。 在主主同步配置时，需要将两台服务器的：12auto_increment_increment 增长量都配置为2auto_increment_offset 分别配置为1和2。这是序号，第一台从1开始，第二台就是2，以此类推..... 这样才可以避免两台服务器同时做更新时自增长字段的值之间发生冲突。（针对的是有自增长属性的字段） 主主同步实现操作过程1）在master上的my.cnf配置：12345678910111213[root@master ~]# vim /etc/my.cnfserver-id = 1 log-bin = mysql-bin binlog-ignore-db = mysql,information_schemasync_binlog = 1binlog_checksum = nonebinlog_format = mixedauto-increment-increment = 2 auto-increment-offset = 1 slave-skip-errors = all [root@master ~]# /etc/init.d/mysql restartShutting down MySQL. SUCCESS!Starting MySQL.. SUCCESS! 数据同步授权（iptables防火墙开启3306端口，要确保对方机器能使用下面权限连接到本机mysql）12mysql&gt; grant replication slave,replication client on *.* to repl@'192.168.0.104' identified by "repl123";mysql&gt; flush privileges; 最好将库锁住，仅仅允许读，以保证数据一致性；待主主同步环境部署后再解锁；锁住后，就不能往表里写数据，但是重启mysql服务后就会自动解锁！12345678910mysql&gt; FLUSH TABLES WITH READ LOCK; //注意该参数设置后，如果自己同步对方数据，同步前一定要记得先解锁！Query OK, 0 rows affected (0.00 sec) mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 158 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 2）slave数据库上1234567891011121314[root@slave ~]# vim /etc/my.cnfserver-id = 2 log-bin = mysql-bin binlog-ignore-db = mysql,information_schemasync_binlog = 1binlog_checksum = nonebinlog_format = mixedauto-increment-increment = 2 auto-increment-offset = 2 slave-skip-errors = all [root@slave ~]# /etc/init.d/mysql restartShutting down MySQL. SUCCESS!Starting MySQL.. SUCCESS! 数据同步授权（iptables防火墙开启3306端口，要确保对方机器能使用下面权限连接到本机mysql）同理，slave也要授权给master机器远程同步数据的权限1234567891011mysql&gt; grant replication slave ,replication client on *.* to repl@'192.168.0.103' identified by "repl123"; mysql&gt; flush privileges; mysql&gt; FLUSH TABLES WITH READ LOCK;mysql&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 | 256 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 3）执行主张同步操作 先在slave数据库上做同步master的设置。（确保slave上要同步的数据，提前在master上存在。最好双方数据保持一致）1234567891011121314151617181920mysql&gt; unlock tables; //先解锁，将对方数据同步到自己的数据库中mysql&gt; slave stop；mysql&gt; change master to master_host='192.168.0.103',master_user='repl',master_password='repl123',master_log_file='master-bin.000001',master_log_pos=158; mysql&gt; start slave;mysql&gt; show slave status \G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.0.103 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 158 nelay_Log_File: mysql-relay-bin.000003 Relay_Log_Pos: 750 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes .................. 这样就实现了slave－&gt;master的同步环境。 再在master数据库上做同步slave的设置。（确保slave上要同步的数据，提前在master上存在。最好双方数据保持一致）1234567891011121314151617181920mysql&gt; unlock tables;mysql&gt; slave stop；mysql&gt; change master to master_host='192.168.0.104',master_user='repl',master_password='repl123',master_log_file='master-bin.000001',master_log_pos=256; mysql&gt; start slave;mysql&gt; show slave status \G;*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 192.168.0.103 Master_User: repl Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 256 Relay_Log_File: mysql-relay-bin.000003 Relay_Log_Pos: 750 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes .................. 这样就实现了master－&gt;slave的同步环境。至此，主主双向同步环境已经实现！ 最后测试下Mysql主主同步的效果在master上写入新数据123456789mysql&gt; select * from liting.haha;+-----+-----------+| id | name |+-----+-----------+| 100 | anhui |+-----+-----------+1 rows in set (0.00 sec) mysql&gt; insert into huanqiu.haha values(10,"beijing"); 在slave数据库中查看，发现master新写入的数据已经同步过来了12345678mysql&gt; select * from liting.haha;+-----+------------+| id | name |+-----+------------+| 10| beijing || 100 | anhui |+-----+------------+2 rows in set (0.00 sec) 在slave上删除数据1mysql&gt; delete from liting.haha where id=100; 在master数据库中查看1234567mysql&gt; select * from liting.haha;+-----+------------+| id | name |+-----+------------+| 10 | beijing |+-----+------------+3 rows in set (0.00 sec) 以上，主主同步实现 binlog，redo log，undo log区别 binlog是MySQL Server层记录的日志， redo log是InnoDB存储引擎层的日志。 两者都是记录了某些操作的日志(不是所有)自然有些重复（但两者记录的格式不同）。 选择binlog日志作为replication我想主要原因是MySQL的特点就是支持多存储引擎，为了兼容绝大部分引擎来支持复制这个特性，那么自然要采用MySQL Server自己记录的日志而不是仅仅针对InnoDB的redo log，因为如果采用了InnoDB redo log复制，那么其他引擎也想复制，此时改怎么办呢？对吧 binlog属于逻辑日志，是逻辑操作。innodb redo属于物理日志，是物理变更。逻辑日志有个缺点是难以并行，而物理日志可以比较好的并行操作，所以redo复制还是有优势的，也许5.7能搞出来。 binlogbinlog日志用于记录所有更新且提交了数据或者已经潜在更新提交了数据（例如，没有匹配任何行的一个DELETE）的所有语句。语句以“事件”的形式保存，它描述数据更改。 binlog作用 1.恢复使能够最大可能地更新数据库，因为二进制日志包含备份后进行的所有更新。2.在主复制服务器上记录所有将发送给从服务器的语句。 binlog 主要参数 log_bin设置此参数表示启用binlog功能，并指定路径名称 innodb_flush_log_at_trx_commit = N： N=0 – 每隔一秒，把事务日志缓存区的数据写到日志文件中，以及把日志文件的数据刷新到磁盘上； N=1 – 每个事务提交时候，把事务日志从缓存区写到日志文件中，并且刷新日志文件的数据到磁盘上； N=2 – 每事务提交的时候，把事务日志数据从缓存区写到日志文件中；每隔一秒，刷新一次日志文件，但不一定刷新到磁盘上，而是取决于操作系统的调度； sync_binlog = N： N&gt;0 — 每向二进制日志文件写入N条SQL或N个事务后，则把二进制日志文件的数据刷新到磁盘上； N=0 — 不主动刷新二进制日志文件的数据到磁盘上，而是由操作系统决定； 推荐配置组合： N=1,1 — 适合数据安全性要求非常高，而且磁盘IO写能力足够支持业务，比如充值消费系统； N=1,0 — 适合数据安全性要求高，磁盘IO写能力支持业务不富余，允许备库落后或无复制； N=2,0或2,m(0&lt;m&lt;100) — 适合数据安全性有要求，允许丢失一点事务日志，复制架构的延迟也能接受； N=0,0 — 磁盘IO写能力有限，无复制或允许复制延迟稍微长点能接受，例如：日志性登记业务； Undo LogUndo Log是为了实现事务的原子性，在MySQL数据库InnoDB存储引擎中，还用UndoLog来实现多版本并发控制(简称：MVCC)。 事务的原子性(Atomicity)- 事务中的所有操作，要么全部完成，要么不做任何操作，不能只做部分操作。如果在执行的过程中发了错误，要回滚(Rollback)到事务开始前的状态，就像这个事务从来没有执行过。 原理Undo Log的原理很简单，为了满足事务的原子性，在操作任何数据之前，首先将数据备份到一个地方（这个存储数据备份的地方称为UndoLo）。然后进行数据的修改。如果出现了错误或者用户执行了ROLLBACK语句，系统可以利用UndoLog中的备份将数据恢复到事务开始之前的状态。除了可以保证事务的原子性，Undo Log也可以用来辅助完成事务的持久化。 事务的持久性(Durability)事务一旦完成，该事务对数据库所做的所有修改都会持久的保存到数据库中。为了保证持久性，数据库系统会将修改后的数据完全的记录到持久的存储上。 用Undo Log实现原子性和持久化的事务的简化过程 假设有A、B两个数据，值分别为1,2。A.事务开始. B.记录A=1到undolog. C.修改A=3. D.记录B=2到undolog. E.修改B=4. F.将undolog写到磁盘。 G.将数据写到磁盘。 H.事务提交 这里有一个隐含的前提条件：‘数据都是先读到内存中，然后修改内存中的数据，最后将数据写回磁盘’。 之所以能同时保证原子性和持久化，是因为以下特点： A.更新数据前记录Undo log。 B.为了保证持久性，必须将数据在事务提交前写到磁盘。只要事务成功提交，数据必然已经持久化。 C.Undo log必须先于数据持久化到磁盘。如果在G,H之间系统崩溃，undo log是完整的，可以用来回滚事务。 D.如果在A-F之间系统崩溃,因为数据没有持久化到磁盘。所以磁盘上的数据还是保持在事务开始前的状态。 缺陷：每个事务提交前将数据和Undo Log写入磁盘，这样会导致大量的磁盘IO，因此性能很低。如果能够将数据缓存一段时间，就能减少IO提高性能。但是这样就会丧失事务的持久性。因此引入了另外一种机制来实现持久化，即 Redo log记录的是新数据的备份。在事务提交前，只要将Redo Log持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是RedoLog已经持久化。系统可以根据RedoLog的内容，将所有数据恢复到最新的状态。 -Undo+Redo事务的简化过程 假设有A、B两个数据，值分别为1,2. A.事务开始. B.记录A=1到undolog. C.修改A=3. D.记录A=3到redolog. E.记录B=2到undolog. F.修改B=4. G.记录B=4到redolog. H.将redolog写入磁盘。 I.事务提交 -Undo+Redo事务的特点 A.为了保证持久性，必须在事务提交前将RedoLog持久化。 B.数据不需要在事务提交前写入磁盘，而是缓存在内存中。 C.RedoLog保证事务的持久性。 D.UndoLog保证事务的原子性。 E.有一个隐含的特点，数据必须要晚于redolog写入持久存 mysql有哪些索引类型？有哪些存储引擎？有什么区别 索引类型 FULLTEXT：即为全文索引，目前只有MyISAM引擎支持。其可以在CREATE TABLE ，ALTER TABLE ，CREATE INDEX 使用，不过目前只有 CHAR、VARCHAR ，TEXT 列上可以创建全文索引。全文索引并不是和MyISAM一起诞生的，它的出现是为了解决WHERE name LIKE “%word%”这类针对文本的模糊查询效率较低的问题。 HASH：由于HASH的唯一（几乎100%的唯一）及类似键值对的形式，很适合作为索引。HASH索引可以一次定位，不需要像树形索引那样逐层查找,因此具有极高的效率。但是，这种高效是有条件的，即只在“=”和“in”条件下高效，对于范围查询、排序及组合索引仍然效率不高。 BTREE：BTREE索引就是一种将索引值按一定的算法，存入一个树形的数据结构中（二叉树），每次查询都是从树的入口root开始，依次遍历node，获取leaf。这是MySQL里默认和最常用的索引类型。 RTREE：RTREE在MySQL很少使用，仅支持geometry数据类型，支持该类型的存储引擎只有MyISAM、BDb、InnoDb、NDb、Archive几种。相对于BTREE，RTREE的优势在于范围查找。 索引种类： 普通索引：仅加速查询。 唯一索引：加速查询 + 列值唯一（可以有null） 主键索引：加速查询 + 列值唯一（不可以有null）+ 表中只有一个 组合索引：多列值组成一个索引，专门用于组合搜索，其效率大于索引合并 全文索引：对文本的内容进行分词，进行搜索 存储引擎 InnoDB InnoDB 也采用 B+Tree这种数据结构来实现 B-Tree索引。而很大的区别在于，InnoDB 存储引擎采用“聚集索引”的数据存储方式实现B-Tree索引，所谓“聚集”，就是指数据行和相邻的键值紧凑地存储在一起，注意 InnoDB 只能聚集一个叶子页（16K）的记录（即聚集索引满足一定的范围的记录），因此包含相邻键值的记录可能会相距甚远。 当InnoDB做全表扫描时并不高效，因为 InnoDB 实际上并没有顺序读取,在大多情况下是在随机读取。做全表扫描时,InnoDB 会按主键顺序扫描页面和行。这应用于所有的InnoDB 表，包括碎片化的表。如果主键页表没有碎片（存储主键和行的页表),全表扫描是相当快，因为读取顺序接近物理存储顺序。但是当主键页有碎片时，该扫描就会变得十分缓慢 遵循ACID原则(atomicity原子性，consistency一致性，isolation隔离性，durability持久性)，具有事务特性的能力：commit，rollback，crash-recovery。 仅InnoDB和NDB(Network DB clustered database engine)支持事务和MVCC 行级锁和Oracle风格的读一致性，提高多用户下的并发度和性能，提供行锁(locking on row level)，提供与 Oracle 类型一致的不加锁读取(non-locking read in SELECTs)，另外，InnoDB表的行锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表，例如update table set num=1 where name like “%aaa%”。 只有通过索引条件检索数据，InnoDB才使用行级锁，否则仍然使用表锁 读一致性：query时使用snapshot快照，允许其他事务进行修改，之后再根据undo log调整数据 默认的隔离级别是可重复读，即同一个事务中多次读取，数据相同 使用主键优化查询，主键索引是聚集索引(Clustered index，仅InnoDB支持)，使查询主键时的I/O最小化 聚集索引是指整个表是按照这个索引来组织的，物理存储顺序与索引顺序相同，所以聚集索引字段的修改需要很大开销 InnoDB聚集索引的实现方式，同时也体现了一张 innoDB表的结构，可以看到，InnoDB 中，主键索引和数据是一体的，没有分开。 支持外码约束 崩溃后能很好地恢复 未完成的事务将根据redo log的数据重做 已提交但未写入的修改，将从doublewrite buffer重做 系统闲时会purge buffer 维护一个内存中的buffer pool缓冲池，数据被访问时，表和索引数据会被缓存 对增删改的change buffering策略，如果被修改数据的页不在缓冲池中，则这个修改可以存在change buffer中，等相应页被放进缓冲池(发生对该页的访问)时，再写入修改，称为merge adaptive hash index，经常被访问的页会自动在内存建立一个哈希索引，适于=和IN的查询。buffer pool中会预留这种索引需要的内存空间。建立在已有的B树索引基础上，哈希索引可以是部分的，B树索引不需要全部缓存在缓冲池中 使用checksum校验和机制检测内存或硬盘的损坏 InnoDB是为处理巨大数据量的最大性能设计 可以在一个查询中join混用InnoDB引擎的表和其他引擎的表 MyISAM 适用场景：read-only or read-mostly workloads in Web and data warehousing configurations(查询效率很高，适合大量读操作的场景) 每个MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。MyISAM索引文件【.MYI (MYIndex)】和数据文件【.MYD (MYData)】是分离的，索引文件仅保存记录所在页的指针（物理位置），通过这些地址来读取页，进而读取被索引的行 MyISAM 默认会把索引读入内存，直接在内存中操作 Innodb强调多功能性，支持的拓展功能比较多，myisam主要侧重于性能 将创建3个文件，一个.frm文件，一个.MYD(MYData)文件存数据，一个.MYI(MYIndex)文件存索引 数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 所有数据值都按小字节(low byte first)存储，因此独立于操作系统(可移植性)。但没有明显降低速度，只是需要多处理一下对齐问题，况且获取列值所花的时间不是最主要的 所有数字键都按大字节(high byte first)存储，利于压缩 BLOB和TEXT列可以创建索引 每一个character列可以使用不同的字符编码 会保存表的具体行数 使用B树索引，string索引会被压缩，当string是索引第一项时还会压缩前缀 支持真正的变长字段varchar 支持并发的insert 区别 InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务； InnoDB是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。而MyISAM是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。 InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快； Innodb不支持全文索引，而MyISAM支持全文索引，查询效率上MyISAM要高； 如何选择 是否要支持事务，如果要请选择innodb，如果不需要可以考虑MyISAM； 如果表中绝大多数都只是读查询，可以考虑MyISAM，如果既有读写也挺频繁，请使用InnoDB。 系统奔溃后，MyISAM恢复起来更困难，能否接受； MySQL5.5版本开始Innodb已经成为Mysql的默认引擎(之前是MyISAM)，说明其优势是有目共睹的，如果你不知道用什么，那就用InnoDB，至少不会差。 ARCHIVE 适用场景：作为仓库，存储大量的独立的作为历史记录的数据(插入速度快但查询支持较差） 不支持索引 没有存储大小限制(InnoDB是64TB) 能很好地压缩数据 使用行级锁 支持INSERT, REPLACE, SELECT, 不支持 DELETE, UPDATE 使用zlib 无损数据压缩。数据insert后即被压缩，放在一个压缩缓冲区中，select操作会导致清空缓冲区，此时数据被真正存储。支持批处理insert。 行会根据需要解压，不设缓冲。select会导致全表扫描。select是读一致性的。大量查询during insertion会影响压缩。使用REPAIR TABLE或OPTIMIZE TABLE能获取更好的压缩。 BLACKHOLE 适用场景:转发器（会保存SQL语句的日志，并且复制给slave servers） 过滤器（设置使用黑洞引擎的“dummy” slave进程，依据一定规则将master的日志进行过滤并在BLACKHOLE表写一个新的日志，再复制给slaves，这样只会导致很少的开销） 像黑洞一样接受数据但不存储 创建table A会生成一个A.frm表文件，没有其他文件 支持所有索引 会保存SQL语句的日志，并且复制给slave servers，适合做转发器或过滤器 会导致错误，因为不论log文件是row-based还是statement-based，blackhole表不会存储自增列的数据，所以在slaves上insert时会出现重复的主码错误 使用row-based replication时，如果slaves的表的字段比master少，那么过滤机制其实是在slaves上。如果缺失字段是私密的，不能给slaves获取的；或是有很多slaves，需要在发送数据前就把数据过滤掉以减少网络负载，就不适合这种方式。BLACKHOLE表就能实现在master上进行过滤。 MRG_MYISAM 适用场景：Good for VLDB environments such as data warehousing 要求多个Mylsam表要有相同的列信息(包括顺序)和索引信息(包括索引的order) 这些信息不同不会影响表合并 列名和索引名 所有的备注comment 表的选项，例如 AVG_ROW_LENGTH, MAX_ROWS, or PACK_KEYS 创建merge表时会创建2个文件，一个是存数据的.frm文件，一个是.mrg文件(存储哪些表应当merge起来使用) merge表中的表可以存于不同的数据库中 支持merge表的增删改查，前提是必须拥有处理其中所有表的权限 drop table只是删除了merge表，实际存储数据的表不会被删除 建表需要指定UNION=(list-of-tables)表明使用哪些表，以及INSERT_METHOD=LAST/FIRST表明在哪一个表中插入数据，否则无法执行insert操作 merge表没有主键，因为不能强制实行唯一索引 FEDERATED 适用场景：Very good for distributed or data mart environments 数据不存储在本地，而是在远程数据库，本地访问时会pull远程数据库的数据 远程数据库的表可以是任何存储引擎的表 本地表和远程表应有相同的定义 本地用.frm文件存储表定义，并且包含一个指向远程数据库的连接字符串 本地执行操作时，会发送给远程去执行，使用MySQL client API 远程表可以是一个FEDERATED表，但注意不要造成一个循环 FEDERATED表不支持一般意义上的索引，要远程表上有索引才有效 如果一个查询语句不能使用远程表的索引，会导致全表扫描，本地数据库会获取全表数据（存在本地内存中，如果数据量过大会引起交换和挂起），再在本地进行过滤 不支持alter table或drop table，执行drop table只会删除本地FEDERATED表 不支持分区 如果远程表改变，本地表无法获知 PERFORMANCE_SCHEMA 关注收集mysql server运行中的性能数据，会监视server的所有events performance_schema数据库名及其表名都是小写的，查询时要用小写 很多表都是只读的，对数据库所有表的GRANT ALL授权是不允许的 数据库中表的更改不会写在日志中 是完全in-memory的，不占用磁盘空间，mysql服务启动时表会被重新填充，关闭服务时便丢弃 数据收集的实现是在源码中添加”监控点”(instrumentation)，没有用额外的线程(不像”复制”或”事件调度”) 用户不能创建存储该类型的表 MEMORY 适用场景：存储临时、不重要的数据，例如作为缓存，适合大量读的情形 (limited updates) 不支持变长的数据类型variable-length data types (including BLOB and TEXT) 不支持外码约束 不支持压缩 不支持MVCC 支持哈希索引和B树索引，不支持全文索引和T树索引 mysql服务关闭或重启，数据会消失(表还在) 数据量不能超过内存大小 性能限制 单线程执行 表更新用表级锁(高并发读写情形下，表级锁严重降低性能，还不如InnoDB快) 内置的临时表(也在内存中)太大时会自动转成磁盘存储，但用户自创的内存表永远不会转化 可以从persistent data source装载数据到内存表 被删除的row会放进一个链表(不会回收内存)，等插入新数据时拿出来复用，只有整个表被删除后才会回收内存。采用定长的行存储，即使是varchar也是定长存储的。 默认使用哈希索引，并且允许非唯一的哈希索引(但如果字段含大量重复值，性能会很低，这种情况最好用B树索引)，被索引字段可以有NULL。 CSV 创建一个csv表，除了.frm文件外，还创建一个.csv文件用于存储数据，还有一个.csm文件存储表状态、行数等信息，称为metafile 所有字段都必须NOT NULL 不支持索引、分区 对索引的理解，组合索引，索引的最佳实践索引类型 B-Tree 索引：MySQL 中最主要的索引； RTREE 索引：仅仅是 MyISAM，GIS； 哈希索引：MyISAM，5.6 开始的 Innodb。 BTREE 索引能做什么？ 直接查看 KEY=5 的所有列； 找到 KEY &gt; 5 的列，范围查找； 查找 5&lt;KEY&lt;10 之间的所有列，封闭范围查找； 不能找到 KEY 的最后一个数字是 0 的列（这个不是范围查找）。 字符串索引 字符串索引实际上也没什么不同，按照字典顺序排列，例如 ”AAAA” &lt; “AAAB”; like 前缀是一个特殊排序，例如 LIKE “ABC%” 意味着 “ABC[LOWEST]”&lt;KEY&lt;“ABC[HIGHEST]”，但是 LIKE “%ABC” 不走索引。 多列索引 按照定义的顺序从左往右进行比较，例如在 KEY(col1,col2,col3) 中，(1,2,3) &lt; (1,3,1)； 多列索引仍然是一个 BTREE 索引，但不是每列都是一个单独的 BTREE。 MySQL 怎么使用索引在数据查询中使用索引用了索引 LAST_NAMESELECT * FROM EMPLOYEES WHERE LAST_NAME=“Smith”; 用了索引 (DEPT,LAST_NAME) 123SELECT * FROM EMPLOYEES WHERE LAST_NAME=“Smith” AND DEPT=“Accounting” 这里虽然索引字段顺序和查询的顺序颠倒，依然会走索引，不是因为最左匹配不走索引。 多列索引会变的困难，对于索引 (A,B,C)： 下面的条件会走索引: A&gt;5 A=5 AND B&gt;6 A=5 AND B=6 AND C=7 A=5 AND B IN (2,3) AND C&gt;5 下面的条件不走索引，因为不符合最左匹配，缺少第一列 B &gt; 5 B = 6 AND C = 7 在 MySQL5.7 中使用 explain 执行了一下，发现还是会走索引的，估计 MySQL 底层做了什么优化？ 下面条件会走部分索引 A&gt;5 AND B=2 A=5 AND B&gt;6 AND C=2 SQL 优化的第一原则： MySQL 在多列索引中，一遇到 （&lt;,&gt;,between）就会停止使用 key，然而能继续使用 key 直到 in 范围的右边。 在排序中使用索引排序 SELECT * FROM PLAYERS ORDER BY SCORE DESC LIMIT 10 该 SQL 会使用建立在 SCORE 列上的 索引； 如果排序的时候没有使用索引，将会导致非常耗时的文件排序； 在排序中经常会考虑组合索引， 例如下面的 SQL 可以考虑(COUNTRY,SCORE) 索引： SELECT * FROM PLAYERS WHERE COUNTRY=“US” ORDER BY SCORE DESC LIMIT 10使用多列索引进行高效的排序，在排序中使用索引有很多的限制，对于 KEY(A，B）: 下面排序会使用索引： ORDER BY A：主列索引； A=5 ORDER BY B：通过第一列过滤数据，第二列进行排序； ORDER BY A DESC, B DESC：用相同的排序进行排序； A&gt;5 ORDER BY A：主列上进行查询和排序 下面的语句不会使用索引： ORDER BY B ：非主列索引排序； A&gt;5 ORDER BY B：第一列上使用范围，第二列进行排序； A IN(1,2) ORDER BY B：第一列上用 IN； ORDER BY A ASC, B DESC：两列的排列顺序不同。 使用索引进行排序的规则 两列的排列顺序不能不一致； 非排序的列中索引部分只能用 =，in 也不能用。 表中存在多个索引 MySQL 中可以存在多个索引：会有索引合并； SELECT * FROM TBL WHERE A=5 AND B=6：该语句能分别使用在 A 和 B 上的索引，但是在 （A,B) 上建立索引是更好的； SELECT * FROM TBL WHERE A=5 OR B=6：该语句使用两个独立的索引，但不会使用在（A,B) 上建立的索引 前缀索引可以在索引最左边一列上建立前缀索引： ALTER TABLE TITLE ADD KEY(TITLE(20)); 需要在 BLOB/TEXT 上建立索引； 能显著的提升效率； 不能被用作覆盖索引； 选择合适的前缀长度是一个问题。 Explain命令详解 EXPLAIN 输出格式 EXPLAIN 命令的输出内容大致如下:123456789101112131415mysql&gt; explain select * from user_info where id = 2\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 各列的含义如下: id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符. select_type: SELECT 查询的类型. table: 查询的是哪个表 partitions: 匹配的分区 type: join 类型 possible_keys: 此次查询中可能选用的索引 key: 此次查询中确切使用到的索引. ref: 哪个字段或常数与 key 一起被使用 rows: 显示此查询一共扫描了多少行. 这个是一个估计值. filtered: 表示此查询条件所过滤的数据的百分比 extra: 额外的信息 接下来我们来重点看一下比较重要的几个字段. select_typeselect_type 表示了查询的类型, 它的常用取值有: SIMPLE, 表示此查询不包含 UNION 查询或子查询 PRIMARY, 表示此查询是最外层的查询 UNION, 表示此查询是 UNION 的第二或随后的查询 DEPENDENT UNION, UNION 中的第二个或后面的查询语句, 取决于外面的查询 UNION RESULT, UNION 的结果 SUBQUERY, 子查询中的第一个 SELECT DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果. 最常见的查询类别应该是 SIMPLE 了, 比如当我们的查询没有子查询, 也没有 UNION 查询时, 那么通常就是 SIMPLE 类型, 例如: 123456789101112131415mysql&gt; explain select * from user_info where id = 2\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 如果我们使用了 UNION 查询, 那么 EXPLAIN 输出 的结果类似如下:1234567891011mysql&gt; EXPLAIN (SELECT * FROM user_info WHERE id IN (1, 2, 3)) -&gt; UNION -&gt; (SELECT * FROM user_info WHERE id IN (3, 4, 5));+----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-----------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-----------------+| 1 | PRIMARY | user_info | NULL | range | PRIMARY | PRIMARY | 8 | NULL | 3 | 100.00 | Using where || 2 | UNION | user_info | NULL | range | PRIMARY | PRIMARY | 8 | NULL | 3 | 100.00 | Using where || NULL | UNION RESULT | &lt;union1,2&gt; | NULL | ALL | NULL | NULL | NULL | NULL | NULL | NULL | Using temporary |+----+--------------+------------+------------+-------+---------------+---------+---------+------+------+----------+-----------------+3 rows in set, 1 warning (0.00 sec) table表示查询涉及的表或衍生表 typetype 字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 type 字段, 我们判断此次查询是 全表扫描 还是 索引扫描 等. type 常用类型type 常用的取值有: system: 表中只有一条数据. 这个类型是特殊的 const 类型. const: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可. 例如下面的这个查询, 它使用了主键索引, 因此 type 就是 const 类型的. 123456789101112131415mysql&gt; explain select * from user_info where id = 2\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) eq_ref: 此类型通常出现在多表的 join 查询, 表示对于前表的每一个结果, 都只能匹配到后表的一行结果. 并且查询的比较操作通常是 =, 查询效率较高. 例如: 12345678910111213141516171819202122232425262728mysql&gt; EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: indexpossible_keys: user_product_detail_index key: user_product_detail_index key_len: 314 ref: NULL rows: 9 filtered: 100.00 Extra: Using where; Using index*************************** 2. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: eq_refpossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: test.order_info.user_id rows: 1 filtered: 100.00 Extra: NULL2 rows in set, 1 warning (0.00 sec) ref: 此类型通常出现在多表的 join 查询, 针对于非唯一或非主键索引, 或者是使用了 最左前缀 规则索引的查询.例如下面这个例子中, 就使用到了 ref 类型的查询: 12345678910111213141516171819202122232425262728mysql&gt; EXPLAIN SELECT * FROM user_info, order_info WHERE user_info.id = order_info.user_id AND order_info.user_id = 5\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: constpossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL*************************** 2. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: refpossible_keys: user_product_detail_index key: user_product_detail_index key_len: 9 ref: const rows: 1 filtered: 100.00 Extra: Using index2 rows in set, 1 warning (0.01 sec) range: 表示使用索引范围查询, 通过索引字段范围获取表中部分数据记录. 这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中.当 type 是 range 时, 那么 EXPLAIN 输出的 ref 字段为 NULL, 并且 key_len 字段是此次查询中使用到的索引的最长的那个. 例如下面的例子就是一个范围查询: 1234567891011121314151617mysql&gt; EXPLAIN SELECT * -&gt; FROM user_info -&gt; WHERE id BETWEEN 2 AND 8 \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: rangepossible_keys: PRIMARY key: PRIMARY key_len: 8 ref: NULL rows: 7 filtered: 100.00 Extra: Using where1 row in set, 1 warning (0.00 sec) index: 表示全索引扫描(full index scan), 和 ALL 类型类似, 只不过 ALL 类型是全表扫描, 而 index 类型则仅仅扫描所有的索引, 而不扫描数据.index 类型通常出现在: 所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据. 当是这种情况时, Extra 字段 会显示 Using index. 例如:123456789101112131415mysql&gt; EXPLAIN SELECT name FROM user_info \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: indexpossible_keys: NULL key: name_index key_len: 152 ref: NULL rows: 10 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.00 sec) 上面的例子中, 我们查询的 name 字段恰好是一个索引, 因此我们直接从索引中获取数据就可以满足查询的需求了, 而不需要查询表中的数据. 因此这样的情况下, type 的值是 index, 并且 Extra 的值是 Using index. ALL: 表示全表扫描, 这个类型的查询是性能最差的查询之一. 通常来说, 我们的查询不应该出现 ALL 类型的查询, 因为这样的查询在数据量大的情况下, 对数据库的性能是巨大的灾难. 如一个查询是 ALL 类型查询, 那么一般来说可以对相应的字段添加索引来避免.下面是一个全表扫描的例子, 可以看到, 在全表扫描时, possible_keys 和 key 字段都是 NULL, 表示没有使用到索引, 并且 rows 十分巨大, 因此整个查询效率是十分低下的. 123456789101112131415mysql&gt; EXPLAIN SELECT age FROM user_info WHERE age = 20 \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 10 filtered: 10.00 Extra: Using where1 row in set, 1 warning (0.00 sec) type 类型的性能比较 通常来说, 不同的 type 类型的性能关系如下:ALL &lt; index &lt; range ~ index_merge &lt; ref &lt; eq_ref &lt; const &lt; systemALL 类型因为是全表扫描, 因此在相同的查询条件下, 它是速度最慢的.而 index 类型的查询虽然不是全表扫描, 但是它扫描了所有的索引, 因此比 ALL 类型的稍快.后面的几种类型都是利用了索引来查询数据, 因此可以过滤部分或大部分数据, 因此查询效率就比较高了. possible_keyspossible_keys 表示 MySQL 在查询时, 能够使用到的索引. 注意, 即使有些索引在 possible_keys 中出现, 但是并不表示此索引会真正地被 MySQL 使用到. MySQL 在查询时具体使用了哪些索引, 由 key 字段决定. key此字段是 MySQL 在当前查询时所真正使用到的索引. key_len表示查询优化器使用了索引的字节数. 这个字段可以评估组合索引是否完全被使用, 或只有最左部分字段被使用到.key_len 的计算规则如下: 字符串 char(n): n 字节长度 varchar(n): 如果是 utf8 编码, 则是 3 n + 2字节; 如果是 utf8mb4 编码, 则是 4 n + 2 字节. 数值类型: TINYINT: 1字节 SMALLINT: 2字节 MEDIUMINT: 3字节 INT: 4字节 BIGINT: 8字节 时间类型 DATE: 3字节 TIMESTAMP: 4字节 DATETIME: 8字节 字段属性: NULL 属性 占用一个字节. 如果一个字段是 NOT NULL 的, 则没有此属性. 我们来举两个简单的栗子:123456789101112131415mysql&gt; EXPLAIN SELECT * FROM order_info WHERE user_id &lt; 3 AND product_name = 'p1' AND productor = 'WHH' \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: rangepossible_keys: user_product_detail_index key: user_product_detail_index key_len: 9 ref: NULL rows: 5 filtered: 11.11 Extra: Using where; Using index1 row in set, 1 warning (0.00 sec) 上面的例子是从表 order_info中查询指定的内容, 而我们从此表的建表语句中可以知道, 表 order_info 有一个联合索引:1KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`) 不过此查询语句 WHERE user_id &lt; 3 AND product_name = &#39;p1&#39; AND productor = &#39;WHH&#39; 中, 因为先进行 user_id 的范围查询, 而根据 最左前缀匹配 原则, 当遇到范围查询时, 就停止索引的匹配, 因此实际上我们使用到的索引的字段只有 user_id, 因此在 EXPLAIN 中, 显示的 key_len 为 9. 因为 user_id 字段是 BIGINT, 占用 8 字节, 而 NULL 属性占用一个字节, 因此总共是 9 个字节. 若我们将user_id 字段改为 BIGINT(20) NOT NULL DEFAULT &#39;0&#39;, 则 key_length 应该是8. 上面因为 最左前缀匹配 原则, 我们的查询仅仅使用到了联合索引的 user_id 字段, 因此效率不算高. 接下来我们来看一下下一个例子: 123456789101112131415mysql&gt; EXPLAIN SELECT * FROM order_info WHERE user_id = 1 AND product_name = 'p1' \G;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: refpossible_keys: user_product_detail_index key: user_product_detail_index key_len: 161 ref: const,const rows: 2 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.00 sec) 这次的查询中, 我们没有使用到范围查询, key_len 的值为 161. 为什么呢? 因为我们的查询条件 WHERE user_id = 1 AND product_name = &#39;p1&#39; 中, 仅仅使用到了联合索引中的前两个字段, 因此 keyLen(user_id) + keyLen(product_name) = 9 + 50 * 3 + 2 = 161 rowsrows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数.这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好. ExtraEXplain 中的很多额外的信息会在 Extra 字段显示, 常见的有以下几种内容: Using filesort 当 Extra 中有 Using filesort 时, 表示 MySQL 需额外的排序操作, 不能通过索引顺序达到排序效果. 一般有 Using filesort, 都建议优化去掉, 因为这样的查询 CPU 资源消耗大. 例如下面的例子:123456789101112131415mysql&gt; EXPLAIN SELECT * FROM order_info ORDER BY product_name \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: indexpossible_keys: NULL key: user_product_detail_index key_len: 253 ref: NULL rows: 9 filtered: 100.00 Extra: Using index; Using filesort1 row in set, 1 warning (0.00 sec) 我们的索引是1KEY `user_product_detail_index` (`user_id`, `product_name`, `productor`) 但是上面的查询中根据 product_name 来排序, 因此不能使用索引进行优化, 进而会产生 Using filesort.如果我们将排序依据改为ORDER BY user_id, product_name, 那么就不会出现 Using filesort 了. 例如:123456789101112131415mysql&gt; EXPLAIN SELECT * FROM order_info ORDER BY user_id, product_name \G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: order_info partitions: NULL type: indexpossible_keys: NULL key: user_product_detail_index key_len: 253 ref: NULL rows: 9 filtered: 100.00 Extra: Using index1 row in set, 1 warning (0.00 sec) Using index “覆盖索引扫描”, 表示查询在索引树中就可查找所需数据, 不用扫描表数据文件, 往往说明性能不错 Using temporary 查询有使用临时表, 一般出现于排序, 分组和多表 join 的情况, 查询效率不高, 建议优化. 数据库和缓存的一致性问题。先更新数据库，再更新缓存，若更新完数据库了，还没有更新缓存，此时有请求过来了，访问到了缓存中的数据，怎么办？产生原因主要有两种情况，会导致缓存和 DB 的一致性问题： 并发的场景下，导致读取老的 DB 数据，更新到缓存中。 缓存和 DB 的操作，不在一个事务中，可能只有一个操作成功，而另一个操作失败，导致不一致。 当然，有一点我们要注意，缓存和 DB 的一致性，我们指的更多的是最终一致性。我们使用缓存只要是提高读操作的性能，真正在写操作的业务逻辑，还是以数据库为准。例如说，我们可能缓存用户钱包的余额在缓存中，在前端查询钱包余额时，读取缓存，在使用钱包余额时，读取数据库。 更新缓存的设计模式Cache Aside Pattern(旁路缓存)这是最常用最常用的pattern了。其具体逻辑如下： 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从cache中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 一个是查询操作，一个是更新操作的并发，首先，没有了删除cache数据的操作了，而是先更新了数据库中的数据，此时，缓存依然有效，所以，并发的查询操作拿的是没有更新的数据，但是，更新操作马上让缓存的失效了，后续的查询操作再把数据从数据库中拉出来。而不会像文章开头的那个逻辑产生的问题，后续的查询操作一直都在取老的数据。 要么通过2PC或是Paxos协议保证一致性，要么就是拼命的降低并发时脏数据的概率，而Facebook使用了这个降低概率的玩法，因为2PC太慢，而Paxos太复杂。当然，最好还是为缓存设置上过期时间。 Read/Write Through Pattern在上面的Cache Aside套路中，我们的应用代码需要维护两个数据存储，一个是缓存（Cache），一个是数据库（Repository）。所以，应用程序比较啰嗦。而Read/Write Through套路是把更新数据库（Repository）的操作由缓存自己代理了，所以，对于应用层来说，就简单很多了。可以理解为，应用认为后端就是一个单一的存储，而存储自己维护自己的Cache。 Read Through Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或LRU换出），Cache Aside是由调用方负责把数据加载入缓存，而Read Through则用缓存服务自己来加载，从而对应用方是透明的。 Write Through Write Through 套路和Read Through相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作） 下图自来Wikipedia的Cache词条。其中的Memory你可以理解为就是我们例子里的数据库。 Write Behind Caching PatternWrite Behind 又叫 Write Back。write back就是Linux文件系统的Page Cache的算法。 Write Back套路，一句说就是，在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。 这个设计的好处就是让数据的I/O操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。 但是，其带来的问题是，数据不是强一致性的，而且可能会丢失（我们知道Unix/Linux非正常关机会导致数据丢失，就是因为这个事）。在软件设计上，我们基本上不可能做出一个没有缺陷的设计，就像算法设计中的时间换空间，空间换时间一个道理，有时候，强一致性和高性能，高可用和高性性是有冲突的。软件设计从来都是取舍Trade-Off。 另外，Write Back实现逻辑比较复杂，因为他需要track有哪数据是被更新了的，需要刷到持久层上。操作系统的write back会在仅当这个cache需要失效的时候，才会被真正持久起来，比如，内存不够了，或是进程退出了等情况，这又叫lazy write。 在wikipedia上有一张write back的流程图，基本逻辑如下： 缓存架构设计更新缓存 VS 淘汰缓存更新缓存：数据不但写入数据库，还会写入缓存；优点：缓存不会增加一次miss，命中率高 淘汰缓存：数据只会写入数据库，不会写入缓存，只会把数据淘汰掉；优点：简单 这两者的选择主要取决于“更新缓存的复杂度”。 例如，上述场景，只是简单的把余额money设置成一个值，那么： （1）淘汰缓存的操作为deleteCache(uid) （2）更新缓存的操作为setCache(uid, money) 更新缓存的代价很小，此时我们应该更倾向于更新缓存，以保证更高的缓存命中率 如果余额是通过很复杂的数据计算得出来的，例如业务上除了账户表account，还有商品表product，折扣表discount account(uid, money) product(pid, type, price, pinfo) discount(type, zhekou) 业务场景是用户买了一个商品product，这个商品的价格是price，这个商品从属于type类商品，type类商品在做促销活动要打折扣zhekou，购买了商品过后，这个余额的计算就复杂了，需要： （1）先把商品的品类，价格取出来：SELECT type, price FROM product WHERE pid=XXX （2）再把这个品类的折扣取出来：SELECT zhekou FROM discount WHERE type=XXX （3）再把原有余额从缓存中查询出来money = getCache(uid) （4）再把新的余额写入到缓存中去setCache(uid, money-price*zhekou) 更新缓存的代价很大，此时我们应该更倾向于淘汰缓存。 总之，淘汰缓存操作简单，并且带来的副作用只是增加了一次cache miss，建议作为通用的处理方式。 先操作数据库 vs 先操作缓存当写操作发生时，假设淘汰缓存作为对缓存通用的处理方式，又面临两种抉择： （1）先写数据库，再淘汰缓存 （2）先淘汰缓存，再写数据库 对于一个不能保证事务性的操作，一定涉及“哪个任务先做，哪个任务后做”的问题，解决这个问题的方向是：如果出现不一致，谁先做对业务的影响较小，就谁先执行。 由于写数据库与淘汰缓存不能保证原子性，谁先谁后同样要遵循上述原则。 假设先写数据库，再淘汰缓存：第一步写数据库操作成功，第二步淘汰缓存失败，则会出现DB中是新数据，Cache中是旧数据，数据不一致。 假设先淘汰缓存，再写数据库：第一步淘汰缓存成功，第二步写数据库失败，则只会引发一次Cache miss。 结论：数据和缓存的操作时序：先淘汰缓存，再写数据库。 缓存架构优化 上述缓存架构有一个缺点：业务方需要同时关注缓存与DB，主要有两种优化方案： 一种方案是服务化：加入一个服务层，向上游提供帅气的数据访问接口，向上游屏蔽底层数据存储的细节，这样业务线不需要关注数据是来自于cache还是DB。 另一种方案是异步缓存更新：业务线所有的写操作都走数据库，所有的读操作都总缓存，由一个异步的工具来做数据库与缓存之间数据的同步，具体细节是： （1）要有一个init cache的过程，将需要缓存的数据全量写入cache （2）如果DB有写操作，异步更新程序读取binlog，更新cache 在（1）和（2）的合作下，cache中有全部的数据，这样： （a）业务线读cache，一定能够hit（很短的时间内，可能有脏数据），无需关注数据库 （b）业务线写DB，cache中能得到异步更新，无需关注缓存 这样将大大简化业务线的调用逻辑，存在的缺点是，如果缓存的数据业务逻辑比较复杂，async-update异步更新的逻辑可能也会比较复杂。 结论（1）淘汰缓存是一种通用的缓存处理方式 （2）先淘汰缓存，再写数据库 （3）服务化是向业务方屏蔽底层数据库与缓存复杂性的一种通用方式 缓存和DB一致性的解决方案先淘汰缓存，再写数据库因为先淘汰缓存，所以数据的最终一致性是可以得到有效的保证的。因为先淘汰缓存，即使写数据库发生异常，也就是下次缓存读取时，多读取一次数据库。 但是，这种方案会存在缓存和 DB 的数据会不一致的情况，参照《缓存与数据库一致性优化》 所说。 我们需要解决缓存并行写，实现串行写。比较简单的方式，引入分布式锁。 在写请求时，先淘汰缓存之前，获取该分布式锁。 在读请求时，发现缓存不存在时，先获取分布式锁。 这样，缓存的并行写就成功的变成串行写落。写请求时，是否主动更新缓存，根据自己业务的需要，是否有，都没问题。 先写数据库，再更新缓存按照“先写数据库，再更新缓存”，我们要保证 DB 和缓存的操作，能够在“同一个事务”中，从而实现最终一致性。 基于定时任务来实现 首先，写入数据库。 然后，在写入数据库所在的事务中，插入一条记录到任务表。该记录会存储需要更新的缓存 KEY 和 VALUE 。 【异步】最后，定时任务每秒扫描任务表，更新到缓存中，之后删除该记录。 基于消息队列来实现 首先，写入数据库。 然后，发送带有缓存 KEY 和 VALUE 的事务消息。此时，需要有支持事务消息特性的消息队列，或者我们自己封装消息队列，支持事务消息。 【异步】最后，消费者消费该消息，更新到缓存中。 这两种方式，可以进一步优化，可以先尝试更新缓存，如果失败，则插入任务表，或者事务消息。 另外，极端情况下，如果并发写执行时，先更新成功 DB 的，结果后更新缓存： 理论来说，希望的更新缓存顺序是，线程 1 快于线程 2 ，但是实际线程1 晚于线程 2 ，导致数据不一致。 图中一直是基于定时任务或消息队列来实现异步更新缓存，如果网络抖动，导致【插入任务表，或者事务消息】的顺序不一致。 那么怎么解决呢？需要做如下三件事情： 1、在缓存值中，拼接上数据版本号或者时间戳。例如说：value = {value: 原值, version: xxx} 。 2、在任务表的记录，或者事务消息中，增加上数据版本号或者时间戳的字段。 3、在定时任务或消息队列执行更新缓存时，先读取缓存，对比版本号或时间戳，大于才进行更新。 当然，此处也会有并发问题，所以还是得引入分布式锁或 CAS 操作。 关于 Redis 分布式锁，可以看看 《精尽 Redis 面试题》 的 「如何使用 Redis 实现分布式锁？」 问题。 关于 Redis CAS 操作，可以看看 《精尽 Redis 面试题》 的 「什么是 Redis 事务？」 问题。 基于数据库的 binlog 日志重客户端写入缓存： 应用同时更新数据库和缓存 如果数据库更新成功，则开始更新缓存，否则如果数据库更新失败，则整个更新过程失败。 判断更新缓存是否成功，如果成功则返回 如果缓存没有更新成功，则将数据发到MQ中 应用监控MQ通道，收到消息后继续更新Redis。 问题点：如果更新Redis失败，同时在将数据发到MQ之前的时间，应用重启了，这时候MQ就没有需要更新的数据，如果Redis对所有数据没有设置过期时间，同时在读多写少的场景下，只能通过人工介入来更新缓存。 读缓存： 如何来解决这个问题？那么在写入Redis数据的时候，在数据中增加一个时间戳插入到Redis中。在从Redis中读取数据的时候，首先要判断一下当前时间有没有过期，如果没有则从缓存中读取，如果过期了则从数据库中读取最新数据覆盖当前Redis数据并更新时间戳。具体过程如下图所示： 客户端数据库与缓存解耦上述方案对于应用的研发人员来讲比较重，需要研发人员同时考虑数据库和Redis是否成功来做不同方案，如何让研发人员只关注数据库层面，而不用关心缓存层呢？请看下图： 应用直接写数据到数据库中。 数据库更新binlog日志。 利用Canal中间件读取binlog日志。 Canal借助于限流组件按频率将数据发到MQ中。 应用监控MQ通道，将MQ的数据更新到Redis缓存中。 可以看到这种方案对研发人员来说比较轻量，不用关心缓存层面，而且这个方案虽然比较重，但是却容易形成统一的解决方案。 PS：下面这两种比较实用 “先淘汰缓存，再写数据库”的方案，并且无需引入分布式锁。 “先写数据库，再更新缓存”的方案，并且无需引入定时任务或者消息队列。 使用缓存过程中，经常会遇到缓存数据的不一致性和脏读现象。一般情况下，采取缓存双淘汰机制，在更新数据库的前淘汰缓存。此外，设定超时时间，例如三十分钟。 极端场景下，即使有脏数据进入缓存，这个脏数据也最存在一段时间后自动销毁。 主从DB与cache一致性优化聚簇索引/非聚簇索引，MySQL索引底层实现，为什么不用B-Tree，为什么不用hash，叶子结点存放的是数据还是指向数据的内存地址，使用索引需要注意的几个地方？二叉搜索树 1.所有非叶子结点至多拥有两个儿子（Left和Right）； 2.所有结点存储一个关键字； 3.非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树； 如： 二叉搜索树的搜索，从根结点开始，如果查询的关键字与结点的关键字相等，那么就命中； 否则，如果查询关键字比结点关键字小，就进入左儿子；如果比结点关键字大，就进入 右儿子；如果左儿子或右儿子的指针为空，则报告找不到相应的关键字； 如果 二叉搜索树的所有非叶子结点的左右子树的结点数目均保持差不多（平衡），那么 二叉搜索树 的搜索性能逼近二分查找；但它比连续内存空间的二分查找的优点是，改变 二叉搜索树结构 （插入与删除结点）不需要移动大段的内存数据，甚至通常是常数开销； 如： 但 二叉搜索树在经过多次插入与删除后，有可能导致不同的结构： 右边也是一个 二叉搜索树，但它的搜索性能已经是线性的了；同样的关键字集合有可能导致不同的 树结构索引；所以，使用 二叉搜索树还要考虑尽可能让 二叉搜索树保持左图的结构，和避免右图的结构，也就是所谓的“平衡”问题； 实际使用的 二叉搜索树都是在原二叉搜索树的基础上加上平衡算法，即“平衡二叉树”；如何保持 二叉搜索树 结点分布均匀的平衡算法是平衡二叉树的关键；平衡算法是一种在 二叉搜索树中插入和删除结点的策略； B-树是一种多路搜索树（并不是二叉的）： 1.定义任意非叶子结点最多只有M个儿子；且M&gt;2； 2.根结点的儿子数为[2, M]； 3.除根结点以外的非叶子结点的儿子数为[M/2, M]； 4.每个结点存放至少M/2-1（取上整）和至多M-1个关键字；（至少2个关键字） 5.非叶子结点的关键字个数=指向儿子的指针个数-1； 6.非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]； 7.非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 8.所有叶子结点位于同一层； 如：（M=3） B-树的搜索，从根结点开始，对结点内的关键字（有序）序列进行二分查找，如果 命中则结束，否则进入查询关键字所属范围的儿子结点；重复，直到所对应的儿子指针为 空，或已经是叶子结点； B-树的特性： 1.关键字集合分布在整颗树中； 2.任何一个关键字出现且只出现在一个结点中； 3.搜索有可能在非叶子结点结束； 4.其搜索性能等价于在关键字全集内做一次二分查找； 5.自动层次控制； 由于限制了除根结点以外的非叶子结点，至少含有M/2个儿子，确保了结点的至少 利用率，其最底搜索性能为： 其中，M为设定的非叶子结点最多子树个数，N为关键字总数； 所以B-树的性能总是等价于二分查找（与M值无关），也就没有B树平衡的问题； 由于M/2的限制，在插入结点时，如果结点已满，需要将结点分裂为两个各占M/2的结点；删除结点时，需将两个不足M/2的兄弟结点合并； B+树 B+树是B-树的变体，也是一种多路搜索树： 1.其定义基本与B-树同，除了： 2.非叶子结点的子树指针与关键字个数相同； 3.非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树 （B-树是开区间）； 5.为所有叶子结点增加一个链指针； 6.所有关键字都在叶子结点出现； B+的搜索与B-树也基本相同，区别是B+树只有达到叶子结点才命中（B-树可以在 非叶子结点命中），其性能也等价于在关键字全集做一次二分查找； B+的特性： 1.所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好 是有序的； 2.不可能在非叶子结点命中； 3.非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储 （关键字）数据的数据层； 4.更适合文件索引系统； B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针； B*树定义了非叶子结点关键字个数至少为(2/3)*M，即块的最低使用率为2/3 （代替B+树的1/2）； B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据 复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父 结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针； B*树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分 数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字 （因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之 间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针； 所以，B*树分配新结点的概率比B+树要低，空间使用率更高； 小结B树：二叉树，每个结点只存储一个关键字，等于则命中，小于走左结点，大于走右结点； B-树：多路搜索树，每个结点存储M/2到M个关键字，非叶子结点存储指向关键字范围的子结点；所有关键字在整颗树中出现，且只出现一次，非叶子结点可以命中； B+树：在B-树基础上，为叶子结点增加链表指针，所有关键字都在叶子结点中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中； B*树：在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2/3； 聚簇索引所谓聚簇索引，就是指主索引文件和数据文件为同一份文件，聚簇索引主要用在Innodb存储引擎中。在该索引实现方式中B+Tree的叶子节点上的data就是数据本身，key为主键，如果是一般索引的话，data便会指向对应的主索引，如下图所示： 在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。 非聚簇索引非聚簇索引就是指B+Tree的叶子节点上的data，并不是数据本身，而是数据存放的地址。主索引和辅助索引没啥区别，只是主索引中的key一定得是唯一的。主要用在MyISAM存储引擎中 MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图： 这里设表一共有三列，假设我们以Col1为主键，则上图是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，只是主索引要求key是唯一的，而辅助索引的key可以重复。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示： 同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。 MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。 InnoDB索引实现 虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。 第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 上图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。 第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，下图为定义在Col3上的一个辅助索引： 这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 MyisAM顺序储存数据，索引叶子节点保存对应数据行地址，辅助索引跟主键索引相差无几（主键索引key不能相同）；InnoDB主键节点同时保存数据行，其他辅助索引保存的是主键索引的值； 了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调(可能是指“非递增”的意思)的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调(可能是指“非递增”的意思)的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。 为什么选用B+/-Tree一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。 B-Tree：如果一次检索需要访问4个节点，数据库系统设计者利用磁盘预读原理，把节点的大小设计为一个页，那读取一个节点只需要一次I/O操作，完成这次检索操作，最多需要3次I/O(根节点常驻内存)。数据记录越小，每个节点存放的数据就越多，树的高度也就越小，I/O操作就少了，检索效率也就上去了。 B+Tree：非叶子节点只存key，大大滴减少了非叶子节点的大小，那么每个节点就可以存放更多的记录，树更矮了，I/O操作更少了。所以B+Tree拥有更好的性能。 MySQL默认的事务隔离级别，MVCC、RR怎么实现的？RC如何实现的？MySQL事务隔离级别 事务隔离级别 脏读 不可重复读 幻读 读未提交（read-uncommitted） 是 是 是 不可重复读（read-committed） 否 是 是 可重复读（repeatable-read） 否 否 是 串行化（serializable） 否 否 否 mysql 默认的隔离级别:可重复读 Oracle 默认的隔离 级别:读已提交 MVCCMVCC(Multi Version Concurrency Control的简称)，代表多版本并发控制。与MVCC相对的，是基于锁的并发控制，Lock-Based Concurrency Control)。MVCC最大的优势：读不加锁，读写不冲突。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能 了解MVCC前，我们先学习下Mysql架构和数据库事务隔离级别 MYSQL 架构 MySQL从概念上可以分为四层，顶层是接入层，不同语言的客户端通过mysql的协议与mysql服务器进行连接通信，接入层进行权限验证、连接池管理、线程管理等。下面是mysql服务层，包括sql解析器、sql优化器、数据缓冲、缓存等。再下面是mysql中的存储引擎层，mysql中存储引擎是基于表的。最后是系统文件层，保存数据、索引、日志等。 MVCC是为了解决什么问题? 大多数的MYSQL事务型存储引擎,如,InnoDB，Falcon以及PBXT都不使用一种简单的行锁机制.事实上,他们都和MVCC–多版本并发控制来一起使用。 大家都应该知道,锁机制可以控制并发操作,但是其系统开销较大,而MVCC可以在大多数情况下代替行级锁,使用MVCC,能降低其系统开销。 MVCC具体实现MVCC是通过在每行记录后面保存两个隐藏的列来实现的。这两个列，一个保存了行的创建时间，一个保存行的过期时间（或删除时间）。当然存储的并不是实际的时间值，而是系统版本号（system version number)。每开始一个新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号，用来和查询到的每行记录的版本号进行比较。下面看一下在REPEATABLE READ隔离级别下，MVCC具体是如何操作的。 SELECT InnoDB会根据以下两个条件检查每行记录： 1、InnoDB只查找版本早于当前事务版本的数据行（也就是，行的系统版本号小于或等于事务的系统版本号），这样可以确保事务读取的行，要么是在事务开始前已经存在的，要么是事务自身插入或者修改过的。 2、行的删除版本要么未定义，要么大于当前事务版本号。这可以确保事务读取到的行，在事务开始之前未被删除。 只有符合上述两个条件的记录，才能返回作为查询结果。 INSERT InnoDB为新插入的每一行保存当前系统版本号作为行版本号。 DELETE InnoDB为删除的每一行保存当前系统版本号作为行删除标识。 UPDATE InnoDB为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。 保存这两个额外系统版本号，使大多数读操作都可以不用加锁。这样设计使得读数据操作很简单，性能很好，并且也能保证只会读取到符合标准的行，不足之处是每行记录都需要额外的存储空间，需要做更多的行检查工作，以及一些额外的维护工作 举例Demo123create table riemann( id int primary key auto_increment, name varchar(20)); transaction 1:1234start transaction;insert into riemann values(NULL,'riemann');insert into riemann values(NULL,'chow');commit; 假设系统初始事务ID为1； ID NAME 创建时间(事务ID) 过期时间(事务ID) 1 riemann 1 undefined 2 chow 1 undefined transaction 2: 1234start transaction;select * from riemann ; //(1)select * from riemann ; //(2)commit SELECT假设当执行事务2的过程中，准备执行语句(2)时，开始执行事务3： transaction 3:123start transaction;insert into riemann values(NULL,'peng');commit; ID NAME 创建时间(事务ID) 过期时间(事务ID) 1 riemann 1 undefined 2 chow 1 undefined 3 peng 3 undefined 事务3执行完毕，开始执行事务2 语句2，由于事务2只能查询创建时间小于等于2的，所以事务3新增的记录在事务2中是查不出来的，这就通过乐观锁的方式避免了幻读的产生。 UPDATE假设当执行事务2的过程中，准备执行语句(2)时，开始执行事务4： transaction session 4:123start transaction;update riemann set name = 'edgar' where id = 2;commit; InnoDB执行UPDATE，实际上是新插入了一行记录，并保存其创建时间为当前事务的ID，同时保存当前事务ID到要UPDATE的行的删除时间。 ID NAME 创建时间(事务ID) 过期时间(事务ID) 1 riemann 1 undefined 2 chow 1 4 3 edgar 4 undefined 事务4执行完毕，开始执行事务2 语句2，由于事务2只能查询创建时间小于等于2的，所以事务修改的记录在事务2中是查不出来的，这样就保证了事务在两次读取时读取到的数据的状态是一致的。 DELETE假设当执行事务2的过程中，准备执行语句(2)时，开始执行事务5： transaction session 5:123start transaction;delete from riemann where id = 2;commit; ID NAME 创建时间(事务ID) 过期时间(事务ID) 1 riemann 1 undefined 2 chow 1 5 事务5执行完毕，开始执行事务2 语句2，由于事务2只能查询创建时间小于等于2、并且过期时间大于等于2，所以id=2的记录在事务2 语句2中，也是可以查出来的,这样就保证了事务在两次读取时读取到的数据的状态是一致的。 RRMVCC(Multi-Version Concurrent Control)：多版本并发控制，只作用于RC和RR隔离级别，主要是为了避免脏读、非重复读，而非幻读，很多文章说通过MVCC避免幻读，其实这种说法是不完善的，RR隔离级别是通过next-key lock 来避免幻读。 优点：避免了许多需要加锁的情形 缺点：需要维护每行记录版本号，造成额外资源消耗 怎么避免脏读、不可重复读、幻读？ 采用RR隔离级别，结合MVCC特性，可以避免脏读、非重复读，有些文章说MVCC用来避免幻读，其实这是不准确的，MVCC通过多版本并发控制来避免非重复读，像幻读定义所说的情况即使有MVCC还是会存在。RR隔离级别是通过禁用innodb_locks_unsafe_for_binlog，在搜索和扫描索引的时候使用next-key locks来避免幻读（下面有对锁说明）。也就是为什么RR隔离级别下，非主键索引DML的操作并发性能会下降的原因了。 为了减少Next-key lock影响，可以设置innodb_locks_unsafe_for_binlog=1，就是disable Next-Key lock，但是并不建议。 想要真正避免幻读只能采取serializable串行化隔离级别，因为都要加表级共享锁或排他锁，所以性能会很差，一般不会采用。 MVCC如何避免非重复读： MVCC为查询提供了一个基于时间的点的快照。这个查询只能看到在自己之前提交的数据，而在查询开始之后提交的数据是不可以看到的。 在每行记录后面记录两个隐藏的列，一个记录创建时间，一个记录删除时间，记录的是版本号，这里可以理解为事物号。 INSERT：Innodb 为新插入的每一行保存当前系统版本号作为行版本号； DELETE：Innodb 为删除的每一行保存当前系统版本号作为行删除标识； UPDATE：Innodb 为插入一行新记录，保存当前系统版本号作为行版本号，同时保存当前系统版本号到原来的行作为行删除标识。 RR隔离级别下锁介绍Record Lock在主键或唯一索引上对单行记录加锁 Gap Lock针对非唯一索引而言，锁定一个范围的记录，但不包括记录本身。锁加在未使用的空闲空间上，可能是两个索引记录之间，也可能是第一个索引记录之前或最后一个索引之后的空间。 如果更新两端的记录会影响到间隙锁，那么操作会被挂起，等待间隙锁释放。 比如锁定范围（4，7），update table set v1=6 where v1=1; 虽然1不在此范围，但是6在（4，7）范围还是会锁定。 Next-Key Lock针对非唯一索引而言，行记录锁与间隙锁组合起来用就叫做Next-Key Lock。锁定一个范围，并且锁定记录本身。对于行的查询，都是采用该方法，主要目的是解决幻读的问题。 通过一个例子介绍间隙锁 表test5中存在如下数据： select * from test5 where v1=45 for update; 对v1=45的行加X锁，此时会对(40,45][45,50)加间隙锁，其他事物不能操作在此范围内的数据。 但是为什么在左侧值为40，右侧值为50的时候，有时候操作会被挂起，有时候操作不会挂起呢？ update table set v1=41 where v1=40;41在(40，50)范围会被锁定。 update table set v1=39 where v1=40; 39不在(40，50)范围不会被锁定。 update table set v1=42 where v1=1; 42在(40，50)范围会被锁定。 update table set v1=30 where v1=45; 30不在(40，50)范围，但是45行上面存在的行级record lock，45行记录也被加了锁。 insert into table(id,name) values(14,40);可以插入 insert into table(id,name) values(20,40);不可以插入 insert into table(id,name) values(13,50);不可以插入 insert into table(id,name) values(21,40);可以插入 当插入左侧值的时候，即插入v1=40的时候，要求插入的id值小于id=16的范围。当v1=40的记录有多条的时候，插入的id值要小于其中的最大id值。则可以成功插入； 当插入右侧值的时候，即插入v1=50的时候，要求插入的id值要大于id=18的范围。当v1=50的记录有多条的时候，插入的id值要大于其中的最小id值。则可以成功插入。 所以为什么RR隔离级别下并发性能会有所下降，就是因为存在间隙锁。我们应该尽量使用主键或唯一索引，因为唯一索引会把Next-Key Lock降级为Record Lock。 AUTO-INC Lock只针对存在主键的insert操作，由innodb_autoinc_lock_mode参数决定锁粒度。 在了解自增锁前需要知道mysql都有哪些insert操作： 锁类型 描述 INSERT-like 所有可以向表中增加行的语句 Simple inserts 可以预先确定要插入的行数insert…values… Bulk inserts 事先不知道要插入的行数（INSERT…SELECT,REPLACE…SELECT,LOAD DATA） Mixed-mode inserts 一些是“Simple inserts”语句但是有一些是null的自增值 innodb_autoinc_lock_mode= 0 传统锁定模式（所有insert采用传统AUTO-INC机制），所有“INSERT-like”语句获得一个特殊的表级AUTO-INC锁，在存在自增列的表获得一个特殊的表级AUTO-INC锁，(statement-based replication)操作是安全。 innodb_autoinc_lock_mode= 1 默认锁定模式（bulk-insert采用表级锁） “bulk inserts”仍然使用AUTO-INC表级锁,并保持到语句结束；“Simple inserts”（要插入的行数事先已知）通过在mutex（轻量锁）的控制下获得所需数量的自动递增值来避免表级AUTO-INC锁，只在分配的时间内持有，不是整个语句，(statement-based replication)操作是安全。 innodb_autoinc_lock_mode= 2 轻量锁定模式(所有insert采用轻量级） 所有类INSERT(“INSERT-like” )语句都不会使用表级AUTO-INC lock，”批量插入”时，在由任何给定语句分配的自动递增值中可能存在间隙，(statement-based replication)操作是不安全。 可以汇总为如下表格： 示例：innodb_autoinc_lock_mode= 1时不连续 123456789创建一个表id为自增主键：CREATE TABLE `test6` (id int(11) NOT NULL AUTO_INCREMENT,name int(11),modified TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 先插入一条记录，然后再多次自插入数据，发现id没有5、10~12，如下： 这种情况就是上面锁说的，insert…select…属于Bulk insert，不能预判要插入多少条数据，所以在自增值分配上每次都会按照2^n-1分配： 第一次，先分配一个自增值，因为只有一条数据，正好 第二次，先分配一个自增值3，发现还有数据，继续按2^n-1分配，分配4、5，此时只剩一条数据4，但5已经被分配出去。 第三次，因为5已经被分配出去，此时只能从6开始，以此类推。 Dead lock是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象。 死锁检测开关innodb_deadlock_detect 5.7.15后引入，关闭会提升性能，一般应用在秒杀等场景。 出现死锁场景很多，绝大多数是高并发下同时操作一行数据，加锁顺序相反引起。 先删再插，两条insert当需要进行唯一性冲突检测时，需要先加一个S锁，也会产生死锁。 那么对应的解决死锁问题的关键就是：让不同的session加锁有次序。 MySQL 中RC和RR隔离级别的区别MySQL数据库中默认隔离级别为RR，但是实际情况是使用RC 和 RR隔离级别的都不少。好像淘宝、网易都是使用的 RC 隔离级别。那么在MySQL中 RC 和 RR有什么区别呢？我们该如何选择呢？为什么MySQL将RR作为默认的隔离级别呢？ RC 与 RR 在锁方面的区别1&gt; 显然 RR 支持 gap lock(next-key lock)，而RC则没有gap lock。因为MySQL的RR需要gap lock来解决幻读问题。而RC隔离级别则是允许存在不可重复读和幻读的。所以RC的并发一般要好于RR； 2&gt; RC 隔离级别，通过 where 条件过滤之后，不符合条件的记录上的行锁，会释放掉(虽然这里破坏了“两阶段加锁原则”)；但是RR隔离级别，即使不符合where条件的记录，也不会是否行锁和gap lock；所以从锁方面来看，RC的并发应该要好于RR；另外 insert into t select … from s where 语句在s表上的锁也是不一样的，参见下面的例子2； 下面是来自 github 的一个例子： MySQL5.6, 隔离级别RR，autocommit=off; 表结构：12345678910111213mysql&gt; show create table t1\G*************************** 1. row *************************** Table: t1Create Table: CREATE TABLE `t1` ( `a` int(11) NOT NULL, `b` int(11) NOT NULL, `c` int(11) NOT NULL, `d` int(11) NOT NULL, `e` varchar(20) DEFAULT NULL, PRIMARY KEY (`a`), KEY `idx_t1_bcd` (`b`,`c`,`d`)) ENGINE=InnoDB DEFAULT CHARSET=latin11 row in set (0.00 sec) 表数据：1234567891011121314mysql&gt; select * from t1;+---+---+---+---+------+| a | b | c | d | e |+---+---+---+---+------+| 1 | 1 | 1 | 1 | a || 2 | 2 | 2 | 2 | b || 3 | 3 | 2 | 2 | c || 4 | 3 | 1 | 1 | d || 5 | 2 | 3 | 5 | e || 6 | 6 | 4 | 4 | f || 7 | 4 | 5 | 5 | g || 8 | 8 | 8 | 8 | h |+---+---+---+---+------+8 rows in set (0.00 sec) session 1:1delete from t1 where b&gt;2 and b&lt;5 and c=2; 执行计划如下：12345678910111213mysql&gt; explain select * from t1 where b&gt;2 and b&lt;5 and c=2\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: t1 type: rangepossible_keys: idx_t1_bcd key: idx_t1_bcd key_len: 4 ref: NULL rows: 2 Extra: Using index condition1 row in set (0.00 sec) session 2:1delete from t1 where a=4 结果 session 2 被锁住。session 3:1234567mysql&gt; select * from information_schema.innodb_locks;+---------------+-------------+-----------+-----------+-------------+------------+------------+-----------+----------+-----------+| lock_id | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |+---------------+-------------+-----------+-----------+-------------+------------+------------+-----------+----------+-----------+| 38777:390:3:5 | 38777 | X | RECORD | `test`.`t1` | PRIMARY | 390 | 3 | 5 | 4 || 38771:390:3:5 | 38771 | X | RECORD | `test`.`t1` | PRIMARY | 390 | 3 | 5 | 4 |+---------------+-------------+-----------+-----------+-------------+------------+------------+-----------+----------+-----------+ 根据锁及ICP的知识，此时加锁的情况应该是在索引 idx_t1_bcd 上的b&gt;2 and b&lt;5之间加gap lock, idx_t1_bcd上的c=2 加 X锁主键 a=3 加 x 锁。应该a=4上是没有加X锁的，可以进行删除与更改。但是从session3上的结果来，此时a=4上被加上了X锁。求大牛解惑，谢谢。 要理解这里为什么 a=4 被锁住了，需要理解 gap lock，锁处理 RR 隔离级别和RC隔离级别的区别等等。 这里的原因如下： 很简单，我们注意到：key_len: 4 和 Extra: Using index condition这说明了，仅仅使用了索引 idx_t1_bcd 中的 b 一列，没有使用到 c 这一列。c 这一列是在ICP时进行过滤的。所以： delete from t1 where b&gt;2 and b&lt;5 and c=2 其实锁定的行有：12345678910mysql&gt; select * from t1 where b&gt;2 and b&lt;=6;+---+---+---+---+------+| a | b | c | d | e |+---+---+---+---+------+| 3 | 3 | 2 | 2 | c || 4 | 3 | 1 | 1 | d || 6 | 6 | 4 | 4 | f || 7 | 4 | 5 | 5 | g |+---+---+---+---+------+4 rows in set (0.00 sec) 所以显然 delete from t1 where a=4就被阻塞了。那么为什么 delete from t1 where a=6 也会被阻塞呢？？？ 这里 b&lt;=6的原因是，b 列中没有等于 5 的记录，所以 and b&lt;5 实现为锁定 b&lt;=6 的所有索引记录，这里有等于号的原因是，如果我们不锁定 =6 的索引记录，那么怎么实现锁定 &lt;5 的gap 呢？也就是说锁定 b=6 的索引记录，是为了实现锁定 b&lt; 5 的gap。也就是不能删除 b=6 记录的原因。而这里 b &gt;2 没有加等于号(b&gt;=2) 的原因，是因为 b&gt;2的这个gap 是由 b=3这个索引记录(的gap)来实现的，不是由 b=2索引记录(的gap) 来实现的，b=2的索引记录的gap lock只能实现锁定&lt;2的gap，b&gt;2的gap锁定功能，需要由 b=3的索引记录对应的gap来实现(b&gt;2，b&lt;3的gap)。所以我们在session2中可以删除：a=1,2,5,8的记录，但是不能删除 a=6(因为该行的b=6)的记录。 如果我们使用 RC 隔离级别时，则不会发生阻塞，其原因就是： RC和RR隔离级别中的锁处理不一样，RC隔离级别时，在使用c列进行ICP where条件过滤时，对于不符合条件的记录，锁会释放掉，而RR隔离级别时，即使不符合条件的记录，锁也不会释放(虽然违反了“2阶段锁”原则)。所以RC隔离级别时session 2不会被阻塞。 Gap lock: This is a lock on a gap between index records, or a lock on the gap before the first or after the last index record. 例子2：insert into t select ... from s where 在RC 和 RR隔离级别下的加锁过程 下面是官方文档中的说明： 12345INSERT INTO T SELECT ... FROM S WHERE ... sets an exclusive index record lock (without a gap lock) on each row inserted into T. If the transaction isolation level is READ COMMITTED, or innodb_locks_unsafe_for_binlog is enabled and the transaction isolation level is not SERIALIZABLE, InnoDB does the search on S as a consistent read (no locks). Otherwise, InnoDB sets shared next-key locks on rows from S. InnoDB has to set locks in the latter case: In roll-forward recovery from a backup, every SQL statement must be executed in exactly the same way it was done originally.CREATE TABLE ... SELECT ... performs the SELECT with shared next-key locks or as a consistent read, as for INSERT ... SELECT.When a SELECT is used in the constructs REPLACE INTO t SELECT ... FROM s WHERE ... or UPDATE t ... WHERE col IN (SELECT ... FROM s ...), InnoDB sets shared next-key locks on rows from table s. insert inot t select ... from s where ...语句和 create table ... select ... from s where加锁过程是相似的(RC 和 RR 加锁不一样)： 1&gt; RC 隔离级别时和 RR隔离级别但是设置innodb_locks_unsafe_for_binlog=1 时，select ... from s where对 s 表进行的是一致性读，所以是无需加锁的； 2&gt; 如果是RR隔离级别(默认innodb_locks_unsafe_for_binlog=0)，或者是 serializable隔离级别，那么对 s 表上的每一行都要加上 shared next-key lock. 这个区别是一个很大的不同，下面是生成中的一个 insert into t select ... from s where导致的系统宕机的案例： 一程序猿执行一个分表操作：123insert into tb_async_src_acct_201508 select * from tb_async_src_acct where src_status=3 and create_time&gt;='2015-08-01 00:00:00' and create_time &lt;= '2015-08-31 23:59:59'; 表 tb_async_src_acct有4000W数据。分表的目的是想提升下性能。结果一执行该语句，该条SQL被卡住，然后所有向 tb_async_src_acct的写操作，要么是 get lock fail, 要么是 lost connection，全部卡住，然后主库就宕机了。 显然这里的原因，就是不知道默认RR隔离级别中 insert into t select ... from s where语句的在 s 表上的加锁过程，该语句一执行，所有符合 where 条件的 s 表中的行记录都会加上 shared next-key lock(如果没有使用到索引，还会锁住表中所有行)，在整个事务过程中一直持有，因为表 tb_async_src_acct 数据很多，所以运行过程是很长的，所以加锁过程也是很长，所以其它所有的对tb_async_src_acct 的insert, delete, update, DDL 都会被阻塞掉，这样被阻塞的事务就越来越多，而事务也会申请其它的表中的行锁，结果就是系统中被卡住的事务越来越多，系统自然就宕机了。 RC 与 RR 在复制方面的区别 RC 隔离级别不支持 statement 格式的bin log，因为该格式的复制，会导致主从数据的不一致；只能使用 mixed 或者 row 格式的bin log; 这也是为什么MySQL默认使用RR隔离级别的原因。复制时，我们最好使用：binlog_format=row MySQL5.6 的早期版本，RC隔离级别是可以设置成使用statement格式的bin log，后期版本则会直接报错； RC 与 RR 在一致性读方面的区别简单而且，RC隔离级别时，事务中的每一条select语句会读取到他自己执行时已经提交了的记录，也就是每一条select都有自己的一致性读ReadView; 而RR隔离级别时，事务中的一致性读的ReadView是以第一条select语句的运行时，作为本事务的一致性读snapshot的建立时间点的。只能读取该时间点之前已经提交的数据。 RC 支持半一致性读，RR不支持RC隔离级别下的update语句，使用的是半一致性读(semi consistent)；而RR隔离级别的update语句使用的是当前读；当前读会发生锁的阻塞。 1&gt; 半一致性读： A type of read operation used for UPDATE statements, that is a combination of read committed and consistent read. When an UPDATE statement examines a row that is already locked, InnoDB returns the latest committed version to MySQL so that MySQL can determine whether the row matches the WHERE condition of the UPDATE. If the row matches (must be updated), MySQL reads the row again, and this time InnoDB either locks it or waits for a lock on it. This type of read operation can only happen when the transaction has the read committed isolation level, or when the innodb_locks_unsafe_for_binlog option is enabled. 简单来说，semi-consistent read是read committed与consistent read两者的结合。一个update语句，如果读到一行已经加锁的记录，此时InnoDB返回记录最近提交的版本，由MySQL上层判断此版本是否满足 update的where条件。若满足(需要更新)，则MySQL会重新发起一次读操作，此时会读取行的最新版本(并加锁)。semi-consistent read只会发生在read committed隔离级别下，或者是参数innodb_locks_unsafe_for_binlog被设置为true(该参数即将被废弃)。 对比RR隔离级别，update语句会使用当前读，如果一行被锁定了，那么此时会被阻塞，发生锁等待。而不会读取最新的提交版本，然后来判断是否符合where条件。 半一致性读的优点： 减少了update语句时行锁的冲突；对于不满足update更新条件的记录，可以提前放锁，减少并发冲突的概率。 具体可以参见： Oracle中的update好像有“重启动”的概念。 MySQL间隙锁有没有了解，死锁有没有了解，写一段会造成死锁的SQL语句，死锁发生了如何解决，MySQL有没有提供什么机制去解决死锁间隙锁之前我们介绍了排他锁，其实innodb下的记录锁（也叫行锁），间隙锁，next-key锁统统属于排他锁。 行锁记录锁其实很好理解，对表中的记录加锁，叫做记录锁，简称行锁。 生活中的间隙锁编程的思想源于生活，生活中的例子能帮助我们更好的理解一些编程中的思想。生活中排队的场景，小明，小红，小花三个人依次站成一排，此时，如何让新来的小刚不能站在小红旁边，这时候只要将小红和她前面的小明之间的空隙封锁，将小红和她后面的小花之间的空隙封锁，那么小刚就不能站到小红的旁边。这里的小红，小明，小花，小刚就是数据库的一条条记录。他们之间的空隙也就是间隙，而封锁他们之间距离的锁，叫做间隙锁。 Mysql中的间隙锁下表中（见图一），id为主键，number字段上有非唯一索引的二级索引，有什么方式可以让该表不能再插入number=5的记录？ 图一根据上面生活中的例子，我们自然而然可以想到，只要控制几个点，number=5之前不能插入记录，number=5现有的记录之间不能再插入新的记录，number=5之后不能插入新的记录，那么新的number=5的记录将不能被插入进来。 那么，mysql是如何控制number=5之前，之中，之后不能有新的记录插入呢（防止幻读）？答案是用间隙锁，在RR级别下，mysql通过间隙锁可以实现锁定number=5之前的间隙，number=5记录之间的间隙，number=5之后的间隙，从而使的新的记录无法被插入进来。 间隙是怎么划分的？ 注：为了方面理解，我们规定（id=A,number=B）代表一条字段id=A,字段number=B的记录，（C，D）代表一个区间，代表C-D这个区间范围。 图一中，根据number列，我们可以分为几个区间：（无穷小，2），（2，4），（4，5），（5，5），（5,11），（11，无穷大）。只要这些区间对应的两个临界记录中间可以插入记录，就认为区间对应的记录之间有间隙。例如：区间（2，4）分别对应的临界记录是（id=1,number=2），（id=3，number=4），这两条记录中间可以插入（id=2,number=3）等记录，那么就认为（id=1,number=2）与（id=3，number=4）之间存在间隙。 很多人会问，那记录（id=6，number=5）与（id=8，number=5）之间有间隙吗？答案是有的，（id=6，number=5）与（id=8，number=5）之间可以插入记录（id=7，number=5），因此（id=6,number=5）与（id=8,number=5）之间有间隙的， 间隙锁锁定的区域根据检索条件向左寻找最靠近检索条件的记录值A，作为左区间，向右寻找最靠近检索条件的记录值B作为右区间，即锁定的间隙为（A，B）。图一中，where number=5的话，那么间隙锁的区间范围为（4,11）； 间隙锁的目的是为了防止幻读，其主要通过两个方面实现这个目的：（1）防止间隙内有新数据被插入（2）防止已存在的数据，更新成间隙内的数据（例如防止numer=3的记录通过update变成number=5） innodb自动使用间隙锁的条件：（1）必须在RR级别下（2）检索条件必须有索引（没有索引的话，mysql会全表扫描，那样会锁定整张表所有的记录，包括不存在的记录，此时其他事务不能修改不能删除不能添加） 接下来，通过实际操作观察下间隙锁的作用范围 案例一12345678910111213session 1:start transaction ;select * from news where number=4 for update ;session 2:start transaction ;insert into news value(2,4);#（阻塞）insert into news value(2,2);#（阻塞）insert into news value(4,4);#（阻塞）insert into news value(4,5);#（阻塞）insert into news value(7,5);#（执行成功）insert into news value(9,5);#（执行成功）insert into news value(11,5);#（执行成功） 检索条件number=4,向左取得最靠近的值2作为左区间，向右取得最靠近的5作为右区间，因此，session 1的间隙锁的范围（2，4），（4，5），如下图所示： 间隙锁锁定的区间为（2，4），（4，5），即记录（id=1,number=2）和记录（id=3,number=4）之间间隙会被锁定，记录（id=3,number=4）和记录（id=6,number=5）之间间隙被锁定。 因此记录（id=2,number=4），（id=2,number=2），（id=4,number=4），（id=4,number=5）正好处在（id=3,number=4）和（id=6,number=5）之间，所以插入不了，需要等待锁的释放，而记录(id=7,number=5)，（id=9,number=5），（id=11,number=5）不在上述锁定的范围内，因此都会插入成功。 案例二123456789101112session 1:start transaction ;select * from news where number=13 for update ;session 2:start transaction ;insert into news value(11,5);#(执行成功)insert into news value(12,11);#(执行成功)insert into news value(14,11);#(阻塞)insert into news value(15,12);#(阻塞)update news set id=14 where number=11;#(阻塞)update news set id=11 where number=11;#(执行成功) 检索条件number=13,向左取得最靠近的值11作为左区间，向右由于没有记录因此取得无穷大作为右区间，因此，session 1的间隙锁的范围（11，无穷大），如下图所示： 此表中没有number=13的记录的，innodb依然会为该记录左右两侧加间隙锁，间隙锁的范围（11，无穷大）。 有人会问，为啥update news set id=14 where number=11会阻塞，但是update news set id=11 where number=11却执行成功呢？ 间隙锁采用在指定记录的前面和后面以及中间的间隙上加间隙锁的方式避免数据被插入，此图间隙锁锁定的区域是（11，无穷大），也就是记录（id=13,number=11）之后不能再插入记录，update news set id=14 where number=11这条语句如果执行的话，将会被插入到（id=13,number=11）的后面，也就是在区间（11，无穷大）之间，由于该区间被间隙锁锁定，所以只能阻塞等待，而update news set id=11 where number=11执行后是会被插入到（id=13,number=11）的记录前面，也就不在（11，无穷大）的范围内，所以无需等待，执行成功。 案例三12345678910111213141516session 1:start transaction ;select * from news where number=5 for update;session 2:start transaction ;insert into news value(4,4);#(阻塞)insert into news value(4,5);#(阻塞)insert into news value(5,5);#(阻塞)insert into news value(7,11);#(阻塞)insert into news value(9,12);#(执行成功)insert into news value(12,11);#(阻塞)update news set number=5 where id=1;#(阻塞)update news set id=11 where number=11;#(阻塞)update news set id=2 where number=4 ;#（执行成功）update news set id=4 where number=4 ;#（阻塞） 检索条件number=5,向左取得最靠近的值4作为左区间，向右取得11为右区间，因此，session 1的间隙锁的范围（4，5），（5，11），如下图所示： 有人会问，为啥insert into news value(9,12)会执行成功？间隙锁采用在指定记录的前面和后面以及中间的间隙上加间隙锁的方式避免数据被插入，（id=9,number=12）很明显在记录（13,11）的后面，因此不再锁定的间隙范围内。 为啥update news set number=5 where id=1会阻塞？number=5的记录的前面，后面包括中间都被封锁了，你这个update news set number=5 where id=1根本没法执行，因为innodb已经把你可以存放的位置都锁定了，因为只能等待。 同理，update news set id=11 where number=11由于记录（id=10,number=5）与记录（id=13,number=11）中间的间隙被封锁了，你这句sql也没法执行，必须等待，因为存放的位置被封锁了。 案例四1234567891011session 1:start transaction;select * from news where number&gt;4 for update;session 2:start transaction;update news set id=2 where number=4 ;#(执行成功)update news set id=4 where number=4 ;#(阻塞)update news set id=5 where number=5 ;#(阻塞)insert into news value(2,3);#(执行成功)insert into news value(null,13);#(阻塞) 检索条件number&gt;4,向左取得最靠近的值4作为左区间，向右取无穷大，因此，session 1的间隙锁的范围（4，无穷大），如下图所示： session2中之所以有些阻塞，有些执行成功，其实就是因为插入的区域被锁定，从而阻塞。 next-key锁 next-key锁其实包含了记录锁和间隙锁，即锁定一个范围，并且锁定记录本身，InnoDB默认加锁方式是next-key 锁。上面的案例一session 1中的sql是：select * from news where number=4 for update ;next-key锁锁定的范围为间隙锁+记录锁，即区间（2，4），（4，5）加间隙锁，同时number=4的记录加记录锁。 死锁概念MySQL有三种锁的级别：页级、表级、行级。 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 算法： next KeyLocks锁，同时锁住记录(数据)，并且锁住记录前面的GapGap锁，不锁记录，仅仅记录前面的Gap Recordlock锁（锁数据，不锁Gap） 所以其实 Next-KeyLocks=Gap锁+ Recordlock锁 什么情况下会造成死锁所谓死锁&lt;DeadLock&gt;: 是指两个或两个以上的进程在执行过程中,因争夺资源而造成的一种互相等待的现象,若无外力作用,它们都将无法推进下去.此时称系统处于死锁状态或系统产生了死锁,这些永远在互相等竺的进程称为死锁进程.表级锁不会产生死锁.所以解决死锁主要还是针对于最常用的InnoDB. 死锁的关键在于：两个(或以上)的Session加锁的顺序不一致。 那么对应的解决死锁问题的关键就是：让不同的session加锁有次序 一些常见的死锁案例案例一需求：将投资的钱拆成几份随机分配给借款人。 起初业务程序思路是这样的： 投资人投资后，将金额随机分为几份，然后随机从借款人表里面选几个，然后通过一条条select for update 去更新借款人表里面的余额等。 抽象出来就是一个session通过for循环会有几条如下的语句：Select * from xxx where id=&#39;随机id&#39; for update 基本来说，程序开启后不一会就死锁。这可以是说最经典的死锁情形了。 例如两个用户同时投资，A用户金额随机分为2份，分给借款人1，2B用户金额随机分为2份，分给借款人2，1由于加锁的顺序不一样，死锁当然很快就出现了。 对于这个问题的改进很简单，直接把所有分配到的借款人直接一次锁住就行了。 Select * from xxx where id in (xx,xx,xx) for update 在in里面的列表值mysql是会自动从小到大排序，加锁也是一条条从小到大加的锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061例如（以下会话id为主键）：Session1:mysql&gt; select * from t3 where id in (8,9) for update;+----+--------+------+---------------------+| id | course | name | ctime |+----+--------+------+---------------------+| 8 | WA | f | 2016-03-02 11:36:30 || 9 | JX | f | 2016-03-01 11:36:30 |+----+--------+------+---------------------+rows in set (0.04 sec) Session2:select * from t3 where id in (10,8,5) for update;锁等待中……其实这个时候id=10这条记录没有被锁住的，但id=5的记录已经被锁住了，锁的等待在id=8的这里。 不信请看Session3:mysql&gt; select * from t3 where id=5 for update;锁等待中 Session4:mysql&gt; select * from t3 where id=10 for update;+----+--------+------+---------------------+| id | course | name | ctime |+----+--------+------+---------------------+| 10 | JB | g | 2016-03-10 11:45:05 |+----+--------+------+---------------------+row in set (0.00 sec) 在其它session中id=5是加不了锁的，但是id=10是可以加上锁的。 案例2在开发中，经常会做这类的判断需求：根据字段值查询（有索引），如果不存在，则插入；否则更新。 12345678910111213141516171819202122232425262728293031以id为主键为例，目前还没有id=22的行Session1:select * from t3 where id=22 for update;Empty set (0.00 sec) session2:select * from t3 where id=23 for update;Empty set (0.00 sec) Session1:insert into t3 values(22,'ac','a',now());锁等待中…… Session2:insert into t3 values(23,'bc','b',now());ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction 当对存在的行进行锁的时候(主键)，mysql就只有行锁。 当对未存在的行进行锁的时候(即使条件为主键)，mysql是会锁住一段范围（有gap锁） 锁住的范围为： (无穷小或小于表中锁住id的最大值，无穷大或大于表中锁住id的最小值) 如：如果表中目前有已有的id为（11 ， 12） 那么就锁住（12，无穷大） 如果表中目前已有的id为（11 ， 30） 那么就锁住（11，30） 对于这种死锁的解决办法是： insert into t3(xx,xx) on duplicate key update `xx`=&#39;XX&#39;; 用mysql特有的语法来解决此问题。因为insert语句对于主键来说，插入的行不管有没有存在，都会只有行锁。 案例312345678910111213141516171819202122232425262728mysql&gt; select * from t3 where id=9 for update;+----+--------+------+---------------------+| id | course | name | ctime |+----+--------+------+---------------------+| 9 | JX | f | 2016-03-01 11:36:30 |+----+--------+------+---------------------+row in set (0.00 sec) Session2:mysql&gt; select * from t3 where id&lt;20 for update;锁等待中 Session1:mysql&gt; insert into t3 values(7,'ae','a',now());ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction 这个跟案例一其它是差不多的情况，只是session1不按常理出牌了， Session2在等待Session1的id=9的锁，session2又持了1到8的锁（注意9到19的范围并没有被session2锁住），最后，session1在插入新行时又得等待session2,故死锁发生了。 这种一般是在业务需求中基本不会出现，因为你锁住了id=9，却又想插入id=7的行，这就有点跳了，当然肯定也有解决的方法，那就是重理业务需求，避免这样的写法。 有两个表，table a，table b，写SQL查询出仅在table a中的数据、仅在table b中的数据、既在table a 又在table b 中的数据？]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试分享(二).框架相关(Spring)]]></title>
    <url>%2F2019%2F05%2F18%2F%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB(%E4%BA%8C).%E6%A1%86%E6%9E%B6%E7%9B%B8%E5%85%B3(Spring)%2F</url>
    <content type="text"><![CDATA[框架相关（Spring）Spring源码看过没有，会多少讲多少？灵魂问题，，，自己发挥 各个组件Resource是对资源的抽象，每一个接口实现类都代表了一种资源类型，如 ClasspathResource 、 URLResource ， FileSystemResource 等。每一个资源类型都封装了对某一种特定资源的访问策略。它是 spring 资源访问策略的一个基础实现，应用在很多场景。 BeanDefinition用来抽象和描述一个具体 bean 对象。是描述一个 bean 对象的基本数据结构。 BeanDefinitionReaderBeanDefinitionReader 将外部资源对象描述的 bean 定义统一转化为统一的内部数据结构 BeanDefinition 。对应不同的描述需要有不同的 Reader 。如 XmlBeanDefinitionReader 用来读取 xml 描述配置的 bean 对象。 BeanFactory用来定义一个很纯粹的 bean 容器。它是一个 bean 容器的必备结构。同时和外部应用环境等隔离。 BeanDefinition 是它的基本数据结构。它维护一个 BeanDefinitions Map, 并可根据 BeanDefinition 的描述进行 bean 的创建和管理。 ApplicationContext从名字来看叫应用上下文，是和应用环境息息相关的。没错这个就是我们平时开发中经常直接使用打交道的一个类，应用上下文，或者也叫做 spring 容器。其实它的基本实现是会持有一个 BeanFactory 对象，并基于此提供一些包装和功能扩展。为什么要这么做呢？因为 BeanFactory 实现了一个容器基本结构和功能，但是与外部环境隔离。那么读取配置文件，并将配置文件解析成 BeanDefinition ，然后注册到 BeanFactory 的这一个过程的封装自然就需要 ApplicationContext 。 ApplicationContext 和应用环境细细相关，常见实现有 ClasspathXmlApplicationContext,FileSystemXmlApplicationContext,WebApplicationContext 等。 Classpath 、 xml 、 FileSystem 、 Web 等词都代表了应用和环境相关的一些意思，从字面上不难理解各自代表的含义。 当然 ApplicationContext 和 BeanFactory 的区别远不止于此，有： 资源访问功能：在 Resource 和 ResourceLoader 的基础上可以灵活的访问不同的资源。 支持不同的信息源。 支持应用事件：继承了接口 ApplicationEventPublisher ，这样在上下文中为 bean 之间提供了事件机制。 以上 5 个组件基本代表了 ioc 容器的一个最基本组成，而组件的组合是放在 ApplicationContext 的实现这一层来完成。 左边黄色部分是 ApplicationContext 体系继承结构，右边是 BeanFactory 的结构体系,两个结构是典型模板方法设计模式的使用。 从该继承体系可以看出： BeanFactory 是一个 bean 工厂的最基本定义，里面包含了一个 bean 工厂的几个最基本的方法， getBean(…) 、 containsBean(…) 等 ,是一个很纯粹的bean工厂，不关注资源、资源位置、事件等。 ApplicationContext 是一个容器的最基本接口定义，它继承了 BeanFactory, 拥有工厂的基本方法。同时继承了 ApplicationEventPublisher 、 MessageSource 、 ResourcePatternResolver 等接口，使其 定义了一些额外的功能，如资源、事件等这些额外的功能。 AbstractBeanFactory 和 AbstractAutowireCapableBeanFactory 是两个模板抽象工厂类。 AbstractBeanFactory 提供了 bean 工厂的抽象基类，同时提供了 ConfigurableBeanFactory 的完整实现。 AbstractAutowireCapableBeanFactory 是继承了 AbstractBeanFactory 的抽象工厂，里面提供了 bean 创建的支持，包括 bean 的创建、依赖注入、检查等等功能，是一个核心的 bean 工厂基类。 ClassPathXmlApplicationContext之 所以拥有 bean 工厂的功能是通过持有一个真正的 bean 工厂 DefaultListableBeanFactory 的实例，并通过 代理 该工厂完成。 ClassPathXmlApplicationContext 的初始化过程是对本身容器的初始化同时也是对其持有的 DefaultListableBeanFactory 的初始化。 容器初始化过程整个过程可以理解为是容器的初始化过程。第一个过程是 ApplicationContext 的职责范围，第二步是 BeanFactory 的职责范围。可以看出 ApplicationContext 是一个运行时的容器需要提供不容资源环境的支持，屏蔽不同环境的差异化。而 BeanDifinition 是内部关于 bean 定义的基本结构。 Bean 的创建就是基于它，回头会介绍一下改结构的定义。下面看一下整个容器的初始化过程。 容器的初始化是通过调用 refresh() 来实现。该方法是非常重要的一个方法，定义在 AbstractApplicationContext 接口里。 AbstractApplicationContext 是容器的最基础的一个抽象父类。也就是说在该里面定义了一个容器初始化的基本流程，流程里的各个方法有些有提供了具体实现，有些是抽象的 ( 因为不同的容器实例不一样 ) ，由继承它的每一个具体容器完成定制。看看 refresh 的基本流程：1234567891011121314151617181920212223242526272829303132333435363738public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; // Destroy already created singletons to avoid dangling resources. beanFactory.destroySingletons(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; &#125; &#125; Bean 的创建过程Bean的创建过程基本是BeanFactory所要完成的事情. 根据以上过程，将会重点带着以下两个个问题来理解核心代码： 1.Bean 的创建时机 bean 是在什么时候被创建的，有哪些规则。 2.Bean 的创建过程 bean 是怎么创建的，会选择哪个构造函数？依赖如何注入？ InitializingBean 的 set 方法什么时候被调用？实现 ApplicationContextAware, BeanFactoryAware,BeanNameAware, ResourceLoaderAware 这些接口的 bean 的 set 方法何时被调用？ 在解释这两个问题前，先看一下 BeanDefinition 接口的定义。 从该接口定义可以看出，通过 bean 定义能够得到 bean 的详细信息，如类名子、工厂类名称、 scope 、是否单例、是否抽象、是否延迟加载等等。基于此，来看一下以下两个问题： 问题 1 ： Bean 的创建时机bean 是在什么时候被创建的，有哪些规则？ 容器初始化的时候会预先对单例和非延迟加载的对象进行预先初始化。其他的都是延迟加载是在第一次调用 getBean 的时候被创建。从 DefaultListableBeanFactory 的 preInstantiateSingletons 里可以看到这个规则的实现。 123456789101112131415161718192021222324252627public void preInstantiateSingletons() throws BeansException &#123; if (this.logger.isInfoEnabled()) &#123; this.logger.info("Pre-instantiating singletons in " + this); &#125; synchronized (this.beanDefinitionMap) &#123; for (Iterator it = this.beanDefinitionNames.iterator(); it.hasNext();) &#123; String beanName = (String) it.next(); RootBeanDefinition bd = getMergedLocalBeanDefinition(beanName); if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123;//对非抽象、单例的和非延迟加载的对象进行实例化。 if (isFactoryBean(beanName)) &#123; FactoryBean factory = (FactoryBean) getBean(FACTORY_BEAN_PREFIX + beanName); if (factory instanceof SmartFactoryBean &amp;&amp; ((SmartFactoryBean) factory).isEagerInit()) &#123; getBean(beanName); &#125; &#125; else &#123; getBean(beanName); &#125; &#125; &#125; &#125; &#125; 从上面来看对于以下配置，只有 singletonBean 会被预先创建。1234567&lt;?xml version="1.0" encoding="GB2312"?&gt; &lt;!DOCTYPE beans PUBLIC "-//SPRING//DTD BEAN 2.0//EN" "http://www.springframework.org/dtd/spring-beans-2.0.dtd"&gt; &lt;beans default-autowire="byName"&gt; &lt;bean id="otherBean" class="com.test.OtherBean" scope="prototype"/&gt; &lt;bean id="myBean" class="com.test.MyBean" lazy-init="true"/&gt; &lt;bean id="singletonBean" class="com.test.SingletonBean"/&gt; &lt;/beans&gt; 问题二：Bean 的创建过程对于 bean 的创建过程其实都是通过调用工厂的 getBean 方法来完成的。这里面将会完成对构造函数的选择、依赖注入等。 无论预先创建还是延迟加载都是调用getBean实现，AbstractBeanFactory 定义了 getBean 的过程： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134protected Object doGetBean( final String name, final Class requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException &#123; final String beanName = transformedBeanName(name); Object bean = null; // Eagerly check singleton cache for manually registered singletons. Object sharedInstance = getSingleton(beanName); if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isDebugEnabled()) &#123; if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.debug("Returning eagerly cached instance of singleton bean '" + beanName + "' that is not fully initialized yet - a consequence of a circular reference"); &#125; else &#123; logger.debug("Returning cached instance of singleton bean '" + beanName + "'"); &#125; &#125; bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; // Fail if we're already creating this bean instance: // We're assumably within a circular reference. if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // Check if bean definition exists in this factory. BeanFactory parentBeanFactory = getParentBeanFactory(); if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. String nameToLookup = originalBeanName(name); if (args != null) &#123; // Delegation to parent with explicit args. return parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; if (!typeCheckOnly) &#123; markBeanAsCreated(beanName); &#125; final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. String[] dependsOn = mbd.getDependsOn(); if (dependsOn != null) &#123; for (int i = 0; i &lt; dependsOn.length; i++) &#123; String dependsOnBean = dependsOn[i]; getBean(dependsOnBean); registerDependentBean(dependsOnBean, beanName); &#125; &#125; // Create bean instance. if (mbd.isSingleton()) &#123;//单例对象创建过程,间接通过getSingleton方法来创建，里面会实现将单例对象缓存 sharedInstance = getSingleton(beanName, new ObjectFactory() &#123; public Object getObject() throws BeansException &#123; try &#123; return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. destroySingleton(beanName); throw ex; &#125; &#125; &#125;); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; else if (mbd.isPrototype()) &#123;//非单例对象创建 // It's a prototype -&gt; create a new instance. Object prototypeInstance = null; try &#123; beforePrototypeCreation(beanName); prototypeInstance = createBean(beanName, mbd, args);//直接调用createBean &#125; finally &#123; afterPrototypeCreation(beanName); &#125; bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; else &#123; String scopeName = mbd.getScope(); final Scope scope = (Scope) this.scopes.get(scopeName); if (scope == null) &#123; throw new IllegalStateException("No Scope registered for scope '" + scopeName + "'"); &#125; try &#123; Object scopedInstance = scope.get(beanName, new ObjectFactory() &#123; public Object getObject() throws BeansException &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125; &#125;); bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, "Scope '" + scopeName + "' is not active for the current thread; " + "consider defining a scoped proxy for this bean if you intend to refer to it from a singleton", ex); &#125; &#125; &#125; // Check if required type matches the type of the actual bean instance. if (requiredType != null &amp;&amp; bean != null &amp;&amp; !requiredType.isAssignableFrom(bean.getClass())) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; return bean; &#125; GetBean 的大概过程： 1.先试着从单例缓存对象里获取。 2.从父容器里取定义，有则由父容器创建。 3.如果是单例，则走单例对象的创建过程：在 spring 容器里单例对象和非单例对象的创建过程是一样的。都会调用父类 AbstractAutowireCapableBeanFactory 的 createBean 方法。 不同的是单例对象只创建一次并且需要缓存起来。 DefaultListableBeanFactory 的父类 DefaultSingletonBeanRegistry 提供了对单例对象缓存等支持工作。所以是单例对象的话会调用 DefaultSingletonBeanRegistry 的 getSingleton 方法，它会间接调用 AbstractAutowireCapableBeanFactory 的 createBean 方法。 如果是 Prototype 多例则直接调用父类 AbstractAutowireCapableBeanFactory 的 createBean 方法。 bean的创建是由AbstractAutowireCapableBeanFactory来定义：12345678910111213141516171819202122232425262728293031323334353637protected Object createBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) throws BeanCreationException &#123; AccessControlContext acc = AccessController.getContext(); return AccessController.doPrivileged(new PrivilegedAction() &#123; public Object run() &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Creating instance of bean '" + beanName + "'"); &#125; // Make sure bean class is actually resolved at this point. resolveBeanClass(mbd, beanName); // Prepare method overrides. try &#123; mbd.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbd.getResourceDescription(), beanName, "Validation of method overrides failed", ex); &#125; try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. Object bean = resolveBeforeInstantiation(beanName, mbd); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "BeanPostProcessor before instantiation of bean failed", ex); &#125; Object beanInstance = doCreateBean(beanName, mbd, args); if (logger.isDebugEnabled()) &#123; logger.debug("Finished creating instance of bean '" + beanName + "'"); &#125; return beanInstance; &#125; &#125;, acc); &#125; createBean 会调用 doCreateBean 方法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final Object[] args) &#123; // Instantiate the bean. BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = (BeanWrapper) this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; final Object bean = (instanceWrapper != null ? instanceWrapper.getWrappedInstance() : null); Class beanType = (instanceWrapper != null ? instanceWrapper.getWrappedClass() : null); // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); mbd.postProcessed = true; &#125; &#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; addSingletonFactory(beanName, new ObjectFactory() &#123; public Object getObject() throws BeansException &#123; return getEarlyBeanReference(beanName, mbd, bean); &#125; &#125;); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Initialization of bean failed", ex); &#125; &#125; if (earlySingletonExposure) &#123; Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set actualDependentBeans = new LinkedHashSet(dependentBeans.length); for (int i = 0; i &lt; dependentBeans.length; i++) &#123; String dependentBean = dependentBeans[i]; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, "Bean with name '" + beanName + "' has been injected into other beans [" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + "] in its raw version as part of a circular reference, but has eventually been " + "wrapped. This means that said other beans do not use the final version of the " + "bean. This is often the result of over-eager type matching - consider using " + "'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example."); &#125; &#125; &#125; &#125; // Register bean as disposable. registerDisposableBeanIfNecessary(beanName, bean, mbd); return exposedObject; &#125; doCreateBean 的流程： 1.会创建一个 BeanWrapper 对象 用于存放实例化对象。 2.如果没有指定构造函数，会通过反射拿到一个默认的构造函数对象，并赋予 beanDefinition.resolvedConstructorOrFactoryMethod 。 3.调用 spring 的 BeanUtils 的 instantiateClass 方法，通过反射创建对象。 4.applyMergedBeanDefinitionPostProcessors 5.populateBean(beanName, mbd, instanceWrapper); 根据注入方式进行注入。根据是否有依赖检查进行依赖检查。 执行 bean 的注入里面会选择注入类型： 123456789101112131415161718192021222324if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125;//根据名字注入 // Add property values based on autowire by type if applicable. if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125;//根据类型注入 pvs = newPvs; &#125; 6.initializeBean(beanName, exposedObject, mbd); 判断是否实现了 BeanNameAware 、 BeanClassLoaderAware 等 spring 提供的接口，如果实现了，进行默认的注入。同时判断是否实现了 InitializingBean 接口，如果是的话，调用 afterPropertySet 方法。1234567891011121314151617181920212223242526272829303132protected Object initializeBean(String beanName, Object bean, RootBeanDefinition mbd) &#123; if (bean instanceof BeanNameAware) &#123; ((BeanNameAware) bean).setBeanName(beanName); &#125; if (bean instanceof BeanClassLoaderAware) &#123; ((BeanClassLoaderAware) bean).setBeanClassLoader(getBeanClassLoader()); &#125; if (bean instanceof BeanFactoryAware) &#123; ((BeanFactoryAware) bean).setBeanFactory(this); &#125; Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &#125; try &#123; invokeInitMethods(beanName, wrappedBean, mbd); &#125; catch (Throwable ex) &#123; throw new BeanCreationException( (mbd != null ? mbd.getResourceDescription() : null), beanName, "Invocation of init method failed", ex); &#125; if (mbd == null || !mbd.isSynthetic()) &#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &#125; return wrappedBean; &#125; 其中invokeInitMethods实现如下：123456789101112131415161718192021protected void invokeInitMethods(String beanName, Object bean, RootBeanDefinition mbd) throws Throwable &#123; boolean isInitializingBean = (bean instanceof InitializingBean); if (isInitializingBean &amp;&amp; (mbd == null || !mbd.isExternallyManagedInitMethod("afterPropertiesSet"))) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Invoking afterPropertiesSet() on bean with name '" + beanName + "'"); &#125; ((InitializingBean) bean).afterPropertiesSet();//调用afterPropertiesSet方法 &#125; String initMethodName = (mbd != null ? mbd.getInitMethodName() : null); if (initMethodName != null &amp;&amp; !(isInitializingBean &amp;&amp; "afterPropertiesSet".equals(initMethodName)) &amp;&amp; !mbd.isExternallyManagedInitMethod(initMethodName)) &#123; invokeCustomInitMethod(beanName, bean, initMethodName, mbd.isEnforceInitMethod()); &#125; &#125; Spring xml ioc 容器常用标签和自定义标签以 Xml 资源定义的容器配置是我们最常见的一种方式。 Spring 容器需要解析 xml 的标签，并把 xml 里 bean 的定义转化为内部的结构 BeanDifinition 。 Spring 的标签有很多种，其支持的常见的标签有： 标签 说明 例子 &lt;bean&gt; 最常用的，定义一个普通 bean。 &lt;bean id=&quot;myBean&quot; class=&quot;com.test.MyBean&quot; lazy-init=&quot;true&quot;/&gt; &lt;tx&gt; 如&lt;tx: advice&gt; 等,提供事务配置通用支持。 &lt;tx:advice id=&quot;txAdvice&quot;transaction-manager=&quot;transactionManager&quot;&gt; &lt;tx:attributes&gt; &lt;tx:method name=&quot;save*&quot;/&gt; &lt;tx:method name=&quot;remove*&quot;/&gt; &lt;tx:method name=&quot;*&quot; read-only=&quot;true&quot;/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;aop&gt; &lt;aop:config&gt;,&lt;aop: aspectj-autoproxy&gt; 等提供代理 bean 通用配置支持。 &lt;aop:configproxy-target-class=&quot;true&quot;&gt; &lt;aop:advisor pointcut=&quot;...&quot; advice-ref=&quot;txAdvice&quot;/&gt; &lt;aop:advisorpointcut=&quot;...&quot; advice-ref=&quot;fooAdvice&quot;/&gt; &lt;/aop:config&gt; &lt;util&gt; 提供在容器内配置一些JDK自带的工具类、集合类和常量的支持。 &lt;util:list id=&quot;list&quot;list-class=&quot;java.util.ArrayList&quot;&gt;&lt;value&gt;listValue1&lt;/value&gt; &lt;value&gt;listValue2&lt;/value&gt; &lt;/util:list&gt; &lt;util:map id=&quot;map&quot;&gt; &lt;entry key=&quot;key1&quot; value=&quot;mapValue1&quot;&gt;&lt;/entry&gt;&lt;entry key=&quot;key12&quot; value=&quot;mapValue2&quot;&gt;&lt;/entry&gt; &lt;/util:map&gt; &lt;p&gt; 属性的简单访问。 &lt;bean id=&quot;loginAction&quot; class=&quot;com.test.LoginAction&quot; p:name=&quot;test&quot;&gt;&lt;/bean&gt; &lt;lang&gt; &lt;lang:groovy&gt; &lt;lang:jruby&gt;等，提供对动态脚本的支持。 &lt;lang:groovy id=&quot;test&quot; refresh-check-delay=&quot;5000&quot; script-source=&quot;classpath:com/test/groovy/test.groovy&quot;&gt; &lt;/lang:groovy&gt; &lt;jee&gt; &lt;jee:jndi-lookup/&gt;等，对一些javaEE规范的bean配置的简化，如jndi等。 &lt;jee:jndi-lookup id=&quot;simple&quot; jndi-name=&quot;jdbc/MyDataSource&quot; cache=&quot;true&quot; resource-ref=&quot;true&quot; lookup-on-startup=&quot;false&quot; expected-type=&quot;com.myapp.DefaultFoo&quot; proxy-interface=&quot;com.myapp.Foo&quot;/&gt; 基本上每一种标签都是用来定义一类 bean 的（P标签除外）。以上都是 spring 自带的一些标签，当然 spring 也支持自定义标签。其实 &lt;tx&gt;&lt;aop&gt; 这些也可以认为是自定义标签，不过是由 spring 扩展的而已。 其实所有的bean定义都可以用bean标签来实现定义的。而衍生这种自定义标签来定义 bean 有几个好处： 见名知意。 对于同一类的通用 bean。封装不必要的配置，只给外部暴露一个简单易用的标签和一些需要配置的属性。很多时候对于一个框架通用的 bean ，我们不需要把 bean 的所有配置都暴露出来，甚至像类名、默认值等我们都想直接封装，这个时候就可以使用自定义标签了，如： &lt;services:property-placeholder /&gt; 可能这个标签就默认代表配置了一个支持 property placeholder 的通用 bean ，我们都不需要去知道配这样一个 bean 的类路径是什么。 可以说自定义标签是 spring 的 xml 容器的一个扩展点，本身 spring 自己的很多标签也是基于这个设计上面来构造出来的。 Spring 对于自定义（声明式）bean标签解析如何设计Bean 的定义方式有千千万万种，无论是何种标签，无论是何种资源定义，无论是何种容器，最终的 bean 定义内部表示都将转换为内部的唯一结构： BeanDefinition 。外部的各种定义说白了就是为了方便配置。 Spring 提供对其支持的标签解析的天然支持。所以只要按照 spring 的规范编写 xml 配置文件。所有的配置，在启动时都会正常的被解析成 BeanDefinition 。但是如果我们要实现一个自定义标签，则需要提供对自定义标签的全套支持。 我们知道要去完成一个自定义标签，需要完成的事情有： 编写自定义标签 schema 定义文件，放在某个 classpath 下。 在 classpath 的在 META-INF 下面增加 spring.schemas 配置文件，指定 schema 虚拟路径和实际 xsd 的映射。我们在 xml 里的都是虚拟路径，如： 12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd "&gt; &lt;bean id="otherBean" class="com.test.OtherBean" scope="prototype"/&gt; &lt;bean id="myBean" class="com.test.MyBean" lazy-init="true"/&gt; &lt;bean id="singletonBean" class="com.test.SingletonBean"/&gt; &lt;/beans&gt; 头部的1http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd 就是一个虚拟路径，其对应的真实路径在spring jar包里的META-INF/spring.schemas里面有映射到classpath定义： 1http\://www.springframework.org/schema/beans/spring-beans-2.5.xsd=org/springframework/beans/factory/xml/spring-beans-2.5.xsd 增加一个 NamespaceHandler 和 BeanDefinitionParser ，用于解析自定义的标签，将自定义标签的 bean 解析成一个 BeanDefinition 返回。 在 classpath 的在 META-INF 下面增加 spring.handlers 配置文件，指定标签命名空间和 handlers 的映射。 为什么要做以上几个事情？我们来看看设计： Spring 对标签解析的设计的过程如下： 解释： Step 1： 将 xml 文件解析成 Dom 树。将 xml 文件解析成 dom 树的时候，需要 xml 标签定义 schema 来验证文件的语法结构。 Spring 约定将所有的 shema 的虚拟路径和真是文件路径映射定义在 classpath 的在 META-INF/spring.schemas 下面。在容器启动时 Spring 会扫描所有的 META-INF/spring.schemas 并将映射维护到一个 map 里。 如 spring jar 包里会有自带的标签的 schemas 映射，可以看一下部分配置：1234567891011http\://www.springframework.org/schema/aop/spring-aop-2.0.xsd = org/springframework/aop/config/spring-aop-2.0.xsd http\://www.springframework.org/schema/aop/spring-aop-2.5.xsd = org/springframework/aop/config/spring-aop-2.5.xsd http\://www.springframework.org/schema/aop/spring-aop.xsd = org/springframework/aop/config/spring-aop-2.5.xsd http\://www.springframework.org/schema/beans/spring-beans-2.0.xsd = org/springframework/beans/factory/xml/spring-beans-2.0.xsd http\://www.springframework.org/schema/beans/spring-beans-2.5.xsd = org/springframework/beans/factory/xml/spring-beans-2.5.xsd http\://www.springframework.org/schema/beans/spring-beans.xsd = org/springframework/beans/factory/xml/spring-beans-2.5.xsd http\://www.springframework.org/schema/context/spring-context-2.5.xsd = org/springframework/context/config/spring-context-2.5.xsd http\://www.springframework.org/schema/context/spring-context.xsd = org/springframework/context/config/spring-context-2.5.xsd http\://www.springframework.org/schema/jee/spring-jee-2.0.xsd = org/springframework/ejb/config/spring-jee-2.0.xsd http\://www.springframework.org/schema/jee/spring-jee-2.5.xsd = org/springframework/ejb/config/spring-jee-2.5.xsd ...... 等号左边是虚拟路径，右边是真是路径(classpath下的)。虚拟路径用在我们的bean定义配置文件里，如：12345678&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-2.5.xsd&gt; &lt;bean&gt; &lt;/beans&gt; beans里面的1http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.5.xsd 就是个虚拟路径。 Step 2： 将 dom 树解析成 BeanDifinition 。将定义 bean 的标签和 xml 定义解析成 BeanDefinition 的过程。如果是默认的 bean 标签， spring 会直接进行解析。而如果不是默认的 bean 标签，包括自定义和 spring 扩展的 &lt;aop&gt;、 &lt;p&gt;、 &lt;util&gt; 等标签，则需要提供专门的 xmlparser 来处理。 paorser由自己定义和编写，并通过handler注册到容器。Spring 约定了 META-INF/spring.handlers 文件，在这里面定义了标签命名空间和 handler 的映射。容器起来的时候会加载 handler ， handler 会向容器注册该命名空间下的标签和解析器。在解析的自定义标签的时候， spring 会根据标签的命名空间和标签名找到一个解析器。由该解析器来完成对该标签内容的解析，并返回一个 BeanDefinition 。 以下是 spring jar 包自带的一些自定义标签扩展的 spring.handlers 文件，可以看到定义了 aop\p 等其扩展标签的 handlers 。12345678http\://www.springframework.org/schema/aop=org.springframework.aop.config.AopNamespaceHandler http\://www.springframework.org/schema/context=org.springframework.context.config.ContextNamespaceHandler http\://www.springframework.org/schema/jee=org.springframework.ejb.config.JeeNamespaceHandler http\://www.springframework.org/schema/jms=org.springframework.jms.config.JmsNamespaceHandler http\://www.springframework.org/schema/lang=org.springframework.scripting.config.LangNamespaceHandler http\://www.springframework.org/schema/p=org.springframework.beans.factory.xml.SimplePropertyNamespaceHandler http\://www.springframework.org/schema/tx=org.springframework.transaction.config.TxNamespaceHandler http\://www.springframework.org/schema/util=org.springframework.beans.factory.xml.UtilNamespaceHandler 看看UtilNamespaceHandler的代码实现12345678public void init() &#123; registerBeanDefinitionParser("constant", new ConstantBeanDefinitionParser()); registerBeanDefinitionParser("property-path", new PropertyPathBeanDefinitionParser()); registerBeanDefinitionParser("list", new ListBeanDefinitionParser()); registerBeanDefinitionParser("set", new SetBeanDefinitionParser()); registerBeanDefinitionParser("map", new MapBeanDefinitionParser()); registerBeanDefinitionParser("properties", new PropertiesBeanDefinitionParser()); &#125; 实现了标签和对应parser的映射注册。 ListBeanDefinitionParser的实现如下：12345678910111213141516171819private static class ListBeanDefinitionParser extends AbstractSingleBeanDefinitionParser &#123; protected Class getBeanClass(Element element) &#123; return ListFactoryBean.class; &#125; protected void doParse(Element element, ParserContext parserContext, BeanDefinitionBuilder builder) &#123; String listClass = element.getAttribute("list-class"); List parsedList = parserContext.getDelegate().parseListElement(element, builder.getRawBeanDefinition()); builder.addPropertyValue("sourceList", parsedList); if (StringUtils.hasText(listClass)) &#123; builder.addPropertyValue("targetListClass", listClass); &#125; String scope = element.getAttribute(SCOPE_ATTRIBUTE); if (StringUtils.hasLength(scope)) &#123; builder.setScope(scope); &#125; &#125; &#125; 这里父类代码不贴了，主要完成的是beanDifinition的生成。 源码实现Spring 对于自定义（声明式）bean标签源码实现大概的源码结构如下：XmlBeanDefinitionReader 是核心类，它接收 spring 容器传给它的资源 resource 文件，由它负责完成整个转换。它调用 DefaultDocumentLoader 来完成将 Resource 到 Dom 树的转换。调用 DefaultBeanDefinitionDocumentReader 完成将 Dom 树到 BeanDefinition 的转换。 具体的代码流程细节完全可以基于这个结构去阅读，下面就贴几个核心源码段： 源码段 1 ： 加载 spring.shemas，在PluggableSchemaResolver.java里实现：12345678910111213141516171819202122232425262728293031323334353637383940414243public class PluggableSchemaResolver implements EntityResolver &#123; /***定义schema location的映射文件路径***/ public static final String DEFAULT_SCHEMA_MAPPINGS_LOCATION = "META-INF/spring.schemas"; private static final Log logger = LogFactory.getLog(PluggableSchemaResolver.class); private final ClassLoader classLoader; private final String schemaMappingsLocation; /** Stores the mapping of schema URL -&gt; local schema path */ private Properties schemaMappings; public PluggableSchemaResolver(ClassLoader classLoader) &#123; this.classLoader = classLoader; this.schemaMappingsLocation = DEFAULT_SCHEMA_MAPPINGS_LOCATION; &#125; public PluggableSchemaResolver(ClassLoader classLoader, String schemaMappingsLocation) &#123; Assert.hasText(schemaMappingsLocation, "'schemaMappingsLocation' must not be empty"); this.classLoader = classLoader; this.schemaMappingsLocation = schemaMappingsLocation; &#125; /**==========中间省略部分代码=========**/ /***此处完成schema的加载***/ protected String getSchemaMapping(String systemId) &#123; if (this.schemaMappings == null) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Loading schema mappings from [" + this.schemaMappingsLocation + "]"); &#125; try &#123; this.schemaMappings = PropertiesLoaderUtils.loadAllProperties(this.schemaMappingsLocation, this.classLoader); if (logger.isDebugEnabled()) &#123; logger.debug("Loaded schema mappings: " + this.schemaMappings); &#125; &#125; catch (IOException ex) &#123; throw new FatalBeanException( "Unable to load schema mappings from location [" + this.schemaMappingsLocation + "]", ex); &#125; &#125; return this.schemaMappings.getProperty(systemId); &#125; &#125; 源码段 2 ： 加载 spring.handlers,在 DefaultNamespaceHandlerResolver里实现：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class DefaultNamespaceHandlerResolver implements NamespaceHandlerResolver &#123; /** * The location to look for the mapping files. Can be present in multiple JAR files. */ public static final String DEFAULT_HANDLER_MAPPINGS_LOCATION = "META-INF/spring.handlers"; /** Logger available to subclasses */ protected final Log logger = LogFactory.getLog(getClass()); /** ClassLoader to use for NamespaceHandler classes */ private final ClassLoader classLoader; /** Resource location to search for */ private final String handlerMappingsLocation; /** Stores the mappings from namespace URI to NamespaceHandler class name / instance */ private Map handlerMappings; public DefaultNamespaceHandlerResolver() &#123; this(null, DEFAULT_HANDLER_MAPPINGS_LOCATION); &#125; public DefaultNamespaceHandlerResolver(ClassLoader classLoader) &#123; this(classLoader, DEFAULT_HANDLER_MAPPINGS_LOCATION); &#125; public DefaultNamespaceHandlerResolver(ClassLoader classLoader, String handlerMappingsLocation) &#123; Assert.notNull(handlerMappingsLocation, "Handler mappings location must not be null"); this.classLoader = (classLoader != null ? classLoader : ClassUtils.getDefaultClassLoader()); this.handlerMappingsLocation = handlerMappingsLocation; &#125; /**==========中间省略部分代码=========**/ /************************ * Load the specified NamespaceHandler mappings lazily. * 此处加载延迟加载spring.handlers，只有第一次自定义标签被解析到，才会被加载。 ****************************/ private Map getHandlerMappings() &#123; if (this.handlerMappings == null) &#123; try &#123; Properties mappings = PropertiesLoaderUtils.loadAllProperties(this.handlerMappingsLocation, this.classLoader); if (logger.isDebugEnabled()) &#123; logger.debug("Loaded mappings [" + mappings + "]"); &#125; this.handlerMappings = new HashMap(mappings); &#125; catch (IOException ex) &#123; IllegalStateException ise = new IllegalStateException( "Unable to load NamespaceHandler mappings from location [" + this.handlerMappingsLocation + "]"); ise.initCause(ex); throw ise; &#125; &#125; return this.handlerMappings; &#125; &#125; 源码段3 ： xml 到 dom 树的解析。 在 XmlBeanDefinitionReader.java 的 doLoadBeanDefinitions 方法里，调用 DefaultDocumentLoader 完成。1234567891011121314151617181920212223242526272829303132protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; int validationMode = getValidationModeForResource(resource); Document doc = this.documentLoader.loadDocument( inputSource, getEntityResolver(), this.errorHandler, validationMode, isNamespaceAware()); return registerBeanDefinitions(doc, resource); &#125; catch (BeanDefinitionStoreException ex) &#123; throw ex; &#125; catch (SAXParseException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), "Line " + ex.getLineNumber() + " in XML document from " + resource + " is invalid", ex); &#125; catch (SAXException ex) &#123; throw new XmlBeanDefinitionStoreException(resource.getDescription(), "XML document from " + resource + " is invalid", ex); &#125; catch (ParserConfigurationException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), "Parser configuration exception parsing XML from " + resource, ex); &#125; catch (IOException ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), "IOException parsing XML document from " + resource, ex); &#125; catch (Throwable ex) &#123; throw new BeanDefinitionStoreException(resource.getDescription(), "Unexpected exception parsing XML document from " + resource, ex); &#125; &#125; 其中的1getEntityResolver() 会完成spring.schemas的装载,里面会间接调用源码段1。穿进去的entityResolver作为标签解析使用。 源码段4 ： dom 树到 Beandifinition： 在 XmlBeanDefinitionReader .java 的 doLoadBeanDefinitions 方法里，调用 BeanDefinitionDocumentReader 完成。 12345678910111213 public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; // Support old XmlBeanDefinitionParser SPI for backwards-compatibility. if (this.parserClass != null) &#123; XmlBeanDefinitionParser parser = (XmlBeanDefinitionParser) BeanUtils.instantiateClass(this.parserClass); return parser.registerBeanDefinitions(this, doc, resource); &#125; // Read document based on new BeanDefinitionDocumentReader SPI. BeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader(); int countBefore = getRegistry().getBeanDefinitionCount(); documentReader.registerBeanDefinitions(doc, createReaderContext(resource)); return getRegistry().getBeanDefinitionCount() - countBefore; &#125; AOP底层实现原理代理设计模式 什么是代理模式 通过代理控制对象的访问,可以详细访问某个对象的方法，在这个方法调用处理，或调用后处理。既(AOP微实现) ,AOP核心技术面向切面编程。 代理模式应用场景 SpringAOP、事物原理、日志打印、权限控制、远程调用、安全代理 可以隐蔽真实角色 代理的分类 静态代理(静态定义代理类) 动态代理(动态生成代理类) Jdk自带动态代理 Cglib 、javaassist（字节码操作库） 静态代理什么是静态代理 由程序员创建或工具生成代理类的源码，再编译代理类。所谓静态也就是在程序运行前就已经存在代理类的字节码文件，代理类和委托类的关系在运行前就确定了。1234567891011121314151617181920212223public interface IUserDao &#123; void save();&#125;public class UserDao implements IUserDao &#123; public void save() &#123; System.out.println("已经保存数据..."); &#125;&#125;代理类public class UserDaoProxy implements IUserDao &#123; private IUserDao target; public UserDaoProxy(IUserDao iuserDao) &#123; this.target = iuserDao; &#125; public void save() &#123; System.out.println("开启事物..."); target.save(); System.out.println("关闭事物..."); &#125; &#125; 什么是动态代理1.代理对象,不需要实现接口 2.代理对象的生成,是利用JDK的API,动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型) 3.动态代理也叫做:JDK代理,接口代理 JDK动态代理1)原理：是根据类加载器和接口创建代理类（此代理类是接口的实现类，所以必须使用接口 面向接口生成代理，位于java.lang.reflect包下） 2)实现方式： 通过实现InvocationHandler接口创建自己的调用处理器 IvocationHandler handler = new InvocationHandlerImpl(…); 通过为Proxy类指定ClassLoader对象和一组interface创建动态代理类Class clazz = Proxy.getProxyClass(classLoader,new Class[]{…}); 通过反射机制获取动态代理类的构造函数，其参数类型是调用处理器接口类型Constructor constructor = clazz.getConstructor(new Class[]{InvocationHandler.class}); 通过构造函数创建代理类实例，此时需将调用处理器对象作为参数被传入Interface Proxy = (Interface)constructor.newInstance(new Object[] (handler)); 缺点：jdk动态代理，必须是面向接口，目标业务类必须实现接口1234567891011121314151617181920212223242526272829303132// 每次生成动态代理类对象时,实现了InvocationHandler接口的调用处理器对象 public class InvocationHandlerImpl implements InvocationHandler &#123; private Object target;// 这其实业务实现类对象，用来调用具体的业务方法 // 通过构造函数传入目标对象 public InvocationHandlerImpl(Object target) &#123; this.target = target; &#125; public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object result = null; System.out.println("调用开始处理"); result = method.invoke(target, args); System.out.println("调用结束处理"); return result; &#125; public static void main(String[] args) throws NoSuchMethodException, SecurityException, InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException &#123; // 被代理对象 IUserDao userDao = new UserDao(); InvocationHandlerImpl invocationHandlerImpl = new InvocationHandlerImpl(userDao); ClassLoader loader = userDao.getClass().getClassLoader(); Class&lt;?&gt;[] interfaces = userDao.getClass().getInterfaces(); // 主要装载器、一组接口及调用处理动态代理实例 IUserDao newProxyInstance = (IUserDao) Proxy.newProxyInstance(loader, interfaces, invocationHandlerImpl); newProxyInstance.save(); &#125;&#125; CGLIB动态代理原理：利用asm开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。 什么是CGLIB动态代理 使用cglib[Code Generation Library]实现动态代理，并不要求委托类必须实现接口，底层采用asm字节码生成框架生成代理类的字节码 CGLIB动态代理相关代码 12345678910111213141516171819202122232425public class CglibProxy implements MethodInterceptor &#123; private Object targetObject; // 这里的目标类型为Object，则可以接受任意一种参数作为被代理类，实现了动态代理 public Object getInstance(Object target) &#123; // 设置需要创建子类的类 this.targetObject = target; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(target.getClass()); enhancer.setCallback(this); return enhancer.create(); &#125; public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; System.out.println("开启事物"); Object result = proxy.invoke(targetObject, args); System.out.println("关闭事物"); // 返回代理对象 return result; &#125; public static void main(String[] args) &#123; CglibProxy cglibProxy = new CglibProxy(); UserDao userDao = (UserDao) cglibProxy.getInstance(new UserDao()); userDao.save(); &#125;&#125; CGLIB动态代理与JDK动态区别java动态代理是利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。 而cglib动态代理是利用asm开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。 Spring中。 1、如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP 2、如果目标对象实现了接口，可以强制使用CGLIB实现AOP 3、如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换 JDK动态代理只能对实现了接口的类生成代理，而不能针对类 。 CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法 。 因为是继承，所以该类或方法最好不要声明成final ，final可以阻止继承和多态。 springcloud的整体架构Eureka心跳检测机制，如果某个实例在规定的时间内没有进行通讯则会自动被剔除掉，避免了某个实例挂掉而影响服务，Eureka就自动具有了注册中心、负载均衡、故障转移的功能。 HystrixHystrix会在某个服务连续调用N次不响应的情况下，立即通知调用端调用失败，避免调用端持续等待而影响了整体服务。Hystrix间隔时间会再次检查此服务，如果服务恢复将继续提供服务。 Spring Cloud Config解决分布式系统的配置管理方案。它包含了Client和Server两个部分，Server提供配置文件的存储、以接口的形式将配置文件的内容提供出去，Client通过接口获取数据、并依据此数据初始化自己的应用。 Spring Cloud Bus通过轻量消息代理连接各个分布的节点。这会用在广播状态的变化（例如配置变化）或者其它的消息指令中。Spring Cloud Bus的一个核心思想是通过分布式的启动器对Spring Boot应用进行扩展，也可以用来建立一个或多个应用之间的通信频道。目前唯一实现的方式是用AMQP消息代理作为通道。 有了Spring Cloud Bus之后，当我们改变配置文件提交到版本库中时，会自动的触发对应实例的Refresh。 服务网关Spring Cloud体系中支持API Gateway落地的技术就是Zuul。Spring Cloud Zuul路由是微服务架构中不可或缺的一部分，提供动态路由，监控，弹性，安全等的边缘服务。Zuul是Netflix出品的一个基于JVM路由和服务端的负载均衡器。 它的具体作用就是服务转发，接收并转发所有内外部的客户端调用。使用Zuul可以作为资源的统一访问入口，同时也可以在网关做一些权限校验等类似的功能。 链路跟踪Spring Cloud Sleuth和Zipkin，Spring Cloud Sleuth为服务之间调用提供链路追踪。通过Sleuth可以很清楚的了解到一个服务请求经过了哪些服务，每个服务处理花费了多长时间。从而让我们可以很方便的理清各微服务间的调用关系。Zipkin是Twitter的一个开源项目，允许开发者收集 Twitter 各个服务上的监控数据，并提供查询接口 。 Feign技术利用此技术可以伪造接口实现。 负载均衡的算法有哪些轮询（Round Robin）法将所有请求，依次分发到每台服务器上，适合服务器硬件相同的场景。 优点：服务器请求数目相同； 缺点：服务器压力不一样，不适合服务器配置不同的情况，为了做到请求转移的绝对均衡，必须付出相当大的代价，因为为了保证pos变量修改的互斥性，需要引入重量级的悲观锁synchronized，这将会导致该段轮询代码的并发吞吐量发生明显的下降； 随机（Random）法基于概率统计的理论，吞吐量越大，随机算法的效果越接近于轮询算法的效果。 优点：使用简单； 缺点：不适合机器配置不同的场景； 源地址哈希（Hash）法源地址哈希的思想是获取客户端访问的IP地址值，通过哈希函数计算得到一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是要访问的服务器的序号。 优点：保证了相同客户端IP地址将会被哈希到同一台后端服务器，直到后端服务器列表变更。根据此特性可以在服务消费者与服务提供者之间建立有状态的session会话。 缺点：除非集群中服务器的非常稳定，基本不会上下线，否则一旦有服务器上线、下线，那么通过源地址哈希算法路由到的服务器是服务器上线、下线前路由到的服务器的概率非常低，如果是session则取不到session，如果是缓存则可能引发”雪崩”； 加权法在轮询，随机，最少链接，Hash等算法的基础上，通过加权的方式，进行负载服务器分配。 优点：根据权重，调节转发服务器的请求数目； 缺点：使用相对复杂； 最小连接数（Least Connections）法将请求分配到连接数最少的服务器上（目前处理请求最少的服务器）。 优点：根据服务器当前的请求处理情况，动态分配； 缺点：算法实现相对复杂，需要监控服务器请求连接数； SpringBoot如何启动 如果我们使用的是SpringApplication的静态run方法，那么，这个方法里面首先要创建一个SpringApplication对象实例，然后调用这个创建好的SpringApplication的实例方法。在SpringApplication实例初始化的时候，它会提前做几件事情： 根据classpath里面是否存在某个特征类（org.springframework.web.context.ConfigurableWebApplicationContext）来决定是否应该创建一个为Web应用使用的ApplicationContext类型。 使用SpringFactoriesLoader在应用的classpath中查找并加载所有可用的ApplicationContextInitializer。 使用SpringFactoriesLoader在应用的classpath中查找并加载所有可用的ApplicationListener。 推断并设置main方法的定义类。 SpringApplication实例初始化完成并且完成设置后，就开始执行run方法的逻辑了，方法执行伊始，首先遍历执行所有通过SpringFactoriesLoader可以查找到并加载的SpringApplicationRunListener。调用它们的started()方法，告诉这些SpringApplicationRunListener，“嘿，SpringBoot应用要开始执行咯！”。 创建并配置当前Spring Boot应用将要使用的Environment（包括配置要使用的PropertySource以及Profile）。 遍历调用所有SpringApplicationRunListener的environmentPrepared()的方法，告诉他们：“当前SpringBoot应用使用的Environment准备好了咯！”。 如果SpringApplication的showBanner属性被设置为true，则打印banner。 根据用户是否明确设置了applicationContextClass类型以及初始化阶段的推断结果，决定该为当前SpringBoot应用创建什么类型的ApplicationContext并创建完成，然后根据条件决定是否添加ShutdownHook，决定是否使用自定义的BeanNameGenerator，决定是否使用自定义的ResourceLoader，当然，最重要的，将之前准备好的Environment设置给创建好的ApplicationContext使用。 ApplicationContext创建好之后，SpringApplication会再次借助Spring-FactoriesLoader，查找并加载classpath中所有可用的ApplicationContext-Initializer，然后遍历调用这些ApplicationContextInitializer的initialize（applicationContext）方法来对已经创建好的ApplicationContext进行进一步的处理。 遍历调用所有SpringApplicationRunListener的contextPrepared()方法。 最核心的一步，将之前通过@EnableAutoConfiguration获取的所有配置以及其他形式的IoC容器配置加载到已经准备完毕的ApplicationContext。 遍历调用所有SpringApplicationRunListener的contextLoaded()方法。 调用ApplicationContext的refresh()方法，完成IoC容器可用的最后一道工序。 查找当前ApplicationContext中是否注册有CommandLineRunner，如果有，则遍历执行它们。 正常情况下，遍历执行SpringApplicationRunListener的finished()方法、（如果整个过程出现异常，则依然调用所有SpringApplicationRunListener的finished()方法，只不过这种情况下会将异常信息一并传入处理） 去除事件通知点后，整个流程如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public ConfigurableApplicationContext run(String... args) &#123; // 开启定时器,统计启动时间 StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); // 获取并初始化所有RunListener SpringApplicationRunListeners listeners = getRunListeners(args); // 发布启动事件 listeners.starting(); try &#123; ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); // 准备好环境environment,即配置文件等 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); // 打印SpringBoot Logo Banner printedBanner = printBanner(environment); // 创建我们最常用的ApplicationContext context = createApplicationContext(); // 获取异常报告器,在启动发生异常的时候用友好的方式提示用户 exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); // 准备Context,加载启动类作为source prepareContext(context, environment, listeners, applicationArguments, printedBanner); // Spring初始化的核心逻辑,构建整个容器 refreshContext(context); afterRefresh(context, applicationArguments); // 停止计时,统计启动耗时 stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); // 调用runner接口供应用自定义初始化 callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; // 处理启动中抛出的异常,使用异常报告器输出 handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; return context;&#125; 什么是脑裂什么是脑裂脑裂(split-brain)就是“大脑分裂”，也就是本来一个“大脑”被拆分了两个或多个“大脑”，我们都知道，如果一个人有多个大脑，并且相互独立的话，那么会导致人体“手舞足蹈”，“不听使唤”。 脑裂通常会出现在集群环境中，比如ElasticSearch、Zookeeper集群，而这些集群环境有一个统一的特点，就是它们有一个大脑，比如ElasticSearch集群中有Master节点，Zookeeper集群中有Leader节点。 章着重来给大家讲一下Zookeeper中的脑裂问题，以及是如果解决脑裂问题的。 Zookeeper集群中的脑裂场景对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，比如现在有一个由6台zkServer所组成的一个集群，部署在了两个机房： 正常情况下，此集群只会有一个Leader，那么如果机房之间的网络断了之后，两个机房内的zkServer还是可以相互通信的，如果不考虑过半机制，那么就会出现每个机房内部都将选出一个Leader。 这就相当于原本一个集群，被分成了两个集群，出现了两个“大脑”，这就是脑裂。 对于这种情况，我们也可以看出来，原本应该是统一的一个集群对外提供服务的，现在变成了两个集群同时对外提供服务，如果过了一会，断了的网络突然联通了，那么此时就会出现问题了，两个集群刚刚都对外提供服务了，数据该怎么合并，数据冲突怎么解决等等问题。 刚刚在说明脑裂场景时，有一个前提条件就是没有考虑过半机制，所以实际上Zookeeper集群中是不会出现脑裂问题的，而不会出现的原因就跟过半机制有关。 过半机制在领导者选举的过程中，如果某台zkServer获得了超过半数的选票，则此zkServer就可以成为Leader了。 过半机制的源码实现其实非常简单：123456789101112131415161718public class QuorumMaj implements QuorumVerifier &#123; private static final Logger LOG = LoggerFactory.getLogger(QuorumMaj.class); int half; // n表示集群中zkServer的个数（准确的说是参与者的个数，参与者不包括观察者节点） public QuorumMaj(int n)&#123; this.half = n/2; &#125; // 验证是否符合过半机制 public boolean containsQuorum(Set&lt;Long&gt; set)&#123; // half是在构造方法里赋值的 // set.size()表示某台zkServer获得的票数 return (set.size() &gt; half); &#125; &#125; 大家仔细看一下上面方法中的注释，核心代码就是下面两行：12this.half = n/2;return (set.size() &gt; half); 举个简单的例子： 如果现在集群中有5台zkServer，那么half=5/2=2，那么也就是说，领导者选举的过程中至少要有三台zkServer投了同一个zkServer，才会符合过半机制，才能选出来一个Leader。 那么有一个问题我们想一下，选举的过程中为什么一定要有一个过半机制验证？ 因为这样不需要等待所有zkServer都投了同一个zkServer就可以选举出来一个Leader了，这样比较快，所以叫快速领导者选举算法呗。 那么再来想一个问题，过半机制中为什么是大于，而不是大于等于呢？ 这就是更脑裂问题有关系了，比如回到上文出现脑裂问题的场景： 当机房中间的网络断掉之后，机房1内的三台服务器会进行领导者选举，但是此时过半机制的条件是set.size() &gt; 3，也就是说至少要4台zkServer才能选出来一个Leader，所以对于机房1来说它不能选出一个Leader，同样机房2也不能选出一个Leader，这种情况下整个集群当机房间的网络断掉后，整个集群将没有Leader。 而如果过半机制的条件是set.size() &gt;= 3，那么机房1和机房2都会选出一个Leader，这样就出现了脑裂。所以我们就知道了，为什么过半机制中是大于，而不是大于等于。就是为了防止脑裂。 如果假设我们现在只有5台机器，也部署在两个机房： 此时过半机制的条件是set.size() &gt; 2，也就是至少要3台服务器才能选出一个Leader，此时机房件的网络断开了，对于机房1来说是没有影响的，Leader依然还是Leader，对于机房2来说是选不出来Leader的，此时整个集群中只有一个Leader。 所以，我们可以总结得出，有了过半机制，对于一个Zookeeper集群，要么没有Leader，要没只有1个Leader，这样就避免了脑裂问题。 有痛点才有创新，一个技术肯定都是为了解决某个痛点才出现的。 Saga模式与TCC的区别各种形态的分布式事务分布式事务有多种主流形态，包括： 基于消息实现的分布式事务 基于补偿实现的分布式事务 基于TCC实现的分布式事务 基于SAGA实现的分布式事务 基于2PC实现的分布式事务这些形态的原理已经在很多文章中进行了剖析，用“分布式事务”关键字就能搜到对应的文章，本文不再赘述这些形态的原理，并将重点放在如何根据业务选择对应的分布式事务形态上。 何时选择单机事务这个相信大家都很清楚，在条件允许的情况下，我们应该尽可能地使用单机事务，因为单机事务里，无需额外协调其他数据源，减少了网络交互时间消耗以及协调时所需的存储IO消耗，在修改等量业务数据的情况下，单机事务将会有更高的性能。 但单机数据库由于 业务逻辑解耦等因素进行了数据库垂直拆分、或者由于单机数据库性能压力等因素进行了数据库水平拆分之后，数据分布于多个数据库，这时若需要对多个数据库的数据进行协调变更，则需要引入分布式事务。 分布式事务的模式有很多种，那究竟要怎么选择适合业务的模式呢？以下我们将从使用场景、性能、开发成本这几个方面进行分析。 何时选择基于消息实现的事务基于消息实现的事务适用于分布式事务的提交或回滚只取决于事务发起方的业务需求，其他数据源的数据变更跟随发起方进行的业务场景。 举个例子，假设存在业务规则：某笔订单成功后，为用户加一定的积分。 在这条规则里，管理订单数据源的服务为事务发起方，管理积分数据源的服务为事务跟随者。 从这个过程可以看到，基于消息队列实现的事务存在以下操作： 订单服务创建订单，提交本地事务订单服务发布一条消息积分服务收到消息后加积分我们可以看到它的整体流程是比较简单的，同时业务开发工作量也不大： 编写订单服务里订单创建的逻辑 编写积分服务里增加积分的逻辑可以看到该事务形态过程简单，性能消耗小，发起方与跟随方之间的流量峰谷可以使用队列填平，同时业务开发工作量也基本与单机事务没有差别，都不需要编写反向的业务逻辑过程。因此基于消息队列实现的事务是我们除了单机事务外最优先考虑使用的形态。 何时选择利用补偿实现的事务？但是基于消息实现的事务并不能解决所有的业务场景，例如以下场景：某笔订单完成时，同时扣掉用户的现金。 这里事务发起方是管理订单库的服务，但对整个事务是否提交并不能只由订单服务决定，因为还要确保用户有足够的钱，才能完成这笔交易，而这个信息在管理现金的服务里。这里我们可以引入基于补偿实现的事务，其流程如下： 创建订单数据，但暂不提交本地事务 订单服务发送远程调用到现金服务，以扣除对应的金额 上述步骤成功后提交订单库的事务以上这个是正常成功的流程，异常流程需要回滚的话，将额外发送远程调用到现金服务以加上之前扣掉的金额。 以上流程比基于消息队列实现的事务的流程要复杂，同时开发的工作量也更多： 编写订单服务里创建订单的逻辑 编写现金服务里扣钱的逻辑 编写现金服务里补偿返还的逻辑可以看到，该事务流程相对于基于消息实现的分布式事务更为复杂，需要额外开发相关的业务回滚方法，也失去了服务间流量削峰填谷的功能。但其仅仅只比基于消息的事务复杂多一点，若不能使用基于消息队列的最终一致性事务，那么可以优先考虑使用基于补偿的事务形态。 （题外话：阿里GTS也是利用补偿实现，只不过补偿代码自动生成，无需业务干预，同时接管应用数据源，禁止业务修改处于全局事务状态中的记录。） 何时选择利用TCC实现的事务然而基于补偿的事务形态也并非能实现所有的需求，如以下场景：某笔订单完成时，同时扣掉用户的现金，但交易未完成，也未被取消时，不能让客户看到钱变少了。 这时我们可以引入TCC，其流程如下： 订单服务创建订单 订单服务发送远程调用到现金服务，冻结客户的现金 提交订单服务数据 订单服务发送远程调用到现金服务，扣除客户冻结的现金以上是正常完成的流程，若为异常流程，则需要发送远程调用请求到现金服务，撤销冻结的金额。 以上流程比基于补偿实现的事务的流程要复杂，同时开发的工作量也更多： 订单服务编写创建订单的逻辑 现金服务编写冻结现金的逻辑 现金服务编写扣除现金的逻辑 现金服务编写解冻现金的逻辑TCC实际上是最为复杂的一种情况，其能处理所有的业务场景，但无论出于性能上的考虑，还是开发复杂度上的考虑，都应该尽量避免该类事务。 何时选择利用SAGA实现的事务？saga是30年前的一篇数据库论文提到的概念。 论文中定义saga事务是一个长事务，整个事务可以由多个本地事务组成，每个本地事务有相应的执行模块和补偿模块，当saga事务中任意一个事务出错了，可以调用相关事务进行对应的补偿恢复，达到事务的最终一致性。 由于分布式系统中网络带来的不可靠性，saga调用服务提出了服务应该支持幂等，在服务调用超时重试情况下，不至于产生问题。 saga事务没有准备阶段，不具备隔离性，如果多个saga事务同时操作同一资源会遇到多线程临界资源的情况，产生数据丢失或者脏数据。 为解决隔离性，可以参考TCC模式，在业务层加入session及锁机制保证操作串型化，通过业务层面达到隔离效果。 saga在分布式架构下，采用事务驱动方式，让服务进行相关交互，业务方订阅相关领域事件即可。 通过事件方式降低系统复杂度，提升系统扩展性，但要注意事件循环依赖的问题。 SAGA可以看做一个异步的、利用队列实现的补偿事务。 其适用于无需马上返回业务发起方最终状态的场景，例如：你的请求已提交，请稍后查询或留意通知 之类。 将上述补偿事务的场景用SAGA改写，其流程如下： 订单服务创建最终状态未知的订单记录，并提交事务 现金服务扣除所需的金额，并提交事务 订单服务更新订单状态为成功，并提交事务以上为成功的流程，若现金服务扣除金额失败，那么，最后一步订单服务将会更新订单状态为失败。 其业务编码工作量比补偿事务多一点，包括以下内容： 订单服务创建初始订单的逻辑 订单服务确认订单成功的逻辑 订单服务确认订单失败的逻辑 现金服务扣除现金的逻辑 现金服务补偿返回现金的逻辑但其相对于补偿事务形态有性能上的优势，所有的本地子事务执行过程中，都无需等待其调用的子事务执行，减少了加锁的时间，这在事务流程较多较长的业务中性能优势更为明显。同时，其利用队列进行进行通讯，具有削峰填谷的作用。 因此该形式适用于不需要同步返回发起方执行最终结果、可以进行补偿、对性能要求较高、不介意额外编码的业务场景。 但当然SAGA也可以进行稍微改造，变成与TCC类似、可以进行资源预留的形态。 2PC事务其适用于参与者较少，单个本地事务执行时间较少，并且参与者自身可用性很高的场景，否则，其很可能导致性能下降严重。 并非一种事务形态就能打遍天下通过分析我们可以发现，并不存在一种事务形态能解决所有的问题，我们需要根据特定的业务场景选择合适的事务形态。甚至于有时需要混合多种事务形态才能更好的完成目标，如 上面提到的 订单、积分、钱包混合的场景：订单的成功与否需要依赖于钱包的余额，但不依赖于积分的多少，因此可以混合基于消息的事务形态以加积分 及 基于补偿的事务形态以确保扣钱成功，从而得到一个性能更好，编码量更少的形态。 然而目前很多框架都专注于某单一方面的事务形态，如TCC单独一个框架，可靠消息单独一个框架，SAGA单独一个框架，他们各自独立，容易导致以下问题： 由于前期只采用了其中一种类型事务的框架，因为工具目前只有锤子，引入其他工具又涉及测试、阅读代码等过程，因此把所有问题都看做钉子，导致性能偏低或者实现不够优雅 由于不同框架管理事务的形态可能不一致，导致不能很好的协调工作，如某一个TCC框架和另一个基于消息的事务框架无法很好融合。 事务隔离级别Spring事务的隔离级别 ISOLATION_DEFAULT： 这是一个 PlatfromTransactionManager 默认的隔离级别，使用数据库默认的事务隔离级别. 另外四个与 JDBC的隔离级别相对应: ISOLATION_READ_UNCOMMITTED： 这是事务最低的隔离级别，它允许令外一个事务可以看到这个事务未提交的数据, 这种隔离级别会产生脏读，不可重复读和幻像读。 ISOLATION_READ_COMMITTED： 保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据 ISOLATION_REPEATABLE_READ： 这种事务隔离级别可以防止脏读，不可重复读。但是可能出现幻像读。它除了保证一个事务不能读取另一个事务未提交的数据外，还保证了避免下面的情况产生(不可重复读)。 ISOLATION_SERIALIZABLE 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。除了防止脏读，不可重复读外，还避免了幻像读。 其中的一些概念的说明：脏读: 指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据， 那么另外一 个事务读到的这个数据是脏数据，依据脏数据所做的操作可能是不正确的。 不可重复读: 指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。 那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。 幻觉读:指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及 到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，就会发生操作第一个事务的用户发现表中还有 没有修改的数据行,也就是说幻像读是指同一查询在同一事务中多次进行，由于其他提交事务所做的插入操作，每次返回不同的结果集，此时发生幻像读,就好象发生了幻觉一样。 事务的传播行为和隔离级别之间有什么联系事务传播行为事务传播行为(为了解决业务层方法之间互相调用的事务问题): 当事务方法被另一个事务方法调用时,必须指定事务应该如何传播。例如:方法可能继续在现有事务中运行,也可能开启一个新事务,并在自己的事务中运行。在TransactionDefinition定义中包括了如下几个表示传播行为的常量: 支持当前事务的情况 TransactionDefinition.PROPAGATION_REQUIRED: 如果当前存在事务,则加入该事务;如果当前没有事务,则创建一个新的事务。 TransactionDefinition.PROPAGATION_SUPPORTS: 如果当前存在事务,则加入该事务;如果当前没有事务,则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_MANDATORY: 如果当前存在事务,则加入该事务;如果当前没有事务,则抛出异常。(mandatory:强制性) 不支持当前事务的情况 TransactionDefinition.PROPAGATION_REQUIRES_NEW: 创建一个新的事务,如果当前存在事务,则把当前事务挂起。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED: 以非事务方式运行,如果当前存在事务,则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER: 以非事务方式运行,如果当前存在事务,则抛出异常。 其他情况 TransactionDefinition.PROPAGATION_NESTED: 如果当前存在事务,则创建一个事务作为当前事务的嵌套事务来运行;如果当前没有事务,则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。 隔离级别TransactionDefinition 接口中定义了五个表示隔离级别的常量: TransactionDefinition.ISOLATION_DEFAULT: 使用后端数据库默认的隔离级别,Mysql 默认采用的REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别。 TransactionDefinition.ISOLATION_READ_UNCOMMITTED: 最低的隔离级别,允许读取尚未提交的数据变更,可能会导致脏读、幻读或不可重复读。 TransactionDefinition.ISOLATION_READ_COMMITTED: 允许读取并发事务已经提交的数据,可以阻止脏读,但是幻读或不可重复读仍有可能发生。 TransactionDefinition.ISOLATION_REPEATABLE_READ: 对同一字段的多次读取结果都是一致的,除非数据是被本身事务自己所修改,可以阻止脏读和不可重复读,但幻读仍有可能发生。 TransactionDefinition.ISOLATION_SERIALIZABLE: 最高的隔离级别,完全服从ACID的隔离级别。所有的事务依次逐个执行,这样事务之间就完全不可能产生干扰,也就是说,该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 如何理解Spring中的AOP 和 IOC，以及DI，读过Spring源码没有？AOP 什么是aop AOP（Aspect Oriented Programming）称为面向切面编程，在程序开发中主要用来解决一些系统层面上的问题，比如日志，事务，权限等待，Struts2的拦截器设计就是基于AOP的思想，是个比较经典的例子。 在不改变原有的逻辑的基础上，增加一些额外的功能。代理也是这个功能，读写分离也能用aop来做。 AOP可以说是OOP（Object Oriented Programming，面向对象编程）的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，用于模拟公共行为的一个集合。不过OOP允许开发者定义纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，而与它对应的对象的核心功能毫无关系对于其他类型的代码，如安全性、异常处理和透明的持续性也都是如此，这种散布在各处的无关的代码被称为横切（cross cutting），在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。 AOP技术恰恰相反，它利用一种称为”横切”的技术，剖解开封装的对象内部，并将那些影响了多个类的公共行为封装到一个可重用模块，并将其命名为”Aspect”，即切面。所谓”切面”，简单说就是那些与业务无关，却为业务模块所共同调用的逻辑或责任封装起来，便于减少系统的重复代码，降低模块之间的耦合度，并有利于未来的可操作性和可维护性。 使用”横切”技术，AOP把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处基本相似，比如权限认证、日志、事物。AOP的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。 AOP的相关概念(1)横切关注点：对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点 (2)Aspect(切面):通常是一个类，里面可以定义切入点和通知 (3)JointPoint(连接点):程序执行过程中明确的点，一般是方法的调用。被拦截到的点，因为Spring只支持方法类型的连接点，所以在Spring中连接点指的就是被拦截到的方法，实际上连接点还可以是字段或者构造器 (4)Advice(通知):AOP在特定的切入点上执行的增强处理，有before(前置),after(后置),afterReturning(最终),afterThrowing(异常),around(环绕) (5)Pointcut(切入点):就是带有通知的连接点，在程序中主要体现为书写切入点表达式 (6)weave(织入)：将切面应用到目标对象并导致代理对象创建的过程 (7)introduction(引入)：在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法或字段 (8)AOP代理(AOP Proxy)：AOP框架创建的对象，代理就是目标对象的加强。Spring中的AOP代理可以使JDK动态代理，也可以是CGLIB代理，前者基于接口，后者基于子类 (9)目标对象（Target Object）: 包含连接点的对象。也被称作被通知或被代理对象。POJO Advice通知类型介绍(1)Before:在目标方法被调用之前做增强处理,@Before只需要指定切入点表达式即可 (2)AfterReturning:在目标方法正常完成后做增强,@AfterReturning除了指定切入点表达式后，还可以指定一个返回值形参名returning,代表目标方法的返回值 (3)AfterThrowing:主要用来处理程序中未处理的异常,@AfterThrowing除了指定切入点表达式后，还可以指定一个throwing的返回值形参名,可以通过该形参名 来访问目标方法中所抛出的异常对象 (4)After:在目标方法完成之后做增强，无论目标方法时候成功完成。@After可以指定一个切入点表达式 (5)Around:环绕通知,在目标方法完成前后做增强处理,环绕通知是最重要的通知类型,像事务,日志等都是环绕通知,注意编程中核心是一个ProceedingJoinPoint AOP使用场景 Authentication 权限 Caching 缓存 Context passing 内容传递 Error handling 错误处理 Lazy loading 懒加载 Debugging 调试 logging, tracing, profiling and monitoring 记录跟踪 优化 校准 Performance optimization 性能优化 Persistence 持久化 Resource pooling 资源池 Synchronization 同步 Transactions 事务 使用AOP的几种方式1.经典的基于代理的AOP 2.@AspectJ注解驱动的切面 3.纯POJO切面（纯粹通过&lt;aop:fonfig&gt;标签配置） 4.注入式AspectJ切面 IOCIoC 全称为 Inversion of Control，翻译为 “控制反转”，它还有一个别名为 DI（Dependency Injection）,即依赖注入。 如何理解“控制反转”好呢？理解好它的关键在于我们需要回答如下四个问题： 谁控制谁 控制什么 为何是反转 哪些方面反转了 在回答这四个问题之前，我们先看 IOC 的定义： 所谓 IOC ，就是由 Spring IOC 容器来负责对象的生命周期和对象之间的关系 上面这句话是整个 IoC 理论的核心。如何来理解这句话？我们引用一个例子来走阐述（看完该例子上面四个问题也就不是问题了）。 已找女朋友为例（对于程序猿来说这个值得探究的问题）。一般情况下我们是如何来找女朋友的呢？首先我们需要根据自己的需求（漂亮、身材好、性格好）找一个妹子，然后到处打听她的兴趣爱好、微信、电话号码，然后各种投其所好送其所要，最后追到手。如下： 123456789101112131415161718192021222324/** * 年轻小伙子 */public class YoungMan &#123; private BeautifulGirl beautifulGirl; YoungMan()&#123; // 可能你比较牛逼，指腹为婚 // beautifulGirl = new BeautifulGirl(); &#125; public void setBeautifulGirl(BeautifulGirl beautifulGirl) &#123; this.beautifulGirl = beautifulGirl; &#125; public static void main(String[] args)&#123; YoungMan you = new YoungMan(); BeautifulGirl beautifulGirl = new BeautifulGirl("你的各种条件"); beautifulGirl.setxxx("各种投其所好"); // 然后你有女票了 you.setBeautifulGirl(beautifulGirl); &#125;&#125; 这就是我们通常做事的方式，如果我们需要某个对象，一般都是采用这种直接创建的方式(new BeautifulGirl())，这个过程复杂而又繁琐，而且我们必须要面对每个环节，同时使用完成之后我们还要负责销毁它，在这种情况下我们的对象与它所依赖的对象耦合在一起。 其实我们需要思考一个问题？我们每次用到自己依赖的对象真的需要自己去创建吗？我们知道，我们依赖对象其实并不是依赖该对象本身，而是依赖它所提供的服务，只要在我们需要它的时候，它能够及时提供服务即可，至于它是我们主动去创建的还是别人送给我们的，其实并不是那么重要。再说了，相比于自己千辛万苦去创建它还要管理、善后而言，直接有人送过来是不是显得更加好呢？ 这个给我们送东西的“人” 就是 IoC，在上面的例子中，它就相当于一个婚介公司，作为一个婚介公司它管理着很多男男女女的资料，当我们需要一个女朋友的时候，直接跟婚介公司提出我们的需求，婚介公司则会根据我们的需求提供一个妹子给我们，我们只需要负责谈恋爱，生猴子就行了。你看，这样是不是很简单明了。 诚然，作为婚介公司的 IoC 帮我们省略了找女朋友的繁杂过程，将原来的主动寻找变成了现在的被动接受（符合我们的要求），更加简洁轻便。你想啊，原来你还得鞍马前后，各种巴结，什么东西都需要自己去亲力亲为，现在好了，直接有人把现成的送过来，多么美妙的事情啊。所以，简单点说，IoC 的理念就是让别人为你服务 在没有引入 IoC 的时候，被注入的对象直接依赖于被依赖的对象，有了 IoC 后，两者及其他们的关系都是通过 Ioc Service Provider 来统一管理维护的。被注入的对象需要什么，直接跟 IoC Service Provider 打声招呼，后者就会把相应的被依赖对象注入到被注入的对象中，从而达到 IOC Service Provider 为被注入对象服务的目的。所以 IoC 就是这么简单！原来是需要什么东西自己去拿，现在是需要什么东西让别人（IOC Service Provider）送过来 现在在看上面那四个问题，答案就显得非常明显了: 谁控制谁：在传统的开发模式下，我们都是采用直接 new 一个对象的方式来创建对象，也就是说你依赖的对象直接由你自己控制，但是有了 IOC 容器后，则直接由 IoC 容器来控制。所以“谁控制谁”，当然是 IoC 容器控制对象。 控制什么：控制对象。 为何是反转：没有 IoC 的时候我们都是在自己对象中主动去创建被依赖的对象，这是正转。但是有了 IoC 后，所依赖的对象直接由 IoC 容器创建后注入到被注入的对象中，依赖的对象由原来的主动获取变成被动接受，所以是反转。 哪些方面反转了：所依赖对象的获取被反转了。妹子有了，但是如何拥有妹子呢？这也是一门学问。 可能你比较牛逼，刚刚出生的时候就指腹为婚了。 大多数情况我们还是会考虑自己想要什么样的妹子，所以还是需要向婚介公司打招呼的。 还有一种情况就是，你根本就不知道自己想要什么样的妹子，直接跟婚介公司说，我就要一个这样的妹子。所以，IOC Service Provider 为被注入对象提供被依赖对象也有如下几种方式：构造方法注入、stter方法注入、接口注入。 构造器注入构造器注入，顾名思义就是被注入的对象通过在其构造方法中声明依赖对象的参数列表，让外部知道它需要哪些依赖对象。123YoungMan(BeautifulGirl beautifulGirl)&#123; this.beautifulGirl = beautifulGirl;&#125; 构造器注入方式比较直观，对象构造完毕后就可以直接使用，这就好比你出生你家里就给你指定了你媳妇。 setter 方法注入对于 JavaBean 对象而言，我们一般都是通过 getter 和 setter 方法来访问和设置对象的属性。所以，当前对象只需要为其所依赖的对象提供相对应的 setter 方法，就可以通过该方法将相应的依赖对象设置到被注入对象中。如下：1234567public class YoungMan &#123; private BeautifulGirl beautifulGirl; public void setBeautifulGirl(BeautifulGirl beautifulGirl) &#123; this.beautifulGirl = beautifulGirl; &#125;&#125; 相比于构造器注入，setter 方式注入会显得比较宽松灵活些，它可以在任何时候进行注入（当然是在使用依赖对象之前），这就好比你可以先把自己想要的妹子想好了，然后再跟婚介公司打招呼，你可以要林志玲款式的，赵丽颖款式的，甚至凤姐哪款的，随意性较强。 接口方式注入接口方式注入显得比较霸道，因为它需要被依赖的对象实现不必要的接口，带有侵入性。一般都不推荐这种方式。 DIDI（Dependency Injection）依赖注入：就是指对象是被动接受依赖类而不是自己主动去找，换句话说就是指对象不是从容器中查找它依赖的类，而是在容器实例化对象的时候主动将它依赖的类注入给它。 依赖注入发生的时间当 Spring IOC 容器完成了 Bean 定义资源的定位、载入和解析注册以后，IOC 容器中已经管理类 Bean定义的相关数据，但是此时 IOC 容器还没有对所管理的 Bean 进行依赖注入，依赖注入在以下两种情况发生：1)、用户第一次调用 getBean()方法时，IOC 容器触发依赖注入。2)、当用户在配置文件中将&lt;bean&gt;元素配置了 lazy-init=false 属性，即让容器在解析注册 Bean 定义时进行预实例化，触发依赖注入。 BeanFactory 接口定义了 Spring IOC 容器的基本功能规范，是 Spring IOC 容器所应遵守的最底层和最基本的编程规范。BeanFactory 接口中定义了几个 getBean()方法，就是用户向 IOC 容器索取管理的Bean 的方法，我们通过分析其子类AbstractBeanFactory 的具体实现，理解 Spring IOC 容器在用户索取 Bean 时如何完成依赖注入。 AbstractBeanFactory 的 getBean()相关方法的源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225//获取IOC容器中指定名称的Bean@Overridepublic Object getBean(String name) throws BeansException &#123; //doGetBean才是真正向IoC容器获取被管理Bean的过程 return doGetBean(name, null, null, false);&#125;//获取IOC容器中指定名称和类型的Bean@Overridepublic &lt;T&gt; T getBean(String name, @Nullable Class&lt;T&gt; requiredType) throws BeansException &#123; //doGetBean才是真正向IoC容器获取被管理Bean的过程 return doGetBean(name, requiredType, null, false);&#125;//获取IOC容器中指定名称和参数的Bean@Overridepublic Object getBean(String name, Object... args) throws BeansException &#123; //doGetBean才是真正向IoC容器获取被管理Bean的过程 return doGetBean(name, null, args, false);&#125;//获取IOC容器中指定名称、类型和参数的Beanpublic &lt;T&gt; T getBean(String name, @Nullable Class&lt;T&gt; requiredType, @Nullable Object... args) throws BeansException &#123; //doGetBean才是真正向IoC容器获取被管理Bean的过程 return doGetBean(name, requiredType, args, false);&#125;@SuppressWarnings("unchecked")//真正实现向IOC容器获取Bean的功能，也是触发依赖注入功能的地方protected &lt;T&gt; T doGetBean(final String name, @Nullable final Class&lt;T&gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException &#123; //根据指定的名称获取被管理Bean的名称，剥离指定名称中对容器的相关依赖 //如果指定的是别名，将别名转换为规范的Bean名称 final String beanName = transformedBeanName(name); Object bean; // Eagerly check singleton cache for manually registered singletons. //先从缓存中取是否已经有被创建过的单态类型的Bean //对于单例模式的Bean整个IOC容器中只创建一次，不需要重复创建 Object sharedInstance = getSingleton(beanName); //IOC容器创建单例模式Bean实例对象 if (sharedInstance != null &amp;&amp; args == null) &#123; if (logger.isDebugEnabled()) &#123; //如果指定名称的Bean在容器中已有单例模式的Bean被创建 //直接返回已经创建的Bean if (isSingletonCurrentlyInCreation(beanName)) &#123; logger.debug("Returning eagerly cached instance of singleton bean '" + beanName + "' that is not fully initialized yet - a consequence of a circular reference"); &#125; else &#123; logger.debug("Returning cached instance of singleton bean '" + beanName + "'"); &#125; &#125; //获取给定Bean的实例对象，主要是完成FactoryBean的相关处理 //注意：BeanFactory是管理容器中Bean的工厂，而FactoryBean是 //创建创建对象的工厂Bean，两者之间有区别 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); &#125; else &#123; // Fail if we're already creating this bean instance: // We're assumably within a circular reference. //缓存没有正在创建的单例模式Bean //缓存中已经有已经创建的原型模式Bean //但是由于循环引用的问题导致实例化对象失败 if (isPrototypeCurrentlyInCreation(beanName)) &#123; throw new BeanCurrentlyInCreationException(beanName); &#125; // Check if bean definition exists in this factory. //对IOC容器中是否存在指定名称的BeanDefinition进行检查，首先检查是否 //能在当前的BeanFactory中获取的所需要的Bean，如果不能则委托当前容器 //的父级容器去查找，如果还是找不到则沿着容器的继承体系向父级容器查找 BeanFactory parentBeanFactory = getParentBeanFactory(); //当前容器的父级容器存在，且当前容器中不存在指定名称的Bean if (parentBeanFactory != null &amp;&amp; !containsBeanDefinition(beanName)) &#123; // Not found -&gt; check parent. //解析指定Bean名称的原始名称 String nameToLookup = originalBeanName(name); if (parentBeanFactory instanceof AbstractBeanFactory) &#123; return ((AbstractBeanFactory) parentBeanFactory).doGetBean( nameToLookup, requiredType, args, typeCheckOnly); &#125; else if (args != null) &#123; // Delegation to parent with explicit args. //委派父级容器根据指定名称和显式的参数查找 return (T) parentBeanFactory.getBean(nameToLookup, args); &#125; else &#123; // No args -&gt; delegate to standard getBean method. //委派父级容器根据指定名称和类型查找 return parentBeanFactory.getBean(nameToLookup, requiredType); &#125; &#125; //创建的Bean是否需要进行类型验证，一般不需要 if (!typeCheckOnly) &#123; //向容器标记指定的Bean已经被创建 markBeanAsCreated(beanName); &#125; try &#123; //根据指定Bean名称获取其父级的Bean定义 //主要解决Bean继承时子类合并父类公共属性问题 final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); checkMergedBeanDefinition(mbd, beanName, args); // Guarantee initialization of beans that the current bean depends on. //获取当前Bean所有依赖Bean的名称 String[] dependsOn = mbd.getDependsOn(); //如果当前Bean有依赖Bean if (dependsOn != null) &#123; for (String dep : dependsOn) &#123; if (isDependent(beanName, dep)) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Circular depends-on relationship between '" + beanName + "' and '" + dep + "'"); &#125; //递归调用getBean方法，获取当前Bean的依赖Bean registerDependentBean(dep, beanName); //把被依赖Bean注册给当前依赖的Bean getBean(dep); &#125; &#125; // Create bean instance. //创建单例模式Bean的实例对象 if (mbd.isSingleton()) &#123; //这里使用了一个匿名内部类，创建Bean实例对象，并且注册给所依赖的对象 sharedInstance = getSingleton(beanName, () -&gt; &#123; try &#123; //创建一个指定Bean实例对象，如果有父级继承，则合并子类和父类的定义 return createBean(beanName, mbd, args); &#125; catch (BeansException ex) &#123; // Explicitly remove instance from singleton cache: It might have been put there // eagerly by the creation process, to allow for circular reference resolution. // Also remove any beans that received a temporary reference to the bean. //显式地从容器单例模式Bean缓存中清除实例对象 destroySingleton(beanName); throw ex; &#125; &#125;); //获取给定Bean的实例对象 bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); &#125; //IOC容器创建原型模式Bean实例对象 else if (mbd.isPrototype()) &#123; // It's a prototype -&gt; create a new instance. //原型模式(Prototype)是每次都会创建一个新的对象 Object prototypeInstance = null; try &#123; //回调beforePrototypeCreation方法，默认的功能是注册当前创建的原型对象 beforePrototypeCreation(beanName); //创建指定Bean对象实例 prototypeInstance = createBean(beanName, mbd, args); &#125; finally &#123; //回调afterPrototypeCreation方法，默认的功能告诉IOC容器指定Bean的原型对象不再创建 afterPrototypeCreation(beanName); &#125; //获取给定Bean的实例对象 bean = getObjectForBeanInstance(prototypeInstance, name, beanName, mbd); &#125; //要创建的Bean既不是单例模式，也不是原型模式，则根据Bean定义资源中 //配置的生命周期范围，选择实例化Bean的合适方法，这种在Web应用程序中 //比较常用，如：request、session、application等生命周期 else &#123; String scopeName = mbd.getScope(); final Scope scope = this.scopes.get(scopeName); //Bean定义资源中没有配置生命周期范围，则Bean定义不合法 if (scope == null) &#123; throw new IllegalStateException("No Scope registered for scope name '" + scopeName + "'"); &#125; try &#123; //这里又使用了一个匿名内部类，获取一个指定生命周期范围的实例 Object scopedInstance = scope.get(beanName, () -&gt; &#123; beforePrototypeCreation(beanName); try &#123; return createBean(beanName, mbd, args); &#125; finally &#123; afterPrototypeCreation(beanName); &#125; &#125;); //获取给定Bean的实例对象 bean = getObjectForBeanInstance(scopedInstance, name, beanName, mbd); &#125; catch (IllegalStateException ex) &#123; throw new BeanCreationException(beanName, "Scope '" + scopeName + "' is not active for the current thread; consider " + "defining a scoped proxy for this bean if you intend to refer to it from a singleton", ex); &#125; &#125; &#125; catch (BeansException ex) &#123; cleanupAfterBeanCreationFailure(beanName); throw ex; &#125; &#125; // Check if required type matches the type of the actual bean instance. //对创建的Bean实例对象进行类型检查 if (requiredType != null &amp;&amp; !requiredType.isInstance(bean)) &#123; try &#123; T convertedBean = getTypeConverter().convertIfNecessary(bean, requiredType); if (convertedBean == null) &#123; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; return convertedBean; &#125; catch (TypeMismatchException ex) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Failed to convert bean '" + name + "' to required type '" + ClassUtils.getQualifiedName(requiredType) + "'", ex); &#125; throw new BeanNotOfRequiredTypeException(name, requiredType, bean.getClass()); &#125; &#125; return (T) bean;&#125; 通过上面对向 IOC 容器获取 Bean 方法的分析，我们可以看到在 Spring 中，如果 Bean 定义的单例模式(Singleton)，则容器在创建之前先从缓存中查找，以确保整个容器中只存在一个实例对象。如果 Bean定义的是原型模式(Prototype)，则容器每次都会创建一个新的实例对象。除此之外，Bean 定义还可以通过其指定的生命周期范围来创建。 上面的源码只是定义了根据 Bean 定义的模式，采取的不同创建 Bean 实例对象的策略，具体的 Bean实例 对象的创 建过程 由实现了AbstractBeanFactory接口 的匿名内 部类的createBean()方法 完成，AbstractBeanFactory使 用 委 派 模 式 ， 具 体 的 Bean 实 例 创 建 过 程 交 由 其 实 现 类AbstractAutowireCapableBeanFactory 完成，我们继续分析AbstractAutowireCapableBeanFactory的 createBean()方法的源码，理解其创建 Bean 实例的具体实现过程。 开始实例化AbstractAutowireCapableBeanFactory 类实现了 AbstractBeanFactory接口，创建容器指定的 Bean 实例对象，同时还对创建的 Bean 实例对象进行初始化处理。其创建 Bean 实例对象的方法源码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179//创建Bean实例对象@Overrideprotected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Creating instance of bean '" + beanName + "'"); &#125; RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. //判断需要创建的Bean是否可以实例化，即是否可以通过当前的类加载器加载 Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; // Prepare method overrides. //校验和准备Bean中的方法覆盖 try &#123; mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, "Validation of method overrides failed", ex); &#125; try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. //如果Bean配置了初始化前和初始化后的处理器，则试图返回一个需要创建Bean的代理对象 Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, "BeanPostProcessor before instantiation of bean failed", ex); &#125; try &#123; //创建Bean的入口 Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isDebugEnabled()) &#123; logger.debug("Finished creating instance of bean '" + beanName + "'"); &#125; return beanInstance; &#125; catch (BeanCreationException ex) &#123; // A previously detected exception with proper bean creation context already... throw ex; &#125; catch (ImplicitlyAppearedSingletonException ex) &#123; // An IllegalStateException to be communicated up to DefaultSingletonBeanRegistry... throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException( mbdToUse.getResourceDescription(), beanName, "Unexpected exception during bean creation", ex); &#125;&#125;//真正创建Bean的方法protected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. //封装被创建的Bean对象 BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; final Object bean = instanceWrapper.getWrappedInstance(); //获取实例化对象的类型 Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; // Allow post-processors to modify the merged bean definition. //调用PostProcessor后置处理器 synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Post-processing of merged bean definition failed", ex); &#125; mbd.postProcessed = true; &#125; &#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. //向容器中缓存单例模式的Bean对象，以防循环引用 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isDebugEnabled()) &#123; logger.debug("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; //这里是一个匿名内部类，为了防止循环引用，尽早持有对象的引用 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // Initialize the bean instance. //Bean对象的初始化，依赖注入在此触发 //这个exposedObject在初始化完成之后返回作为依赖注入完成后的Bean Object exposedObject = bean; try &#123; //将Bean实例对象封装，并且Bean定义中配置的属性值赋值给实例对象 populateBean(beanName, mbd, instanceWrapper); //初始化Bean对象 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Initialization of bean failed", ex); &#125; &#125; if (earlySingletonExposure) &#123; //获取指定名称的已注册的单例模式Bean对象 Object earlySingletonReference = getSingleton(beanName, false); if (earlySingletonReference != null) &#123; //根据名称获取的已注册的Bean和正在实例化的Bean是同一个 if (exposedObject == bean) &#123; //当前实例化的Bean初始化完成 exposedObject = earlySingletonReference; &#125; //当前Bean依赖其他Bean，并且当发生循环引用时不允许新创建实例对象 else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); //获取当前Bean所依赖的其他Bean for (String dependentBean : dependentBeans) &#123; //对依赖Bean进行类型检查 if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, "Bean with name '" + beanName + "' has been injected into other beans [" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + "] in its raw version as part of a circular reference, but has eventually been " + "wrapped. This means that said other beans do not use the final version of the " + "bean. This is often the result of over-eager type matching - consider using " + "'getBeanNamesOfType' with the 'allowEagerInit' flag turned off, for example."); &#125; &#125; &#125; &#125; // Register bean as disposable. //注册完成依赖注入的Bean try &#123; registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Invalid destruction signature", ex); &#125; return exposedObject;&#125; 通过上面的源码注释，我们看到具体的依赖注入实现其实就在以下两个方法中：1)、createBeanInstance()方法，生成 Bean 所包含的 java 对象实例。2)、populateBean()方法，对 Bean 属性的依赖注入进行处理。下面继续分析这两个方法的代码实现。 选择 Bean 实例化策略在 createBeanInstance()方法中，根据指定的初始化策略，使用简单工厂、工厂方法或者容器的自动装配特性生成 Java 实例对象，创建对象的源码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586//创建Bean的实例对象protected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) &#123; // Make sure bean class is actually resolved at this point. //检查确认Bean是可实例化的 Class&lt;?&gt; beanClass = resolveBeanClass(mbd, beanName); //使用工厂方法对Bean进行实例化 if (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Bean class isn't public, and non-public access not allowed: " + beanClass.getName()); &#125; Supplier&lt;?&gt; instanceSupplier = mbd.getInstanceSupplier(); if (instanceSupplier != null) &#123; return obtainFromSupplier(instanceSupplier, beanName); &#125; if (mbd.getFactoryMethodName() != null) &#123; //调用工厂方法实例化 return instantiateUsingFactoryMethod(beanName, mbd, args); &#125; // Shortcut when re-creating the same bean... //使用容器的自动装配方法进行实例化 boolean resolved = false; boolean autowireNecessary = false; if (args == null) &#123; synchronized (mbd.constructorArgumentLock) &#123; if (mbd.resolvedConstructorOrFactoryMethod != null) &#123; resolved = true; autowireNecessary = mbd.constructorArgumentsResolved; &#125; &#125; &#125; if (resolved) &#123; if (autowireNecessary) &#123; //配置了自动装配属性，使用容器的自动装配实例化 //容器的自动装配是根据参数类型匹配Bean的构造方法 return autowireConstructor(beanName, mbd, null, null); &#125; else &#123; //使用默认的无参构造方法实例化 return instantiateBean(beanName, mbd); &#125; &#125; // Need to determine the constructor... //使用Bean的构造方法进行实例化 Constructor&lt;?&gt;[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName); if (ctors != null || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR || mbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args)) &#123; //使用容器的自动装配特性，调用匹配的构造方法实例化 return autowireConstructor(beanName, mbd, ctors, args); &#125; // No special handling: simply use no-arg constructor. //使用默认的无参构造方法实例化 return instantiateBean(beanName, mbd);&#125;//使用默认的无参构造方法实例化Bean对象protected BeanWrapper instantiateBean(final String beanName, final RootBeanDefinition mbd) &#123; try &#123; Object beanInstance; final BeanFactory parent = this; //获取系统的安全管理接口，JDK标准的安全管理API if (System.getSecurityManager() != null) &#123; //这里是一个匿名内置类，根据实例化策略创建实例对象 beanInstance = AccessController.doPrivileged((PrivilegedAction&lt;Object&gt;) () -&gt; getInstantiationStrategy().instantiate(mbd, beanName, parent), getAccessControlContext()); &#125; else &#123; //将实例化的对象封装起来 beanInstance = getInstantiationStrategy().instantiate(mbd, beanName, parent); &#125; BeanWrapper bw = new BeanWrapperImpl(beanInstance); initBeanWrapper(bw); return bw; &#125; catch (Throwable ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Instantiation of bean failed", ex); &#125;&#125; 经过对上面的代码分析，我们可以看出，对使用工厂方法和自动装配特性的 Bean 的实例化相当比较清楚，调用相应的工厂方法或者参数匹配的构造方法即可完成实例化对象的工作，但是对于我们最常使用的默认无参构造方法就需要使用相应的初始化策略(JDK 的反射机制或者 CGLib)来进行初始化了，在方法 getInstantiationStrategy().instantiate()中就具体实现类使用初始策略实例化对象。 执行 Bean 实例化在使用默认的无参构造方法创建 Bean 的实例化对象时，方法 getInstantiationStrategy().instantiate()调用了 SimpleInstantiationStrategy 类中的实例化 Bean 的方法，其源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142//使用初始化策略实例化Bean对象@Overridepublic Object instantiate(RootBeanDefinition bd, @Nullable String beanName, BeanFactory owner) &#123; // Don't override the class with CGLIB if no overrides. //如果Bean定义中没有方法覆盖，则就不需要CGLIB父类类的方法 if (!bd.hasMethodOverrides()) &#123; Constructor&lt;?&gt; constructorToUse; synchronized (bd.constructorArgumentLock) &#123; //获取对象的构造方法或工厂方法 constructorToUse = (Constructor&lt;?&gt;) bd.resolvedConstructorOrFactoryMethod; //如果没有构造方法且没有工厂方法 if (constructorToUse == null) &#123; //使用JDK的反射机制，判断要实例化的Bean是否是接口 final Class&lt;?&gt; clazz = bd.getBeanClass(); if (clazz.isInterface()) &#123; throw new BeanInstantiationException(clazz, "Specified class is an interface"); &#125; try &#123; if (System.getSecurityManager() != null) &#123; //这里是一个匿名内置类，使用反射机制获取Bean的构造方法 constructorToUse = AccessController.doPrivileged( (PrivilegedExceptionAction&lt;Constructor&lt;?&gt;&gt;) () -&gt; clazz.getDeclaredConstructor()); &#125; else &#123; constructorToUse = clazz.getDeclaredConstructor(); &#125; bd.resolvedConstructorOrFactoryMethod = constructorToUse; &#125; catch (Throwable ex) &#123; throw new BeanInstantiationException(clazz, "No default constructor found", ex); &#125; &#125; &#125; //使用BeanUtils实例化，通过反射机制调用”构造方法.newInstance(arg)”来进行实例化 return BeanUtils.instantiateClass(constructorToUse); &#125; else &#123; // Must generate CGLIB subclass. //使用CGLIB来实例化对象 return instantiateWithMethodInjection(bd, beanName, owner); &#125;&#125; 通过上面的代码分析，我们看到了如果 Bean 有方法被覆盖了，则使用 JDK 的反射机制进行实例化，否则，使用 CGLib 进行实例化。instantiateWithMethodInjection() 方 法 调 用SimpleInstantiationStrategy 的 子 类CGLibSubclassingInstantiationStrategy 使用 CGLib 来进行初始化，其源码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243//使用CGLIB进行Bean对象实例化 public Object instantiate(@Nullable Constructor&lt;?&gt; ctor, @Nullable Object... args) &#123; //创建代理子类 Class&lt;?&gt; subclass = createEnhancedSubclass(this.beanDefinition); Object instance; if (ctor == null) &#123; instance = BeanUtils.instantiateClass(subclass); &#125; else &#123; try &#123; Constructor&lt;?&gt; enhancedSubclassConstructor = subclass.getConstructor(ctor.getParameterTypes()); instance = enhancedSubclassConstructor.newInstance(args); &#125; catch (Exception ex) &#123; throw new BeanInstantiationException(this.beanDefinition.getBeanClass(), "Failed to invoke constructor for CGLIB enhanced subclass [" + subclass.getName() + "]", ex); &#125; &#125; // SPR-10785: set callbacks directly on the instance instead of in the // enhanced class (via the Enhancer) in order to avoid memory leaks. Factory factory = (Factory) instance; factory.setCallbacks(new Callback[] &#123;NoOp.INSTANCE, new LookupOverrideMethodInterceptor(this.beanDefinition, this.owner), new ReplaceOverrideMethodInterceptor(this.beanDefinition, this.owner)&#125;); return instance; &#125; private Class&lt;?&gt; createEnhancedSubclass(RootBeanDefinition beanDefinition) &#123; //CGLIB中的类 Enhancer enhancer = new Enhancer(); //将Bean本身作为其基类 enhancer.setSuperclass(beanDefinition.getBeanClass()); enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE); if (this.owner instanceof ConfigurableBeanFactory) &#123; ClassLoader cl = ((ConfigurableBeanFactory) this.owner).getBeanClassLoader(); enhancer.setStrategy(new ClassLoaderAwareGeneratorStrategy(cl)); &#125; enhancer.setCallbackFilter(new MethodOverrideCallbackFilter(beanDefinition)); enhancer.setCallbackTypes(CALLBACK_TYPES); //使用CGLIB的createClass方法生成实例对象 return enhancer.createClass(); &#125;&#125; CGLib 是一个常用的字节码生成器的类库，它提供了一系列 API 实现 Java 字节码的生成和转换功能。JDK 的动态代理只能针对接口，如果一个类没有实现任何接口，要对其进行动态代理只能使用 CGLib。 准备依赖注入在前面的分析中我们已经了解到 Bean 的依赖注入主要分为两个步骤，首先调用 createBeanInstance()方法生成 Bean 所包含的 Java 对象实例。然后，调用 populateBean()方法，对 Bean 属性的依赖注入进行处理。上面我们已经分析了容器初始化生成 Bean 所包含的 Java 实例对象的过程，现在我们继续分析生成对象后，Spring IOC 容器是如何将 Bean 的属性依赖关系注入 Bean 实例对象中并设置好的，回到AbstractAutowireCapableBeanFactory 的 populateBean()方法，对属性依赖注入的代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201//将Bean属性设置到生成的实例对象上protected void populateBean(String beanName, RootBeanDefinition mbd, @Nullable BeanWrapper bw) &#123; if (bw == null) &#123; if (mbd.hasPropertyValues()) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Cannot apply property values to null instance"); &#125; else &#123; // Skip property population phase for null instance. return; &#125; &#125; // Give any InstantiationAwareBeanPostProcessors the opportunity to modify the // state of the bean before properties are set. This can be used, for example, // to support styles of field injection. boolean continueWithPropertyPopulation = true; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; if (!ibp.postProcessAfterInstantiation(bw.getWrappedInstance(), beanName)) &#123; continueWithPropertyPopulation = false; break; &#125; &#125; &#125; &#125; if (!continueWithPropertyPopulation) &#123; return; &#125; //获取容器在解析Bean定义资源时为BeanDefiniton中设置的属性值 PropertyValues pvs = (mbd.hasPropertyValues() ? mbd.getPropertyValues() : null); //对依赖注入处理，首先处理autowiring自动装配的依赖注入 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME || mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; MutablePropertyValues newPvs = new MutablePropertyValues(pvs); // Add property values based on autowire by name if applicable. //根据Bean名称进行autowiring自动装配处理 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_NAME) &#123; autowireByName(beanName, mbd, bw, newPvs); &#125; // Add property values based on autowire by type if applicable. //根据Bean类型进行autowiring自动装配处理 if (mbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_BY_TYPE) &#123; autowireByType(beanName, mbd, bw, newPvs); &#125; pvs = newPvs; &#125; //对非autowiring的属性进行依赖注入处理 boolean hasInstAwareBpps = hasInstantiationAwareBeanPostProcessors(); boolean needsDepCheck = (mbd.getDependencyCheck() != RootBeanDefinition.DEPENDENCY_CHECK_NONE); if (hasInstAwareBpps || needsDepCheck) &#123; if (pvs == null) &#123; pvs = mbd.getPropertyValues(); &#125; PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(bw, mbd.allowCaching); if (hasInstAwareBpps) &#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &#123; if (bp instanceof InstantiationAwareBeanPostProcessor) &#123; InstantiationAwareBeanPostProcessor ibp = (InstantiationAwareBeanPostProcessor) bp; pvs = ibp.postProcessPropertyValues(pvs, filteredPds, bw.getWrappedInstance(), beanName); if (pvs == null) &#123; return; &#125; &#125; &#125; &#125; if (needsDepCheck) &#123; checkDependencies(beanName, mbd, filteredPds, pvs); &#125; &#125; if (pvs != null) &#123; //对属性进行注入 applyPropertyValues(beanName, mbd, bw, pvs); &#125;&#125;//解析并注入依赖属性的过程protected void applyPropertyValues(String beanName, BeanDefinition mbd, BeanWrapper bw, PropertyValues pvs) &#123; if (pvs.isEmpty()) &#123; return; &#125; //封装属性值 MutablePropertyValues mpvs = null; List&lt;PropertyValue&gt; original; if (System.getSecurityManager() != null) &#123; if (bw instanceof BeanWrapperImpl) &#123; //设置安全上下文，JDK安全机制 ((BeanWrapperImpl) bw).setSecurityContext(getAccessControlContext()); &#125; &#125; if (pvs instanceof MutablePropertyValues) &#123; mpvs = (MutablePropertyValues) pvs; //属性值已经转换 if (mpvs.isConverted()) &#123; // Shortcut: use the pre-converted values as-is. try &#123; //为实例化对象设置属性值 bw.setPropertyValues(mpvs); return; &#125; catch (BeansException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Error setting property values", ex); &#125; &#125; //获取属性值对象的原始类型值 original = mpvs.getPropertyValueList(); &#125; else &#123; original = Arrays.asList(pvs.getPropertyValues()); &#125; //获取用户自定义的类型转换 TypeConverter converter = getCustomTypeConverter(); if (converter == null) &#123; converter = bw; &#125; //创建一个Bean定义属性值解析器，将Bean定义中的属性值解析为Bean实例对象的实际值 BeanDefinitionValueResolver valueResolver = new BeanDefinitionValueResolver(this, beanName, mbd, converter); // Create a deep copy, resolving any references for values. //为属性的解析值创建一个拷贝，将拷贝的数据注入到实例对象中 List&lt;PropertyValue&gt; deepCopy = new ArrayList&lt;&gt;(original.size()); boolean resolveNecessary = false; for (PropertyValue pv : original) &#123; //属性值不需要转换 if (pv.isConverted()) &#123; deepCopy.add(pv); &#125; //属性值需要转换 else &#123; String propertyName = pv.getName(); //原始的属性值，即转换之前的属性值 Object originalValue = pv.getValue(); //转换属性值，例如将引用转换为IOC容器中实例化对象引用 Object resolvedValue = valueResolver.resolveValueIfNecessary(pv, originalValue); //转换之后的属性值 Object convertedValue = resolvedValue; //属性值是否可以转换 boolean convertible = bw.isWritableProperty(propertyName) &amp;&amp; !PropertyAccessorUtils.isNestedOrIndexedProperty(propertyName); if (convertible) &#123; //使用用户自定义的类型转换器转换属性值 convertedValue = convertForProperty(resolvedValue, propertyName, bw, converter); &#125; // Possibly store converted value in merged bean definition, // in order to avoid re-conversion for every created bean instance. //存储转换后的属性值，避免每次属性注入时的转换工作 if (resolvedValue == originalValue) &#123; if (convertible) &#123; //设置属性转换之后的值 pv.setConvertedValue(convertedValue); &#125; deepCopy.add(pv); &#125; //属性是可转换的，且属性原始值是字符串类型，且属性的原始类型值不是 //动态生成的字符串，且属性的原始值不是集合或者数组类型 else if (convertible &amp;&amp; originalValue instanceof TypedStringValue &amp;&amp; !((TypedStringValue) originalValue).isDynamic() &amp;&amp; !(convertedValue instanceof Collection || ObjectUtils.isArray(convertedValue))) &#123; pv.setConvertedValue(convertedValue); //重新封装属性的值 deepCopy.add(pv); &#125; else &#123; resolveNecessary = true; deepCopy.add(new PropertyValue(pv, convertedValue)); &#125; &#125; &#125; if (mpvs != null &amp;&amp; !resolveNecessary) &#123; //标记属性值已经转换过 mpvs.setConverted(); &#125; // Set our (possibly massaged) deep copy. //进行属性依赖注入 try &#123; bw.setPropertyValues(new MutablePropertyValues(deepCopy)); &#125; catch (BeansException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Error setting property values", ex); &#125;&#125; 分析上述代码，我们可以看出，对属性的注入过程分以下两种情况：1)、属性值类型不需要强制转换时，不需要解析属性值，直接准备进行依赖注入。2)、属性值需要进行类型强制转换时，如对其他对象的引用等，首先需要解析属性值，然后对解析后的属性值进行依赖注入。对属性值的解析是在 BeanDefinitionValueResolver 类中的 resolveValueIfNecessary()方法中进行的，对属性值的依赖注入是通过 bw.setPropertyValues()方法实现的，在分析属性值的依赖注入之前，我们先分析一下对属性值的解析过程 解析属性注入规则当容器在对属性进行依赖注入时，如果发现属性值需要进行类型转换，如属性值是容器中另一个 Bean实例对象的引用，则容器首先需要根据属性值解析出所引用的对象，然后才能将该引用对象注入到目标实例对象的属性上去，对属性进行解析的由 resolveValueIfNecessary()方法实现。 Spring IOC 容器是如何将属性的值注入到 Bean 实例对象中去的：1)、对于集合类型的属性，将其属性值解析为目标类型的集合后直接赋值给属性。 2)、对于非集合类型的属性，大量使用了 JDK 的反射机制，通过属性的 getter()方法获取指定属性注入以前的值，同时调用属性的 setter()方法为属性设置注入后的值。看到这里相信很多人都明白了 Spring的 setter()注入原理 Spring DI运行时序图 如何理解分布式事务，为什么会出现这个问题，如何去解决，了解哪些分布式事务中间件？ 分布式中间件，我自己了解的就有 seata tx-lcn easyTransaction serviceComb Dubbo有了解没有？阿里开源的一款分布式框架。 Hystrix功能和在项目中怎么使用的？Hystrix怎么检测断路器是否要开启/关闭？Hystrix实现原理？除Hystrix之外的其他熔断限流中间件有了解没有，了解多少说多少？在一个分布式系统中，必然会有部分系统的调用会失败。Hystrix是一个通过添加超时容错和失败容错逻辑来帮助你控制这些分布式系统的交互。Hystrix通过隔离服务之间的访问，阻止他们之间的级联故障以及提供后背选项来实现这些，所有新而这些都用来提高系统的整体弹性。 Hystrix被设计用来解决一下几个方面 通过第三方（一般来源网络）的调用，给与保护和控制延迟和失败。 在复杂的分布式系统中复制级联失败。 快速失败和修复。 在可能的情况下，回滚挥着优雅的失败。 实现几乎实时监控，警报和操作控制。 复杂的分布式体系结构中的应用程序具有许多依赖关系，每个依赖关系都会在某些时候不可避免的失败。如果主机应用程序未与这些外部的故障隔离，那么可能会被这些故障拖垮。 例如:一个依赖30个SOA服务的系统,每个服务99.99%可用。 99.99%的30次方 ≈ 99.7% 0.3% 意味着一亿次请求 会有 3,000,00次失败 换算成时间大约每月有2个小时服务不稳定. 随着服务依赖数量的变多，服务不稳定的概率会成指数性提高.而实际中可能更糟糕。 Hystrix设计模式设计详解（命令模式）流程图流程说明 构造一个HystrixCommand或者HystrixObserverCommand对象，把需要调用的依赖放在run()中 执行execute/queue做同步或者异步执行 是否做了缓存 熔断是否打开 线程池/队列/信号量是否满了 调用run（）或者construct（） 计算熔断健康度（成功，失败，拒绝，超时）的数据，上报给熔断器，用于统计从而判断熔断器状态，可以根据这些数据来决定是否进行熔断，例如：错误率在80%以上，接口等待超过预定的时间等。 获取Fallback，如果fallback失败，系统报错，所以要尽量防止fallback报错，当然也可以在fallback上加上一层fallback 返回执行结果 功能介绍熔断器下图显示了HystrixCommand或者HystrixObserverCommand如何与HystrixCircuitBreaker及其逻辑和决策流程。包括计数器在断路器中的行为方式。熔断行为 断路器打开还是关闭的步骤如下 假定请求的量超过预定的阈值（circuitBreakerRequestVolumeThreshold） 再假定错误百分比超过了设定的百分比（circuitBreakerErrorThresholdPercentage） 断路器会从close状态到open状态 当打开的状态，会短路所有针对该断路器的请求 过了一定时间（circuitBreakerSleepWindowInMilliseconds（短路超过一定时间会重新去请求）），下一个请求将通过，不会被短路（当前是half-open状态）。如果这个请求失败了，则断路器在睡眠窗口期间返回open状态，如果请求成功，则断路器返回close状态，并重新回到第一步逻辑判断。 隔离Hystrix使用璧仓模式来隔离彼此的依赖关系，并限制对其中任何一个的并发访问。 线程和线程池客户端（第三方，网络调用等）依赖和请求线程运行在不同的线程上，这个将他们从调用线程隔离开来，这样调用者就可以从一个耗时太长的依赖中隔离。如下图所示，也可以为不同的请求开启不同的线程池，彼此之间不相互干扰。 （注：上图右边表示的是信号量模式） 线程隔离1、线程隔离的好处： 整个应用的即是在客户端调用失效的情况下也能健康的运行，线程池能够保证这个线程下面的失效不会影响应用其他部分的运行 当失效的客户端调用回复的时候，这个线程池也会被清理并且应用会立马回复健康，比tomcat那种长时间的恢复要好很多 简而言之，线程隔离能够允许在不引起中断的情况下优雅的处理第三方调用的各种问题。 2、线程隔离的缺点 主要缺点是增加了上下文切换的开销，每个明亮的执行都涉及到队列，调度和上下文切换。不过NetFix在设计这个系统的时候，已经决定接受这笔开销，以换取他的好处。 信号量隔离你可以使用信号量（或者计数器）来限制当前依赖调用的并发数，而不是使用线程池或者队列。如果客户端是可信的，且能快速返回，可以使用信号量来代替线程隔离，降低开销。信号量的大小可以动态调节，线程池却不行。 HystrixCommand和HystrixObserverCommand提供信号量隔离在下面两个地方： Fallback：当Hystrix检索fallback的时候，他心总是调用tomcat线程上执行此操作 如果你设置execution.isolation.strategy为SEMAPHORE的时候，Hystrix会使用信号量代替线程池去限制当前调用Command的并发数。 请求合并设置某个时间内的请求，合并为一个发送，例如：id和ids参数 请求缓存仪表盘Hystrix仪表盘 主要用来实时监控Hystrix的各项指标信息。通过Hystrix DashBoard反馈的实时信息，可以帮助我们快速防线系统中存在的问题，从而及时地采取对应措施。 开启仪表盘 1、在服务实例中新增spring-boot-starter-actuator，监控模块已开启监控相关的端点，并且映入断路器依赖：spring-cloud-starter-hystrix 2、确保在服务实例的主类中已经使用了@EnableCircuitBreaker注解，开启了断路器功能。 使用案例12345678910111213141516171819202122232425262728293031323334353637383940public class MyHystrixCommand extends HystrixCommand&lt;String&gt; &#123; protected MyHystrixCommand(String groupKey) &#123; super(Setter.withGroupKey(HystrixCommandGroupKey.Factory.asKey(groupKey))); &#125; @Override protected String run() throws Exception &#123; //实际调用外部的地方 return "reality invoke。"; &#125; @Override protected String getFallback() &#123; //run抛出异常，或者调用超时之后调用fallback return "invoke failed。"; &#125; public static void main(String args[])&#123; MyHystrixCommand hystrixCommand = new MyHystrixCommand("myCommand"); System.out.println(hystrixCommand.execute()); &#125;&#125;输出：reality invoke。//注解方式@RequestMapping("get-demo1-test")@HystrixCommand(fallbackMethod = "fallback", groupKey = "userGroup")public String getDemo1Name() throws InterruptedException &#123; //测试重试机制 int sleepTime = new Random().nextInt(300); Thread.sleep(sleepTime); return demo1Service.getAppName();&#125; public String fallback(Throwable t) &#123; System.out.println("erroe: " + t.getMessage()); return "error";&#125; 配置几个主要的配置信息：在构造方法中通过Setter设置 1.1、execution.isolation. thread.timeoutinMilliseconds: 该属性用来配 置HystrixCommand执行的超时时间， 单位为毫秒。当HystrixCommand执行 时间超过该配置值之后， Hystrix会将该执行命令标记为TIMEOUT并进入服务降级 处理逻辑。默认值1000 1.2、execution.isolation.semaphore.maxConcurrentRequests:当HystrixCommand的隔离策略使用信号量的时候，该属性用来配置信号量的大小（并发请求数）。 当最大并发请求数达到该设置值时， 后续的请求将会被拒绝。默认值10 1.3、circuitBreaker.requestVolumeThreshold该属性设置滚动窗口中将使断路器跳闸的最小请求数量，默认值：20 1.4、circuitBreaker.sleepWindowInMilliseconds 断路器跳闸后，在此值的时间的内，hystrix会拒绝新的请求，只有过了这个时间断路器才会打开闸门 默认值：5000 1.5、circuitBreaker.errorThresholdPercentage 设置失败百分比的阈值。如果失败比率超过这个值，则断路器跳闸并且进入fallback逻辑 默认值：50 1.6、metrics.rollingStats.timeInMilliseconds 滚动窗口时间大小，默认10s Feign了解多少说多少？Feignfeign是声明式的web service客户端，它让微服务之间的调用变得更简单了，类似controller调用service。Spring Cloud集成了Ribbon和Eureka，可在使用Feign时提供负载均衡的http客户端。 因为feign底层是使用了ribbon作为负载均衡的客户端，而ribbon的负载均衡也是依赖于eureka 获得各个服务的地址，所以要引入eureka-client。 Feign原理 启动时，程序会进行包扫描，扫描所有包下所有@FeignClient注解的类，并将这些类注入到spring的IOC容器中。当定义的Feign中的接口被调用时，通过JDK的动态代理来生成RequestTemplate。 RequestTemplate中包含请求的所有信息，如请求参数，请求URL等。 RequestTemplate声场Request，然后将Request交给client处理，这个client默认是JDK的HTTPUrlConnection，也可以是OKhttp、Apache的HTTPClient等。 最后client封装成LoadBaLanceClient，结合ribbon负载均衡地发起调用。 Zookeeper，了解多少说多少？ZooKeeper是一个分布式的开源协调服务，用于分布式应用程序。它公开了一组简单的原子操作，分布式应用程序可以构建这些原子操作，以实现更高级别的服务，以实现同步，配置维护以及组和命名。它的设计易于编程，并使用在熟悉的文件系统目录树结构之后设计的数据模型。它运行在Java中，并且对Java和C都有绑定。 周所周知，协调服务是很难做到的。它们特别容易出现诸如竞态条件和死锁等错误。ZooKeeper背后的动机是减轻分布式应用程序从头开始实施协调服务的责任。 设计目标Zookeeper是简单的。Zookeeper允许分布式进程之间彼此协调，通过一个共享的分级命名空间，它非常像标准的文件系统。 ZooKeeper实现非常重视高性能，高可用性，严格有序的访问。ZooKeeper的性能方面意味着它可以在大型分布式系统中使用。可靠性方面使其不会成为单点故障。严格的排序意味着可以在客户端实现复杂的同步原子操作。 Zookeeper是可复制的。 与它协调的分布式进程一样，ZooKeeper本身也可以在称为集合的一组主机上进行复制。 组成ZooKeeper服务的服务器必须彼此了解。它们保持状态的内存映像，以及持久存储中的事务日志和快照。只要大多数服务器可用，ZooKeeper服务就可用。客户端连接到单个ZooKeeper服务器。客户端维护一个TCP连接，通过它发送请求，获取响应，获取观看事件并发送心跳。如果与服务器的TCP连接中断，则客户端将连接到其他服务器。 Zookeeper是有序的。 ZooKeeper使用反映所有ZooKeeper事务顺序的数字标记每个更新。后续操作可以使用该顺序来实现更高级别的抽象，例如同步原子操作。 Zookeeper是非常快的。 它在“读取主导”工作负载中速度特别快。ZooKeeper应用程序在数千台计算机上运行，并且在读取比写入更常见的情况下表现最佳，比率大约为10：1。 数据模型和分层名称空间ZooKeeper提供的名称空间非常类似于标准文件系统。名称是由斜线（/）分隔的一系列路径元素。ZooKeeper名称空间中的每个节点都由一个路径标识。 节点和临时节点与标准文件系统不同的是，ZooKeeper命名空间中的每个节点都可以拥有与其相关的数据以及子级。这就像拥有一个允许文件也是目录的文件系统。（ZooKeeper旨在存储协调数据：状态信息，配置，位置信息等，因此存储在每个节点的数据通常很小，在字节到千字节范围内。）我们使用术语 znode来表明我们正在谈论ZooKeeper数据节点。 Znodes维护一个stat结构，包括数据更改，ACL更改和时间戳的版本号，以允许缓存验证和协调更新。每次znode的数据更改时，版本号都会增加。例如，每当客户端检索数据时，它也会收到数据的版本。 存储在名称空间中每个节点上的数据是以原子方式读取和写入的。读取获取与znode关联的所有数据字节，写入将替换所有数据。每个节点都有一个访问控制列表（ACL），限制谁可以做什么。 ZooKeeper也有临时节点的概念。只要创建znode的会话处于活动状态，就会存在这些znode。当会话结束时，znode被删除。 有条件的更新和监视ZooKeeper支持观察的概念。客户可以在znode上设置观察器。当znode更改时，将触发并删除观察器。 当观察被触发时，客户端收到一个数据包，说明znode已经改变。如果客户端和其中一个Zoo Keeper服务器之间的连接断开，客户端将收到本地通知。 担保ZooKeeper非常快速且非常简单。但是，由于其目标是构建更复杂的服务（如同步）的基础，因此它提供了一系列保证。这些是： 顺序一致性 - 客户端的更新将按照它们发送的顺序进行应用。 原子性 - 更新成功或失败。没有部分结果。 单系统映像 - 无论服务器连接到哪个服务器，客户端都会看到相同的服务视图。 可靠性 - 一旦应用更新，它将一直持续到客户覆盖更新为止。 及时性 - 系统的客户视图保证在特定时间范围内是最新的。 简单的APIZooKeeper的设计目标之一是提供一个非常简单的编程接口。因此，它仅支持以下操作： 创建——在树中的某个位置创建一个节点 删除——删除节点 存在——测试某个位置是否存在节点 获取数据——从节点读取数据 设定数据——将数据写入节点 得到子节点——检索节点的子节点列表 同步——等待数据传播 能用zookeeper做什么1、 命名服务 这个似乎最简单，在zookeeper的文件系统里创建一个目录，即有唯一的path。在我们使用tborg无法确定上游程序的部署机器时即可与下游程序约定好path，通过path即能互相探索发现，不见不散了。 2、 配置管理 程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。好吧，现在把这些配置全部放到zookeeper上去，保存在 Zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中就好。 3、 集群管理 所谓集群管理无在乎两点：是否有机器退出和加入、选举master。 对于第一点，所有机器约定在父目录GroupMembers下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与 zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除，于是，所有人都知道：它上船了。新机器加入 也是类似，所有机器收到通知：新兄弟目录加入，highcount又有了。 对于第二点，我们稍微改变一下，所有机器创建临时顺序编号目录节点，每次选取编号最小的机器作为master就好。 4、 分布式锁 有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。 对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过createznode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。厕所有言：来也冲冲，去也冲冲，用完删除掉自己创建的distribute_lock 节点就释放出锁。 对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小的获得锁，用完删除，依次方便。 5、队列管理 两种类型的队列： 1、 同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。 2、队列按照 FIFO 方式进行入队和出队操作。 第一类，在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 第二类，和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。 终于了解完我们能用zookeeper做什么了，可是作为一个程序员，我们总是想狂热了解zookeeper是如何做到这一点的，单点维护一个文件系统没有什么难度，可是如果是一个集群维护一个文件系统保持数据的一致性就非常困难了。 分布式与数据复制Zookeeper作为一个集群提供一致的数据服务，自然，它要在所有机器间做数据复制。数据复制的好处： 1、 容错一个节点出错，不致于让整个系统停止工作，别的节点可以接管它的工作； 2、提高系统的扩展能力把负载分布到多个节点上，或者增加节点来提高系统的负载能力； 3、提高性能让客户端本地访问就近的节点，提高用户访问速度。 从客户端读写访问的透明度来看，数据复制集群系统分下面两种： 1、写主(WriteMaster)对数据的修改提交给指定的节点。读无此限制，可以读取任何一个节点。这种情况下客户端需要对读与写进行区别，俗称读写分离； 2、写任意(Write Any)对数据的修改可提交给任意的节点，跟读一样。这种情况下，客户端对集群节点的角色与变化透明。 对zookeeper来说，它采用的方式是写任意。通过增加机器，它的读吞吐能力和响应能力扩展性非常好，而写，随着机器的增多吞吐能力肯定下降（这也是它建立observer的原因），而响应能力则取决于具体实现方式，是延迟复制保持最终一致性，还是立即复制快速响应。 我们关注的重点还是在如何保证数据在集群所有机器的一致性，这就涉及到paxos算法。 数据一致性与paxos算法据说Paxos算法的难理解与算法的知名度一样令人敬仰，所以我们先看如何保持数据的一致性，这里有个原则就是： 在一个分布式数据库系统中，如果各节点的初始状态一致，每个节点都执行相同的操作序列，那么他们最后能得到一个一致的状态。 Paxos算法解决的什么问题呢，解决的就是保证每个节点执行相同的操作序列。好吧，这还不简单，master维护一个全局写队列，所有写操作都必 须放入这个队列编号，那么无论我们写多少个节点，只要写操作是按编号来的，就能保证一致性。没错，就是这样，可是如果master挂了呢。 Paxos算法通过投票来对写操作进行全局编号，同一时刻，只有一个写操作被批准，同时并发的写操作要去争取选票，只有获得过半数选票的写操作才会 被批准（所以永远只会有一个写操作得到批准），其他的写操作竞争失败只好再发起一轮投票，就这样，在日复一日年复一年的投票中，所有写操作都被严格编号排 序。编号严格递增，当一个节点接受了一个编号为100的写操作，之后又接受到编号为99的写操作（因为网络延迟等很多不可预见原因），它马上能意识到自己 数据不一致了，自动停止对外服务并重启同步过程。任何一个节点挂掉都不会影响整个集群的数据一致性（总2n+1台，除非挂掉大于n台）。 Paxos算法角色（核心就3个角色）Client：客户端，发起请求并等待返回。Proposer（提案者）：处理客户端请求，将客户端的请求发送到集群中，以便决定这个值是否可以被批准。Acceptor（接受者）：负责处理接收到的提议，他们的回复就是一次投票。会存储一些状态来决定是否接收一个值。Learner（学习者）：当有同一个value的协议被超过一半的Acceptor采纳并发送消息给Learner时，Learner采纳该协议值。Leader：一个特殊的Proposer。 Basic-Paxos算法核心实现Paxos Instance主要包括两个阶段: 准备阶段(prepare phase)和提议阶段(accept phase) 简单来说，Basic Paxos 是一个经典两阶段提交（2PC） 第一阶段： 1a prepare 准备: proposer向acceptors提出一个协议，这里的协议就是期望的“一致性内容” 1a promise 承诺: acceptor承诺只接收最大协议号的协议（包括prepare和accept），并拒绝比当前协议号N小的协议，回复proposer之前接收的所有协议值。如果当前协议号N比之前都小，那么回复拒绝。 第二阶段： 2a Accept Request 发起“accept”请求：proposer收到acceptor反馈的足够的承诺后，给协议设最大值，如果没回复，随便设置一个值。发送”accept”请求给选定值的acceptors. 2b Accepted: acceptor接受协议（该acceptor之前没有承诺过大于该协议号的协议），并通知给proposer和learner 其中prepare阶段的作用，如下图所示： 1.S1首先发起accept(1,red)，并在S1,S2和S3达成多数派，red在S1，S2，S3上持久化 2.随 后S5发起accept(5,blue)，在S3，S4和S5达成多数派，blue在S3，S4和S5持久化 3.最后的结果是，S1和S2的值是red，而S4和S5的值是blue，s3存在异议，red覆盖了blue？ 解决方案： 将提议进行排序，可以为每个提议赋予一个唯一的ID，规定这个ID越大越新，很明显（5，blue）和（1，red），5比1大,所以保留blue 采用两阶段方法，拒绝旧提议。 Muti-Paxos算法很多文章有误解说Muti-Paxos是一阶段提交，那是仅限于leader稳定时。刚选出来一个新的leader时，依然是二阶段提交如下图：如果leader稳定，不需要prepare和promise步骤，如下图（图中Proposer就是一个Leader）：Multi Paxos中leader用于避免活锁(例如1个leader,4个Proposer,2个提议A，2个提议B不能达成一致，导致活锁)，但leader的存在会带来其他问题，一是如何选举和保持唯一leader(虽然无leader或多leader不影响一致性，但影响决议进程progress)，二是充当leader的节点会承担更多压力，如何均衡节点的负载。Mencius[1]提出节点轮流担任leader，以达到均衡负载的目的；租约(lease)可以帮助实现唯一leader，但leader故障情况下可导致服务短期不可用。 Muti-Paxos在google chubby中的应用Google Chubby是一个高可用分布式锁服务，被设计成一个需要访问中心化节点的分布式锁服务。本文只分析chubby服务端的实现。 Chubby服务端的基本架构大致分为三层 ① 最底层是容错日志系统（Fault-Tolerant Log），通过Paxos算法能够保证集群所有机器上的日志完全一致，同时具备较好的容错性。 ② 日志层之上是Key-Value类型的容错数据库（Fault-Tolerant DB），其通过下层的日志来保证一致性和容错性。 ③ 存储层之上的就是Chubby对外提供的分布式锁服务和小文件存储服务。 Paxos算法用于保证集群内各个副本节点的日志能够保持一致，Chubby事务日志（Transaction Log）中的每一个Value对应Paxos算法中的一个Instance（对应Proposer），由于Chubby需要对外提供不断的服务，因此事务日志会无限增长，于是在整个Chubby运行过程中，会存在多个Paxos Instance，同时，Chubby会为每个Paxos Instance都按序分配一个全局唯一的Instance编号，并将其顺序写入到事务日志中去。 在Paxos中，每一个Paxos Instance都需要进行一轮或多轮的Prepare-&gt;Promise-&gt;Propose-&gt;Accept这样完整的二阶段请求过程来完成对一个提议值的选定，为了保证正确性的前提下尽可能地提高算法运行性能，可以让多个Instance共用一套序号分配机制，并将Prepare-&gt;Promise合并为一个阶段。具体做法如下： ① 当某个副本节点通过选举成为Master后，就会使用新分配的编号N来广播一个Prepare消息，该Prepare消息会被所有未达成一致的Instance和目前还未开始的Instance共用。 ② 当Acceptor接收到Prepare消息后，必须对多个Instance同时做出回应，这通常可以通过将反馈信息封装在一个数据包中来实现，假设最多允许K个Instance同时进行提议值的选定，那么： 当前之多存在K个未达成一致的Instance，将这些未决的Instance各自最后接受的提议值封装进一个数据包，并作为Promise消息返回。 同时，判断N是否大于当前Acceptor的highestPromisedNum值（当前已经接受的最大的提议编号值），如果大于，那么就标记这些未决Instance和所有未来的Instance的highestPromisedNum的值为N，这样，这些未决Instance和所有未来Instance都不能再接受任何编号小于N的提议。 ③ Master对所有未决Instance和所有未来Instance分别执行Propose-&gt;Accept阶段的处理，如果Master能够一直稳定运行的话，那么在接下来的算法运行过程中，就不再需要进行Prepare-&gt;Promise处理了。但是，一旦Master发现Acceptor返回了一个Reject消息，说明集群中存在另一个Master并且试图使用更大的提议编号发送了Prepare消息，此时，当前Master就需要重新分配新的提议编号并再次进行Prepare-&gt;Promise阶段的处理。 可见chubby就是一个典型的Muti-Paxos算法应用，在Master稳定运行的情况下，只需要使用同一个编号来依次执行每一个Instance的Promise-&gt;Accept阶段处理。 sentinel，了解多少说多少？Sentinel 是阿里中间件团队开源的，面向分布式服务架构的轻量级高可用流量控制组件，主要以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度来帮助用户保护服务的稳定性。 Sentinel 和之前常用的熔断降级库 Netflix Hystrix 有什么异同呢？Sentinel官网有一个对比的文章，这里摘抄一个总结的表格 对比内容 Sentinel Hystrix 隔离策略 信号量隔离 线程池隔离/信号量隔离 熔断降级策略 基于响应时间或失败比率 基于失败比率 实时指标实现 滑动窗口 滑动窗口（基于 RxJava） 规则配置 支持多种数据源 支持多种数据源 扩展性 多个扩展点 插件的形式 基于注解的支持 支持 支持 限流 基于 QPS，支持基于调用关系的限流 不支持 流量整形 支持慢启动、匀速器模式 不支持 系统负载保护 支持 不支持 控制台 开箱即用，可配置规则、查看秒级监控、机器发现等 不完善 常见框架的适配 Servlet、Spring Cloud、Dubbo、gRPC 等 Servlet、Spring Cloud Netflix 原理解析感兴趣的可以看这篇文章 Spring Cloud Alibaba，了解多少说多少？Spring Cloud 是基于 Spring Boot 设计的一套微服务规范，并增强了应用上下文。Spring Cloud Alibaba 采用阿里中间件作为基础，实现了 Spring Cloud 的微服务规范。 对XA、TCC的理解，了解哪些分布式事务框架，有什么缺点？事务拥有以下四个特性，习惯上被称为 ACID 特性： 原子性（Atomicity）：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。 一致性（Consistency）：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态是指数据库中的数据应满足完整性约束。除此之外，一致性还有另外一层语义，就是事务的中间状态不能被观察到（这层语义也有说应该属于原子性）。 隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行，如同只有这一个操作在被数据库所执行一样。 持久性（Durability）：已被提交的事务对数据库的修改应该永久保存在数据库中。在事务结束时，此操作将不可逆转。 常见分布式事务模型 ACID 实现分析X/Open XA 协议最早的分布式事务模型是 X/Open 国际联盟提出的 X/Open Distributed Transaction Processing（DTP）模型，也就是大家常说的 X/Open XA 协议，简称XA 协议。DTP 模型中包含一个全局事务管理器（TM，Transaction Manager）和多个资源管理器（RM，Resource Manager）。全局事务管理器负责管理全局事务状态与参与的资源，协同资源一起提交或回滚；资源管理器则负责具体的资源操作。 XA 协议描述了 TM 与 RM 之间的接口，允许多个资源在同一分布式事务中访问。 基于 DTP 模型的分布式事务流程大致如下： 应用程序（AP，Application）向 TM 申请开始一个全局事务。 针对要操作的 RM，AP 会先向 TM 注册（TM 负责记录 AP 操作过哪些 RM，即分支事务），TM 通过 XA 接口函数通知相应 RM 开启分布式事务的子事务，接着 AP 就可以对该 RM 管理的资源进行操作。 当 AP 对所有 RM 操作完毕后，AP 根据执行情况通知 TM 提交或回滚该全局事务，TM 通过 XA 接口函数通知各 RM 完成操作。TM 会先要求各个 RM 做预提交，所有 RM 返回成功后，再要求各 RM 做正式提交，XA 协议要求，一旦 RM 预提交成功，则后续的正式提交也必须能成功；如果任意一个 RM 预提交失败，则 TM 通知各 RM 回滚。 所有 RM 提交或回滚完成后，全局事务结束。 原子性XA 协议使用 2PC（Two Phase Commit，两阶段提交）原子提交协议来保证分布式事务原子性。 两阶段提交是指将提交过程分为两个阶段，即准备阶段（投票阶段）和提交阶段（执行阶段）： 准备阶段 TM 向每个 RM 发送准备消息。如果 RM 的本地事务操作执行成功，则返回成功；如果 RM 的本地事务操作执行失败，则返回失败。 提交阶段 如果 TM 收到了所有 RM 回复的成功消息，则向每个 RM 发送提交消息；否则发送回滚消息；RM 根据 TM 的指令执行提交或者回滚本地事务操作，释放所有事务处理过程中使用的锁资源。 隔离性XA 协议中没有描述如何实现分布式事务的隔离性，但是 XA 协议要求DTP 模型中的每个 RM 都要实现本地事务，也就是说，基于 XA 协议实现的分布式事务的隔离性是由每个 RM 本地事务的隔离性来保证的，当一个分布式事务的所有子事务都是隔离的，那么这个分布式事务天然的就实现了隔离性。 以 MySQL 来举例，MySQL 使用 2PL（Two-Phase Locking，两阶段锁）机制来控制本地事务的并发，保证隔离性。2PL 与 2PC 类似，也是将锁操作分为加锁和解锁两个阶段，并且保证两个阶段完全不相交。加锁阶段，只加锁，不放锁。解锁阶段，只放锁，不加锁。 如上图所示，在一个本地事务中，每执行一条更新操作之前，都会先获取对应的锁资源，只有获取锁资源成功才会执行该操作，并且一旦获取了锁资源就会持有该锁资源直到本事务执行结束。 MySQL 通过这种 2PL 机制，可以保证在本地事务执行过程中，其他并发事务不能操作相同资源，从而实现了事务隔离。 一致性前面提到一致性有两层语义，一层是确保事务执行结束后，数据库从一个一致状态转变为另一个一致状态。另一层语义是事务执行过程中的中间状态不能被观察到。 前一层语义的实现很简单，通过原子性、隔离性以及 RM 自身一致性的实现就可以保证。至于后一层语义，我们先来看看单个 RM 上的本地事务是怎么实现的。还是以 MySQL 举例，MySQL 通过 MVCC（Multi Version Concurrency Control，多版本并发控制）机制，为每个一致性状态生成快照（Snapshot），每个事务看到的都是各Snapshot对应的一致性状态，从而也就保证了本地事务的中间状态不会被观察到。 虽然单个 RM 上实现了Snapshot，但是在分布式应用架构下，会遇到什么问题呢？如上图所示，在 RM1 的本地子事务提交完毕到 RM2 的本地子事务提交完毕之间，只能读到 RM1 上子事务执行的内容，读不到 RM2 上的子事务。也就是说，虽然在单个 RM 上的本地事务是一致的，但是从全局来看，一个全局事务执行过程的中间状态被观察到了，全局一致性就被破坏了。 XA 协议并没有定义怎么实现全局的 Snapshot，像 MySQL 官方文档里就建议使用串行化的隔离级别来保证分布式事务一致性： “As with nondistributed transactions, SERIALIZABLE may be preferred if your applications are sensitive to read phenomena. REPEATABLE READ may not be sufficient for distributed transactions.”（对于分布式事务来说，可重复读隔离级别不足以保证事务一致性，如果你的程序有全局一致性读要求，可以考虑串行化隔离级别.） 当然，由于串行化隔离级别的性能较差，所以很多分布式数据库都自己实现了分布式 MVCC 机制来提供全局的一致性读。一个基本思路是用一个集中式或者逻辑上单调递增的东西来控制生成全局 Snapshot，每个事务或者每条 SQL 执行时都去获取一次，从而实现不同隔离级别下的一致性。比如 Google 的 Spanner 就是用 TrueTime 来控制访问全局 Snapshot。 小结XA 协议通常实现在数据库资源层，直接作用于资源管理器上。因此，基于 XA 协议实现的分布式事务产品，无论是分布式数据库，还是分布式事务框架，对业务几乎都没有侵入，就像使用普通数据库一样。 XA 协议严格保障事务 ACID 特性，能够满足所有业务领域的功能需求，但是，这同样是一把双刃剑。 由于隔离性的互斥要求，在事务执行过程中，所有的资源都被锁定，只适用于执行时间确定的短事务。同时，整个事务期间都是独占数据，对于热点数据的并发性能可能会很低，实现了分布式 MVCC 或乐观锁（optimistic locking）以后，性能可能会有所提升。 同时，为了保障一致性，要求所有 RM 同等可信、可靠，要求故障恢复机制可靠、快速，在网络故障隔离的情况下，服务基本不可用。 TCC 模型TCC（Try-Confirm-Cancel）分布式事务模型相对于 XA 等传统模型，其特征在于它不依赖资源管理器（RM）对分布式事务的支持，而是通过对业务逻辑的分解来实现分布式事务。 TCC 模型认为对于业务系统中一个特定的业务逻辑，其对外提供服务时，必须接受一些不确定性，即对业务逻辑初步操作的调用仅是一个临时性操作，调用它的主业务服务保留了后续的取消权。如果主业务服务认为全局事务应该回滚，它会要求取消之前的临时性操作，这就对应从业务服务的取消操作。而当主业务服务认为全局事务应该提交时，它会放弃之前临时性操作的取消权，这对应从业务服务的确认操作。每一个初步操作，最终都会被确认或取消。 因此，针对一个具体的业务服务，TCC 分布式事务模型需要业务系统提供三段业务逻辑： 初步操作 Try：完成所有业务检查，预留必须的业务资源。 确认操作 Confirm：真正执行的业务逻辑，不作任何业务检查，只使用 Try 阶段预留的业务资源。因此，只要 Try 操作成功，Confirm 必须能成功。另外，Confirm 操作需满足幂等性，保证一笔分布式事务有且只能成功一次。 取消操作 Cancel：释放 Try 阶段预留的业务资源。同样的，Cancel 操作也需要满足幂等性。 TCC 分布式事务模型包括三部分： 主业务服务：主业务服务为整个业务活动的发起方，服务的编排者，负责发起并完成整个业务活动。 从业务服务：从业务服务是整个业务活动的参与方，负责提供 TCC 业务操作，实现初步操作（Try）、确认操作（Confirm）、取消操作（Cancel）三个接口，供主业务服务调用。 业务活动管理器：业务活动管理器管理控制整个业务活动，包括记录维护 TCC 全局事务的事务状态和每个从业务服务的子事务状态，并在业务活动提交时调用所有从业务服务的 Confirm 操作，在业务活动取消时调用所有从业务服务的 Cancel 操作。 一个完整的 TCC 分布式事务流程如下： 主业务服务首先开启本地事务； 主业务服务向业务活动管理器申请启动分布式事务主业务活动； 然后针对要调用的从业务服务，主业务活动先向业务活动管理器注册从业务活动，然后调用从业务服务的 Try 接口； 当所有从业务服务的 Try 接口调用成功，主业务服务提交本地事务；若调用失败，主业务服务回滚本地事务； 若主业务服务提交本地事务，则 TCC 模型分别调用所有从业务服务的 Confirm 接口；若主业务服务回滚本地事务，则分别调用 Cancel 接口； 所有从业务服务的 Confirm 或 Cancel 操作完成后，全局事务结束。 原子性TCC 模型也使用 2PC 原子提交协议来保证事务原子性。Try 操作对应2PC 的一阶段准备（Prepare）；Confirm 对应 2PC 的二阶段提交（Commit），Cancel 对应 2PC 的二阶段回滚（Rollback），可以说 TCC 就是应用层的 2PC。 隔离性TCC 分布式事务模型仅提供两阶段原子提交协议，保证分布式事务原子性。事务的隔离交给业务逻辑来实现。 隔离的本质是控制并发，防止并发事务操作相同资源而引起的结果错乱。 举个例子，比如金融行业里管理用户资金，当用户发起交易时，一般会先检查用户资金，如果资金充足，则扣除相应交易金额，增加卖家资金，完成交易。如果没有事务隔离，用户同时发起两笔交易，两笔交易的检查都认为资金充足，实际上却只够支付一笔交易，结果两笔交易都支付成功，导致资损。 可以发现，并发控制是业务逻辑执行正确的保证，但是像两阶段锁这样的并发访问控制技术要求一直持有数据库资源锁直到整个事务执行结束，特别是在分布式事务架构下，要求持有锁到分布式事务第二阶段执行结束，也就是说，分布式事务会加长资源锁的持有时间，导致并发性能进一步下降。 因此，TCC 模型的隔离性思想就是通过业务的改造，在第一阶段结束之后，从底层数据库资源层面的加锁过渡为上层业务层面的加锁，从而释放底层数据库锁资源，放宽分布式事务锁协议，提高业务并发性能。 还是以上面的例子举例： 第一阶段：检查用户资金，如果资金充足，冻结用户本次交易资金，这笔资金被业务隔离，不允许除本事务之外的其它并发事务动用。 第二阶段：扣除第一阶段预冻结的用户资金，增加卖家资金，完成交易。 采用业务加锁的方式，隔离用户冻结资金，在第一阶段结束后直接释放底层资源锁，该用户和卖家的其他交易都可以立刻并发执行，而不用等到整个分布式事务结束，可以获得更高的并发交易能力。 一致性再来看看 TCC 分布式事务模型下的一致性实现。与 XA 协议实现一致性第一层语义类似，通过原子性保证事务的原子提交、业务隔离性控制事务的并发访问，实现分布式事务的一致性状态转变。 至于第二层语义：事务的中间状态不能被观察到。我们来看看，在 SOA分布式应用环境下是否是必须的。 还是以账务服务举例。转账业务（用户 A -&gt; 用户 B），由交易服务和账务服务组成分布式事务，交易服务作为主业务服务，账务服务作为从业务服务，账务服务的 Try 操作预冻结用户 A 的资金；Commit 操作扣除用户 A 的预冻结资金，增加用户 B 的可用资金；Cancel 操作解冻用户 A 的预冻结资金。 当账务服务执行完 Try 阶段后，交易主业务就可以 Commit 了，然后由TCC 框架调用账务的 Commit 阶段。在账务 Commit 阶段还没执行结束的时候，用户 A 可以查询到自己的余额已扣除，但是，此时用户 B 的可用资金还没增加。 从系统的角度来看，确实有问题与不确定性。在第一阶段执行结束到第二阶段执行结束之间，有一段时间的延时，在这段时间内，看似任何用户都不享有这笔资产。 但是，从用户的角度来考虑这个问题的话，这个时间间隔可能就无所谓或者根本就不存在。特别是当这个时间间隔仅仅是几秒钟，对于具体沟通资产转移的用户来讲，这个过程是隐蔽的或确实可以接受的，且保证了结果的最终一致性。 当然，对于这样的系统，如果确实需要查看系统的某个一致性状态，可以采用额外的方法实现。 一般来讲，服务之间的一致性比服务内部的一致性要更加容易弱化，这也是为什么 XA 等直接在资源层面上实现通用分布式事务的模型会注重一致性的保证，而当上升到服务层面，服务与服务之间已经实现了功能的划分，逻辑的解耦，也就更容易弱化一致性，这就是 SOA 架构下 BASE 理论的最终一致性思想。 BASE 理论是指 BA（Basic Availability，基本业务可用性）；S（Soft state，柔性状态）；E（Eventual consistency，最终一致性）。该理论认为为了可用性、性能与降级服务的需要，可以适当降低一点一致性的要求，即“基本可用，最终一致”。 业内通常把严格遵循 ACID 的事务称为刚性事务；而基于 BASE 思想实现的事务称为柔性事务。柔性事务并不是完全放弃了 ACID，仅仅是放宽了一致性要求：事务完成后的一致性严格遵循，事务中的一致性可适当放宽。 小结TCC 分布式事务模型的业务实现特性决定了其可以跨 DB、跨服务实现资源管理，将对不同的 DB 访问、不同的业务操作通过 TCC 模型协调为一个原子操作，解决了分布式应用架构场景下的事务问题。 TCC 模型通过 2PC 原子提交协议保证分布式事务的的原子性，把资源层的隔离性上升到业务层，交给业务逻辑来实现。TCC 的每个操作对于资源层来说，就是单个本地事务的使用，操作结束则本地事务结束，规避了资源层在 2PC 和 2PL 下对资源占用导致的性能低下问题。 同时，TCC 模型也可以根据业务需要，做一些定制化的功能，比如交易异步化实现削峰填谷等。 但是，业务接入 TCC 模型需要拆分业务逻辑成两个阶段，并实现 Try、Confirm、Cancel 三个接口，定制化程度高，开发成本高。 总结本文首先介绍了典型的分布式事务的架构场景。分布式事务刚开始是为解决单服务多数据库资源的场景而诞生的。随着技术的发展，特别是 SOA 分布式应用架构以及微服务时代的到来，服务变成了基本业务单元。因此，又产生了跨服务的分布式事务需求。 然后从 XA 和 TCC 两种常用的分布式事务模型入手，介绍了其实现机制，着重分析了各模型是如何实现分布式事务 ACID 特性的。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试分享(一).JAVA知识]]></title>
    <url>%2F2019%2F04%2F18%2F%E9%9D%A2%E8%AF%95%E5%88%86%E4%BA%AB(%E4%B8%80).JAVA%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[JAVA知识ArrayList和LinkList有什么区别 ArrayList是数组实现的集合操作，而LinkedList是链表实现的集合操作,（LinkedList是双向链表，有next也有previous）。 只是用List集合中的get()方法根据索引取数据的时候，ArrayList的时间复杂度为“O(1)”,而LinkedList的时间复杂度为“O(n)”(n为集合的长度)，因为LinkedList要移动指针。 ArrayList在使用的时候默认的初始化数组的长度为10，如果空间不足则会采用2倍的形式进行容量的扩充，如果保存大数据的时候有可能造成垃圾的产生以及性能的下降，这个时候就可以用LinkedList子类保存。对于新增和删除操作add和remove，LinedList比较占优势，因为ArrayList要移动数据。 JDK动态代理与CGLib动态代理的区别 区别 java动态代理是利用反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。 而cglib动态代理是利用asm开源包，对代理对象类的class文件加载进来，通过修改其字节码生成子类来处理。 如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP 如果目标对象实现了接口，可以强制使用CGLIB实现AOP 如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换 如何强制使用CGLIB实现AOP？ 添加CGLIB库，SPRING_HOME/cglib/*.jar 在spring配置文件中加入&lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot;/&gt; JDK动态代理和CGLIB字节码生成的区别 JDK动态代理只能对实现了接口的类生成代理，而不能针对类 CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法因为是继承，所以该类或方法最好不要声明成final 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107package com.lf.shejimoshi.proxy.entity;//用户管理接口public interface UserManager &#123; //新增用户抽象方法 void addUser(String userName,String password); //删除用户抽象方法 void delUser(String userName); &#125;package com.lf.shejimoshi.proxy.entity;//用户管理实现类,实现用户管理接口public class UserManagerImpl implements UserManager&#123; //重写新增用户方法 @Override public void addUser(String userName, String password) &#123; System.out.println("调用了新增的方法！"); System.out.println("传入参数为 userName: "+userName+" password: "+password); &#125; //重写删除用户方法 @Override public void delUser(String userName) &#123; System.out.println("调用了删除的方法！"); System.out.println("传入参数为 userName: "+userName); &#125; &#125;//JDK动态代理package com.lf.shejimoshi.proxy.jdk;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import com.lf.shejimoshi.proxy.entity.UserManager;import com.lf.shejimoshi.proxy.entity.UserManagerImpl;//JDK动态代理实现InvocationHandler接口public class JdkProxy implements InvocationHandler &#123; private Object target ;//需要代理的目标对象 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println("JDK动态代理，监听开始！"); Object result = method.invoke(target, args); System.out.println("JDK动态代理，监听结束！"); return result; &#125; //定义获取代理对象方法 private Object getJDKProxy(Object targetObject)&#123; //为目标对象target赋值 this.target = targetObject; //JDK动态代理只能针对实现了接口的类进行代理，newProxyInstance 函数所需参数就可看出 return Proxy.newProxyInstance(targetObject.getClass().getClassLoader(), targetObject.getClass().getInterfaces(), this); &#125; public static void main(String[] args) &#123; JdkProxy jdkProxy = new JdkProxy();//实例化JDKProxy对象 UserManager user = (UserManager) jdkProxy.getJDKProxy(new UserManagerImpl());//获取代理对象 user.addUser("admin", "123123");//执行新增方法 &#125; &#125;//Cglib动态代理（需要导入两个jar包，asm-5.2.jar,cglib-3.2.5.jar。版本自行选择）package com.lf.shejimoshi.proxy.cglib;import java.lang.reflect.Method;import com.lf.shejimoshi.proxy.entity.UserManager;import com.lf.shejimoshi.proxy.entity.UserManagerImpl;import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;//Cglib动态代理，实现MethodInterceptor接口public class CglibProxy implements MethodInterceptor &#123; private Object target;//需要代理的目标对象 //重写拦截方法 @Override public Object intercept(Object obj, Method method, Object[] arr, MethodProxy proxy) throws Throwable &#123; System.out.println("Cglib动态代理，监听开始！"); Object invoke = method.invoke(target, arr);//方法执行，参数：target 目标对象 arr参数数组 System.out.println("Cglib动态代理，监听结束！"); return invoke; &#125; //定义获取代理对象方法 public Object getCglibProxy(Object objectTarget)&#123; //为目标对象target赋值 this.target = objectTarget; Enhancer enhancer = new Enhancer(); //设置父类,因为Cglib是针对指定的类生成一个子类，所以需要指定父类 enhancer.setSuperclass(objectTarget.getClass()); enhancer.setCallback(this);// 设置回调 Object result = enhancer.create();//创建并返回代理对象 return result; &#125; public static void main(String[] args) &#123; CglibProxy cglib = new CglibProxy();//实例化CglibProxy对象 UserManager user = (UserManager) cglib.getCglibProxy(new UserManagerImpl());//获取代理对象 user.delUser("admin");//执行删除方法 &#125; &#125; Java中序列化有哪些方式Java原生序列化Java原生序列化方法即通过Java原生流(InputStream和OutputStream之间的转化)的方式进行转化。需要注意的是JavaBean实体类必须实现Serializable接口，否则无法序列化。Java原生序列化代码示例如下所示：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package serialize;import java.io.BufferedInputStream;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.io.ObjectInputStream;import java.io.ObjectOutputStream;import java.util.ArrayList;import java.util.List;/** * * @author liqqc * */public class JavaSerialize &#123; public static void main(String[] args) throws ClassNotFoundException, IOException &#123; new JavaSerialize().start(); &#125; public void start() throws IOException, ClassNotFoundException &#123; User u = new User(); List&lt;User&gt; friends = new ArrayList&lt;&gt;(); u.setUserName("张三"); u.setPassWord("123456"); u.setUserInfo("张三是一个很牛逼的人"); u.setFriends(friends); User f1 = new User(); f1.setUserName("李四"); f1.setPassWord("123456"); f1.setUserInfo("李四是一个很牛逼的人"); User f2 = new User(); f2.setUserName("王五"); f2.setPassWord("123456"); f2.setUserInfo("王五是一个很牛逼的人"); friends.add(f1); friends.add(f2); Long t1 = System.currentTimeMillis(); ByteArrayOutputStream out = new ByteArrayOutputStream(); ObjectOutputStream obj = new ObjectOutputStream(out); for(int i = 0; i&lt;10; i++) &#123; obj.writeObject(u); &#125; System.out.println("java serialize: " +(System.currentTimeMillis() - t1) + "ms; 总大小：" + out.toByteArray().length ); Long t2 = System.currentTimeMillis(); ObjectInputStream ois = new ObjectInputStream(new BufferedInputStream(new java.io.ByteArrayInputStream(out.toByteArray()))); User user = (User) ois.readObject(); System.out.println("java deserialize: " + (System.currentTimeMillis() - t2) + "ms; User: " + user); &#125;&#125; Json序列化Json序列化一般会使用jackson包，通过ObjectMapper类来进行一些操作，比如将对象转化为byte数组或者将json串转化为对象。现在的大多数公司都将json作为服务器端返回的数据格式。比如调用一个服务器接口，通常的请求为xxx.json?a=xxx&amp;b=xxx的形式。Json序列化示例代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package serialize;import java.io.IOException;import java.util.ArrayList;import java.util.List;import com.fasterxml.jackson.databind.ObjectMapper;/** * * @author liqqc * */public class JsonSerialize &#123; public static void main(String[] args) throws IOException &#123; new JsonSerialize().start(); &#125; public void start() throws IOException &#123; User u = new User(); List&lt;User&gt; friends = new ArrayList&lt;&gt;(); u.setUserName("张三"); u.setPassWord("123456"); u.setUserInfo("张三是一个很牛逼的人"); u.setFriends(friends); User f1 = new User(); f1.setUserName("李四"); f1.setPassWord("123456"); f1.setUserInfo("李四是一个很牛逼的人"); User f2 = new User(); f2.setUserName("王五"); f2.setPassWord("123456"); f2.setUserInfo("王五是一个很牛逼的人"); friends.add(f1); friends.add(f2); ObjectMapper mapper = new ObjectMapper(); Long t1 = System.currentTimeMillis(); byte[] writeValueAsBytes = null; for (int i = 0; i &lt; 10; i++) &#123; writeValueAsBytes = mapper.writeValueAsBytes(u); &#125; System.out.println("json serialize: " + (System.currentTimeMillis() - t1) + "ms; 总大小：" + writeValueAsBytes.length); Long t2 = System.currentTimeMillis(); User user = mapper.readValue(writeValueAsBytes, User.class); System.out.println("json deserialize: " + (System.currentTimeMillis() - t2) + "ms; User: " + user); &#125;&#125; FastJson序列化fastjson 是由阿里巴巴开发的一个性能很好的Java 语言实现的 Json解析器和生成器。特点：速度快，测试表明fastjson具有极快的性能，超越任其他的java json parser。功能强大，完全支持java bean、集合、Map、日期、Enum，支持范型和自省。无依赖，能够直接运行在Java SE 5.0以上版本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package serialize;import java.util.ArrayList;import java.util.List;import com.alibaba.fastjson.JSON;/** * * @author liqqc * */public class FastJsonSerialize &#123; public static void main(String[] args) &#123; new FastJsonSerialize().start(); &#125; public void start()&#123; User u = new User(); List&lt;User&gt; friends = new ArrayList&lt;&gt;(); u.setUserName("张三"); u.setPassWord("123456"); u.setUserInfo("张三是一个很牛逼的人"); u.setFriends(friends); User f1 = new User(); f1.setUserName("李四"); f1.setPassWord("123456"); f1.setUserInfo("李四是一个很牛逼的人"); User f2 = new User(); f2.setUserName("王五"); f2.setPassWord("123456"); f2.setUserInfo("王五是一个很牛逼的人"); friends.add(f1); friends.add(f2); //序列化 Long t1 = System.currentTimeMillis(); String text = null; for(int i = 0; i&lt;10; i++) &#123; text = JSON.toJSONString(u); &#125; System.out.println("fastJson serialize: " +(System.currentTimeMillis() - t1) + "ms; 总大小：" + text.getBytes().length); //反序列化 Long t2 = System.currentTimeMillis(); User user = JSON.parseObject(text, User.class); System.out.println("fastJson serialize: " + (System.currentTimeMillis() -t2) + "ms; User: " + user); &#125;&#125; ProtoBuff序列化ProtocolBuffer是一种轻便高效的结构化数据存储格式，可以用于结构化数据序列化。适合做数据存储或 RPC 数据交换格式。可用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。 优点：跨语言；序列化后数据占用空间比JSON小，JSON有一定- 的格式，在数据量上还有可以压缩的空间。 缺点：它以二进制的方式存储，无法直接读取编辑，除非你有 .proto 定义，否则无法直接读出 Protobuffer的任何内容。 其与thrift的对比：两者语法类似，都支持版本向后兼容和向前兼容，thrift侧重点是构建跨语言的可伸缩的服务，支持的语言多，同时提供了全套RPC解决方案，可以很方便的直接构建服务，不需要做太多其他的工作。 Protobuffer主要是一种序列化机制，在数据序列化上进行性能比较，Protobuffer相对较好。 ProtoBuff序列化对象可以很大程度上将其压缩，可以大大减少数据传输大小，提高系统性能。对于大量数据的缓存，也可以提高缓存中数据存储量。原始的ProtoBuff需要自己写.proto文件，通过编译器将其转换为java文件，显得比较繁琐。百度研发的jprotobuf框架将Google原始的protobuf进行了封装，对其进行简化，仅提供序列化和反序列化方法。其实用上也比较简洁，通过对JavaBean中的字段进行注解就行，不需要撰写.proto文件和实用编译器将其生成.java文件，百度的jprotobuf都替我们做了这些事情了。 一个带有jprotobuf注解的JavaBean如下所示123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package serialize;import java.io.Serializable;import java.util.List;import com.baidu.bjf.remoting.protobuf.FieldType;import com.baidu.bjf.remoting.protobuf.annotation.Protobuf;public class User implements Serializable &#123; private static final long serialVersionUID = -7890663945232864573L; @Protobuf(fieldType = FieldType.INT32, required = false, order = 1) private Integer userId; @Protobuf(fieldType = FieldType.STRING, required = false, order = 2) private String userName; @Protobuf(fieldType = FieldType.STRING, required = false, order = 3) private String passWord; @Protobuf(fieldType = FieldType.STRING, required = false, order = 4) private String userInfo; @Protobuf(fieldType = FieldType.OBJECT, required = false, order = 5) private List&lt;User&gt; friends; public Integer getUserId() &#123; return userId; &#125; public void setUserId(Integer userId) &#123; this.userId = userId; &#125; public String getUserName() &#123; return userName; &#125; public void setUserName(String userName) &#123; this.userName = userName; &#125; public String getPassWord() &#123; return passWord; &#125; public void setPassWord(String passWord) &#123; this.passWord = passWord; &#125; public String getUserInfo() &#123; return userInfo; &#125; public void setUserInfo(String userInfo) &#123; this.userInfo = userInfo; &#125; public List&lt;User&gt; getFriends() &#123; return friends; &#125; public void setFriends(List&lt;User&gt; friends) &#123; this.friends = friends; &#125; @Override public String toString() &#123; return "User [userId=" + userId + ", userName=" + userName + ", passWord=" + passWord + ", userInfo=" + userInfo + ", friends=" + friends + "]"; &#125;&#125;package serialize;import java.io.IOException;import java.util.ArrayList;import java.util.List;import com.baidu.bjf.remoting.protobuf.Codec;import com.baidu.bjf.remoting.protobuf.ProtobufProxy;/** * * @author liqqc * */public class ProtoBuffSerialize &#123; public static void main(String[] args) throws IOException &#123; new ProtoBuffSerialize().start(); &#125; public void start() throws IOException &#123; Codec&lt;User&gt; studentClassCodec = ProtobufProxy.create(User.class, false); User u2 = new User(); List&lt;User&gt; friends = new ArrayList&lt;&gt;(); u2.setUserName("张三"); u2.setPassWord("123456"); u2.setUserInfo("张三是一个很牛逼的人"); u2.setFriends(friends); User f1 = new User(); f1.setUserName("李四"); f1.setPassWord("123456"); f1.setUserInfo("李四是一个很牛逼的人"); User f2 = new User(); f2.setUserName("王五"); f2.setPassWord("123456"); f2.setUserInfo("王五是一个很牛逼的人"); friends.add(f1); friends.add(f2); Long stime_jpb_encode = System.currentTimeMillis(); byte[] bytes = null; for(int i = 0; i&lt;10; i++) &#123; bytes = studentClassCodec.encode(u2); &#125; System.out.println("jprotobuf序列化耗时：" + (System.currentTimeMillis() - stime_jpb_encode) + "ms; 总大小：" + bytes.length); Long stime_jpb_decode = System.currentTimeMillis(); User user = studentClassCodec.decode(bytes); Long etime_jpb_decode = System.currentTimeMillis(); System.out.println("jprotobuf反序列化耗时："+ (etime_jpb_decode-stime_jpb_decode) + "ms; User: " + user); &#125;&#125; 序列化底层实现1234567891011121314151617181920212223242526public class SerialDemo &#123; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; //序列化 FileOutputStream fos = new FileOutputStream("object.out"); ObjectOutputStream oos = new ObjectOutputStream(fos); User user1 = new User("xuliugen", "123456", "male"); oos.writeObject(user1); oos.flush(); oos.close(); //反序列化 FileInputStream fis = new FileInputStream("object.out"); ObjectInputStream ois = new ObjectInputStream(fis); User user2 = (User) ois.readObject(); System.out.println(user2.getUserName()+ " " + user2.getPassword() + " " + user2.getSex()); //反序列化的输出结果为：xuliugen 123456 male &#125;&#125;public class User implements Serializable &#123; private String userName; private String password; private String sex; //全参构造方法、get和set方法省略&#125; object.out文件如下注：上图中0000000h-000000c0h表示行号；0-f表示列；行后面的文字表示对这行16进制的解释；对上述字节码所表述的内容感兴趣的可以对照相关的资料，查阅一下每一个字符代表的含义，这里不在探讨！ 类似于我们Java代码编译之后的.class文件，每一个字符都代表一定的含义。序列化和反序列化的过程就是生成和解析上述字符的过程！ 序列化图示：反序列化图示： 相关注意事项1、序列化时，只对对象的状态进行保存，而不管对象的方法； 2、当一个父类实现序列化，子类自动实现序列化，不需要显式实现Serializable接口； 3、当一个对象的实例变量引用其他对象，序列化该对象时也把引用对象进行序列化； 4、并非所有的对象都可以序列化，至于为什么不可以，有很多原因了，比如： 安全方面的原因，比如一个对象拥有private，public等field，对于一个要传输的对象，比如写到文件，或者进行RMI传输等等，在序列化进行传输的过程中，这个对象的private等域是不受保护的； 资源分配方面的原因，比如socket，thread类，如果可以序列化，进行传输或者保存，也无法对他们进行重新的资源分配，而且，也是没有必要这样实现； 5、声明为static和transient类型的成员数据不能被序列化。因为static代表类的状态，transient代表对象的临时数据。 6、序列化运行时使用一个称为 serialVersionUID 的版本号与每个可序列化类相关联，该序列号在反序列化过程中用于验证序列化对象的发送者和接收者是否为该对象加载了与序列化兼容的类。为它赋予明确的值。显式地定义serialVersionUID有两种用途： 在某些场合，希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有相同的serialVersionUID； 在某些场合，不希望类的不同版本对序列化兼容，因此需要确保类的不同版本具有不同的serialVersionUID。 7、Java有很多基础类已经实现了serializable接口，比如String,Vector等。但是也有一些没有实现serializable接口的； 8、如果一个对象的成员变量是一个对象，那么这个对象的数据成员也会被保存！这是能用序列化解决深拷贝的重要原因； 并发编程的包，AQS和普通锁相比有什么好处队列同步器AbstractQueuedSynchronizer，是用来构建锁或者其他同步组件的基础框架，它使用一个int成员表示同步状态，通过内部的FIFO队列来完成资源获取线程的排序工作。 AQS的设计 AQS的设计是基于模板方法模式的，也就是说，使用者需要继承AQS并重写指定的方法，随后将AQS组合在自定义同步组件的实现中，并调用AQS提供的模板方法，而这些模板方法将会调用使用者重写的方法。1private volatile int state; AQS使用一个int的成员变量来表示同步状态。123protected final void setState(int newState) &#123; state = newState;&#125; setState方法用来设置同步状态123protected final int getState() &#123; return state;&#125; getState方法用来获取同步状态1234protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; compareAndSetState方法使用CAS操作来讲同步状态设置为给定的值 AQS中的同步队列最开始就提到过AQS内部维护着一个FIFO的队列。而AQS就是依赖这个同步队列来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成一个节点Node，并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。 同步队列中节点属性12//共享锁对应的节点static final Node SHARED = new Node(); 因为如果是共享锁，线程可以被多个线程获得。所以将这个属性定义为一个常量。 12 //独占锁对应的节点static final Node EXCLUSIVE = null; 独占锁因为只能对一个线程获得，所以设置为null，当某个线程获得锁时，将该线程对应的赋予这个属性12//节点的等待状态volatile int waitStatus; 节点的等待状态有4个 CANCELLED：值为1，由于在同步队列中等待的线程等待超时或被中断，需要从同步队列中取消等待，节点进入该状态将不会变化 SINGAL：值为-1，后继节点的线程处于等待状态，当前节点如果释放了同步状态，将会通知后继节点，使后继节点得以运行 CONDITION：值为-2，节点在等待队列中（这个在Condition的博客里会讲到），节点线程等待在Condition上，当其他线程对Condition调用了singal后，该节点会从等待队列转移到同步队列，加入到对同步状态的获取中去 PROPAGEATE：值为-3，表示下一次共享式同步状态获取将会无条件被传播下去12//前驱节点，当节点加入同步队列时被设置（尾部添加）volatile Node prev; 同步队列中某个节点的前驱节点12//后继节点volatile Node next; 同步队列中某个节点的后继节点12//等待队列的后继节点。如果当前节点是共享的，那么这个字段将是一个SHARED常量Node nextWaiter; 这个是等待队列的后继节点（不是同步队列）12//获取同步状态的线程volatile Thread thread; 当前获取到同步状态的线程 节点时构成同步队列的基础，AQS拥有首节点和尾节点，没有成功获取到同步状态的节点会加入到同步队列的尾部，同步队列的结构如下图所示 同步器AQS包含两个节点类型的引用，一个指向头结点，一个指向尾节点。 同步队列的操作 将节点加入到同步队列：当一个线程成功获取了同步状态（或者锁），其他线程将无法获取到同步状态，转而被构造成节点并加入到同步队列中，而这个加入队列的过程必须要保证线程安全。AQS提供了一个基于CAS的设置尾节点的方法：compareAndSerTail，它需要传递当前线程认为的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。 将节点设置为首节点：同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点。设置首节点是通过成功获取同步状态的线程完成的，由于只有一个线程能成功获取到同步状态，因此设置头节点并不需要使用CAS来保证，它只需要将首节点设置为原首节点的后继节点并断开原首节点的next引用即可。 synchronized底层实现，加在方法上和加在同步代码块中编译后的区别、类锁、对象锁。原文链接 概念synchronized是Java中的关键字，是一种同步锁。它修饰的对象有以下几种： 修饰一个代码块，被修饰的代码块称为同步语句块，其作用的范围是大括号{}括起来的代码，作用的对象是调用这个代码块的对象。 一个线程访问一个对象中的synchronized(this)同步代码块时，其他试图访问该对象的线程将被阻塞 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 同步线程 */class SyncThread implements Runnable &#123; private static int count; public SyncThread() &#123; count = 0; &#125; public void run() &#123; synchronized(this) &#123; for (int i = 0; i &lt; 5; i++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + ":" + (count++)); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public int getCount() &#123; return count; &#125;&#125;//SyncThread的调用SyncThread syncThread = new SyncThread();Thread thread1 = new Thread(syncThread, "SyncThread1");Thread thread2 = new Thread(syncThread, "SyncThread2");thread1.start();thread2.start();//结果如下SyncThread1:0SyncThread1:1SyncThread1:2SyncThread1:3SyncThread1:4SyncThread2:5SyncThread2:6SyncThread2:7SyncThread2:8SyncThread2:9* 当两个并发线程(thread1和thread2)访问同一个对象(syncThread)中的synchronized代码块时，在同一时刻只能有一个线程得到执行，另一个线程受阻塞，必须等待当前线程执行完这个代码块以后才能执行该代码块。Thread1和thread2是互斥的，因为在执行synchronized代码块时会锁定当前的对象，只有执行完该代码块才能释放该对象锁，下一个线程才能执行并锁定该对象。 我们再把SyncThread的调用稍微改一下：123456789101112131415Thread thread1 = new Thread(new SyncThread(), "SyncThread1");Thread thread2 = new Thread(new SyncThread(), "SyncThread2");thread1.start();thread2.start();//结果如下：SyncThread1:0SyncThread2:1SyncThread1:2SyncThread2:3SyncThread1:4SyncThread2:5SyncThread2:6SyncThread1:7SyncThread1:8SyncThread2:9 不是说一个线程执行synchronized代码块时其它的线程受阻塞吗？为什么上面的例子中thread1和thread2同时在执行。这是因为synchronized只锁定对象，每个对象只有一个锁（lock）与之相关联，而上面的代码等同于下面这段代码：123456SyncThread syncThread1 = new SyncThread();SyncThread syncThread2 = new SyncThread();Thread thread1 = new Thread(syncThread1, "SyncThread1");Thread thread2 = new Thread(syncThread2, "SyncThread2");thread1.start();thread2.start(); 这时创建了两个SyncThread的对象syncThread1和syncThread2，线程thread1执行的是syncThread1对象中的synchronized代码(run)，而线程thread2执行的是syncThread2对象中的synchronized代码(run)；我们知道synchronized锁定的是对象，这时会有两把锁分别锁定syncThread1对象和syncThread2对象，而这两把锁是互不干扰的，不形成互斥，所以两个线程可以同时执行。 当一个线程访问对象的一个synchronized(this)同步代码块时，另一个线程仍然可以访问该对象中的非synchronized(this)同步代码块。 多个线程访问synchronized和非synchronized代码块12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Counter implements Runnable&#123; private int count; public Counter() &#123; count = 0; &#125; public void countAdd() &#123; synchronized(this) &#123; for (int i = 0; i &lt; 5; i ++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + ":" + (count++)); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; //非synchronized代码块，未对count进行读写操作，所以可以不用synchronized public void printCount() &#123; for (int i = 0; i &lt; 5; i ++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + " count:" + count); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public void run() &#123; String threadName = Thread.currentThread().getName(); if (threadName.equals("A")) &#123; countAdd(); &#125; else if (threadName.equals("B")) &#123; printCount(); &#125; &#125;&#125;//调用代码Counter counter = new Counter();Thread thread1 = new Thread(counter, "A");Thread thread2 = new Thread(counter, "B");thread1.start();thread2.start();//结果如下A:0B count:1A:1B count:2A:2B count:3A:3B count:4A:4B count:5 上面代码中countAdd是一个synchronized的，printCount是非synchronized的。从上面的结果中可以看出一个线程访问一个对象的synchronized代码块时，别的线程可以访问该对象的非synchronized代码块而不受阻塞。 指定要给某个对象加锁12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * 银行账户类 */class Account &#123; String name; float amount; public Account(String name, float amount) &#123; this.name = name; this.amount = amount; &#125; //存钱 public void deposit(float amt) &#123; amount += amt; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //取钱 public void withdraw(float amt) &#123; amount -= amt; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public float getBalance() &#123; return amount; &#125;&#125;/** * 账户操作类 */class AccountOperator implements Runnable&#123; private Account account; public AccountOperator(Account account) &#123; this.account = account; &#125; public void run() &#123; synchronized (account) &#123; account.deposit(500); account.withdraw(500); System.out.println(Thread.currentThread().getName() + ":" + account.getBalance()); &#125; &#125;&#125;//调用代码Account account = new Account("zhang san", 10000.0f);AccountOperator accountOperator = new AccountOperator(account);final int THREAD_NUM = 5;Thread threads[] = new Thread[THREAD_NUM];for (int i = 0; i &lt; THREAD_NUM; i ++) &#123; threads[i] = new Thread(accountOperator, "Thread" + i); threads[i].start();&#125;//结果如下Thread3:10000.0Thread2:10000.0Thread1:10000.0Thread4:10000.0Thread0:10000.0 在AccountOperator 类中的run方法里，我们用synchronized 给account对象加了锁。这时，当一个线程访问account对象时，其他试图访问account对象的线程将会阻塞，直到该线程访问account对象结束。也就是说谁拿到那个锁谁就可以运行它所控制的那段代码。当有一个明确的对象作为锁时，就可以用类似下面这样的方式写程序。12345678public void method3(SomeObject obj)&#123; //obj 锁定的对象 synchronized(obj) &#123; // todo &#125;&#125; 当没有明确的对象作为锁，只是想让一段代码同步时，可以创建一个特殊的对象来充当锁：1234567891011121314class Test implements Runnable&#123; private byte[] lock = new byte[0]; // 特殊的instance变量 public void method() &#123; synchronized(lock) &#123; // todo 同步代码块 &#125; &#125; public void run() &#123; &#125;&#125; 说明：零长度的byte数组对象创建起来将比任何对象都经济――查看编译后的字节码：生成零长度的byte[]对象只需3条操作码，而Object lock = new Object()则需要7行操作码。 修饰一个方法Synchronized修饰一个方法很简单，就是在方法的前面加synchronized，public synchronized void method(){//todo}; synchronized修饰方法和修饰一个代码块类似，只是作用范围不一样，修饰代码块是大括号括起来的范围，而修饰方法范围是整个函数。如将【Demo1】中的run方法改成如下的方式，实现的效果一样。12345678910111213141516171819202122232425public synchronized void run() &#123; for (int i = 0; i &lt; 5; i ++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + ":" + (count++)); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;//Synchronized作用于整个方法的写法。//写法一public synchronized void method()&#123; // todo&#125;//写法二public void method()&#123; synchronized(this) &#123; // todo &#125;&#125; 写法一修饰的是一个方法，写法二修饰的是一个代码块，但写法一与写法二是等价的，都是锁定了整个方法时的内容。 在用synchronized修饰方法时要注意以下几点： synchronized关键字不能继承。虽然可以使用synchronized来定义方法，但synchronized并不属于方法定义的一部分，因此，synchronized关键字不能被继承。如果在父类中的某个方法使用了synchronized关键字，而在子类中覆盖了这个方法，在子类中的这个方法默认情况下并不是同步的，而必须显式地在子类的这个方法中加上synchronized关键字才可以。当然，还可以在子类方法中调用父类中相应的方法，这样虽然子类中的方法不是同步的，但子类调用了父类的同步方法，因此，子类的方法也就相当于同步了。这两种方式的例子代码如下：在子类方法中加上synchronized关键字123456class Parent &#123; public synchronized void method() &#123; &#125;&#125;class Child extends Parent &#123; public synchronized void method() &#123; &#125;&#125; 在子类方法中调用父类的同步方法123456class Parent &#123; public synchronized void method() &#123; &#125;&#125;class Child extends Parent &#123; public void method() &#123; super.method(); &#125;&#125; 在定义接口方法时不能使用synchronized关键字。 构造方法不能使用synchronized关键字，但可以使用synchronized代码块来进行同步。 修饰一个静态的方法123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 同步线程 */class SyncThread implements Runnable &#123; private static int count; public SyncThread() &#123; count = 0; &#125; public synchronized static void method() &#123; for (int i = 0; i &lt; 5; i ++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + ":" + (count++)); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; public synchronized void run() &#123; method(); &#125;&#125;SyncThread syncThread1 = new SyncThread();SyncThread syncThread2 = new SyncThread();Thread thread1 = new Thread(syncThread1, "SyncThread1");Thread thread2 = new Thread(syncThread2, "SyncThread2");thread1.start();thread2.start();SyncThread1:0SyncThread1:1SyncThread1:2SyncThread1:3SyncThread1:4SyncThread2:5SyncThread2:6SyncThread2:7SyncThread2:8SyncThread2:9 syncThread1和syncThread2是SyncThread的两个对象，但在thread1和thread2并发执行时却保持了线程同步。这是因为run中调用了静态方法method，而静态方法是属于类的，所以syncThread1和syncThread2相当于用了同一把锁。这与Demo1是不同的。 修饰一个类123456789101112131415161718192021222324252627/** * 同步线程 */class SyncThread implements Runnable &#123; private static int count; public SyncThread() &#123; count = 0; &#125; public static void method() &#123; synchronized(SyncThread.class) &#123; for (int i = 0; i &lt; 5; i ++) &#123; try &#123; System.out.println(Thread.currentThread().getName() + ":" + (count++)); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; public synchronized void run() &#123; method(); &#125;&#125; 其效果和【Demo5】是一样的，synchronized作用于一个类T时，是给这个类T加锁，T的所有对象用的是同一把锁。 总结 无论synchronized关键字加在方法上还是对象上，如果它作用的对象是非静态的，则它取得的锁是对象；如果synchronized作用的对象是一个静态方法或一个类，则它取得的锁是对类，该类所有的对象同一把锁。 每个对象只有一个锁（lock）与之相关联，谁拿到这个锁谁就可以运行它所控制的那段代码。实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。 锁升级的过程。 修饰一个方法，被修饰的方法称为同步方法，其作用的范围是整个方法，作用的对象是调用这个方法的对象 修改一个静态的方法，其作用的范围是整个静态方法，作用的对象是这个类的所有对象 修改一个类，其作用的范围是synchronized后面括号括起来的部分，作用主的对象是这个类的所有对象 Java中提供了两种实现同步的基础语义：synchronized方法和synchronized块 12345678910public class SyncTest &#123; public void syncBlock()&#123; synchronized (this)&#123; System.out.println("hello block"); &#125; &#125; public synchronized void syncMethod()&#123; System.out.println("hello method"); &#125;&#125; 当SyncTest.java被编译成class文件的时候，synchronized关键字和synchronized方法的字节码略有不同，我们可以用javap -v 命令查看class文件对应的JVM字节码信息，部分信息如下：123456789101112131415161718192021222324252627282930313233343536373839&#123; public void syncBlock(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter // monitorenter指令进入同步块 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #3 // String hello block 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: aload_1 13: monitorexit // monitorexit指令退出同步块 14: goto 22 17: astore_2 18: aload_1 19: monitorexit // monitorexit指令退出同步块 20: aload_2 21: athrow 22: return Exception table: from to target type 4 14 17 any 17 20 17 any public synchronized void syncMethod(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED //添加了ACC_SYNCHRONIZED标记 Code: stack=2, locals=1, args_size=1 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #5 // String hello method 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return &#125; 从上面的中文注释处可以看到，对于synchronized关键字而言，javac在编译时，会生成对应的monitorenter和monitorexit指令分别对应synchronized同步块的进入和退出，有两个monitorexit指令的原因是：为了保证抛异常的情况下也能释放锁，所以javac为同步代码块添加了一个隐式的try-finally，在finally中会调用monitorexit命令释放锁。而对于synchronized方法而言，javac为其生成了一个ACC_SYNCHRONIZED关键字，在JVM进行方法调用时，发现调用的方法被ACC_SYNCHRONIZED修饰，则会先尝试获得锁。 在JVM底层，对于这两种synchronized语义的实现大致相同。 锁的几种形式传统的锁（也就是下文要说的重量级锁）依赖于系统的同步函数，在linux上使用mutex互斥锁，最底层实现依赖于futex，关于futex可以看我之前的文章，这些同步函数都涉及到用户态和内核态的切换、进程的上下文切换，成本较高。对于加了synchronized关键字但运行时并没有多线程竞争，或两个线程接近于交替执行的情况，使用传统锁机制无疑效率是会比较低的。 在JDK 1.6之前,synchronized只有传统的锁机制，因此给开发者留下了synchronized关键字相比于其他同步机制性能不好的印象。 在JDK 1.6引入了两种新型锁机制：偏向锁和轻量级锁，它们的引入是为了解决在没有多线程竞争或基本没有竞争的场景下因使用传统锁机制带来的性能开销问题。 在看这几种锁机制的实现前，我们先来了解下对象头，它是实现多种锁机制的基础。 对象头因为在Java中任意对象都可以用作锁，因此必定要有一个映射关系，存储该对象以及其对应的锁信息（比如当前哪个线程持有锁，哪些线程在等待）。一种很直观的方法是，用一个全局map，来存储这个映射关系，但这样会有一些问题：需要对map做线程安全保障，不同的synchronized之间会相互影响，性能差；另外当同步对象较多时，该map可能会占用比较多的内存。 所以最好的办法是将这个映射关系存储在对象头中，因为对象头本身也有一些hashcode、GC相关的数据，所以如果能将锁信息与这些信息共存在对象头中就好了。 在JVM中，对象在内存中除了本身的数据外还会有个对象头，对于普通对象而言，其对象头中有两类信息：mark word和类型指针。另外对于数组而言还会有一份记录数组长度的数据。 类型指针是指向该对象所属类对象的指针，mark word用于存储对象的HashCode、GC分代年龄、锁状态等信息。在32位系统上mark word长度为32字节，64位系统上长度为64字节。为了能在有限的空间里存储下更多的数据，其存储格式是不固定的，在32位系统上各状态的格式如下： 可以看到锁信息也是存在于对象的mark word中的。当对象状态为偏向锁（biasable）时，mark word存储的是偏向的线程ID；当状态为轻量级锁（lightweight locked）时，mark word存储的是指向线程栈中Lock Record的指针；当状态为重量级锁（inflated）时，为指向堆中的monitor对象的指针。 重量级锁重量级锁是我们常说的传统意义上的锁，其利用操作系统底层的同步机制去实现Java中的线程同步。 重量级锁的状态下，对象的mark word为指向一个堆中monitor对象的指针。 一个monitor对象包括这么几个关键字段：cxq（下图中的ContentionList），EntryList ，WaitSet，owner。 其中cxq ，EntryList ，WaitSet都是由ObjectWaiter的链表结构，owner指向持有锁的线程。 当一个线程尝试获得锁时，如果该锁已经被占用，则会将该线程封装成一个ObjectWaiter对象插入到cxq的队列尾部，然后暂停当前线程。当持有锁的线程释放锁前，会将cxq中的所有元素移动到EntryList中去，并唤醒EntryList的队首线程。 如果一个线程在同步块中调用了Object#wait方法，会将该线程对应的ObjectWaiter从EntryList移除并加入到WaitSet中，然后释放锁。当wait的线程被notify之后，会将对应的ObjectWaiter从WaitSet移动到EntryList中。 以上只是对重量级锁流程的一个简述，其中涉及到的很多细节，比如ObjectMonitor对象从哪来？释放锁时是将cxq中的元素移动到EntryList的尾部还是头部？notfiy时，是将ObjectWaiter移动到EntryList的尾部还是头部？ 关于具体的细节，会在重量级锁的文章中分析。 轻量级锁JVM的开发者发现在很多情况下，在Java程序运行时，同步块中的代码都是不存在竞争的，不同的线程交替的执行同步块中的代码。这种情况下，用重量级锁是没必要的。因此JVM引入了轻量级锁的概念。 线程在执行同步块之前，JVM会先在当前的线程的栈帧中创建一个Lock Record，其包括一个用于存储对象头中的 mark word（官方称之为Displaced Mark Word）以及一个指向对象的指针。下图右边的部分就是一个Lock Record。 加锁过程 在线程栈中创建一个Lock Record，将其obj（即上图的Object reference）字段指向锁对象。 直接通过CAS指令将Lock Record的地址存储在对象头的mark word中，如果对象处于无锁状态则修改成功，代表该线程获得了轻量级锁。如果失败，进入到步骤3。 如果是当前线程已经持有该锁了，代表这是一次锁重入。设置Lock Record第一部分（Displaced Mark Word）为null，起到了一个重入计数器的作用。然后结束。 走到这一步说明发生了竞争，需要膨胀为重量级锁。 解锁过程 遍历线程栈,找到所有obj字段等于当前锁对象的Lock Record。 如果Lock Record的Displaced Mark Word为null，代表这是一次重入，将obj设置为null后continue。 如果Lock Record的Displaced Mark Word不为null，则利用CAS指令将对象头的mark word恢复成为Displaced Mark Word。如果成功，则continue，否则膨胀为重量级锁。 偏向锁Java是支持多线程的语言，因此在很多二方包、基础库中为了保证代码在多线程的情况下也能正常运行，也就是我们常说的线程安全，都会加入如synchronized这样的同步语义。但是在应用在实际运行时，很可能只有一个线程会调用相关同步方法。比如下面这个demo： 12345678910111213141516171819import java.util.ArrayList;import java.util.List;public class SyncDemo1 &#123; public static void main(String[] args) &#123; SyncDemo1 syncDemo1 = new SyncDemo1(); for (int i = 0; i &lt; 100; i++) &#123; syncDemo1.addString("test:" + i); &#125; &#125; private List&lt;String&gt; list = new ArrayList&lt;&gt;(); public synchronized void addString(String s) &#123; list.add(s); &#125;&#125; 在这个demo中为了保证对list操纵时线程安全，对addString方法加了synchronized的修饰，但实际使用时却只有一个线程调用到该方法，对于轻量级锁而言，每次调用addString时，加锁解锁都有一个CAS操作；对于重量级锁而言，加锁也会有一个或多个CAS操作（这里的’一个‘、’多个‘数量词只是针对该demo，并不适用于所有场景）。 在JDK1.6中为了提高一个对象在一段很长的时间内都只被一个线程用做锁对象场景下的性能，引入了偏向锁，在第一次获得锁时，会有一个CAS操作，之后该线程再获取锁，只会执行几个简单的命令，而不是开销相对较大的CAS命令。我们来看看偏向锁是如何做的。 对象创建当JVM启用了偏向锁模式（1.6以上默认开启），当新创建一个对象的时候，如果该对象所属的class没有关闭偏向锁模式（什么时候会关闭一个class的偏向模式下文会说，默认所有class的偏向模式都是是开启的），那新创建对象的mark word将是可偏向状态，此时mark word中的thread id（参见上文偏向状态下的mark word格式）为0，表示未偏向任何线程，也叫做匿名偏向(anonymously biased)。 加锁过程case 1：当该对象第一次被线程获得锁的时候，发现是匿名偏向状态，则会用CAS指令，将mark word中的thread id由0改成当前线程Id。如果成功，则代表获得了偏向锁，继续执行同步块中的代码。否则，将偏向锁撤销，升级为轻量级锁。 case 2：当被偏向的线程再次进入同步块时，发现锁对象偏向的就是当前线程，在通过一些额外的检查后（细节见后面的文章），会往当前线程的栈中添加一条Displaced Mark Word为空的Lock Record中，然后继续执行同步块的代码，因为操纵的是线程私有的栈，因此不需要用到CAS指令；由此可见偏向锁模式下，当被偏向的线程再次尝试获得锁时，仅仅进行几个简单的操作就可以了，在这种情况下，synchronized关键字带来的性能开销基本可以忽略。 case 3.当其他线程进入同步块时，发现已经有偏向的线程了，则会进入到撤销偏向锁的逻辑里，一般来说，会在safepoint中去查看偏向的线程是否还存活，如果存活且还在同步块中则将锁升级为轻量级锁，原偏向的线程继续拥有锁，当前线程则走入到锁升级的逻辑里；如果偏向的线程已经不存活或者不在同步块中，则将对象头的mark word改为无锁状态（unlocked），之后再升级为轻量级锁。 由此可见，偏向锁升级的时机为：当锁已经发生偏向后，只要有另一个线程尝试获得偏向锁，则该偏向锁就会升级成轻量级锁。当然这个说法不绝对，因为还有批量重偏向这一机制。 解锁过程当有其他线程尝试获得锁时，是根据遍历偏向线程的lock record来确定该线程是否还在执行同步块中的代码。因此偏向锁的解锁很简单，仅仅将栈中的最近一条lock record的obj字段设置为null。需要注意的是，偏向锁的解锁步骤中并不会修改对象头中的thread id。 下图展示了锁状态的转换流程： 另外，偏向锁默认不是立即就启动的，在程序启动后，通常有几秒的延迟，可以通过命令 -XX:BiasedLockingStartupDelay=0来关闭延迟。 批量重偏向与撤销从上文偏向锁的加锁解锁过程中可以看出，当只有一个线程反复进入同步块时，偏向锁带来的性能开销基本可以忽略，但是当有其他线程尝试获得锁时，就需要等到safe point时将偏向锁撤销为无锁状态或升级为轻量级/重量级锁。safe point这个词我们在GC中经常会提到，其代表了一个状态，在该状态下所有线程都是暂停的（大概这么个意思），详细可以看这篇文章。总之，偏向锁的撤销是有一定成本的，如果说运行时的场景本身存在多线程竞争的，那偏向锁的存在不仅不能提高性能，而且会导致性能下降。因此，JVM中增加了一种批量重偏向/撤销的机制。 存在如下两种情况: 一个线程创建了大量对象并执行了初始的同步操作，之后在另一个线程中将这些对象作为锁进行之后的操作。这种case下，会导致大量的偏向锁撤销操作。 存在明显多线程竞争的场景下使用偏向锁是不合适的，例如生产者/消费者队列。 批量重偏向（bulk rebias）机制是为了解决第一种场景。批量撤销（bulk revoke）则是为了解决第二种场景。 其做法是：以class为单位，为每个class维护一个偏向锁撤销计数器，每一次该class的对象发生偏向撤销操作时，该计数器+1，当这个值达到重偏向阈值（默认20）时，JVM就认为该class的偏向锁有问题，因此会进行批量重偏向。每个class对象会有一个对应的epoch字段，每个处于偏向锁状态对象的mark word中也有该字段，其初始值为创建该对象时，class中的epoch的值。每次发生批量重偏向时，就将该值+1，同时遍历JVM中所有线程的栈，找到该class所有正处于加锁状态的偏向锁，将其epoch字段改为新值。下次获得锁时，发现当前对象的epoch值和class的epoch不相等，那就算当前已经偏向了其他线程，也不会执行撤销操作，而是直接通过CAS操作将其mark word的Thread Id 改成当前线程Id。 当达到重偏向阈值后，假设该class计数器继续增长，当其达到批量撤销的阈值后（默认40），JVM就认为该class的使用场景存在多线程竞争，会标记该class为不可偏向，之后，对于该class的锁，直接走轻量级锁的逻辑。 Java运行时区域及各个区域的作用、对GC的了解、Java内存模型及为什么要这么设计？Java运行时区域及各个区域的作用Java虚拟机所管理的内存将会包括一下几个运行时数据区域 程序计数器 程序计数器（Program Counter Register） 是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条执行字节码指令。 每条线程都有一个独立的程序计数器。 如果执行的是java方法，这个计数器记录的是正在执行的虚拟机字节码指令地址。如果是native方法，计数器为空。此内存区域是唯一一个在java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 Java虚拟机栈同样是线程私有，描述Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。一个方法对应一个栈帧。 局部变量表存放了各种基本类型、对象引用和returnAddress类型（指向了一条字节码指令地址）。其中64位长度long 和 double占两个局部变量空间，其他只占一个。 规定的异常情况有两种：1.线程请求的栈的深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；2.如果虚拟机可以动态扩展，如果扩展时无法申请到足够的内存，就抛出OutOfMemoryError异常。 本地方法栈 和Java虚拟机栈很类似，不同的是本地方法栈为Native方法服务。 Java堆是Java虚拟机所管理的内存中最大的一块。由所有线程共享，在虚拟机启动时创建。堆区唯一目的就是存放对象实例。 堆中可细分为新生代和老年代，再细分可分为Eden空间、From Survivor空间、To Survivor空间。 堆无法扩展时，抛出OutOfMemoryError异常 方法区所有线程共享，存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 当方法区无法满足内存分配需求时，抛出OutOfMemoryError 运行时常量池它是方法区的一部分，Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项是常量池（Const Pool Table），用于存放编译期生成的各种字面量和符号引用。并非预置入Class文件中常量池的内容才进入方法运行时常量池，运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的便是String类的intern()方法。 当方法区无法满足内存分配需求时，抛出OutOfMemoryError 直接内存并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。 JDK1.4加入了NIO，引入一种基于通道与缓冲区的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。因为避免了在Java堆和Native堆中来回复制数据，提高了性能。 当各个内存区域总和大于物理内存限制，抛出OutOfMemoryError异常。 GC相关jvm 中，程序计数器、虚拟机栈、本地方法栈都是随线程而生随线程而灭，栈帧随着方法的进入和退出做入栈和出栈操作，实现了自动的内存清理，因此，我们的内存垃圾回收主要集中于 java 堆和方法区中，在程序运行期间，这部分内存的分配和使用都是动态的。 GC的对象需要进行回收的对象就是已经没有存活的对象，判断一个对象是否存活常用的有两种办法：引用计数和可达分析。 引用计数：每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收。此方法简单，无法解决对象相互循环引用的问题。 可达性分析（Reachability Analysis）：从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。不可达对象。123456789在Java语言中，GC Roots包括：虚拟机栈中引用的对象。方法区中类静态属性实体引用的对象。方法区中常量引用的对象。本地方法栈中JNI引用的对象。 什么时候触发GC 程序调用System.gc时可以触发 系统自身来决定GC触发的时机（根据Eden区和From Space区的内存大小来决定。当内存大小不足时，则会启动GC线程并停止应用线程） 123456789101112131415GC又分为 minor GC 和 Full GC (也称为 Major GC )Minor GC触发条件：当Eden区满时，触发Minor GC。Full GC触发条件： a.调用System.gc时，系统建议执行Full GC，但是不必然执行 b.老年代空间不足 c.方法区空间不足 d.通过Minor GC后进入老年代的平均大小大于老年代的可用内存 e.由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 GC常用算法GC常用算法有：标记-清除算法，标记-压缩算法，复制算法，分代收集算法。目前主流的JVM（HotSpot）采用的是分代收集算法。 标记-清除算法为每个对象存储一个标记位，记录对象的状态（活着或是死亡）。分为两个阶段，一个是标记阶段，这个阶段内，为每个对象更新标记位，检查对象是否死亡；第二个阶段是清除阶段，该阶段对死亡的对象进行清除，执行 GC 操作。 优点 最大的优点是，标记—清除算法中每个活着的对象的引用只需要找到一个即可，找到一个就可以判断它为活的。此外，更重要的是，这个算法并不移动对象的位置。 缺点 它的缺点就是效率比较低（递归与全堆对象遍历）。每个活着的对象都要在标记阶段遍历一遍；所有对象都要在清除阶段扫描一遍，因此算法复杂度较高。没有移动对象，导致可能出现很多碎片空间无法利用的情况。 标记-压缩算法（标记-整理）标记-压缩法是标记-清除法的一个改进版。同样，在标记阶段，该算法也将所有对象标记为存活和死亡两种状态；不同的是，在第二个阶段，该算法并没有直接对死亡的对象进行清理，而是将所有存活的对象整理一下，放到另一处空间，然后把剩下的所有对象全部清除。这样就达到了标记-整理的目的。 优点 该算法不会像标记-清除算法那样产生大量的碎片空间。 缺点 如果存活的对象过多，整理阶段将会执行较多复制操作，导致算法效率降低。 左边是标记阶段，右边是整理之后的状态。可以看到，该算法不会产生大量碎片内存空间。 复制算法该算法将内存平均分成两部分，然后每次只使用其中的一部分，当这部分内存满的时候，将内存中所有存活的对象复制到另一个内存中，然后将之前的内存清空，只使用这部分内存，循环下去。 注意： 这个算法与标记-整理算法的区别在于，该算法不是在同一个区域复制，而是将所有存活的对象复制到另一个区域内。 优点 实现简单；不产生内存碎片 缺点 每次运行，总有一半内存是空的，导致可使用的内存空间只有原来的一半。 分代收集算法现在的虚拟机垃圾收集大多采用这种方式，它根据对象的生存周期，将堆分为新生代(Young)和老年代(Tenure)。在新生代中，由于对象生存期短，每次回收都会有大量对象死去，那么这时就采用复制算法。老年代里的对象存活率较高，没有额外的空间进行分配担保，所以可以使用标记-整理 或者 标记-清除。 具体过程：新生代(Young)分为Eden区，From区与To区 当系统创建一个对象的时候，总是在Eden区操作，当这个区满了，那么就会触发一次YoungGC，也就是年轻代的垃圾回收。一般来说这时候不是所有的对象都没用了，所以就会把还能用的对象复制到From区。 这样整个Eden区就被清理干净了，可以继续创建新的对象，当Eden区再次被用完，就再触发一次YoungGC，然后呢，注意，这个时候跟刚才稍稍有点区别。这次触发YoungGC后，会将Eden区与From区还在被使用的对象复制到To区， 再下一次YoungGC的时候，则是将Eden区与To区中的还在被使用的对象复制到From区。 经过若干次YoungGC后，有些对象在From与To之间来回游荡，这时候From区与To区亮出了底线（阈值），这些家伙要是到现在还没挂掉，对不起，一起滚到（复制）老年代吧。 老年代经过这么几次折腾，也就扛不住了（空间被用完），好，那就来次集体大扫除（Full GC），也就是全量回收。如果Full GC使用太频繁的话，无疑会对系统性能产生很大的影响。所以要合理设置年轻代与老年代的大小，尽量减少Full GC的操作。 垃圾收集器如果说收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现 Serial收集器串行收集器是最古老，最稳定以及效率高的收集器可能会产生较长的停顿，只使用一个线程去回收-XX:+UseSerialGC 新生代、老年代使用串行回收 新生代复制算法 老年代标记-压缩 并行收集器 ParNew-XX:+UseParNewGC（new代表新生代，所以适用于新生代） 新生代并行 老年代串行Serial收集器新生代的并行版本在新生代回收时使用复制算法多线程，需要多核支持 -XX:ParallelGCThreads 限制线程数量 Parallel收集器类似ParNew新生代复制算法老年代标记-压缩更加关注吞吐量-XX:+UseParallelGC 使用Parallel收集器+ 老年代串行-XX:+UseParallelOldGC 使用Parallel收集器+ 老年代并行 其他GC参数 -XX:MaxGCPauseMills - 最大停顿时间，单位毫秒 - GC尽力保证回收时间不超过设定值 -XX:GCTimeRatio - 0-100的取值范围 - 垃圾收集时间占总时间的比 - 默认99，即最大允许1%时间做GC 这两个参数是矛盾的。因为停顿时间和吞吐量不可能同时调优 CMS收集器 Concurrent Mark Sweep 并发标记清除（应用程序线程和GC线程交替执行） 使用标记-清除算法 并发阶段会降低吞吐量（停顿时间减少，吞吐量降低） 老年代收集器（新生代使用ParNew） -XX:+UseConcMarkSweepGC CMS运行过程比较复杂，着重实现了标记的过程，可分为 初始标记（会产生全局停顿） 根可以直接关联到的对象 速度快 并发标记（和用户线程一起） 主要标记过程，标记全部对象 重新标记 （会产生全局停顿） 由于并发标记时，用户线程依然运行，因此在正式清理前，再做修正 并发清除（和用户线程一起） 基于标记结果，直接清理对象 这里就能很明显的看出，为什么CMS要使用标记清除而不是标记压缩，如果使用标记压缩，需要多对象的内存位置进行改变，这样程序就很难继续执行。但是标记清除会产生大量内存碎片，不利于内存分配。 CMS收集器特点： 尽可能降低停顿 会影响系统整体吞吐量和性能 比如，在用户线程运行过程中，分一半CPU去做GC，系统性能在GC阶段，反应速度就下降一半 清理不彻底 因为在清理阶段，用户线程还在运行，会产生新的垃圾，无法清理 因为和用户线程一起运行，不能在空间快满时再清理（因为也许在并发GC的期间，用户线程又申请了大量内存，导致内存不够） -XX:CMSInitiatingOccupancyFraction设置触发GC的阈值 如果不幸内存预留空间不够，就会引起concurrent mode failure一旦 concurrent mode failure产生，将使用串行收集器作为后备。 CMS也提供了整理碎片的参数： - -XX:+ UseCMSCompactAtFullCollection Full GC后，进行一次整理 整理过程是独占的，会引起停顿时间变长 -XX:+CMSFullGCsBeforeCompaction - 设置进行几次Full GC后，进行一次碎片整理 -XX:ParallelCMSThreads - 设定CMS的线程数量（一般情况约等于可用CPU数量） CMS的提出是想改善GC的停顿时间，在GC过程中的确做到了减少GC时间，但是同样导致产生大量内存碎片，又需要消耗大量时间去整理碎片，从本质上并没有改善时间。 G1收集器G1是目前技术发展的最前沿成果之一，HotSpot开发团队赋予它的使命是未来可以替换掉JDK1.5中发布的CMS收集器。 与CMS收集器相比G1收集器有以下特点： (1) 空间整合，G1收集器采用标记整理算法，不会产生内存空间碎片。分配大对象时不会因为无法找到连续空间而提前触发下一次GC。 (2)可预测停顿，这是G1的另一大优势，降低停顿时间是G1和CMS的共同关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为N毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒，这几乎已经是实时Java（RTSJ）的垃圾收集器的特征了。 上面提到的垃圾收集器，收集的范围都是整个新生代或者老年代，而G1不再是这样。使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔阂了，它们都是一部分（可以不连续）Region的集合。 G1的新生代收集跟ParNew类似，当新生代占用达到一定比例的时候，开始出发收集。 和CMS类似，G1收集器收集老年代对象会有短暂停顿。 步骤： (1)标记阶段，首先初始标记(Initial-Mark),这个阶段是停顿的(Stop the World Event)，并且会触发一次普通Mintor GC。对应GC log:GC pause (young) (inital-mark) (2)Root Region Scanning，程序运行过程中会回收survivor区(存活到老年代)，这一过程必须在young GC之前完成。 (3)Concurrent Marking，在整个堆中进行并发标记(和应用程序并发执行)，此过程可能被young GC中断。在并发标记阶段，若发现区域对象中的所有对象都是垃圾，那个这个区域会被立即回收(图中打X)。同时，并发标记过程中，会计算每个区域的对象活性(区域中存活对象的比例)。 (4)Remark, 再标记，会有短暂停顿(STW)。再标记阶段是用来收集 并发标记阶段 产生新的垃圾(并发阶段和应用程序一同运行)；G1中采用了比CMS更快的初始快照算法:snapshot-at-the-beginning (SATB)。 (5)Copy/Clean up，多线程清除失活对象，会有STW。G1将回收区域的存活对象拷贝到新区域，清除Remember Sets，并发清空回收区域并把它返回到空闲区域链表中。 (6)复制/清除过程后。回收区域的活性对象已经被集中回收到深蓝色和深绿色区域。 finalize()方法详解finalize的作用(1)finalize()是Object的protected方法，子类可以覆盖该方法以实现资源清理工作，GC在回收对象之前调用该方法。 (2)finalize()与C++中的析构函数不是对应的。C++中的析构函数调用的时机是确定的（对象离开作用域或delete掉），但Java中的finalize的调用具有不确定性 (3)不建议用finalize方法完成“非内存资源”的清理工作，但建议用于： ① 清理本地对象(通过JNI创建的对象)； ② 作为确保某些非内存资源(如Socket、文件等)释放的一个补充：在finalize方法中显式调用其他资源释放方法 finalize的问题(1)一些与finalize相关的方法，由于一些致命的缺陷，已经被废弃了，如System.runFinalizersOnExit()方法、Runtime.runFinalizersOnExit()方法 (2)System.gc()与System.runFinalization()方法增加了finalize方法执行的机会，但不可盲目依赖它们 (3)Java语言规范并不保证finalize方法会被及时地执行、而且根本不会保证它们会被执行 (4)finalize方法可能会带来性能问题。因为JVM通常在单独的低优先级线程中完成finalize的执行 (5)对象再生问题：finalize方法中，可将待回收对象赋值给GC Roots可达的对象引用，从而达到对象再生的目的 (6)finalize方法至多由GC执行一次(用户当然可以手动调用对象的finalize方法，但并不影响GC对finalize的行为) finalize的执行过程(生命周期)(1) 首先，大致描述一下finalize流程：当对象变成(GC Roots)不可达时，GC会判断该对象是否覆盖了finalize方法，若未覆盖，则直接将其回收。否则，若对象未执行过finalize方法，将其放入F-Queue队列，由一低优先级线程执行该队列中对象的finalize方法。执行finalize方法完毕后，GC会再次判断该对象是否可达，若不可达，则进行回收，否则，对象“复活”。 (2) 具体的finalize流程： 对象可由两种状态，涉及到两类状态空间，一是终结状态空间 F = {unfinalized, finalizable, finalized}；二是可达状态空间 R = {reachable, finalizer-reachable, unreachable}。各状态含义如下： unfinalized: 新建对象会先进入此状态，GC并未准备执行其finalize方法，因为该对象是可达的 finalizable: 表示GC可对该对象执行finalize方法，GC已检测到该对象不可达。正如前面所述，GC通过F-Queue队列和一专用线程完成finalize的执行 finalized: 表示GC已经对该对象执行过finalize方法reachable: 表示GC Roots引用可达 finalizer-reachable(f-reachable)：表示不是reachable，但可通过某个finalizable对象可达 unreachable：对象不可通过上面两种途径可达 状态变迁图： 变迁说明： (1)新建对象首先处于[reachable, unfinalized]状态(A) (2)随着程序的运行，一些引用关系会消失，导致状态变迁，从reachable状态变迁到f-reachable(B, C, D)或unreachable(E, F)状态 (3)若JVM检测到处于unfinalized状态的对象变成f-reachable或unreachable，JVM会将其标记为finalizable状态(G,H)。若对象原处于[unreachable, unfinalized]状态，则同时将其标记为f-reachable(H)。 (4)在某个时刻，JVM取出某个finalizable对象，将其标记为finalized并在某个线程中执行其finalize方法。由于是在活动线程中引用了该对象，该对象将变迁到(reachable, finalized)状态(K或J)。该动作将影响某些其他对象从f-reachable状态重新回到reachable状态(L, M, N) (5)处于finalizable状态的对象不能同时是unreahable的，由第4点可知，将对象finalizable对象标记为finalized时会由某个线程执行该对象的finalize方法，致使其变成reachable。这也是图中只有八个状态点的原因 (6)程序员手动调用finalize方法并不会影响到上述内部标记的变化，因此JVM只会至多调用finalize一次，即使该对象“复活”也是如此。程序员手动调用多少次不影响JVM的行为 (7)若JVM检测到finalized状态的对象变成unreachable，回收其内存(I) (8)若对象并未覆盖finalize方法，JVM会进行优化，直接回收对象（O） (9)注：System.runFinalizersOnExit()等方法可以使对象即使处于reachable状态，JVM仍对其执行finalize方法 总结根据GC的工作原理，我们可以通过一些技巧和方式，让GC运行更加有效率，更加符合应用程序的要求。一些关于程序设计的几点建议： 1.最基本的建议就是尽早释放无用对象的引用。大多数程序员在使用临时变量的时候，都是让引用变量在退出活动域（scope）后，自动设置为 null.我们在使用这种方式时候，必须特别注意一些复杂的对象图，例如数组，队列，树，图等，这些对象之间有相互引用关系较为复杂。对于这类对象，GC 回收它们一般效率较低。如果程序允许，尽早将不用的引用对象赋为null.这样可以加速GC的工作。 2.尽量少用finalize函数。finalize函数是Java提供给程序员一个释放对象或资源的机会。但是，它会加大GC的工作量，因此尽量少采用finalize方式回收资源。 3.如果需要使用经常使用的图片，可以使用soft应用类型。它可以尽可能将图片保存在内存中，供程序调用，而不引起OutOfMemory. 4.注意集合数据类型，包括数组，树，图，链表等数据结构，这些数据结构对GC来说，回收更为复杂。另外，注意一些全局的变量，以及一些静态变量。这些变量往往容易引起悬挂对象（dangling reference），造成内存浪费。 5.当程序有一定的等待时间，程序员可以手动执行System.gc（），通知GC运行，但是Java语言规范并不保证GC一定会执行。使用增量式GC可以缩短Java程序的暂停时间。 countDownLatch用过没有，在项目中如何使用的，对AQS的了解。介绍 countDownLatch是在java1.5被引入，跟它一起被引入的工具类还有CyclicBarrier、Semaphore、concurrentHashMap和BlockingQueue。 存在于java.util.cucurrent包下。 countDownLatch这个类使一个线程等待其他线程各自执行完毕后再执行。 是通过一个计数器来实现的，计数器的初始值是线程的数量。每当一个线程执行完毕后，计数器的值就-1，当计数器的值为0时，表示所有线程都执行完毕，然后在闭锁上等待的线程就可以恢复工作了。 类中有三个方法是最重要的123456//调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行public void await() throws InterruptedException &#123; &#125;; //和await()类似，只不过等待一定的时间后count值还没变为0的话就会继续执行public boolean await(long timeout, TimeUnit unit) throws InterruptedException &#123; &#125;; //将count值减1public void countDown() &#123; &#125;; 示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class CountDownLatchTest &#123; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(2); System.out.println("主线程开始执行…… ……"); //第一个子线程执行 ExecutorService es1 = Executors.newSingleThreadExecutor(); es1.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(3000); System.out.println("子线程："+Thread.currentThread().getName()+"执行"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; latch.countDown(); &#125; &#125;); es1.shutdown(); //第二个子线程执行 ExecutorService es2 = Executors.newSingleThreadExecutor(); es2.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("子线程："+Thread.currentThread().getName()+"执行"); latch.countDown(); &#125; &#125;); es2.shutdown(); System.out.println("等待两个线程执行完毕…… ……"); try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("两个子线程都执行完毕，继续执行主线程"); &#125;&#125;//运行结果主线程开始执行…… ……等待两个线程执行完毕…… ……子线程：pool-1-thread-1执行子线程：pool-2-thread-1执行两个子线程都执行完毕，继续执行主线程//模拟并发示例public class Parallellimit &#123; public static void main(String[] args) &#123; ExecutorService pool = Executors.newCachedThreadPool(); CountDownLatch cdl = new CountDownLatch(100); for (int i = 0; i &lt; 100; i++) &#123; CountRunnable runnable = new CountRunnable(cdl); pool.execute(runnable); &#125; &#125;&#125; class CountRunnable implements Runnable &#123; private CountDownLatch countDownLatch; public CountRunnable(CountDownLatch countDownLatch) &#123; this.countDownLatch = countDownLatch; &#125; @Override public void run() &#123; try &#123; synchronized (countDownLatch) &#123; /*** 每次减少一个容量*/ countDownLatch.countDown(); System.out.println("thread counts = " + (countDownLatch.getCount())); &#125; countDownLatch.await(); System.out.println("concurrency counts = " + (100 - countDownLatch.getCount())); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; CountDownLatch和CyclicBarrier区别： countDownLatch是一个计数器，线程完成一个记录一个，计数器递减，只能只用一次 CyclicBarrier的计数器更像一个阀门，需要所有线程都到达，然后继续执行，计数器递增，提供reset功能，可以多次使用 AQS AQS的全称：AbstractQueuedSynchronizer，抽象队列同步器 java并发包下很多API都是基于AQS来实现的加锁和释放锁等功能的，AQS是java并发包的基础类。ReentrantLock、ReentrantReadWriteLock底层都是基于AQS来实现的。 看一下ReentrantLock和AQS之间的关系ReentrantLock内部包含了一个AQS对象，也就是AbstractQueuedSynchronizer类型的对象。这个AQS对象就是ReentrantLock可以实现加锁和释放锁的关键性的核心组件。 ReentrantLock加锁和释放锁的底层原理 如果有一个线程过来尝试用ReentrantLock的lock()方法进行加锁，这个AQS对象内部有一个核心的变量叫做state，是int类型的，代表了加锁的状态。初始状态下，这个state的值是0。 另外，这个AQS内部还有一个关键变量，用来记录当前加锁的是哪个线程，初始化状态下，这个变量是null。 接着线程1跑过来调用ReentrantLock的lock()方法尝试进行加锁，这个加锁的过程，直接就是用CAS操作将state值从0变为1。如果之前没人加过锁，那么state的值肯定是0，此时线程1就可以加锁成功。一旦线程1加锁成功了之后，就可以设置当前加锁线程是自己。所以大家看下面的图，就是线程1跑过来加锁的一个过程。看到这儿，大家应该对所谓的AQS有感觉了。说白了，就是并发包里的一个核心组件，里面有state变量、加锁线程变量等核心的东西，维护了加锁状态。ReentrantLock这种东西只是一个外层的API，内核中的锁机制实现都是依赖AQS组件的。 这个ReentrantLock之所以用Reentrant打头，意思就是他是一个可重入锁。可重入锁的意思，就是你可以对一个ReentrantLock对象多次执行lock()加锁和unlock()释放锁，也就是可以对一个锁加多次，叫做可重入加锁。 大家看明白了那个state变量之后，就知道了如何进行可重入加锁！其实每次线程1可重入加锁一次，会判断一下当前加锁线程就是自己，那么他自己就可以可重入多次加锁，每次加锁就是把state的值给累加1，别的没啥变化。 接着，如果线程1加锁了之后，线程2跑过来加锁会怎么样呢？我们来看看锁的互斥是如何实现的？线程2跑过来一下看到，哎呀！state的值不是0啊？所以CAS操作将state从0变为1的过程会失败，因为state的值当前为1，说明已经有人加锁了！ 接着线程2会看一下，是不是自己之前加的锁啊？当然不是了，“加锁线程”这个变量明确记录了是线程1占用了这个锁，所以线程2此时就是加锁失败。 接着，线程2会将自己放入AQS中的一个等待队列，因为自己尝试加锁失败了，此时就要将自己放入队列中来等待，等待线程1释放锁之后，自己就可以重新尝试加锁了 接着，线程1在执行完自己的业务逻辑代码之后，就会释放锁！他释放锁的过程非常的简单，就是将AQS内的state变量的值递减1，如果state值为0，则彻底释放锁，会将“加锁线程”变量也设置为null！整个过程，参见下图： 接下来，线程1会从等待队列的队头唤醒线程2重新尝试加锁。线程2现在就重新尝试加锁，这时还是用CAS操作将state从0变为1，- - 此时就会成功，成功之后代表加锁成功，就会将state设置为1；此外，还要把“加锁线程”设置为线程2自己，同时线程2自己就从等待队列中出队了。 总结其实一句话总结AQS就是一个并发包的基础组件，用来实现各种锁，各种同步组件的。它包含了state变量、加锁线程、等待队列等并发中的核心组件。 写生产者消费者问题，考虑高并发的情况，可以使用Java 类库，白纸写代码。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798class Info&#123; // 定义信息类 private String name = "name";//定义name属性，为了与下面set的name属性区别开 private String content = "content" ;// 定义content属性，为了与下面set的content属性区别开 private boolean flag = true ; // 设置标志位,初始时先生产 public synchronized void set(String name,String content)&#123; while(!flag)&#123; try&#123; super.wait() ; &#125;catch(InterruptedException e)&#123; e.printStackTrace() ; &#125; &#125; this.setName(name) ; // 设置名称 try&#123; Thread.sleep(300) ; &#125;catch(InterruptedException e)&#123; e.printStackTrace() ; &#125; this.setContent(content) ; // 设置内容 flag = false ; // 改变标志位，表示可以取走 super.notify(); &#125; public synchronized void get()&#123; while(flag)&#123; try&#123; super.wait() ; &#125;catch(InterruptedException e)&#123; e.printStackTrace() ; &#125; &#125; try&#123; Thread.sleep(300) ; &#125;catch(InterruptedException e)&#123; e.printStackTrace() ; &#125; System.out.println(this.getName() + " --&gt; " + this.getContent()) ; flag = true ; // 改变标志位，表示可以生产 super.notify(); &#125; public void setName(String name)&#123; this.name = name ; &#125; public void setContent(String content)&#123; this.content = content ; &#125; public String getName()&#123; return this.name ; &#125; public String getContent()&#123; return this.content ; &#125; &#125; class Producer implements Runnable&#123; // 通过Runnable实现多线程 private Info info = null ; // 保存Info引用 public Producer(Info info)&#123; this.info = info ; &#125; public void run()&#123; boolean flag = true ; // 定义标记位 for(int i=0;i&lt;10;i++)&#123; if(flag)&#123; this.info.set("姓名--1","内容--1") ; // 设置名称 flag = false ; &#125;else&#123; this.info.set("姓名--2","内容--2") ; // 设置名称 flag = true ; &#125; &#125; &#125; &#125; class Consumer implements Runnable&#123; private Info info = null ; public Consumer(Info info)&#123; this.info = info ; &#125; public void run()&#123; for(int i=0;i&lt;10;i++)&#123; this.info.get() ; &#125; &#125; &#125; public class ThreadCaseDemo03&#123; public static void main(String args[])&#123; Info info = new Info(); // 实例化Info对象 Producer pro = new Producer(info) ; // 生产者 Consumer con = new Consumer(info) ; // 消费者 new Thread(pro).start() ; //启动了生产者线程后，再启动消费者线程 try&#123; Thread.sleep(500) ; &#125;catch(InterruptedException e)&#123; e.printStackTrace() ; &#125; new Thread(con).start() ; &#125; &#125; 有没有排查过线上OOM的问题，如何排查的？查看当前路径，oom.out文件已经生成了，该文件就是应用在发生OOM异常时自动导出的堆文件。那我们此时需要对该文件进行分析，因为其中记录了是什么对象导出了应用程OOM的发生。 分析OOM的工具推荐使用MAT，下载地址，在配置好Java环境的电脑中，直接打开即可，不需要安装，然后通过MAT打开已经生成的OOM文件oom.out，出现如下提示，选择“Leak Suspects Report”执行内存泄漏检查分析： 点击Finish按钮后，MAT会将可疑的内存泄漏的对象都展现出来： 可以看到线程java.lang.Thread @ 0xff617e80 的main方法中，有一个本地变量占用了96.43%的堆内存，实际内存占用的是char[]数组，因而被检测出来为OOM可疑的元凶。点击红色框中的“See stacktrace”，可以直接看到该对象所在线程的堆栈信息： 直接定位到了发生OOM的代码所在位置，至此该示例分析完成，MAT工具本身还有其它许多的功能，这里就不一一细说了。 下一篇会写服务器由于时间戳不一致，导致有些服务器可以访问，有些服务器却不能够访问的问题，如果感兴趣，请继续观注。 有没有使用过JVM自带的工具，如何使用的？%JAVA_HOME/bin%下就是安装java时为我们自带的可运行程序的文件夹。 jps命令jps(java process status)：用于查看java进程。 option description - 查看java进程 -l 显示全类名 -m 带参显示 -v JVM参数 jstat jstat -gcutil pid 其中的pid是你关注的java进程号，可根据jps查询。-gcutil是关心的指标，更多详尽信息请参看官方文档。 options description(后面也有详尽的字段说明) jstat -option pid peroid times(周期监控) jinfojinfo进行指定参数的查询。 jmapjmap用于内存管理。 jmap -histo pid（类数量 / 实例数量） jmap -dump:format=b,file=file导出运行信息以便于后续线下分析。 jhat（JVM Heap Analysis Tool） jhat a.bin分析导出数据 jstack options description - 打印方法栈 -F 强制打印 -m 本地方法栈 -l 打印锁信息 jstack pid jstack -l pid(锁信息，能看见线程状态) jconsole 假设有下图所示的一个Full GC 的图，纵向是内存使用情况，横向是时间，你如何排查这个Full GC 的问题，怎么去解决你说出来的这些问题？ Full GC的原因我们知道Full GC的触发条件大致情况有以下几种情况： 程序执行了System.gc() //建议jvm执行fullgc，并不一定会执行 执行了jmap -histo:live pid命令 //这个会立即触发fullgc 在执行minor gc的时候进行的一系列检查 12345执行Minor GC的时候，JVM会检查老年代中最大连续可用空间是否大于了当前新生代所有对象的总大小。如果大于，则直接执行Minor GC（这个时候执行是没有风险的）。如果小于了，JVM会检查是否开启了空间分配担保机制，如果没有开启则直接改为执行Full GC。如果开启了，则JVM会检查老年代中最大连续可用空间是否大于了历次晋升到老年代中的平均大小，如果小于则执行改为执行Full GC。如果大于则会执行Minor GC，如果Minor GC执行失败则会执行Full GC 使用了大对象 //大对象会直接进入老年代 在程序中长期持有了对象的引用 //对象年龄达到指定阈值也会进入老年代 对于我们的情况，可以初步排除1，2两种情况，最有可能是4和5这两种情况。为了进一步排查原因，我们在线上开启了 -XX:+HeapDumpBeforeFullGC。 123注意： JVM在执行dump操作的时候是会发生stop the word事件的，也就是说此时所有的用户线程都会暂停运行。 为了在此期间也能对外正常提供服务，建议采用分布式部署，并采用合适的负载均衡算法 JVM参数的设置：线上这个dubbo服务是分布式部署，在其中一台机子上开启了 -XX:HeapDumpBeforeFullGC，总体JVM参数如下：1234567891011-Xmx2g -XX:+HeapDumpBeforeFullGC -XX:HeapDumpPath=. -Xloggc:gc.log -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100m -XX:HeapDumpOnOutOfMemoryError Dump文件分析dump下来的文件大约1.8g，用jvisualvm查看，发现用char[]类型的数据占用了41%内存，同时另外一个com.alibaba.druid.stat.JdbcSqlStat类型的数据占用了35%的内存，也就是说整个堆中几乎全是这两类数据。如下图： 查看char[]类型数据，发现几乎全是sql语句。 接下来查看char[]的引用情况： 找到了JdbcSqlStat类，在代码中查看这个类的代码，关键代码如下：1234567891011121314151617181920212223242526//构造函数只有这一个public JdbcSqlStat(String sql)&#123; this.sql = sql; this.id = DruidDriver.createSqlStatId();&#125;//查看这个函数的调用情况，找到com.alibaba.druid.stat.JdbcDataSourceStat#createSqlStat方法：public JdbcSqlStat createSqlStat(String sql) &#123; lock.writeLock().lock(); try &#123; JdbcSqlStat sqlStat = sqlStatMap.get(sql); if (sqlStat == null) &#123; sqlStat = new JdbcSqlStat(sql); sqlStat.setDbType(this.dbType); sqlStat.setName(this.name); sqlStatMap.put(sql, sqlStat); &#125; return sqlStat; &#125; finally &#123; lock.writeLock().unlock(); &#125;&#125;//这里用了一个map来存放所有的sql语句。 其实到这里也就知道什么原因造成了这个问题，因为我们使用的数据源是阿里巴巴的druid，这个druid提供了一个sql语句监控功能，同时我们也开启了这个功能。只需要在配置文件中把这个功能关掉应该就能消除这个问题，事实也的确如此，关掉这个功能后到目前为止线上没再触发FullGC 其他 如果用mat工具查看，建议把 “Keep unreachable objects” 勾上，否则mat会把堆中不可达的对象去除掉，这样我们的分析也许会变得没有意义。如下图：Window–&gt;References 。另外jvisualvm对ool的支持不是很好，如果需要oql建议使用mat。 说说对Java中集合类的理解，项目中用过哪些，哪个地方用的，如何使用的？从数据结构开始了解 数据结构线性表 顺序存储结构(也叫顺序表)：一个线性表是n个具有相同特性的数据元素的有限序列。数据元素是一个抽象的符号，其具体含义在不同的情况下一般不同。 链表：链表里面节点的地址不是连续的，是通过指针连起来的。 哈希表解释一:哈希表hashtable(key，value) 就是把Key通过一个固定的算法函数既所谓的哈希函数转换成一个整型数字，然后就将该数字对数组长度进行取余，取余结果就当作数组的下标，将value存储在以该数字为下标的数组空间里。 解释二: 数组的特点是：寻址容易，插入和删除困难； 而链表的特点是：寻址困难，插入和删除容易。 那么我们能不能综合两者的特性，做出一种寻址容易，插入删除也容易的数据结构？答案是肯定的，这就是我们要提起的哈希表，哈希表有多种不同的实现方法，我接下来解释的是最常用的一种方法——拉链法，我们可以理解为“链表的数组”，如图： 左边很明显是个数组，数组的每个成员包括一个指针，指向一个链表的头，当然这个链表可能为空，也可能元素很多。我们根据元素的一些特征把元素分配到不同的链表中去，也是根据这些特征，找到正确的链表，再从链表中找出这个元素。 Hash 表的查询速度非常的快，几乎是O(1)的时间复杂度。 hash就是找到一种数据内容和数据存放地址之间的映射关系。 散列法：元素特征转变为数组下标的方法。 我想大家都在想一个很严重的问题：“如果两个字符串在哈希表中对应的位置相同怎么办？”,毕竟一个数组容量是有限的，这种可能性很大。解决该问题的方法很多，我首先想到的就是用“链表”。我遇到的很多算法都可以转化成链表来解决，只要在哈希表的每个入口挂一个链表，保存所有对应的字符串就OK了。 散列表的查找步骤 当存储记录时，通过散列函数计算出记录的散列地址 当查找记录时，我们通过同样的是散列函数计算记录的散列地址，并按此散列地址访问该记录 优缺点 优点：不论哈希表中有多少数据，查找、插入、删除（有时包括删除）只需要接近常量的时间即0(1）的时间级。实际上，这只需要几条机器指令。 哈希表运算得非常快，在计算机程序中，如果需要在一秒种内查找上千条记录通常使用哈希表（例如拼写检查器)哈希表的速度明显比树快，树的操作通常需要O(N)的时间级。哈希表不仅速度快，编程实现也相对容易。 如果不需要有序遍历数据，并且可以提前预测数据量的大小。那么哈希表在速度和易用性方面是无与伦比的。 缺点：它是基于数组的，数组创建后难于扩展，某些哈希表被基本填满时，性能下降得非常严重，所以程序员必须要清楚表中将要存储多少数据（或者准备好定期地把数据转移到更大的哈希表中，这是个费时的过程）。 哈希表的原理： 1，对对象元素中的关键字(对象中的特有数据)，进行哈希算法的运算，并得出一个具体的算法值，这个值 称为哈希值。 2，哈希值就是这个元素的位置。 3，如果哈希值出现冲突，再次判断这个关键字对应的对象是否相同。如果对象相同，就不存储，因为元素重复。如果对象不同，就存储，在原来对象的哈希值基础 +1顺延。 4，存储哈希值的结构，我们称为哈希表。 5，既然哈希表是根据哈希值存储的，为了提高效率，最好保证对象的关键字是唯一的。 这样可以尽量少的判断关键字对应的对象是否相同，提高了哈希表的操作效率。 扩展:相同的字符串如果存进去，哈希值相同并且equals方法为true，不会存入相同的 只要哈希值相同或者equals方法为true都成立才不会存入，只要其中一条不满足，都会储存 哈希表存储过程：1.调用对象的哈希值(通过一个函数f()得到哈希值):存储位置 = f(关键字) 2.集合在容器内搜索有没有重复的哈希值，如果没有，存入新元素，记录哈希值 3.再次存储，重复上边的过程 4.如果有重复的哈希值，调用后来者的equals方法，参数为前来者，结果得到true，集合判断为重复元素，不存入 哈希冲突然而万事无完美，如果两个不同的元素，通过哈希函数得出的实际存储地址相同怎么办？也就是说，当我们对某个元素进行哈希运算，得到一个存储地址，然后要进行插入的时候，发现已经被其他元素占用了，其实这就是所谓的哈希冲突，也叫哈希碰撞。前面我们提到过，哈希函数的设计至关重要，好的哈希函数会尽可能地保证 计算简单和散列地址分布均匀,但是，我们需要清楚的是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。那么哈希冲突如何解决呢？ 哈希冲突的解决方案有多种:开放定址法（发生冲突，继续寻找下一块未被占用的存储地址） 再散列函数法 链地址法，而HashMap即是采用了链地址法，也就是数组+链表的方式 关于hashcode和equals的一些问题，在面试中会问道： 1.两个对象哈希值相同，那么equals方法一定返回true吗？ 不一定:取决于如何重写equals，如果重写固定了它返回false，结果就一定是false 2.equals方法返回true，那么哈希值一定相同吗？ 一定:如果类中定义一个静态变量（static int a = 1），然后重写hashcode返回a+1，那么每一个对象的哈希值都不一样,不过java中规定：对象相等，必须具有相同的哈希码值，所以这里是一定的 数组采用一段连续的存储单元来存储数据。对于指定下标的查找，时间复杂度为O(1)；通过给定值进行查找，需要遍历数组，逐一比对给定关键字和数组元素，时间复杂度为O(n)，当然，对于有序数组，则可采用二分查找，插值查找，斐波那契查找等方式，可将查找复杂度提高为O(logn)；对于一般的插入删除操作，涉及到数组元素的移动，其平均复杂度也为O(n) 区别1.数组 优点：(1)随机访问效率高(根据下标查询)，(2)搜索效率较高(可使用折半方法)。 缺点：(1)内存连续且固定，存储效率低。(2)插入和删除效率低(可能会进行数组拷贝或扩容)。 2.链表 优点：(1)不要求连续内存，内存利用率高，(2)插入和删除效率高(只需要改变指针指向)。 缺点：(1)不支持随机访问，(2)搜索效率低(需要遍历)。 3.Hash表 优点：(1)搜索效率高，(2)插入和删除效率较高， 缺点：(1)内存利用率低(基于数组)，(2)存在散列冲突。 集合类种重要概念词解释泛型java中很重要的概念, 集合里面应用很多. 集合的元素，可以是任意类型对象的引用，如果把某个对象放入集合，则会忽略它的类型，就会把它当做Object类型处理. 泛型则是规定了某个集合只可以存放特定类型的对象的引用，会在编译期间进行类型检查,可以直接指定类型来获取集合元素 在泛型集合中有能够存入泛型类型的对象实例还可以存入泛型的子类型的对象实例 注意： 1 泛型集合中的限定类型，不能使用基本数据类型 2 可以通过使用包装类限定允许存放基本数据类型 泛型的好处 1 提高了安全性（将运行期的错误转换到编译期） 2 省去强转的麻烦 哈希值1 就是一个十进制的整数，有操作系统随机给出 2 可以使用Object类中的方法hashCode获取哈希值 3 Object中源码: int hashCode()返回该对象的哈希码值； 源码：12//native:指调用了本地操作系统的方法实现public native int hashCode(); 平衡二叉树(称AVL树)其特点是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。也就是说该二叉树的任何一个子节点，其左右子树的高度都相近。 注意: 关键点是左子树和右子树的深度的绝对值不超过1 那什么是左子树深度和右子树深度呢? 如上图中: 如果插入6元素, 则8的左子树深度就为2, 右子树深度就为0,绝对值就为2, 就不是一个平很二叉树 二叉排序树1若左子树不空，则左子树上所有结点的值均小于它的根结点的值； 2若右子树不空，则右子树上所有结点的值均大于它的根结点的值； 3左、右子树也分别为二叉排序树 解释一: 现在有a[10] = {3, 2, 1, 4, 5, 6, 7, 10, 9, 8}需要构建二叉排序树。在没有学习平衡二叉树之前，根据二叉排序树的特性，通常会将它构建成如下左图。虽然完全符合二叉排序树的定义，但是对这样高度达到8的二叉树来说，查找是非常不利的。因此，更加期望构建出如下右图的样子，高度为4的二叉排序树，这样才可以提供高效的查找效率。平衡二叉树是一种二叉排序树，是一种高度平衡的二叉树，其中每个结点的左子树和右子树的高度至多等于1.意味着：要么是一棵空树，要么左右都是平衡二叉树，且左子树和右子树深度之绝对值不超过1. 将二叉树上结点的左子树深度减去右子树深度的值称为平衡因子BF，那么平衡二叉树上的所有结点的平衡因子只可能是-1、0和1。只要二叉树上有一个结点的平衡因子的绝对值大于1，则该二叉树就是不平衡的。 平衡二叉树的前提是它是一棵二叉排序树。 旋转假设一颗 AVL 树的某个节点为 r，有四种操作会使 r 的左右子树高度差大于 1，从而破坏了原有 AVL 树的平衡性。使用旋转达到平衡性 1.对 r 的左儿子的左子树进行一次插入（左旋转 LL）2.对 r 的左儿子的右子树进行一次插入（LR）3.对 r 的右儿子的左子树进行一次插入（RL）4.对 r 的右儿子的右子树进行一次插入（RR） 红黑树红黑树（Red Black Tree） 是一种自平衡二叉查找树 (1) 检索效率O(log n) (2) 红黑树的五点规定： 1.每个结点要么是红的要么是黑的 2.根结点是黑的 3.每个叶结点（叶结点即指树尾端NIL指针或NULL结点）都是黑的 4.如果一个结点是红的，那么它的两个儿子都是黑的（反之不一定） 5.对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点 它的每个结点都额外有一个颜色的属性，颜色只有两种：红色和黑色。 示例:(这块难度比较大, 建议自行百度,查阅相关文档) 红黑树插入操作 如果是第一次插入,由于原树为空,所以只会违反红黑树的规则2,所以只要把根节点涂黑即可； 如果插入节点的父节点是黑色的，那不会违背红-黑树的规则，什么也不需要做； 但是遇到如下三种情况时，我们就要开始变色和旋转了： 1. 插入节点的父节点和其叔叔节点（祖父节点的另一个子节点）均为红色的； 2. 插入节点的父节点是红色，叔叔节点是黑色，且插入节点是其父节点的右子节点； 3. 插入节点的父节点是红色，叔叔节点是黑色，且插入节点是其父节点的左子节点。 下面我们先挨个分析这三种情况都需要如何操作: 对于情况1：插入节点的父节点和其叔叔节点（祖父节点的另一个子节点）均为红色的。此时，肯定存在祖父节点，但是不知道父节点是其左子节点还是右子节点，但是由于对称性，我们只要讨论出一边的情况，另一种情况自然也与之对应。 这里考虑父节点是祖父节点的左子节点的情况(即插入一个4节点,插入的节点一般为红色,不然可能违反规则5.),如下左图所示： 对于这种情况，我们要做的操作有：将当前节点(4)的父节点(5)和叔叔节点(8)涂黑，将祖父节点(7)涂红，变成上右图所示的情况。再将当前节点指向其祖父节点，再次从新的当前节点开始算法。这样上右图就变成了情况2了。 对于情况2：插入节点的父节点是红色，叔叔节点是黑色，且插入节点是其父节点的右子节点。我们要做的操作有：将当前节点(7)的父节点(2)作为新的节点，以新的当前节点为支点做左旋操作。完成后如左下图所示，这样左下图就变成情况3了。 对于情况3：插入节点的父节点是红色，叔叔节点是黑色，且插入节点是其父节点的左子节点。我们要做的操作有：将当前节点的父节点(7)涂黑，将祖父节点(11)涂红，在祖父节点为支点做右旋操作。最后把根节点涂黑，整个红-黑树重新恢复了平衡，如右上图所示。至此，插入操作完成！ 我们可以看出，如果是从情况1开始发生的，必然会走完情况2和3，也就是说这是一整个流程，当然咯，实际中可能不一定会从情况1发生，如果从情况2开始发生，那再走个情况3即可完成调整，如果直接只要调整情况3，那么前两种情况均不需要调整了。故变色和旋转之间的先后关系可以表示为：变色-&gt;左旋-&gt;右旋。 红黑树删除操作我们现在约定：后继节点的子节点称为“当前节点”. 删除节点有三种情况分析： a. 叶子节点；(直接删除即可)b. 仅有左或右子树的节点；（上移子树即可） c. 左右子树都有的节点。( 用删除节点的直接前驱或者直接后继来替换当前节点，调整直接前驱或者直接后继的位置)删除操作后，如果当前节点是黑色的根节点，那么不用任何操作，因为并没有破坏树的平衡性，即没有违背红-黑树的规则，这很好理解。如果当前节点是红色的，说明刚刚移走的后继节点是黑色的，那么不管后继节点的父节点是啥颜色，我们只要将当前节点涂黑就可以了，红-黑树的平衡性就可以恢复。但是如果遇到以下四种情况，我们就需要通过变色或旋转来恢复红-黑树的平衡了。 当前节点是黑色的，且兄弟节点是红色的（那么父节点和兄弟节点的子节点肯定是黑色的）； 当前节点是黑色的，且兄弟节点是黑色的，且兄弟节点的两个子节点均为黑色的； 当前节点是黑色的，且兄弟节点是黑色的，且兄弟节点的左子节点是红色，右子节点时黑色的； 当前节点是黑色的，且兄弟节点是黑色的，且兄弟节点的右子节点是红色，左子节点任意颜色。 以上四种情况中，我们可以看出2,3,4其实是“当前节点是黑色的，且兄弟节点是黑色的”的三种子集，等会在程序中可以体现出来。现在我们假设当前节点是左子节点（当然也可能是右子节点，跟左子节点相反即可，我们讨论一边就可以了），分别解决上面四种情况： 对于情况1：当前节点是黑色的，且兄弟节点是红色的（那么父节点和兄弟节点的子节点肯定是黑色的）。如左下图所示：A节点表示当前节点。针对这种情况，我们要做的操作有：将父节点（B）涂红，将兄弟节点（D）涂黑，然后将当前节点（A）的父节点（B）作为支点左旋，然后当前节点的兄弟节点就变成黑色的情况了（自然就转换成情况2，3,4的公有特征了），如右下图所示： 对于情况2：当前节点是黑色的，且兄弟节点是黑色的，且兄弟节点的两个子节点均为黑色的。如左下图所示，A表示当前节点。针对这种情况，我们要做的操作有：将兄弟节点（D）涂红，将当前节点指向其父节点（B），将其父节点指向当前节点的祖父节点，继续新的算法（具体见下面的程序），不需要旋转。这样变成了右下图所示的情况： 对于情况3：当前节点是黑色的，且兄弟节点是黑色的，且兄弟节点的左子节点是红色，右子节点时黑色的。如左下图所示，A是当前节点。针对这种情况，我们要做的操作有：把当前节点的兄弟节点（D）涂红，把兄弟节点的左子节点（C）涂黑，然后以兄弟节点作为支点做右旋操作。然后兄弟节点就变成黑色的，且兄弟节点的右子节点变成红色的情况（情况4）了。如右下图： 对于情况4：当前节点是黑色的，且兄弟节点是黑色的，且兄弟节点的右子节点是红色，左子节点任意颜色。如左下图所示：A为当前节点，针对这种情况，我们要做的操作有：把兄弟节点（D）涂成父节点的颜色，再把父节点（B）涂黑，把兄弟节点的右子节点（E）涂黑，然后以当前节点的父节点为支点做左旋操作。至此，删除修复算法就结束了，最后将根节点涂黑即可。 我们可以看出，如果是从情况1开始发生的，可能情况2，3，4中的一种：如果是情况2，就不可能再出现3和4；如果是情况3，必然会导致情况4的出现；如果2和3都不是，那必然是4。当然咯，实际中可能不一定会从情况1发生，这要看具体情况了。 迭代器迭代器模式把访问逻辑从不同类型的集合类中抽取出来，从而避免向外部暴露集合的内部结构。在java中它是一个对象，其目的是遍历并选中其中的每个元素，而使用者（客户端）无需知道里面的具体细节。 IteratorCollection集合元素的通用获取方式：在取出元素之前先判断集合中有没有元素。如果有，就把这个元素取出来，继续再判断，如果还有就再取出来，一直把集合中的所有元素全部取出来，这种取出元素的方式专业术语称为迭代。 java.util.Iterator:在Java中Iterator为一个接口，它只提供了迭代的基本规则。在JDK中它是这样定义的：对Collection进行迭代的迭代器。迭代器取代了Java Collection Framework中的Enumeration。 Collection中有一个抽象方法iterator方法，所有的Collection子类都实现了这个方法；返回一个Iterator对象 定义: 1234567891011package java.util;public interface Iterator&lt;E&gt; &#123; boolean hasNext();//判断是否存在下一个对象元素 E next();//获取下一个元素 void remove();//移除元素&#125; 在使用Iterator的时候禁止对所遍历的容器进行改变其大小结构的操作。例如: 在使用Iterator进行迭代时，如果对集合进行了add、remove操作就会出现ConcurrentModificationException异常。 在进行集合元素取出的时候，如果集合中没有元素了，还继续使用next()方法的话，将发生NoSuchElementException没有集合元素的错误 修改并发异常：在迭代集合中元素的过程中，集合的长度发生改变（进行了元素增加或者元素删除的操作), 增强for的底层原理也是迭代器，所以也需要避免这种操作； 解决以上异常的方法:使用ListIterator 任何集合都有迭代器。 任何集合类，都必须能以某种方式存取元素，否则这个集合容器就没有任何意义。 迭代器，也是一种模式（也叫迭代器模式）。迭代器要足够的“轻量”——创建迭代器的代价小。 Iterable(1.5)Java中还提供了一个Iterable接口，Iterable接口实现后的功能是‘返回’一个迭代器，我们常用的实现了该接口的子接口有:Collection&lt;E&gt;、List&lt;E&gt;、Set&lt;E&gt;等。该接口的iterator()方法返回一个标准的Iterator实现。实现Iterable接口允许对象成为Foreach语句的目标。就可以通过foreach语句来遍历你的底层序列。 Iterable接口包含一个能产生Iterator对象的方法，并且Iterable被foreach用来在序列中移动。因此如果创建了实现Iterable接口的类，都可以将它用于foreach中。 定义: 12345Package java.lang; import java.util.Iterator; public interface Iterable&lt;T&gt; &#123; Iterator&lt;T&gt; iterator(); &#125; Iterable是Java 1.5的新特性, 主要是为了支持forEach语法, 使用容器的时候, 如果不关心容器的类型, 那么就需要使用迭代器来编写代码. 使代码能够重用. 使用方法很简单: 1234List&lt;String&gt; strs = Arrays.asList("a", "b", "c"); for (String str: strs) &#123; out.println(str);&#125; 好处：代码减少，方便遍历 弊端：没有索引，不能操作容器里的元素 增强for循环底层也是使用了迭代器获取的，只不过获取迭代器由jvm完成，不需要我们获取迭代器而已，所以在使用增强for循环变量元素的过程中不准使用集合对象对集合的元素个数进行修改； forEach()(1.8)使用接收lambda表达式的forEach方法进行快速遍历. 123List&lt;String&gt; strs = Arrays.asList("a", "b", "c"); // 使用Java 1.8的lambda表达式 strs.forEach(out::println); Spliterator迭代器Spliterator是1.8新增的迭代器,属于并行迭代器,可以将迭代任务分割交由多个线程来进行。 Spliterator可以理解为Iterator的Split版本（但用途要丰富很多）。使用Iterator的时候，我们可以顺序地遍历容器中的元素，使用Spliterator的时候，我们可以将元素分割成多份，分别交于不于的线程去遍历，以提高效率。使用 Spliterator 每次可以处理某个元素集合中的一个元素 — 不是从 Spliterator 中获取元素，而是使用 tryAdvance() 或 forEachRemaining() 方法对元素应用操作。但Spliterator 还可以用于估计其中保存的元素数量，而且还可以像细胞分裂一样变为一分为二。这些新增加的能力让流并行处理代码可以很方便地将工作分布到多个可用线程上完成 ListIteratorListIterator是一个更强大的Iterator子类型，能用于各种List类访问，前面说过Iterator支持单向取数据，ListIterator可以双向移动，所以能指出迭代器当前位置的前一个和后一个索引，可以用set方法替换它访问过的最后一个元素。我们可以通过调用listIterator方法产生一个指向List开始处的ListIterator，并且还可以用过重载方法listIterator(n)来创建一个指定列表索引为n的元素的ListIterator。 ListIterator可以往前遍历，添加元素，设置元素 Iterator和ListIterator的区别： 两者都有next()和hasNext()，可以实现向后遍历，但是ListIterator有previous()和hasPrevious()方法，即可以实现向前遍历 ListIterator可以定位当前位置，nextIndex()和previous()可以实现 ListIterator有add()方法，可以向list集合中添加数据 都可以实现删除操作，但是ListIterator可以实现对对象的修改，set()可以实现，Iterator仅能遍历，不能修改 Fail-Fast类中的iterator()方法和listIterator()方法返回的iterators迭代器是fail-fast的：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常，产生fail-fast事件。 迭代器与枚举有两点不同: 1. 迭代器在迭代期间可以从集合中移除元素。 2. 方法名得到了改进，Enumeration的方法名称都比较长。 迭代器的好处：屏蔽了集合之间的不同，可以使用相同的方式取出 集合类概念集合类的作用集合类也叫做容器类，和数组一样，用于存储数据，但数组类型单一，并且长度固定，限制性很大，而集合类可以动态增加长度。 集合存储的元素都是对象(引用地址)，所以集合可以存储不同的数据类型，但如果是需要比较元素来排序的集合，则需要类型一致。 集合中提供了统一的增删改查方法，使用方便。 支持泛型，避免数据不一致和转换异常，还对常用的数据结构进行了封装。 所有的集合类的都在java.util包下。 集合框架体系的组成集合框架体系是由Collection、Map(映射关系)和Iterator(迭代器)组成，各部分的作用如下所示。 Collection体系中有三种集合：Set、List、Queue Set(集)： 元素是无序的且不可重复。 List(列表)：元素是有序的且可重复。 Queue(队列)：封装了数据结构中的队列。 Map体系 Map用于保存具有映射关系的数据，即key-value(键值对)。Map集合的key是唯一的，不可重复，而value可以重复。所以一个value可以对应多个key。 Map体系除了常用类之外，还有Properties（属性类）也属于Map体系。 Iterator(迭代器)请查看上面! Collection的由来 由于数组中存放对象，对对象操作起来不方便。java中有一类容器，专门用来存储对象。 集合可以存储多个元素,但我们对多个元素也有不同的需求 多个元素,不能有相同的 多个元素,能够按照某个规则排序 针对不同的需求：java就提供了很多集合类，多个集合类的数据结构不同。但是，结构不重要，重要 的是能够存储东西,能够判断,获取. 把集合共性的内容不断往上提取,最终形成集合的继承体系—-&gt;Collection 并且所有的Collection实现类都重写了toString()方法. 集合和数组集合与数组的区别： 数组的长度固定的，而集合长度时可变的数组只能储存同一类型的元素，而且能存基本数据类型和引用数据类型。集合可以存储不同类型的元素，只能存储引用数据类型 集合类和数组不一样,数组元素既可以是基本类型的值,也可以是对象(实际上保存的是对象的引用变量);而集合只能保存对象。 数组和集合的主要区别包括以下几个方面： 数组声明了它容纳的元素的类型，而集合不声明。这是由于集合以object形式来存储它们的元素。 一个数组实例具有固定的大小，不能伸缩。集合则可根据需要动态改变大小。 数组是一种可读/可写数据结构没有办法创建一个只读数组。然而可以使用集合提供的ReadOnly方 只读方式来使用集合。该方法将返回一个集合的只读版本。 集合的作用： 如果一个类的内部有很多相同类型的属性，并且他们的作用与意义是一样的，比如说学生能选课学生类就有很多课程类型的属性，或者工厂类有很多机器类型的属性，我们用一个类似于容器的集合去盛装他们，这样在类的内部就变的井然有序———这就是： 在类的内部，对数据进行组织的作用。 简单而快速的搜索查找其中的某一条元素 有的集合接口，提供了一系列排列有序的元素，并且可以在序列中间快速的插入或者删除有关元素。 有的集合接口在其内部提供了映射关系的结构，可以通过关键字(key)去快速查找对应的唯一对象，而这个关键可以是任意类型的。 泛型与集合的区别泛型听起来很高深的一个词，但实际上它的作用很简单，就是提高java程序的性能。 比如在计算机中经常用到一些数据结构，如队列，链表等，而其中的元素以前一般这么定义：object a=new object(); 这样就带来一个严重的问题，用object来表示元素没有逻辑问题，但每次拆箱、封箱就占用了大量的计算机资源，导致程序性能低下，而这部分内容恰恰一般都是程序的核心部分，如果使用object，那么程序的表现就比较糟糕。 而使用泛型则很好的解决这个问题，本质就是在编译阶段就告诉编译器，数据结构中元素的种类，既然编译器知道了元素的种类，自然就避免了拆箱、封箱的操作，从而显著提高java程序的性能。 比如List&lt;string&gt;就直接使用string对象作为List的元素，而避免使用object对象带来的封箱、拆箱操作，从而提高程序性能。 集合接口与类数组和集合一般就用到下面接口和集合Array 数组 Arrays 数组工具 Collection 最基本的集合接口 Collections 集合工具类 List 接口 ArrayList 一种可以动态增长和缩减的索引序列 LinkedList 一种可以在任何位置进行高效地插入和删除操作的有序序列 Vector Set HashSet 一种没有重复元素的无序集合 TreeSet 一种有序集 LinkHashSet 一种可以记住元素插入次序的集合 map HashMap 一种存储key：value关联的映射 HashTable TreeMap 一种key有序的映射 LinkedHashMap 一种可以记住插入次序的映射 Deque Stack ArrayDeque 一种用循环数组实现的双端队列 Queue PriorityQueue 一种可以高效删除最小元素的集合 Array数组：是以一段连续内存保存数据的；随机访问是最快的,但不支持插入,删除,迭代等操作。 Array可以包含基本类型和对象类型 Array大小是固定的 指定数组引用为 null，则此类中的方法都会抛出 NullPointerException。 所创建的对象都放在堆中。 够对自身进行枚举(因为都实现了IEnumerable接口)。 具有索引(index),即可以通过index来直接获取和修改任意项。 Array类型的变量在声明的同时必须进行实例化(至少得初始化数组的大小)，而ArrayList可以只是先声明。 Array只能存储同构的对象，而ArrayList可以存储异构的对象。 在CLR托管对中的存放方式 Array是始终是连续存放的，而ArrayList的存放不一定连续。 Array不能够随意添加和删除其中的项，而ArrayList可以在任意位置插入和删除项。 采用数组存在的一些缺陷： 1.数组长度固定不变，不能很好地适应元素数量动态变化的情况。 2.可通过数组名.length获取数组的长度，却无法直接获取数组中真实存储的个数。 3.在进行频繁插入、删除操作时同样效率低下。 Arrays数组的工具类,里面都是操作数组的工具. 常用方法: 1、数组的排序:Arrays.sort(a);//实现了对数组从小到大的排序//注：此类中只有升序排序，而无降序排序。 2、数组元素的定位查找:Arrays.binarySearch(a,8);//二分查找法 3、数组的打印:Arrays.toString(a);//String 前的a和括号中的a均表示数组名称 4、 查看数组中是否有特定的值:Arrays.asList(a).contains(1); CollectionCollection是最基本的集合接口，一个Collection代表一组Object，即Collection的元素（Elements）。一些 Collection允许相同的元素而另一些不行。一些能排序而另一些不行。Java SDK不提供直接继承自Collection的类， Java SDK提供的类都是继承自Collection的“子接口”如List和Set。 所有实现Collection接口的类都必须提供两个标准的构造函数：无参数的构造函数用于创建一个空的Collection，有一个Collection参数的构造函数用于创建一个新的 Collection，这个新的Collection与传入的Collection有相同的元素。后一个构造函数允许用户复制一个Collection。 如何遍历Collection中的每一个元素？不论Collection的实际类型如何，它都支持一个iterator()的方法，该方法返回一个迭代子，使用该迭代子即可逐一访问Collection中每一个元素。典型的用法如下： 12345Iterator it = collection.iterator(); // 获得一个迭代子while(it.hasNext()) &#123; Object obj = it.next(); // 得到下一个元素&#125; 由Collection接口派生的两个接口是List和Set。 Collection返回的是Iterator迭代器接口，而List中又有它自己对应的实现–&gt;ListIterator接口 Collection。标识所含元素的序列，这里面又包含多种集合类，比如List，Set，Queue；它们都有各自的特点，比如List是按顺序插入元素，Set是不重复元素集合，Queue则是典型的FIFO结构 Collection接口描述： Collection接口常用的子接口有List 接口和Set接口 List接口中常用的子类有：ArrayList类（数组列表）和LinkedList（链表） Set接口中常用的子类有：HashSet （哈希表）和LinkedHashSet（基于链表的哈希表） Collection 层次结构 中的根接口。Collection 表示一组对象，这些对象也称为 collection 的元素。一些 collection 允许有重复的元素，而另一些则不允许。一些 collection 是有序的，而另一些则是无序的。JDK 不提供此接口的任何直接 实现：它提供更具体的子接口（如 Set和 List）实现。此接口通常用来传递 collection，并在需要最大普遍性的地方操作这些 collection。（面向接口的编程思想） Collections排序操作Collections提供以下方法对List进行排序操作 void reverse(List list)：反转 void shuffle(List list),随机排序 void sort(List list),按自然排序的升序排序 void sort(List list, Comparator c);定制排序，由Comparator控制排序逻辑 void swap(List list, int i , int j),交换两个索引位置的元素 void rotate(List list, int distance),旋转。当distance为正数时，将list后distance个元素整体移到前面。当distance为负数时，将 list的前distance个元素整体移到后面。 查找，替换操作int binarySearch(List list, Object key), 对List进行二分查找，返回索引，注意List必须是有序的 int max(Collection coll),根据元素的自然顺序，返回最大的元素。 类比int min(Collection coll) int max(Collection coll, Comparator c)，根据定制排序，返回最大元素，排序规则由Comparatator类控制。类比int min(Collection coll, Comparator c) void fill(List list, Object obj),用元素obj填充list中所有元素 int frequency(Collection c, Object o)，统计元素出现次数 int indexOfSubList(List list, List target), 统计targe在list中第一次出现的索引，找不到则返回-1，类比int lastIndexOfSubList(List source, list target). boolean replaceAll(List list, Object oldVal, Object newVal), 用新元素替换旧元素。 同步控制Collections中几乎对每个集合都定义了同步控制方法, 这些方法，来将集合包装成线程安全的集合 SynchronizedList(List); SynchronizedSet(Set; SynchronizedMap(Map); SynchronizedMap和ConcurrentHashMap 区别 Collections.synchronizedMap()和Hashtable一样，实现上在调用map所有方法时，都对整个map进行同步，而ConcurrentHashMap的实现却更加精细，它对map中的所有桶加了锁。所以，只要要有一个线程访问map，其他线程就无法进入map，而如果一个线程在访问ConcurrentHashMap某个桶时，其他线程，仍然可以对map执行某些操作。这样，ConcurrentHashMap在性能以及安全性方面，明显比Collections.synchronizedMap()更加有优势。同时，同步操作精确控制到桶，所以，即使在遍历map时，其他线程试图对map进行数据修改，也不会抛出ConcurrentModificationException。 ConcurrentHashMap从类的命名就能看出，它必然是个HashMap。而Collections.synchronizedMap()可以接收任意Map实例，实现Map的同步 线程安全，并且锁分离。ConcurrentHashMap内部使用段(Segment)来表示这些不同的部分，每个段其实就是一个小的hashtable，它们有自己的锁。只要多个修改操作发生在不同的段上，它们就可以并发进行。 ListList：有序(元素存入集合的顺序和取出的顺序一致)，元素都有索引。元素可以重复。 List本身是Collection接口的子接口，具备了Collection的所有方法。 List的特有方法都有索引，这是该集合最大的特点。 List集合支持对元素的增、删、改、查。 List中存储的元素实现类排序，而且可以重复的存储相关元素。 次序是List最重要的特点：它保证维护元素特定的顺序。 List是有序的Collection，使用此接口能够精确的控制每个元素插入的位置。用户能够使用索引（元素在List中的位置，类似于数组下标）来访问List中的元素，这类似于Java的数组。 和下面要提到的Set不同，List允许有相同的元素。 除了具有Collection接口必备的iterator()方法外，List还提供一个listIterator()方法，返回一个 ListIterator接口，和标准的Iterator接口相比，ListIterator多了一些add()之类的方法，允许添加，删除，设定元素，还能向前或向后遍历。 优点：操作读取操作效率高，基于数组实现的，可以为null值，可以允许重复元素，有序，异步。 缺点：由于它是由动态数组实现的，不适合频繁的对元素的插入和删除操作，因为每次插入和删除都需要移动数组中的元素。 ArrayListArrayList 是基于数组实现，内存中分配连续的空间，需要维护容量大小。随机访问. ArrayList就是动态数组，也是一个对象。 ArrayList不自定义位置添加元素和LinkedList性能没啥区别，ArrayList默认元素追加到数组后面，而LinkedList只需要移动指针，所以两者性能相差无几。 如果ArrayList自定义位置插入元素，越靠前，需要重写排序的元素越多，性能消耗越大，LinkedList无论插入任何位置都一样，只需要创建一个新的表项节点和移动一下指针，性能消耗很低。 ArrayList是基于数组，所以查看任意位置元素只需要获取当前位置的下标的数组就可以，效率很高，然而LinkedList获取元素需要从最前面或者最后面遍历到当前位置元素获取，如果集合中元素很多，就会效率很低，性能消耗大。 频繁遍历查看元素,使用 ArrayList 集合,ArrayList 查询快，增删慢 ArrayList线程不安全的 1、ArrayList是用数组实现的，该对象存放在堆内存中，这个数组的内存是连续的，不存在相邻元素之间还隔着其他内存。底层是一个可动态扩容的数组 2、索引ArrayList时，速度比原生数组慢是因为你要用get方法，这是一个函数调用，而数组直接用[ ]访问，相当于直接操作内存地址，速度当然比函数调用快。 3、新建ArrayList的时候，JVM为其分配一个默认或指定大小的连续内存区域（封装为数组）。 4、每次增加元素会检查容量，不足则创建新的连续内存区域（大小等于初始大小+步长），也用数组形式封装，并将原来的内存区域数据复制到新的内存区域，然后再用ArrayList中引用原来封装的数组对象的引用变量引用到新的数组对象： 1elementData = Arrays.copyOf(elementData, newCapacity); ArrayList里面的removeIf方法就接受一个Predicate参数，采用如下Lambda表达式就能把，所有null元素删除: 1list.removeIf(e -&gt; e == null)； ArrayList：每次添加元素之前会检查是否需要扩容,是按照原数组的1.5倍延长。构造一个初始容量为 10 的空列表。 使用for适合循环ArrayLIst以及数组，当大批量的循环LinkedList时程序将会卡死，for适合循环数组结构，通过下标去遍历。 get访问List内部任意元素时，ArrayList的性能要比LinkedList性能好。LinkedList中的get方法是要按照顺序从列表的一端开始检查，直到另一端。 在ArrayList的 中间插入或删除一个元素意味着这个列表中剩余的元素都会被移动； ArrayList的空 间浪费主要体现在在list列表的结尾预留一定的容量空间 ArrayList只能包含对象类型。 ArrayList的大小是动态变化的。 对于基本类型数据，集合使用自动装箱来减少编码工作量 够对自身进行枚举(因为实现了IEnumerable接口)。 具有索引(index),即可以通过index来直接获取和修改任意项。 ArrayList允许存放（不止一个）null元素 允许存放重复数据，存储时按照元素的添加顺序存储 ArrayList可以存放任何不同类型的数据（因为它里面存放的都是被装箱了的Object型对象，实际上ArrayList内部就是使用”object[] _items;”这样一个私有字段来封装对象的） ArrayList不是一个线程安全的集合，如果集合的增删操作需要保证线程的安全性，可以考虑使用CopyOWriteArrayList或者使用collections.synchronizedList(Lise l)函数返回一个线程安全的ArrayList类。 实现了RandomAccess接口，底层又是数组，get读取元素性能很好 顺序添加很方便 删除和插入需要复制数组 性能很差（可以使用LinkindList） 为什么ArrayList的elementData是用transient修饰的？ transient修饰的属性意味着不会被序列化，也就是说在序列化ArrayList的时候，不序列化elementData。 为什么要这么做呢？ elementData不总是满的，每次都序列化，会浪费时间和空间 重写了writeObject 保证序列化的时候虽然不序列化全部 但是有的元素都序列化 所以说不是不序列化 而是不全部序列化。 elementData属性采用了transient来修饰，不使用Java默认的序列化机制来实例化，自己实现了序列化writeObject()和反序列化readObject()的方法。 每次对下标的操作都会进行安全性检查，如果出现数组越界就立即抛出异常。 如果提前知道数组元素较多，可以在添加元素前通过调用ensureCapacity()方法提前增加容量以减小后期容量自动增长的开销。 当需要插入大量元素时，在插入前可以调用ensureCapacity方法来增加ArrayList的容量以提高插入效率。 ArrayList基于数组方式实现，容量限制不大于Integer.MAX_VALUE的小大，每次扩容1.5倍。有序，可以为null,允许重复，非线程安全。 增加和删除会修改modCount,在迭代的时候需要保持单线程的唯一操作，如果期间进行了插入或者删除操作，就会被迭代器检查获知，从而出现运行时异常。 一般建议在单线程中使用ArrayList。 当在index处放置一个元素的时候，会将数组index处右边的元素全部右移 当在index处删除一个元素的时候，会将数组index处右边的元素全部左移 ArrayList底层是数组结构，因为数组有维护索引，所以查询效率高；而做插入、删除操作时，因为要判断扩容（复制一份新数组）且数组中的元素可能要大规模的后移或前移一个索引位置，所以效率差。 Arrays.asList()方法返回的List集合是一个固定长度的List集合，不是ArrayList实例，也不是Vector的实例 ArrayList也采用了快速失败(Fail-Fast机制)的机制，通过记录modCount参数来实现。在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险。具体介绍请参考HashMap的实现原理中的Fail-Fast机制。 linkedListLinkedList 是基于循环双向链表数据结构，不需要维护容量大小。顺序访问。 频繁插入删除元素 使用 LinkedList 集合 LinkedList 线程不安全的 LinkedList在随机访问方面相对比较慢，但是它的特性集较ArrayList 更大。 LinkedList提供了大量的首尾操作 LinkedList：底层的数据结构是链表，线程不同步，增删元素的速度非常快。 LinkedList：底层基于链表实现，链表内存是散乱的，每一个元素存储本身内存地址的同时还存储下一个元素的地址。链表增删快，查找慢 LinkedList由双链表实现，增删由于不需要移动底层数组数据，其底层是链表实现的，只需要修改链表节点指针，对元素的插入和删除效率较高。 LinkedList缺点是遍历效率较低。HashMap和双链表也有关系。 LinkedList是一个继承于AbstractSequentialList的双向链表，它可以被当做堆栈、队列或双端队列进行操作 LinkedList可被用作堆栈（stack），队列（queue）或双向队列（deque）。 使用foreach适合循环LinkedList，使用双链表结构实现的应当使用foreach循环。 LinkedList实现了List接口，允许null元素。 LinkedList没有同步方法。如果多个线程同时访问一个List，则必须自己实现访问同步。一种解决方法是在创建List时构造一个同步的List： 1List list = Collections.synchronizedList(new LinkedList(…)); 在LinkedList的中间插入或删除一个元素的开销是固定的。 LinkedList不支持高效的随机元素访问。 LinkedList的空间花费则体现在它的每一个元素都需要消耗相当的空间 LinkedList是List和Deque接口的双向链表的实现。实现了所有可选列表操作，并允许包括null值。 Fail-Fast机制:LinkedList也采用了快速失败的机制，通过记录modCount参数来实现。在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险。 LinkedList因为底层为链表结构，查询时需要从头节点（或尾节点）开始遍历所以查询效率差；但同时也因为是链表结构，做插入、删除操作时只要断开当前删除节点前驱、后驱引用，并将原来的前、后节点的引用链接起来，所以效率高。 千万不要使用普通for循环遍历LinkedList，这么做会让你崩溃！可以选择使用foreach或迭代器来进行遍历操作 LinedList适合用迭代遍历； 基于链表结构的集合 LinkedList。LinkedList 属于 java.util 包下面，也实现Iterable接口，说明可以使用迭代器遍历；LinkedList 还实现 Deque&lt;E&gt;，Queue&lt;E&gt;操作。Deque 和 Queue 是 LinkedList 的父接口，那么 LinkedList 也可以看成一种 Deque 或者 Queue；Queue表示一种队列，也是一种数据结构，它的特点是先进先出，因此在队列这个接口里面提供了一些操作队列的方法，同时LinkedList也具有这些方法；Deque(Double ended queues双端队列)，支持在两端插入或者移除元素; 那也应该具有操作双端队列的一些方法；LinkedList 是他们的子类，说明都具有他们两者的方法；LinkedList也可以充当队列，双端队列，堆栈多个角色。 vectorVector：底层的数据结构就是数组，线程同步的，Vector无论查询和增删都巨慢。 Vector：是按照原数组的2倍延长。 Vector是基于线程安全的，效率低 元素有放入顺序，元素可重复 Vector可以由我们自己来设置增长的大小，ArrayList没有提供相关的方法。 Vector相对ArrayList查询慢(线程安全的) Vector相对LinkedList增删慢(数组结构) 以前还能见到Vector和Stack，但Vector太过古老，被ArrayList取代，所以这里不讲；而Stack已经被ArrayDeque取代。 对于想在迭代器迭代过程中针对集合进行增删改的，可以通过返回ListIterator来操作。 Vector：底层结构是数组，线程是安全的，添加删除慢，查找快，（同ArrayList） ArrayList 和Vector是采用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，都允许直接序号索引元素，但是插入数据要涉及到数组元素移动等内存操作，所以索引数据快，插入数据慢，Vector由于使用了synchronized方法（线程安全）所以性能上比ArrayList要差，LinkedList使用双向链表实现存储，按序号索引数据需要进行向前或向后遍历，但是插入数据时只需要记录本项的前后项即可，所以插入数度较快。 Vector 是矢量队列，它是JDK1.0版本添加的类。继承于AbstractList，实现了List, RandomAccess, Cloneable这些接口。 Vector 实现了RandmoAccess接口，即提供了随机访问功能。RandmoAccess是java中用来被List实现，为List提供快速访问功能的。在Vector中，我们即可以通过元素的序号快速获取元素对象；这就是快速随机访问。 Vector 实现了Cloneable接口，即实现clone()函数。它能被克隆。 由Vector创建的Iterator，当一个Iterator被创建而且正在被使用，另一个线程改变了Vector的状态（例如，添加或删除了一些元素），这时调用Iterator的方法时将抛出ConcurrentModificationException，因此必须捕获该异常。 Set无序(存入和取出顺序有可能不一致)，不可以存储重复元素。必须保证元素唯一性。 元素无放入顺序，元素不可重复（注意：元素虽然无放入顺序，但是元素在set中的位置是有该元素的HashCode决定的，其位置其实是固定的） Set具有与Collection完全一样的接口，因此没有任何额外的功能,只是行为不同。这是继承与多态思想的典型应用：表现不同的行为。 Set不保存重复的元素(至于如何判断元素相同则较为负责) 存入Set的每个元素都必须是唯一的，因为Set不保存重复元素,加入Set的元素必须定义equals()方法以确保对象的唯一性。 Set 是基于对象的值来确定归属性的。 Set本身有去重功能是因为String内部重写了hashCode()和equals()方法，在add里实现了去重, Set集合是不允许重复元素的，但是集合是不知道我们对象的重复的判断依据的，默认情况下判断依据是判断两者是否为同一元素（euqals方法，依据是元素==元素），如果要依据我们自己的判断来判断元素是否重复，需要重写元素的equals方法（元素比较相等时调用）hashCode()的返回值是元素的哈希码，如果两个元素的哈希码相同，那么需要进行equals判断。【所以可以自定义返回值作为哈希码】 equals()返回true代表两元素相同，返回false代表不同。 set集合没有索引，只能用迭代器或增强for循环遍历 set的底层是map集合 Set最多有一个null元素 必须小心操作可变对象（Mutable Object）。如果一个Set中的可变元素改变了自身状态导致Object.equals(Object)=true将导致一些问题。 Set具有与Collection完全一样的接口，没有额外的任何功能。所以把Set就是Collection，只是行为不同（这就是多态）；Set是基于对象的值来判断归属的，由于查询速度非常快速，HashSet使用了散列，HashSet维护的顺序与TreeSet或LinkedHashSet都不同，因为它们的数据结构都不同，元素存储方式自然也不同。TreeSet的数据结构是“红-黑树”，HashSet是散列函数，LinkedHashSet也用了散列函数；如果想要对结果进行排序，那么选择TreeSet代替HashSet是个不错的选择 HashsetHashSet : 为快速查找设计的Set。存入HashSet的对象必须定义hashCode()。 Hashset实现set接口，由哈希表（实际上是一个HashMap实例）支持。它不保证set的迭代顺序,别是它不保证该顺序恒久不变。此类允许使用Null元素 对于HashSet而言，它是基于HashMap实现的，HashSet底层使用HashMap来保存所有元素，因此HashSet的实现比较简单，相关HashSet的操作，基本上都说调用HashMap的相关方法来实现的 对于HashSet中保存的对象，请注意正确重写其equals和hashCode方法，以保证放入的对象的唯一性。 HashSet: 哈希表结构的集合 利用哈希表结果构成的集合查找速度会很快。 HashSet ： 底层数据结构是哈希表，线程 是不同步的 。 无序，高效；HashSet 集合保证元素唯一性 ：通过元素的 hashCode 方法，和 equals 方法完成的。当元素的 hashCode 值相同时，才继续判断元素的 equals 是否为 true。如果为 true，那么视为相同元素，不存。如果为 false，那么存储。如果 hashCode 值不同，那么不判断 equals，从而提高对象比较的速度。 HashSet类直接实现了Set接口， 其底层其实是包装了一个HashMap去实现的。HashSet采用HashCode算法来存取集合中的元素，因此具有比较好的读取和查找性能。 元素值可以为NULL,但只能放入一个null HashSet集合保证元素唯一性：通过元素的hashCode方法，和equals方法完成的。 当元素的hashCode值相同时，才继续判断元素的equals是否为true。 如果hashCode值不同，那么不判断equals，从而提高对象比较的速度。 对于HashSet集合，判断元素是否存在，或者删除元素，底层依据的是hashCode方法和equals方法。 特点：存储取出都比较快 1、不能保证元素的排列顺序，顺序可能与添加顺序不同，顺序也有可能发生变化。 2、HashSet不是同步的，必须通过代码来保证其同步。 3、集合元素可以是null. 原理：简单说就是链表数组结合体 对象的哈希值：普通的一个整数,可以理解为身份证号，是hashset存储的依据 HashSet按Hash算法来存储集合中的元素。在存取和查找上有很好的性能。 当向HashSet集合中存入一个元素时，HashSet会调用该对象的hashCode()方法来得到该对象的hashCode值，然后根据该hashCode值决定该hashCode值决定该对象在HashSet中存储的位置。 如果有两个元素通过equals()方法比较返回true,但它们的hashCode()方法返回值不相等,hashSet将会把它们存储在不同位置，依然可以添加成功。如果两个对象的hashCode()方法返回的hashCode值相同，当它们的equals()方法返回false时，会在hashCode所在位置采用链式结构保存多个对象。这样会降低hashSet的查询性能。 在使用HashSet中重写hashCode()方法的基本原则 1、在程序运行过过程中，同一个对象多次调用hashCode()方法应该返回相同的值。 2、当两个对象的equals()方法比较返回true时，这个两个对象的hashCode()方法返回相同的值。 3、对象中用作equals()方法比较标准的实例变量，都应该用于计算hashCode值。 把对象内的每个意义的实例变量(即每个参与equals()方法比较标准的实例变量)计算出一个int类型的hashCode值。用第1步计算出来的多个hashCode值组合计算出一个hashCode值返回 1return f1.hashCode()+(int)f2; 为了避免直接相加产生的偶然相等(两个对象的f1、f2实例变量并不相等，但他们的hashCode的和恰好相等)，可以通过为各个实例变量的hashCode值乘以一个质数后再相加 1return f1.hashCode()*19+f2.hashCode()*37; 如果向HashSet中添加一个可变的对象后，后面的程序修改了该可变对想的实例变量，则可能导致它与集合中的其他元素的相同（即两个对象的equals()方法比较返回true,两个对象的hashCode值也相等），这就有可能导致HashSet中包含两个相同的对象。 LinkedhashsetLinkedHashSet : 具有HashSet的查询速度，且内部使用链表维护元素的顺序(插入的次序)。于是在使用迭代器遍历Set时，结果会按元素插入的次序 LinkedHashSet 综合了链表+哈希表，根据元素的hashCode值来决定元素的存储位置，它同时使用链表维护元素的次序。 当遍历该集合时候，LinkedHashSet 将会以元素的添加顺序访问集合的元素。 对于 LinkedHashSet 而言，它继承与 HashSet、又基于 LinkedHashMap 来实现的。 这个相对于HashSet来说有一个很大的不一样是LinkedHashSet是有序的。LinkedHashSet在迭代访问Set中的全部元素时，性能比HashSet好，但是插入时性能稍微逊色于HashSet。 与HashSet相比，特点： 对集合迭代时，按增加顺序返回元素。 性能略低于HashSet，因为需要维护元素的插入顺序。但迭代访问元素时会有好性能，因为它采用链表维护内部顺序。 LinkedHashSet不允许元素的重复 存储的顺序是元素插入的顺序。 TreeSetTreeSet : 保存次序的Set, 底层为树结构。使用它可以从Set中提取有序的序列。 TreeSet 继承AbstractSet类，实现NavigableSet、Cloneable、Serializable接口。与HashSet是基于HashMap实现一样，TreeSet 同样是基于TreeMap 实现的。由于得到Tree 的支持，TreeSet 最大特点在于排序，它的作用是提供有序的Set集合。 用于对 Set 集合进行元素的指定顺序排序，排序需要依据元素自身具备的比较性。 如果元素不具备比较性，在运行时会抛出ClassCastException 异常。 所以元素需要实现Comparable 接口 ，让元素具备可比较性， 重写 compareTo 方法 。依据 compareTo 方法的返回值，确定元素在 TreeSet 数据结构中的位置。 或者用比较器方式，将Comparator对象传递给TreeSet构造器来告诉树集使用不同的比较方法 TreeSet底层的数据结构就是二叉树。 不能写入空数据 写入的数据是有序的。 不写入重复数据 TreeSet方法保证元素唯一性的方式：就是参考比较方法的结果是否为0，如果return 0，视为两个对象重复，不存。 TreeSet集合排序有两种方式，Comparable和Comparator区别： 1：让元素自身具备比较性，需要元素对象实现Comparable接口，覆盖compareTo方法。 2：让集合自身具备比较性，需要定义一个实现了Comparator接口的比较器，并覆盖compare方法，并将该类对象作为实际参数传递给TreeSet集合的构造函数。 TreeSet类是SortedSet接口的实现类。因为需要排序，所以性能肯定差于HashSet。与HashSet相比，额外增加的方法有： first()：返回第一个元素 last()：返回最后一个元素 lower(Object o)：返回指定元素之前的元素 higher(Obect o)：返回指定元素之后的元素 subSet(fromElement, toElement)：返回子集合 可以定义比较器（Comparator）来实现自定义的排序。默认自然升序排序。 TreeSet两种排序方式：自然排序和定制排序，默认情况下，TreeSet采用自然排序 TreeSet会调用集合元素的compareTo(Object object)方法来比较元素之间的大小关系，然后将元素按升序排列 如果试图把一个元素添加到TreeSet中，则该对象必须实现Comparable接口实现Comparable接口必须实现compareTo(Object object)，两个对象即通过这个方法进行比较Comparable的典型实现 BigDecimal、BigInteger以及所有的数值类型对应的包装类型，按对应的数值大小进行比较 Character：按字符的Unicode值进行比较 Boolean：true对应的包装类实例大于false包装类对应的实例 String：按字符对应的Unicode值进行比较 Date、Time：后面的时间、日期比前面的时间、日期大 向TreeSet中添加一个元素，只有第一个不需要使用compareTo()方法，后面的都要调用该方法 因为只有相同类的两个实例才会比较大小，所以向TreeSet中添加的应该是同一个类的对象 TreeSet采用红黑树的数据结构来存储集合元素 对于TreeSet集合而言，它判断两个对象的是否相等的唯一标准是:两个对象的通过compareTo(Object obj)方法比较是否返回0–如果通过compareTo(Object obj)方法比较返回0，TreeSet则会认为它们相等，否则认为它们不相等。对于语句，obj1.compareTo(obj2),如果该方法返回一个正整数，则表明obj1大于obj2;如果该方法返回一个负整数，则表明obj1小于obj2. 在默认的compareTo方法中，需要将的两个的类型的对象的转换同一个类型，因此需要将的保证的加入到TreeSet中的数据类型是同一个类型，但是如果自己覆盖compareTo方法时，没有要求两个对象强制转换成同一个对象，是可以成功的添加treeSet中 如果两个对象通过CompareTo(Object obj)方法比较返回0时，但它们通过equals()方法比较返回false时，TreeSet不会让第二个元素添加进去 MapMap主要用于存储健值对，根据键得到值，因此不允许键重复，但允许值重复。 Map接口概述：Java.util.Map&lt;k,v&gt;接口：是一个双列集合 Map集合的特点： 是一个双列集合，有两个泛型key和value，使用的时候key和value的数据类型可以相同。也可以不同. Key不允许重复的，value可以重复的； 一个key只能对应一个value 底层是一个哈希表（数组+单向链表）：查询快，增删快, 是一个无序集合 Map接口中的常用方法： 1.get(key) 根据key值返回对应的value值，key值不存在则返回null 2.put(key , value); 往集合中添加元素（key和value） 注意：添加的时候，如果key不存在，返回值null 如果Key已经存在的话，就会新值替换旧值，返回旧值 remove(key); 删除key值对应的键值对；如果key不存在 ，删除失败。返回值为 null，如果key存在则删除成功，返回值为删除的value Map遍历方式 第一种方式：通过key找value的方式： Map中有一个方法： Set keySet(); 返回此映射包含的键的Set 集合 操作步骤: 1.调用Map集合的中方法keySet,把Map集合中所有的健取出来,存储到Set集合中 2.遍历Set集合,获取Map集合中的每一个健 3.通过Map集合中的方法get(key),获取value值 可以使用迭代器跟增强for循环遍历 第二种方式：Map集合遍历键值方式 Map集合中的一个方法： Set&lt;Map.Entry&lt;k,v&gt;&gt; entrySet(); 返回此映射中包含的映射关系的Set视图 使用步骤 * 1.使用Map集合中的方法entrySet,把键值对(键与值的映射关系),取出来存储到Set 集合中 * 2.遍历Set集合,获取每一个Entry对象 * 3.使用Entry对象中的方法getKey和getValue获取健和值 可以使用迭代器跟增强for循环遍历 Collection中的集合元素是孤立的，可理解为单身，是一个一个存进去的，称为单列集合 Map中的集合元素是成对存在的，可理解为夫妻，是一对一对存进去的，称为双列集合 Map中存入的是：键值对，键不可以重复，值可以重复 Map主要用于存储带有映射关系的数据（比如学号与学生信息的映射关系） Map没有继承Collection接口，Map提供key到value的映射。一个Map中不能包含相同的key，每个key只能映射一个 value。Map接口提供3种集合的视图，Map的内容可以被当作一组key集合，一组value集合，或者一组key-value映射。 Map具有将对象映射到其他对象的功能，是一个K-V形式存储容器，你可以通过containsKey()和containsValue()来判断集合是否包含某个减或某个值。Map可以很容以拓展到多维（值可以是其他容器甚至是其他Map）： Map&lt;Object,List&gt; Map集合的数据结构仅仅针对键有效，与值无关。 HashMapHashMap非线程安全，高效，支持null； 根据键的HashCode 来存储数据，根据键可以直接获取它的值，具有很快的访问速度。遍历时，取得数据的顺序是完全随机的。 HashMap最多只允许一条记录的键为Null；允许多条记录的值为 Null。（不允许键重复，但允许值重复） HashMap不支持线程的同步（任一时刻可以有多个线程同时写HashMap，即线程非安全），可能会导致数据的不一致。如果需要同步，可以用 Collections的synchronizedMap() 方法使HashMap具有同步的能力，或者使用ConcurrentHashMap。 Hashtable与 HashMap类似。不同的是：它不允许记录的键或者值为空；它支持线程的同步（任一时刻只有一个线程能写Hashtable，即线程安全），因此也导致了 Hashtable 在写入时会比较慢。 HashMap里面存入的值在取出的时候是随机的，它根据键的HashCode来存储数据，根据键可以直接获取它的值，具有很快的访问速度。在Map 中插入、删除和定位元素，HashMap 是最好的选择。 HashMap基于哈希表的 Map 接口的实现。此实现提供所有可选的映射操作，并允许使用 null 值和 null 键。（除了不同步和允许使用 null 之外，HashMap 类与 Hashtable 大致相同。）此类不保证映射的顺序，特别是它不保证该顺序恒久不变。 值得注意的是HashMap不是线程安全的，如果想要线程安全的HashMap，可以通过Collections类的静态方法synchronizedMap获得线程安全的HashMap。 Map map = Collections.synchronizedMap(new HashMap()); HashMap的底层主要是基于数组和链表来实现的，它之所以有相当快的查询速度主要是因为它是通过计算散列码来决定存储的位置。HashMap中主要是通过key的hashCode来计算hash值的，只要hashCode相同，计算出来的hash值就一样。如果存储的对象对多了，就有可能不同的对象所算出来的hash值是相同的，这就出现了所谓的hash冲突。学过数据结构的同学都知道，解决hash冲突的方法有很多，HashMap底层是通过链表来解决hash冲突的。 HashMap其实也是一个线性的数组实现的,所以可以理解为其存储数据的容器就是一个线性数组。这可能让我们很不解，一个线性的数组怎么实现按键值对来存取数据呢？这里HashMap有做一些处理。首先HashMap里面实现一个静态内部类Entry，其重要的属性有 key , value, next，从属性key,value我们就能很明显的看出来Entry就是HashMap键值对实现的一个基础bean，我们上面说到HashMap的基础就是一个线性数组，这个数组就是Entry[]，Map里面的内容都保存在Entry[]里面。 HashMap是常用的Java集合之一，是基于哈希表的Map接口的实现。与HashTable主要区别为不支持同步和允许null作为key和value。由于HashMap不是线程安全的，如果想要线程安全，可以使用ConcurrentHashMap代替。 HashMap的底层是哈希数组，数组元素为Entry。HashMap通过key的hashCode来计算hash值，当hashCode相同时，通过“拉链法”解决冲突 相比于之前的版本，jdk1.8在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间。原本Map.Entry接口的实现类Entry改名为了Node。转化为红黑树时改用另一种实现TreeNode。 1.8中最大的变化就是在一个Bucket中，如果存储节点的数量超过了8个，就会将该Bucket中原来以链表形式存储节点转换为以树的形式存储节点;而如果少于6个，就会还原成链表形式存储。 为什么要这样做？前面已经说过LinkedList的遍历操作不太友好，如果在节点个数比较多的情况下性能会比较差，而树的遍历效率是比较好的，主要是优化遍历，提升性能。 HashMap:去掉了contains(),保留了containsKey(),containsValue() HashMap:key,value可以为空.null作为key只能有一个,null作为value可以存在多个 HashMap:使用Iterator HashMap:数组初始大小为16,扩容方式为2的指数幂形式 HashMap:重新计算hash值 HashMap是基于哈希表的Map接口的实现，HashMap是一个散列表，存储的内容是键值对（key-value）映射，键值对都可为null； HashMap继承自 AbstractMap&lt;K, V&gt; 并实现Map&lt;K, V&gt;, Cloneable, Serializable接口； HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。底层是个数组，数组上存储的数据是Entry&lt;K,V&gt;类型的链表结构对象。 HashMap是无序的，LinkedHashMap和treeMap是有序的； HashMap基于哈希原理，可以通过put和get方法存储和获取对象。当我们将键值对传递给put方法时，它调用键对象的hashCode()方法来计算hashcode，然后找到对应的bucket位置存储键对象和值对象作为Map.Entry；如果两个对象的hashcode相同，所以对应的bucket位置是相同的，HashMap采用链表解决冲突碰撞，这个Entry（包含有键值对的Map.Entry对象）会存储到链表的下一个节点中；如果对应的hashcode和key值都相同，则修改对应的value的值。HashMap在每个链表节点中存储键值对对象。当使用get()方法获取对象时，HashMap会根据键对象的hashcode去找到对应的bucket位置，找到对应的bucket位置后会调用keys.equals()方法去找到连表中对应的正确的节点找到对象。 HashMap是基于哈希表实现的，每一个元素是一个key-value对，其内部通过单链表解决冲突问题，容量不足（超过了阀值）时，同样会自动增长。 HashMap 实现了Serializable接口，因此它支持序列化，实现了Cloneable接口,能被克隆。 HashMap存数据的过程是： HashMap内部维护了一个存储数据的Entry数组，HashMap采用链表解决冲突，每一个Entry本质上是一个单向链表。当准备添加一个key-value对时，首先通过hash(key)方法计算hash值，然后通过indexFor(hash,length)求该key-value对的存储位置，计算方法是先用hash&amp;0x7FFFFFFF后，再对length取模，这就保证每一个key-value对都能存入HashMap中，当计算出的位置相同时，由于存入位置是一个链表，则把这个key-value对插入链表头。 HashMap中key和value都允许为null。key为null的键值对永远都放在以table[0]为头结点的链表中。 HashMap内存储数据的Entry数组默认是16，如果没有对Entry扩容机制的话，当存储的数据一多，Entry内部的链表会很长，这就失去了HashMap的存储意义了。所以HasnMap内部有自己的扩容机制。HashMap内部有： 变量size，它记录HashMap的底层数组中已用槽的数量； 变量threshold，它是HashMap的阈值，用于判断是否需要调整HashMap的容量（threshold = 容量*加载因子） 变量DEFAULT_LOAD_FACTOR = 0.75f，默认加载因子为0.75 HashMap扩容的条件是：当size大于threshold时，对HashMap进行扩容 扩容是是新建了一个HashMap的底层数组，而后调用transfer方法，将就HashMap的全部元素添加到新的HashMap中（要重新计算元素在新的数组中的索引位置）。 很明显，扩容是一个相当耗时的操作，因为它需要重新计算这些元素在新的数组中的位置并进行复制处理。因此，我们在用HashMap的时，最好能提前预估下HashMap中元素的个数，这样有助于提高HashMap的性能。 加载因子，如果加载因子越大，对空间的利用更充分，但是查找效率会降低（链表长度会越来越长）；如果加载因子太小，那么表中的数据将过于稀疏（很多空间还没用，就开始扩容了），对空间造成严重浪费。如果我们在构造方法中不指定，则系统默认加载因子为0.75，这是一个比较理想的值，一般情况下我们是无需修改的。另外，无论我们指定的容量为多少，构造方法都会将实际容量设为不小于指定容量的2的次方的一个数，且最大值不能超过2的30次方。 HashMap的初始容量为16，Hashtable初始容量为11，两者的填充因子默认都是0.75。 HashMap扩容时是当前容量翻倍即:capacity2，Hashtable扩容时是容量翻倍+1即:capacity2+1。 HashMap和Hashtable的底层实现都是数组+链表结构实现。 HashMap计算hash对key的hashcode进行了二次hash，以获得更好的散列值，然后对table数组长度取摸： 12345678910111213static int hash(int h) &#123; h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125;static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; HashTableHashTable线程安全，低效，不支持null ,Hashtable是同步的 HashTable这个类实现了哈希表从key映射到value的数据结构形式。任何非null的对象都可以作为key或者value。 要在hashtable中存储和检索对象，作为key的对象必须实现hashCode、equals方法。 一般来说，默认的加载因子（0.75）提供了一种对于空间、时间消耗比较好的权衡策略。太高的值（指加载因子loadFactor）虽然减少了空间开销但是增加了检索时间，这反应在对hashtable的很多操作中，比如get、put方法。 初始容量的控制也是在空间消耗和rehash操作耗时(该操作耗时较大)二者之间的权衡。 如果初始容量大于哈希表的当前最大的条目数除以加载因子，则不会发生rehash。但是，将初始容量设置过高会浪费空间。 如果有大量的数据需要放进hashtable，则选择设置较大的初始容量比它自动rehash更优。 如果不需要线程安全的实现，建议使用HashMap代替Hashtable 如果想要一个线程安全的高并发实现，那么建议使用java.util.concurrent.ConcurrentHashMap取代了Hashtable。 HashTable的父类是Dictionary HashTable:线程安全,HashTable方法有synchronized修饰 HashTable:保留了contains(),containsKey(),containsValue() HashTable:key,value都不能为空.原因是源码中方法里会遍历entry,然后用entry的key或者value调用equals(),所以要先判断key/value是否为空,如果为空就会抛出异常 HashTable:使用Enumeration,Iterator HashTable:数组初始大小为11,扩容方式为2*old+1 HashTable: 直接使用hashcode() Hashtable同样是基于哈希表实现的，同样每个元素是一个key-value对，其内部也是通过单链表解决冲突问题，容量不足（超过了阀值）时，同样会自动增长。 Hashtable也是JDK1.0引入的类，是线程安全的，能用于多线程环境中。 Hashtable同样实现了Serializable接口，它支持序列化，实现了Cloneable接口，能被克隆。 Hashtable计算hash是直接使用key的hashcode对table数组的长度直接进行取模： int hash = key.hashCode(); int index = (hash &amp; 0x7FFFFFFF) % tab.length; 底层数据结构是哈希表,特点和 hashMap 是一样的 Hashtable 是线程安全的集合,是单线程的,运行速度慢 HashMap 是线程不安全的集合,是多线程的,运行速度快 Hashtable 命运和 Vector 是一样的,从 JDK1.2 开始,被更先进的 HashMap 取代 HashMap 允许存储 null 值,null 健 Hashtable 不允许存储 null 值,null 健 Hashtable 他的孩子,子类 Properties 依然活跃在开发舞台 Properties Java.util.Properties 集合extends Hashtable&lt;k,v&gt; 集合 Properties 集合特点： Properties集合也是一个双列集合，key跟value都已经被内置为String类型 Properties集合是一个唯一和IO流相结合的集合 可以将集合中存储的临时数据，持久化到硬盘的文件中储存 可以把文件中储存对的键值对，读取到集合中使用 Properties集合的基本操作：添加数据，遍历集合,Key和value都已经被内置为String类型。里面包含了一些和String类的相关方法 Object setProperty(String key ,String value) 往集合中添加键值对，调用Hashtable的方法put添加 String getProperty(String key ) 通过key获取value的值，相当于Map集合中的get(key) 方法 Set&lt;String &gt; stringPropertyNames()返回此属性列表的键集。相当于Map集合中的keySet()方法； Properties类的load方法： 可以把文件中存储的键值对,读取到集合中使用 void load(Reader reader) void load(InputStream inStream) 参数: Reader reader:字符输入流,可以使用FileReader InputStream inStream:字节输入流,可以使用FileInputStream 操作步骤: 1.创建Properties集合对象 2.创建字符输入流FileReader对象,构造方法中绑定要读取的数据源 3.使用Properties集合中的方法load,把文件中存储的键值对,读取到集合中使 用 4.释放资源 5.遍历Properties集合 注意: 1.流使用Reader字符流,可以读取中文数据 2.流使用InputStream字节流,不能操作中文,会有乱码 3.Properties集合的配置文件中,可以使用注释单行数据,使用# 4.Properties集合的配置文件中,key和value默认都是字符串,不用添加””(画蛇 添足) 5.Properties集合的配置文件中,key和value的连接符号可以使用=,也可以使用 空格 Properties类的store方法使用： 可以把集合中存储的临时数据,持久化都硬盘的文件中存储 123void store(Writer writer, String comments) void store(OutputStream out, String comments) 参数: Writer writer:字符输出流,可以使用FileWriter OutputStream out:字节输出流,可以使用FileOutputStream String comments:注释,解释说明存储的文件,不能使用中文(乱码),默认编码格式为 Unicode编码 可以使用””空字符串 操作步骤: 1.创建Properties集合,往集合中添加数据 2.创建字符输出流FileWriter对象,构造方法中绑定要写入的目的地 3.调用Properties集合中的方法store,把集合中存储的临时数据,持久化都硬盘的文 件中存储 4.释放资源 注意: 1.流使用Writer字符流,可以写入中文数据的 2.流使用OutputStream字节流,不能操作中文,会有乱码 3.Propertie集合存储的文件,一般都以.properties结尾(程序员默认) HashMap多线程put操作后，get操作导致死循环。为何出现死循环？ 大家都知道，HashMap采用链表解决Hash冲突，具体的HashMap的分析因为是链表结构，那么就很容易形成闭合的链路，这样在循环的时候只要有线程对这个HashMap进行get操作就会产生死循环。但是，我好奇的是，这种闭合的链路是如何形成的呢。在单线程情况下，只有一个线程对HashMap的数据结构进行操作，是不可能产生闭合的回路的。那就只有在多线程并发的情况下才会出现这种情况，那就是在put操作的时候，如果size&gt;initialCapacity*loadFactor，那么这时候HashMap就会进行rehash操作，随之HashMap的结构就会发生翻天覆地的变化。很有可能就是在两个线程在这个时候同时触发了rehash操作，产生了闭合的回路。 简单来说，HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的，如果定位到的数组位置不含链表（当前entry的next指向null）,那么对于查找，添加等操作很快，仅需一次寻址即可；如果定位到的数组包含链表，对于添加操作，其时间复杂度依然为O(1)，因为最新的Entry会插入链表头部，急需要简单改变引用链即可，而对于查找操作来讲，此时就需要遍历链表，然后通过key对象的equals方法逐一比对查找。所以，性能考虑，HashMap中的链表出现越少，性能才会越好。 HashMap存储自定义类型:使用HashMap储存自定义类形式，因为要保证key的唯一性。需要 自定义类重写 hashCode()跟equals()方法； HashMap的方法基本都是Map中声明的方法 实现原理：实现一个哈希表，存储元素(key/value)时，用key计算hash值，如果hash值没有碰撞，则只用数组存储元素；如果hash值碰撞了，则相同的hash值的元素用链表存储；如果相同hash值超过8个，则相同的hash值的元素用红黑树存储。获取元素时，用key计算hash值，用hash值计算元素在数组中的下标，取得元素如果命中，则返回；如果不是就在红黑树或链表中找。 PS：存储元素的数组是有冗余的。 采用了Fail-Fast机制，通过一个modCount值记录修改次数，在迭代过程中，判断modCount跟初始过程记录的expectedModCount是否相等，如果不相等就表示已经有其他线程修改了Map，马上抛出异常；另外扩容过程中还有可能产生环形链表。 synchronized是针对整张Hash表的，即每次锁住整张表让线程独占 LinkeHashMapLinkedHashMap继承自HashMap，实现了Map&lt;K,V&gt;接口。其内部还维护了一个双向链表，在每次插入数据，或者访问、修改数据时，会增加节点、或调整链表的节点顺序。以决定迭代时输出的顺序。 默认情况，遍历时的顺序是按照插入节点的顺序。这也是其与HashMap最大的区别。 也可以在构造时传入accessOrder参数，使得其遍历顺序按照访问的顺序输出。 LinkedHashMap在实现时，就是重写override了几个方法。以满足其输出序列有序的需求。 LinkedHashMap保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的。 在遍历的时候会比HashMap慢，不过有种情况例外：当HashMap容量很大，实际数据较少时，遍历起来可能会比LinkedHashMap慢。因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和它的容量有关。 LinkedHashMap是HashMap的子类，保存了插入的顺序，需要输出的顺序和输入的顺序相同时可用LinkedHashMap； LinkedHashMap 是HashMap的一个子类，如果需要输出的顺序和输入的相同,那么用LinkedHashMap可以实现. LinkedHashMap取键值对时，是按照你放入的顺序来取的。 LinkedHashMap由于它的插入有序特性，也是一种比较常用的Map集合。它继承了HashMap，很多方法都直接复用了父类HashMap的方法。本文将探讨LinkedHashMap的内部实现，以及它是如何保证插入元素是按插入顺序排序的。 在分析前可以先思考下，既然是按照插入顺序，并且以Linked-开头，就很有可能是链表实现。如果纯粹以链表实现，也不是不可以，LinkedHashMap内部维护一个链表，插入一个元素则把它封装成Entry节点，并把它插入到链表尾部。功能可以实现，但这带来的查找效率达到了O(n)，显然远远大于HashMap在没有冲突的情况下O(1)的时间复杂度。这就丝毫不能体现出Map这种数据结构随机存取快的优点。 所以显然，LinkedHashMap不可能只有一个链表来维护Entry节点，它极有可能维护了两种数据结构：散列表+链表。 LinkedHashMap的LRU特性 先讲一下LRU的定义：LRU(Least Recently Used),即最近最少使用算法，最初是用于内存管理中将无效的内存块腾出而用于加载数据以提高内存使用效率而发明的算法。 目前已经普遍用于提高缓存的命中率，如Redis、Memcached中都有使用。 为啥说LinkedHashMap本身就实现了LRU算法？原因就在于它额外维护的双向链表中。 在上面已经提到过，在做get/put操作时，LinkedHashMap会将当前访问/插入的节点移动到链表尾部，所以此时链表头部的那个节点就是 “最近最少未被访问”的节点。 举个例子： 往一个空的LinkedHashMap中插入A、B、C三个结点，那么链表会经历以下三个状态： A 插入A节点，此时整个链表只有这一个节点，既是头节点也是尾节点 A -&gt; B 插入B节点后，此时A为头节点，B为尾节点，而最近最常访问的节点就是B节点（刚被插入），而最近最少使用的节点就是A节点（相对B节点来讲，A节点已经有一段时间没有被访问过） A -&gt; B -&gt; C 插入C节点后，此时A为头节点，C为尾节点，而最近最常访问的节点就是C节点（刚被插入），最近最少使用的节点就是A节点 （应该很好理解了吧 : )） 那么对于缓存来讲，A就是我最长时间没访问过的缓存，C就是最近才访问过的缓存，所以当缓存队列满时就会从头开始替换新的缓存值进去，从而保证缓存队列中的缓存尽可能是最近一段时间访问过的缓存，提高缓存命中率。 LinkedHashMap实现与HashMap的不同之处在于，后者维护着一个运行于所有条目的双重链接列表。此链接列表定义了迭代顺序，该迭代顺序可以是插入顺序或者是访问顺序。 TreeMapTreeMap实现SortMap接口，能够把它保存的记录根据键排序。 默认是按键的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。 TreeMap取出来的是排序后的键值对。但如果您要按自然顺序或自定义顺序遍历键，那么TreeMap会更好。 TreeMap是基于红黑树结构实现的一种Map，要分析TreeMap的实现首先就要对红黑树有所了解。 要了解什么是红黑树，就要了解它的存在主要是为了解决什么问题，对比其他数据结构比如数组，链表，Hash表等树这种结构又有什么优点。 treeMap实现了sortMap接口，能够把保存的数据按照键的值排序，默认是按照自然数排序也可自定义排序方式。 TreeMap对键进行排序了。 当用Iterator遍历TreeMap时，得到的记录是排过序的。 如果使用排序的映射，建议使用TreeMap。 在使用TreeMap时，key必须实现Comparable接口或者在构造TreeMap传入自定义的Comparator，否则会在运行时抛出java.lang.ClassCastException类型的异常。 二叉树插入元素是有顺序的，TreeSet的元素是有序的。 由于二叉树需要对结点排序（插入的结点位置），默认情况下没有排序方法，所以元素需要继承Comparator并重写compareTo方法来实现元素之间比较大小的功能。 对于TreeSet，compareTo方法来保证元素的唯一性。【这时候可以不重写equals】 二叉树需要结点排序，所以元素之间比较能够比较，所以对于自定义元素对象，需要继承Comparator并重写的compareTo方法。 两个元素相等时，compareTo返回0；左大于右时，返回正整数（一般返回1）;小于时返回负整数（一般返回-1） TreeMap的基本操作 containsKey、get、put 和 remove 的时间复杂度是 log(n) TreeMap中默认的排序为升序 使用entrySet遍历方式要比keySet遍历方式快 entrySet遍历方式获取Value对象是直接从Entry对象中直接获得，时间复杂度T(n)=o(1); keySet遍历获取Value对象则要从Map中重新获取，时间复杂度T(n)=o(n);keySet遍历Map方式比entrySet遍历Map方式多了一次循环，多遍历了一次table，当Map的size越大时，遍历的效率差别就越大。 HashMap通过hashcode对其内容进行快速查找，而TreeMap中所有的元素都保持着某种固定的顺序，如果你需要得到一个有序的结果你就应该使用TreeMap（HashMap中元素的排列顺序是不固定的）。 在Map 中插入、删除和定位元素，HashMap是最好的选择。但如果您要按自然顺序或自定义顺序遍历键，那么TreeMap会更好。使用HashMap要求添加的键类明确定义了hashCode()和 equals()的实现。 TreeMap 底层数据结构是红黑树(一种自平衡的二叉树) ，其根据比较的返回值是否是0来保证元素唯一性， 元素的排序通过两种方式：第一种是自然排序(元素具备比较性) 即让元素所属的类实现Comparable接口，第二种是比较器排序(集合具备比较性) ，即让集合接收一个Comparator的实现类对象。 Comparable 和 Comparator 的区别： Comparable 是一个比较的标准，里面有比较的方法，对象要具有比较的标准，就必须实现 Comparable 接口；类实现这个接口，就有比较的方法；把元素放到 TreeSet 里面去，就会自动的调用 CompareTo 方法；但是这个 Comparable 并不是专为 TreeSet 设计的；只是说，TreeSet 顺便利用而已；就像 HashCode 和 equals 也一样，不是专门为 HashSet 设计一样；只是你顺便利用而已。 Compartor 是个比较器，也不是专门为TreeSet设计. 就是一个第三方的比较器接口；如果对象没有比较性，自己就可以按照比较器的标准，设计一个比较器，创建一个类，实现这个接口，覆写方法。 Queue Queue用于模拟队列这种数据结构，实现“FIFO”等数据结构。即第一个放进去就是第一个拿出来的元素（从一端进去，从另一端出来）。队列常作被当作一个可靠的将对象从程序的某个区域传输到另一个区域的途径。通常，队列不允许随机访问队列中的元素。 Queue 接口并未定义阻塞队列的方法，而这在并发编程中是很常见的。BlockingQueue 接口定义了那些等待元素出现或等待队列中有可用空间的方法，这些方法扩展了此接口。 Queue 实现通常不允许插入 null 元素，尽管某些实现（如 LinkedList）并不禁止插入 null。即使在允许 null 的实现中，也不应该将 null 插入到 Queue 中，因为 null 也用作 poll 方法的一个特殊返回值，表明队列不包含元素。 LinkedList提供了方法以支持队列的行为，并且实现了Queue接口。通过LinkedList向上转型（up cast）为Queue，看Queue的实现就知道相对于LinkedList，Queue添加了element、offer、peek、poll、remove方法 offer：在允许的情况下，将一个元素插入到队尾，或者返回false peek，element：在不移除的情况下返回队头，peek在队列为空返回null，element抛异常NoSuchElementException poll,remove：移除并返回队头，poll当队列为空是返回null，remove抛出NoSuchElementException异常 注意：queue.offer在自动包装机制会自动的把random.nextInt转化程Integer，把char转化成Character DequeDeque是Queue的子接口,我们知道Queue是一种队列形式,而Deque则是双向队列,它支持从两个端点方向检索和插入元素,因此Deque既可以支持LIFO形式也可以支持LIFO形式.Deque接口是一种比Stack和Vector更为丰富的抽象数据形式,因为它同时实现了以上两者. 添加功能 void push(E) 向队列头部插入一个元素,失败时抛出异常 void addFirst(E) 向队列头部插入一个元素,失败时抛出异常 void addLast(E) 向队列尾部插入一个元素,失败时抛出异常 boolean offerFirst(E) 向队列头部加入一个元素,失败时返回false boolean offerLast(E) 向队列尾部加入一个元素,失败时返回false 获取功能 E getFirst() 获取队列头部元素,队列为空时抛出异常 E getLast() 获取队列尾部元素,队列为空时抛出异常 E peekFirst() 获取队列头部元素,队列为空时返回null E peekLast() 获取队列尾部元素,队列为空时返回null 删除功能 boolean removeFirstOccurrence(Object) 删除第一次出现的指定元素,不存在时返回false boolean removeLastOccurrence(Object) 删除最后一次出现的指定元素,不存在时返回false 弹出功能 E pop() 弹出队列头部元素,队列为空时抛出异常 E removeFirst() 弹出队列头部元素,队列为空时抛出异常 E removeLast() 弹出队列尾部元素,队列为空时抛出异常 E pollFirst() 弹出队列头部元素,队列为空时返回null E pollLast() 弹出队列尾部元素,队列为空时返回null 迭代器 Iterator&lt;E&gt; descendingIterator() 返回队列反向迭代器 同Queue一样,Deque的实现也可以划分成通用实现和并发实现. 通用实现主要有两个实现类ArrayDeque和LinkedList. ArrayDeque是个可变数组,它是在Java 6之后新添加的,而LinkedList是一种链表结构的list,LinkedList要比ArrayDeque更加灵活,因为它也实现了List接口的所有操作,并且可以插入null元素,这在ArrayDeque中是不允许的. 从效率来看,ArrayDeque要比LinkedList在两端增删元素上更为高效,因为没有在节点创建删除上的开销.最适合使用LinkedList的情况是迭代队列时删除当前迭代的元素.此外LinkedList可能是在遍历元素时最差的数据结构,并且也LinkedList占用更多的内存,因为LinkedList是通过链表连接其整个队列,它的元素在内存中是随机分布的,需要通过每个节点包含的前后节点的内存地址去访问前后元素. 总体ArrayDeque要比LinkedList更优越,在大队列的测试上有3倍与LinkedList的性能,最好的是给ArrayDeque一个较大的初始化大小,以避免底层数组扩容时数据拷贝的开销. LinkedBlockingDeque是Deque的并发实现,在队列为空的时候,它的takeFirst,takeLast会阻塞等待队列处于可用状态 StackStack继承自Vector，实现一个后进先出的堆栈。Stack提供5个额外的方法使得 Vector得以被当作堆栈使用。基本的push和pop方法，还有peek方法得到栈顶的元素，empty方法测试堆栈是否为空，search方法检测一个元素在堆栈中的位置。Stack刚创建后是空栈。 栈，是指“LIFO”先进后出的集合容器，最后一个压入的元素是第一个出来的，就好比我们洗碗一样（或者叠罗汉）第一个摆放的碗放在最下面，自然是最后一个拿出来的。Stack是由LinkedList实现的，作为Stack的实现，下面是《java编程思想》给出基本的Stack实现： peek和pop是返回T类型的对象。peek方法提供栈顶元素，但不删除栈顶，而pop是返回并删除栈顶元素; ArrayDequeArrayDeque类是双端队列的实现类，类的继承结构如下面，继承自AbastractCollection（该类实习了部分集合通用的方法，其实现了Collection接口），其实现的接口Deque接口中定义了双端队列的主要的方法，比如从头删除，从尾部删除，获取头数据，获取尾部数据等等。 1public class ArrayDeque&lt;E&gt; extends AbstractCollection&lt;E&gt; implements Deque&lt;E&gt;, Cloneable, Serializable ArrayDeque基本特征 就其实现而言，ArrayDeque采用了循环数组的方式来完成双端队列的功能。 无限的扩展，自动扩展队列大小的。（当然在不会内存溢出的情况下。） 非线程安全的，不支持并发访问和修改。 支持fast-fail. 作为栈使用的话比比栈要快. 当队列使用比linklist要快。 null元素被禁止使用。 最小初始化容量限制8(必须是2的幂次) 扩容:之所以说该ArrayDeque容量无限制，是因为只要检测到head==tail的时候，就直接调用doubleCapacity方法进行扩容。 删除元素:删除元素的基本思路为确定那一侧的数据少，少的一侧移动元素位置，这样效率相对于不比较更高些，然后，判断head是跨越最大值还是为跨越最大值，继而可以分两种不同的情况进行拷贝。但是该方法比较慢，因为存在数组的拷贝。 获取并删除元素:这里在举个简单点的例子，中间判断是不是null，可以看出该队列不支持null,通过把其值设为null就算是将其删除了。然后head向递增的方向退一位即可。 ArrayDeque和LinkedList是Deque的两个通用实现 ArrayDeque不是线程安全的。 ArrayDeque不可以存取null元素，因为系统根据某个位置是否为null来判断元素的存在。 当作为栈使用时，性能比Stack好；当作为队列使用时，性能比LinkedList好。 1.添加元素 addFirst(E e)在数组前面添加元素 addLast(E e)在数组后面添加元素 offerFirst(E e) 在数组前面添加元素，并返回是否添加成功 offerLast(E e) 在数组后天添加元素，并返回是否添加成功 2.删除元素 removeFirst()删除第一个元素，并返回删除元素的值,如果元素为null，将抛出异常 pollFirst()删除第一个元素，并返回删除元素的值，如果元素为null，将返回null removeLast()删除最后一个元素，并返回删除元素的值，如果为null，将抛出异常 pollLast()删除最后一个元素，并返回删除元素的值，如果为null，将返回null removeFirstOccurrence(Object o) 删除第一次出现的指定元素 removeLastOccurrence(Object o) 删除最后一次出现的指定元素 3.获取元素 getFirst() 获取第一个元素,如果没有将抛出异常 getLast() 获取最后一个元素，如果没有将抛出异常 4.队列操作 add(E e) 在队列尾部添加一个元素 offer(E e) 在队列尾部添加一个元素，并返回是否成功 remove() 删除队列中第一个元素，并返回该元素的值，如果元素为null，将抛出异常(其实底层调用的是removeFirst()) poll() 删除队列中第一个元素，并返回该元素的值,如果元素为null，将返回null(其实调用的是pollFirst()) element() 获取第一个元素，如果没有将抛出异常 peek() 获取第一个元素，如果返回null 5.栈操作 push(E e) 栈顶添加一个元素 pop(E e) 移除栈顶元素,如果栈顶没有元素将抛出异常 6.其他 size() 获取队列中元素个数 isEmpty() 判断队列是否为空 iterator() 迭代器，从前向后迭代 descendingIterator() 迭代器，从后向前迭代 contain(Object o) 判断队列中是否存在该元素 toArray() 转成数组 clear() 清空队列 clone() 克隆(复制)一个新的队列 PriorityQueue我们知道队列是遵循先进先出（First-In-First-Out）模式的，但有些时候需要在队列中基于优先级处理对象。举个例子，比方说我们有一个每日交易时段生成股票报告的应用程序，需要处理大量数据并且花费很多处理时间。客户向这个应用程序发送请求时，实际上就进入了队列。我们需要首先处理优先客户再处理普通用户。在这种情况下，Java的PriorityQueue(优先队列)会很有帮助。 PriorityQueue类在Java1.5中引入并作为 Java Collections Framework 的一部分。PriorityQueue是基于优先堆的一个无界队列，这个优先队列中的元素可以默认自然排序或者通过提供的Comparator（比较器）在队列实例化的时排序。 优先队列不允许空值，而且不支持non-comparable（不可比较）的对象，比如用户自定义的类。优先队列要求使用Java Comparable和Comparator接口给对象排序，并且在排序时会按照优先级处理其中的元素。 优先队列的头是基于自然排序或者Comparator排序的最小元素。如果有多个对象拥有同样的排序，那么就可能随机地取其中任意一个。当我们获取队列时，返回队列的头对象。 优先队列的大小是不受限制的，但在创建时可以指定初始大小。当我们向优先队列增加元素的时候，队列大小会自动增加。 PriorityQueue是非线程安全的，所以Java提供了PriorityBlockingQueue（实现BlockingQueue接口）用于Java多线程环境。 由于知道PriorityQueue是基于Heap的，当新的元素存储时，会调用siftUpUsingComparator方法 PriorityQueue的逻辑结构是一棵完全二叉树，存储结构其实是一个数组。逻辑结构层次遍历的结果刚好是一个数组。 PriorityQueue优先队列,它逻辑上使用堆结构（完全二叉树）实现，物理上使用动态数组实现，并非像TreeMap一样完全有序，但是如果按照指定方式出队，结果可以是有序的。 这里的堆是一种数据结构而非计算机内存中的堆栈。堆结构在逻辑上是完全二叉树，物理存储上是数组。 完全二叉树并不是堆结构，堆结构是不完全有序的完全二叉树。 BlockingQueueJava中Queue的最重要的应用大概就是其子类BlockingQueue了。 考虑到生产者消费者模型，我们有多个生产者和多个消费者，生产者不断提供资源给消费者，但如果它们的生产/消费速度不匹配或者不稳定，则会造成大量的生产者闲置/消费者闲置。此时，我们需要使用一个缓冲区来存储资源，即生产者将资源置于缓冲区，而消费者不断地从缓冲区中取用资源，从而减少了闲置和阻塞。 BlockingQueue，阻塞队列，即可视之为一个缓冲区应用于多线程编程之中。当队列为空时，它会阻塞所有消费者线程，而当队列为满时，它会阻塞所有生产者线程。 在queue的基础上，BlockingQueue又添加了以下方法： put：队列末尾添加一个元素，若队列已满阻塞。 take：移除并返回队列头部元素，若队列已空阻塞。 drainTo:一次性获取所有可用对象，可以用参数指定获取的个数，该操作是原子操作，不需要针对每个元素的获取加锁。 ArrayBlockingQueue由一个定长数组和两个标识首尾的整型index标识组成，生产者放入数据和消费者取出数据对于ArrayBlockingQueue而言使用了同一个锁（一个私有的ReentrantLock），因而无法实现真正的并行。可以在初始化时除长度参数以外，附加一个boolean类型的变量，用于给其私有的ReentrantLock进行初始化（初始化是否为公平锁，默认为false）。 LinkedBlockingQueueLinkedBlockingQueue的最大特点是，若没有指定最大容量，其可以视为无界队列（有默认最大容量限制,往往系统资源耗尽也无法达到）。即，不对生产者的行为加以限制，只在队列为空的时候限制消费者的行为。LinkedBlockingQueue采用了读写分离的两个ReentrantLock去控制put和take，因而有了更好的性能（类似读写锁提供读写场景下更好的性能），如下： 12345678/** Lock held by take, poll, etc */ private final ReentrantLock takeLock = new ReentrantLock(); /** Wait queue for waiting takes */ private final Condition notEmpty = takeLock.newCondition(); /** Lock held by put, offer, etc */ private final ReentrantLock putLock = new ReentrantLock(); /** Wait queue for waiting puts */ private final Condition notFull = putLock.newCondition(); ArrayBlockingQueue和LinkedBlockingQueue是最常用的两种阻塞队列。 PriorityBlockingQueuePriorityBlockingQueue是对PriorityQueue的包装，因而也是一个优先队列。其优先级默认是直接比较，大者先出队，也可以从构造器传入自定义的Comparator。由于PriorityQueue从实现上是一个无界队列，PriorityBlockingQueue同样是一个无界队列，对生产者不做限制。 DelayQueueDelayQueue是在PriorityBlockingQueue的基础上包装产生的，它用于存放Delayed对象，该队列的头部是延迟期满后保存时间最长的Delayed元素（即，以时间为优先级利用PriorityBlockingQueue），当没有元素延迟期满时，对其进行poll操作将会返回Null。take操作会阻塞。 SynchronousQueueSynchronousQueue十分特殊，它没有容量——换言之，它是一个长度为0的BlockingQueue，生产者和消费者进行的是无中介的直接交易，当生产者/消费者没有找到合适的目标时，即会发生阻塞。但由于减少了环节，其整体性能在一些系统中可能更加适合。该方法同样支持在构造时确定为公平/默认的非公平模式，如果是非公平模式，有可能会导致某些生产者/消费者饥饿。 WeakHashMapWeakHashMap是一种改进的HashMap，它对key实行“弱引用”，如果一个key不再被外部所引用，那么该key可以被GC回收。 EnumSet类EnumSet是一个专门为枚举设计的集合类，EnumSet中的所有元素都必须是指定枚举类型的枚举值，该枚举类型的创建Enumset时显示会隐式的指定。Enumset的集合元素也是有序的，EnumSet以枚举值在Enum类内定义的顺序来决定集合元素的顺序。 使用Java8新增的Predicate操作集合Java 8为Collection集合新增了removeIf(Predicate filter)方法，该方法将会批量删除符合条件的filter条件的所有元素 使用java 8 新增的Stream操作集合Java8新增了Stream、IntStream、LongStream、DoubleStream等流式API，这些API代表了多个支持串行和并行聚集操作的元素，其中Stream是一个通用的流接口，而IntStream、LongStream、DoubleStream则代表了类型为int，long，double的流。 独立使用Stream的步骤如下: 1、使用Stream或XxxStream的builder()类方法创建该Stream对应的Builder。 2、重复调用Builder的add()方法向该流中的添加多个元素 3、调用Builder的build()方法获取对应的Stream 4、调用Stream的聚集方法。 在Stream中方法分为两类中间方法和末端方法 中间方法：中间操作允许流保持打开状态,并允许直接调用后续方法。上面程序中的map()方法就是中间方法。 末端方法：末端方法是对流的最终操作。当对某个Stream执行末端方法后，该流将会被”消耗”且不再可用。上面程序中的sum()、count()、average()等方法都是末端方法。 除此之外，关于流的方法还有如下特征： 有状态的方法：这种方法会给你流增加一些新的属性，比如元素的唯一性、元素的最大数量、保证元素的排序的方式被处理等。有状态的方法往往需要更大的性能开销 短路方法:短路方法可以尽早结束对流的操作，不必检查所有的元素。 对CAS的理解，CAS带来的问题，如何解决这些问题？锁回答这个问题，可以先介绍一下锁要解决的问题，以及锁机制的缺点。 引入锁就是为了解决多线程竞争同一个资源时，出现脏读、数据不一致问题。一般我们常用的是synchronized等排他锁， 这种锁存在的问题： 1、多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调 度延时，引起性能问题 2、一个线程持有锁会导致其它所有需要此锁的线程挂起直至该锁释放 CAScas是另一个无锁解决方案，更准确的是采用乐观锁技术，实现线程安全的问题。cas有三个操作数—-内存对象（V）、预期原值（A）、新值（B）。 CAS原理就是对v对象进行赋值时，先判断原来的值是否为A，如果为A，就把新值B赋值到V对象上面，如果原来的值不是A（代表V的值放生了变化），就不赋新值。 我们看一下AtomicInteger类，AtomicInteger是线程安全的，我们看一下源码 123456789/** * Atomically adds the given value to the current value. * * @param delta the value to add * @return the previous value */public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta);&#125; 再看一下unsafe源码12345678public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2); &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6;&#125; 我们看到do while自循环，这里为什么会有自循环，就是在 判断预期原值 如果与原来的值不符合，会再循环取原值，再走CAS流程，直到能够把新值B赋值成功。 CAS缺点cas这个方式也存在一定的问题： 1、自循环时间长，开销大 2、只能保证一个共享变量的原子操作 3、ABA问题 什么是ABA问题？考虑如下操作： 并发1（上）：获取出数据的初始值是A，后续计划实施CAS乐观锁，期望数据仍是A的时候，修改才能成功 并发2：将数据修改成B 并发3：将数据修改回A 并发1（下）：CAS乐观锁，检测发现初始值还是A，进行数据修改 上述并发环境下，并发1在修改数据时，虽然还是A，但已经不是初始条件的A了，中间发生了A变B，B又变A的变化，此A已经非彼A，数据却成功修改，可能导致错误，这就是CAS引发的所谓的ABA问题。 库存操作，出现ABA问题并不会对业务产生影响。堆栈操作，会出现ABA的问题。 ABA问题的优化ABA问题导致的原因，是CAS过程中只简单进行了“值”的校验，再有些情况下，“值”相同不会引入错误的业务逻辑（例如库存），有些情况下，“值”虽然相同，却已经不是原来的数据了。 优化方向：CAS不能只比对“值”，还必须确保的是原来的数据，才能修改成功。 常见实践：“版本号”的比对，一个数据一个版本，版本变化，即使值相同，也不应该修改成功。 一个共享变量的原子操作问题优化当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁来保证原子性。 volatile底层、synchronized底层、锁升级的过程、MESIvolatile底层Java语言规范对于volatile定义如下： Java编程语言允许线程访问共享变量，为了确保共享变量能够被准确和一致性地更新，线程应该确保通过排它锁单独获得这个变量。 首先我们从定义开始入手，官方定义比较拗口。通俗来说就是一个字段被volatile修饰，Java的内存模型确保所有的线程看到的这个变量值是一致的，但是它并不能保证多线程的原子操作。这就是所谓的线程可见性。我们要知道他是不能保证原子性的。 内存模型相关概念Java线程之间的通信由Java内存模型(JMM)控制，JMM决定一个线程对共享变量的修改何时对另外一个线程可见。JMM定义了线程与主内存的抽象关系：线程之间的变量存储在主内存(Main Memory)中，每个线程都有一个私有的本地内存(Local Memory)保存着共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。 如果线程A与线程B通信： 线程A要先把本地内存A中更新过的共享变量刷写到主内存中。 线程B到主内存中读取线程A更新后的共享变量 计算机在运行程序时，每条指令都是在CPU中执行的，在执行过程中势必会涉及到数据的读写。我们知道程序运行的数据是存储在主存中，这时就会有一个问题，读写主存中的数据没有CPU中执行指令的速度快，如果任何的交互都需要与主存打交道则会大大影响效率，所以就有了CPU高速缓存。CPU高速缓存为某个CPU独有，只与在该CPU运行的线程有关。 有了CPU高速缓存虽然解决了效率问题，但是它会带来一个新的问题：数据一致性。在程序运行中，会将运行所需要的数据复制一份到CPU高速缓存中，在进行运算时CPU不再也主存打交道，而是直接从高速缓存中读写数据，只有当运行结束后才会将数据刷新到主存中。 举个例子： i++; 当线程运行这行代码时，首先会从主内存中读取i，然后复制一份到CPU高速缓存中,接着CPU执行+1的操作，再将+1后的数据写在缓存中，最后一步才是刷新到主内存中。在单线程时没有问题，多线程就有问题了。 如下：假如有两个线程A、B都执行这个操作（i++），按照我们正常的逻辑思维主存中的i值应该=3，但事实是这样么？ 分析如下：两个线程从主存中读取i的值（1）到各自的高速缓存中，然后线程A执行+1操作并将结果写入高速缓存中，最后写入主存中，此时主存i==2,线程B做同样的操作，主存中的i仍然=2。所以最终结果为2并不是3。这种现象就是缓存一致性问题。 解决缓存一致性方案有两种： 通过在总线加LOCK#锁的方式； 通过缓存一致性协议。 但是方案1存在一个问题，它是采用一种独占的方式来实现的，即总线加LOCK#锁的话，只能有一个CPU能够运行，其他CPU都得阻塞，效率较为低下。 第二种方案，缓存一致性协议（MESI协议）它确保每个缓存中使用的共享变量的副本是一致的。所以JMM就解决这个问题。 volatile实现原理有volatile修饰的共享变量进行写操作的时候会多出Lock前缀的指令，该指令在多核处理器下会引发两件事情。 将当前处理器缓存行数据刷写到系统主内存。 这个刷写回主内存的操作会使其他CPU缓存的该共享变量内存地址的数据无效。 这样就保证了多个处理器的缓存是一致的，对应的处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器缓存行设置无效状态，当处理器对这个数据进行修改操作的时候会重新从主内存中把数据读取到缓存里。 使用场景volatile经常用于两个场景：状态标记、double check 1、状态标记12345678//线程1boolean stop = false;while(!stop)&#123; doSomething();&#125;//线程2stop = true; 这段代码是很典型的一段代码，很多人在中断线程时可能都会采用这种标记办法。但是事实上，这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。 下面解释一下这段代码为何有可能导致无法中断线程。在前面已经解释过，每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。 那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。 但是加上volatile就没问题了。如下所示：1234567891011121314151617181920volatile boolean flag = false;while(!flag)&#123; doSomething();&#125;public void setFlag() &#123; flag = true;&#125;volatile boolean inited = false;//线程1:context = loadContext(); inited = true; //线程2:while(!inited )&#123;sleep()&#125;doSomethingwithconfig(context); 2、double check1234567891011121314151617public class Singleton&#123; private volatile static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance==null) &#123; synchronized (Singleton.class) &#123; if(instance==null) instance = new Singleton(); &#125; &#125; return instance; &#125;&#125; synchronized底层上面有写 锁升级的过程Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率，下文会详细分析。 markword因为偏向锁，锁住对象时，会写入对象头相应的标识，我们先把对象头(官方叫法为:Mark Word)的图示如下(借用了网友的图片): 偏向锁HotSpot [1] 的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。 上文中黑体字部分，写得太简略，以致于很多初学者，对这个过程有点不明白，这个过程是怎么实现锁的升级、释放的？下面一一分析 线程2来竞争锁对象; 判断当前对象头是否是偏向锁; 判断拥有偏向锁的线程1是否还存在; 线程1不存在,直接设置偏向锁标识为0(线程1执行完毕后,不会主动去释放偏向锁); 使用cas替换偏向锁线程ID为线程2,锁不升级，仍为偏向锁; 线程1仍然存在,暂停线程1； 设置锁标志位为00(变为轻量级锁),偏向锁为0; 从线程1的空闲monitor record中读取一条,放至线程1的当前monitor record中; 更新mark word，将mark word指向线程1中monitor record的指针; 继续执行线程1的代码; 锁升级为轻量级锁; 线程2自旋来获取锁对象; 轻量级锁（1）轻量级锁加锁线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。（2）轻量级锁解锁轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。下图是两个线程同时争夺锁，导致锁膨胀的流程图。因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。 缓存一致性和MESI缓存一致性协议给缓存行（通常为64字节）定义了个状态：独占（exclusive）、共享（share）、修改（modified）、失效（invalid），用来描述该缓存行是否被多处理器共享、是否修改。所以缓存一致性协议也称MESI协议。 独占（exclusive）：仅当前处理器拥有该缓存行，并且没有修改过，是最新的值。 共享（share）：有多个处理器拥有该缓存行，每个处理器都没有修改过缓存，是最新的值。 修改（modified）：仅当前处理器拥有该缓存行，并且缓存行被修改过了，一定时间内会写回主存，会写成功状态会变为S。 失效（invalid）：缓存行被其他处理器修改过，该值不是最新的值，需要读取主存上最新的值。协议协作如下： 一个处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主存地址的操作，如果监听到，则必须在此操作执行前把其缓存行中的数据写回CPU。 一个处于S状态的缓存行，必须时刻监听使该缓存行无效或者独享该缓存行的请求，如果监听到，则必须把其缓存行状态设置为I。 一个处于E状态的缓存行，必须时刻监听其他试图读取该缓存行对应的主存地址的操作，如果监听到，则必须把其缓存行状态设置为S。 当CPU需要读取数据时，如果其缓存行的状态是I的，则需要从内存中读取，并把自己状态变成S，如果不是I，则可以直接读取缓存中的值，但在此之前，必须要等待其他CPU的监听结果，如其他CPU也有该数据的缓存且状态是M，则需要等待其把缓存更新到内存之后，再读取。 当CPU需要写数据时，只有在其缓存行是M或者E的时候才能执行，否则需要发出特殊的RFO指令(Read Or Ownership，这是一种总线事务)，通知其他CPU置缓存无效(I)，这种情况下会性能开销是相对较大的。在写入完成后，修改其缓存状态为M。 这个图的含义就是当一个core持有一个cacheline的状态为Y时,其它core对应的cacheline应该处于状态X, 比如地址 0x00010000 对应的cacheline在core0上为状态M, 则其它所有的core对应于0x00010000的cacheline都必须为I , 0x00010000 对应的cacheline在core0上为状态S, 则其它所有的core对应于0x00010000的cacheline 可以是S或者I , 另外MESI协议为了提高性能，引入了Store Buffe和Invalidate Queues，还是有可能会引起缓存不一致，还会再引入内存屏障来确保一致性，可以参考[7]和[12] 存储缓存(Store Buffe）也就是常说的写缓存，当处理器修改缓存时，把新值放到存储缓存中，处理器就可以去干别的事了，把剩下的事交给存储缓存。 失效队列（Invalidate Queues）处理失效的缓存也不是简单的，需要读取主存。并且存储缓存也不是无限大的，那么当存储缓存满的时候，处理器还是要等待失效响应的。为了解决上面两个问题，引进了失效队列（invalidate queue）。处理失效的工作如下： 收到失效消息时，放到失效队列中去。为了不让处理器久等失效响应，收到失效消息需要马上回复失效响应。为了不频繁阻塞处理器，不会马上读主存以及设置缓存为invlid，合适的时候再一块处理失效队列。 MESI和CAS关系在x86架构上，CAS被翻译为”lock cmpxchg…”，当两个core同时执行针对同一地址的CAS指令时,其实他们是在试图修改每个core自己持有的Cache line 假设两个core都持有相同地址对应cacheline,且各自cacheline 状态为S, 这时如果要想成功修改,就首先需要把S转为E或者M, 则需要向其它core invalidate 这个地址的cacheline,则两个core都会向ring bus发出 invalidate这个操作, 那么在ringbus上就会根据特定的设计协议仲裁是core0,还是core1能赢得这个invalidate, 胜者完成操作, 失败者需要接受结果, invalidate自己对应的cacheline,再读取胜者修改后的值, 回到起点. 对于我们的CAS操作来说, 其实锁并没有消失,只是转嫁到了ring bus的总线仲裁协议中. 而且大量的多核同时针对一个地址的CAS操作会引起反复的互相invalidate 同一cacheline, 造成pingpong效应, 同样会降低性能（参考[9]）。当然如果真的有性能问题，我觉得这可能会在ns级别体现了,一般的应用程序中使用CAS应该不会引起性能问题 指令重排和内存屏障指令重排现代CPU的速度越来越快，为了充分的利用CPU，在编译器和CPU执行期，都可能对指令重排。举个例子：123LDR R1, [R0];//操作1ADD R2, R1, R1;//操作2ADD R3, R4, R4;//操作3 上面这段代码，如果操作1如果发生cache miss，则需要等待读取内存外存。看看有没有能优先执行的指令，操作2依赖于操作1，不能被优先执行，操作3不依赖1和2，所以能优先执行操作3。JVM的JSR-133规范中定义了as-if-serial语义，即compiler, runtime, and hardware三者需要保证在单线程模型下程序不会感知到指令重排的影响。 在并发模型下，重排序还是可能会引发问题，比较经典的就是“单例模式失效”问题（DoubleCheckedLocking）：12345678910111213141516public class Singleton &#123; private static Singleton instance = null; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if(instance == null) &#123; synchronzied(Singleton.class) &#123; if(instance == null) &#123; instance = new Singleton(); // &#125; &#125; &#125; return instance; &#125;&#125; 上面这段代码，初看没问题，但是在并发模型下，可能会出错,那是因为instance= new Singleton()并非一个原子操作，它实际上下面这三个操作：123memory =allocate(); //1：分配对象的内存空间ctorInstance(memory); //2：初始化对象instance =memory; //3：设置instance指向刚分配的内存地址 上面操作2依赖于操作1，但是操作3并不依赖于操作2，所以JVM是可以针对它们进行指令的优化重排序的，经过重排序后如下：123memory =allocate(); //1：分配对象的内存空间instance =memory; //3：instance指向刚分配的内存地址，此时对象还未初始化ctorInstance(memory); //2：初始化对象 可以看到指令重排之后，instance指向分配好的内存放在了前面，而这段内存的初始化被排在了后面。在多线程场景下，可能A线程执行到了3，B线程发现已经不为空就返回继续执行，就会出错。 在java里面volatile可以防止重排，当然还有另外一个作用即内存可见性，这个知道的人还应该比较普遍，就不说了 内存屏障硬件层的内存屏障分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障。内存屏障有两个作用： 1.阻止屏障两侧的指令重排序；2.强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效。 在JSR规范中定义了4种内存屏障： LoadLoad屏障：（指令Load1; LoadLoad; Load2），在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 LoadStore屏障：（指令Load1; LoadStore; Store2），在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreStore屏障：（指令Store1; StoreStore; Store2），在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 StoreLoad屏障：（指令Store1; StoreLoad; Load2），在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能对于volatile关键字，按照规范会有下面的操作： 在每个volatile写入之前，插入一个StoreStore，写入之后，插入一个StoreLoad 在每个volatile读取之前，插入LoadLoad，之后插入LoadStore 具体到X86来看，其实没那么多指令，只有StoreLoad: 结合上面的【一】和【二】的内容，内存屏障首先阻止了指令的重排，另外也和MESI协议结合，确保了内存的可见性 怎么理解Java 中和 MySQL中的乐观锁、悲观锁？java悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。 乐观锁总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS实现的。 乐观锁常见的两种实现方式乐观锁一般会使用版本号机制或CAS（Compare-and-Swap，即比较并替换）算法实现。 版本号机制一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。 举一个简单的例子： 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。 操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 $50（ $100-$50 ）。 在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 $20 （ $100-$20 ）。 操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。 操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，操作员 B 的提交被驳回。这样，就避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。 CAS算法即 compare and swap（比较与交换），是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。CAS算法涉及到三个操作数 需要读写的内存值 V进行比较的值 A拟写入的新值 B当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自旋操作，即不断的重试。 乐观锁的缺点ABA 问题是乐观锁一个常见的问题。 ABA 问题 如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 “ABA”问题。 JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 循环时间长开销大 自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 只能保证一个共享变量的原子操作 CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。 CAS与synchronized的使用情景简单的来说CAS适用于写比较少的情况下（多读场景，冲突一般较少），synchronized适用于写比较多的情况下（多写场景，冲突一般较多） 对于资源竞争较少（线程冲突较轻）的情况，使用synchronized同步锁进行线程阻塞和唤醒切换以及用户态内核态间的切换操作额外浪费消耗cpu资源；而CAS基于硬件实现，不需要进入内核，不需要切换线程，操作自旋几率较少，因此可以获得更高的性能。 对于资源竞争严重（线程冲突严重）的情况，CAS自旋的概率会比较大，从而浪费更多的CPU资源，效率低于synchronized。补充： Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为 “重量级锁” 。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的 偏向锁 和 轻量级锁 以及其它各种优化之后变得在某些情况下并不是那么重了。synchronized的底层实现主要依靠 Lock-Free 的队列，基本思路是 自旋后阻塞，竞争切换后继续竞争锁，稍微牺牲了公平性，但获得了高吞吐量。在线程冲突较少的情况下，可以获得和CAS类似的性能；而线程冲突严重的情况下，性能远高于CAS。 Mysql悲观锁（Pessimistic Lock）悲观锁的特点是先获取锁，再进行业务操作，即“悲观”的认为获取锁是非常有可能失败的，因此要先确保获取锁成功再进行业务操作。通常所说的“一锁二查三更新”即指的是使用悲观锁。通常来讲在数据库上的悲观锁需要数据库本身提供支持，即通过常用的select … for update操作来实现悲观锁。当数据库执行select for update时会获取被select中的数据行的行锁，因此其他并发执行的select for update如果试图选中同一行则会发生排斥（需要等待行锁被释放），因此达到锁的效果。select for update获取的行锁会在当前事务结束时自动释放，因此必须在事务中使用。 这里需要注意的一点是不同的数据库对select for update的实现和支持都是有所区别的，例如oracle支持select for update no wait，表示如果拿不到锁立刻报错，而不是等待，mysql就没有no wait这个选项。另外mysql还有个问题是select for update语句执行中所有扫描过的行都会被锁上，这一点很容易造成问题。因此如果在mysql中用悲观锁务必要确定走了索引，而不是全表扫描。 乐观锁（Optimistic Lock）乐观锁的特点先进行业务操作，不到万不得已不去拿锁。即“乐观”的认为拿锁多半是会成功的，因此在进行完业务操作需要实际更新数据的最后一步再去拿一下锁就好。 乐观锁在数据库上的实现完全是逻辑的，不需要数据库提供特殊的支持。一般的做法是在需要锁的数据上增加一个版本号，或者时间戳，然后按照如下方式实现：123456781. SELECT data AS old_data, version AS old_version FROM …;2. 根据获取的数据进行业务操作，得到new_data和new_version3. UPDATE SET data = new_data, version = new_version WHERE version = old_versionif (updated row &gt; 0) &#123; // 乐观锁获取成功，操作完成&#125; else &#123; // 乐观锁获取失败，回滚并重试&#125; 乐观锁是否在事务中其实都是无所谓的，其底层机制是这样：在数据库内部update同一行的时候是不允许并发的，即数据库每次执行一条update语句时会获取被update行的写锁，直到这一行被成功更新后才释放。因此在业务操作进行前获取需要锁的数据的当前版本号，然后实际更新数据时再次对比版本号确认与之前获取的相同，并更新版本号，即可确认这之间没有发生并发的修改。如果更新失败即可认为老版本的数据已经被并发修改掉而不存在了，此时认为获取锁失败，需要回滚整个业务操作并可根据需要重试整个过程。 总结 乐观锁在不发生取锁失败的情况下开销比悲观锁小，但是一旦发生失败回滚开销则比较大，因此适合用在取锁失败概率比较小的场景，可以提升系统并发性能 乐观锁还适用于一些比较特殊的场景，例如在业务操作过程中无法和数据库保持连接等悲观锁无法适用的地方 对线程池的理解，项目中哪个地方使用了，如何使用的，用的Excutor框架中的哪个实现类，为什么用这个线程池线程池的作用线程池作用就是限制系统中执行线程的数量。 根据系统的环境情况，可以自动或手动设置线程数量，达到运行的最佳效果；少了浪费了系统资源，多了造成系统拥挤效率不高。用线程池控制线程数量，其他线程排队等候。一个任务执行完毕，再从队列的中取最前面的任务开始执行。若队列中没有等待进程，线程池的这一资源处于等待。当一个新任务需要运行时，如果线程池中有等待的工作线程，就可以开始运行了；否则进入等待队列。 为什么要用线程池？减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。 可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。 Java里面线程池的顶级接口是Executor，但是严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService。 比较重要的几个类： 名称 作用 ExecutorService 真正的线程池接口。 ScheduledExecutorService 能和Timer/TimerTask类似，解决那些需要任务重复执行的问题。 ThreadPoolExecutor ExecutorService的默认实现。 ScheduledThreadPoolExecutor 继承ThreadPoolExecutor的ScheduledExecutorService接口实现，周期性任务调度的类实现。 要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程池不是较优的，因此在Executors类里面提供了一些静态工厂，生成一些常用的线程池。 newSingleThreadExecutor创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺序按照任务的提交顺序执行。 newFixedThreadPool创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线程。 newCachedThreadPool创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程， 那么就会回收部分空闲（60秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。 newScheduledThreadPool创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。 ThreadPoolExecutor详解ThreadPoolExecutor的完整构造方法的签名是：ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) . corePoolSize - 池中所保存的线程数，包括空闲线程。 maximumPoolSize-池中允许的最大线程数。 keepAliveTime - 当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间。 unit - keepAliveTime 参数的时间单位。 workQueue - 执行前用于保持任务的队列。此队列仅保持由 execute方法提交的 Runnable任务。 threadFactory - 执行程序创建新线程时使用的工厂。 handler - 由于超出线程范围和队列容量而使执行被阻塞时所使用的处理程序。 ThreadPoolExecutor是Executors类的底层实现。 下面介绍一下几个类的源码： ExecutorService newFixedThreadPool (int nThreads):固定大小线程池。 可以看到，corePoolSize和maximumPoolSize的大小是一样的（实际上，后面会介绍，如果使用无界queue的话maximumPoolSize参数是没有意义的），keepAliveTime和unit的设值表名什么？-就是该实现不想keep alive！最后的BlockingQueue选择了LinkedBlockingQueue，该queue有一个特点，他是无界的。 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads,0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; ExecutorService newSingleThreadExecutor()：单线程123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; ExecutorService newCachedThreadPool()：无界线程池，可以进行自动线程回收 这个实现就有意思了。首先是无界的线程池，所以我们可以发现maximumPoolSize为big big。其次BlockingQueue的选择上使用SynchronousQueue。可能对于该BlockingQueue有些陌生，简单说：该QUEUE中，每个插入操作必须等待另一个线程的对应移除操作。 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 先从BlockingQueue&lt;Runnable&gt; workQueue这个入参开始说起。在JDK中，其实已经说得很清楚了，一共有三种类型的queue。 所有BlockingQueue 都可用于传输和保持提交的任务。可以使用此队列与池大小进行交互： 如果运行的线程少于 corePoolSize，则 Executor始终首选添加新的线程，而不进行排队。（如果当前运行的线程小于corePoolSize，则任务根本不会存放，添加到queue中，而是直接抄家伙（thread）开始运行） 如果运行的线程等于或多于 corePoolSize，则 Executor始终首选将请求加入队列，而不添加新的线程。 如果无法将请求加入队列，则创建新的线程，除非创建此线程超出 maximumPoolSize，在这种情况下，任务将被拒绝。 queue上的三种类型。 排队有三种通用策略： 直接提交。工作队列的默认选项是 SynchronousQueue，它将任务直接提交给线程而不保持它们。在此，如果不存在可用于立即运行任务的线程，则试图把任务加入队列将失败，因此会构造一个新的线程。此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。直接提交通常要求无界 maximumPoolSizes 以避免拒绝新提交的任务。当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 无界队列。使用无界队列（例如，不具有预定义容量的 LinkedBlockingQueue）将导致在所有 corePoolSize 线程都忙时新任务在队列中等待。这样，创建的线程就不会超过 corePoolSize。（因此，maximumPoolSize的值也就无效了。）当每个任务完全独立于其他任务，即任务执行互不影响时，适合于使用无界队列；例如，在 Web页服务器中。这种排队可用于处理瞬态突发请求，当命令以超过队列所能处理的平均数连续到达时，此策略允许无界线程具有增长的可能性。 有界队列。当使用有限的 maximumPoolSizes时，有界队列（如 ArrayBlockingQueue）有助于防止资源耗尽，但是可能较难调整和控制。队列大小和最大池大小可能需要相互折衷：使用大型队列和小型池可以最大限度地降低 CPU 使用率、操作系统资源和上下文切换开销，但是可能导致人工降低吞吐量。如果任务频繁阻塞（例如，如果它们是 I/O边界），则系统可能为超过您许可的更多线程安排时间。使用小型队列通常要求较大的池大小，CPU使用率较高，但是可能遇到不可接受的调度开销，这样也会降低吞吐量。 BlockingQueue的选择 例子一：使用直接提交策略，也即SynchronousQueue。首先SynchronousQueue是无界的，也就是说他存数任务的能力是没有限制的，但是由于该Queue本身的特性，在某次添加元素后必须等待其他线程取走后才能继续添加。在这里不是核心线程便是新创建的线程，但是我们试想一样下，下面的场景。 我们使用一下参数构造ThreadPoolExecutor： 1new ThreadPoolExecutor( 2, 3, 30, TimeUnit.SECONDS,new SynchronousQueue&lt;Runnable&gt;(),new RecorderThreadFactory("CookieRecorderPool"),new ThreadPoolExecutor.CallerRunsPolicy()); 1new ThreadPoolExecutor(2, 3, 30, TimeUnit.SECONDS,new SynchronousQueue&lt;Runnable&gt;(),new RecorderThreadFactory("CookieRecorderPool"),new ThreadPoolExecutor.CallerRunsPolicy()); 当核心线程已经有2个正在运行. 此时继续来了一个任务（A），根据前面介绍的“如果运行的线程等于或多于 corePoolSize，则 Executor始终首选将请求加入队列，而不添加新的线程。”,所以A被添加到queue中。 又来了一个任务（B），且核心2个线程还没有忙完，OK，接下来首先尝试1中描述，但是由于使用的SynchronousQueue，所以一定无法加入进去。 此时便满足了上面提到的“如果无法将请求加入队列，则创建新的线程，除非创建此线程超出maximumPoolSize，在这种情况下，任务将被拒绝。”，所以必然会新建一个线程来运行这个任务。 暂时还可以，但是如果这三个任务都还没完成，连续来了两个任务，第一个添加入queue中，后一个呢？queue中无法插入，而线程数达到了maximumPoolSize，所以只好执行异常策略了。 所以在使用SynchronousQueue通常要求maximumPoolSize是无界的，这样就可以避免上述情况发生（如果希望限制就直接使用有界队列）。对于使用SynchronousQueue的作用jdk中写的很清楚：此策略可以避免在处理可能具有内部依赖性的请求集时出现锁。 什么意思？如果你的任务A1，A2有内部关联，A1需要先运行，那么先提交A1，再提交A2，当使用SynchronousQueue我们可以保证，A1必定先被执行，在A1么有被执行前，A2不可能添加入queue中。 例子二：使用无界队列策略，即LinkedBlockingQueue这个就拿newFixedThreadPool来说，根据前文提到的规则： 如果运行的线程少于 corePoolSize，则 Executor 始终首选添加新的线程，而不进行排队。那么当任务继续增加，会发生什么呢？ 如果运行的线程等于或多于 corePoolSize，则 Executor 始终首选将请求加入队列，而不添加新的线程。OK，此时任务变加入队列之中了，那什么时候才会添加新线程呢？ 如果无法将请求加入队列，则创建新的线程，除非创建此线程超出 maximumPoolSize，在这种情况下，任务将被拒绝。这里就很有意思了，可能会出现无法加入队列吗？不像SynchronousQueue那样有其自身的特点，对于无界队列来说，总是可以加入的（资源耗尽，当然另当别论）。换句说，永远也不会触发产生新的线程！corePoolSize大小的线程数会一直运行，忙完当前的，就从队列中拿任务开始运行。所以要防止任务疯长，比如任务运行的实行比较长，而添加任务的速度远远超过处理任务的时间，而且还不断增加，不一会儿就爆了。 **例子三：有界队列，使用ArrayBlockingQueue。这个是最为复杂的使用，所以JDK不推荐使用也有些道理。与上面的相比，最大的特点便是可以防止资源耗尽的情况发生。 举例来说，请看如下构造方法：1new ThreadPoolExecutor(2, 4, 30, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2),new RecorderThreadFactory("CookieRecorderPool"), new ThreadPoolExecutor.CallerRunsPolicy()); 1new ThreadPoolExecutor(2, 4, 30, TimeUnit.SECONDS,new ArrayBlockingQueue&lt;Runnable&gt;(2),new RecorderThreadFactory("CookieRecorderPool"),new ThreadPoolExecutor.CallerRunsPolicy()); 假设，所有的任务都永远无法执行完。 对于首先来的A,B来说直接运行，接下来，如果来了C,D，他们会被放到queue中，如果接下来再来E,F，则增加线程运行E，F。但是如果再来任务，队列无法再接受了，线程数也到达最大的限制了，所以就会使用拒绝策略来处理。 keepAliveTimejdk中的解释是：当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间。 有点拗口，其实这个不难理解，在使用了“池”的应用中，大多都有类似的参数需要配置。比如数据库连接池，DBCP中的maxIdle，minIdle参数。 什么意思？接着上面的解释，后来向老板派来的工人始终是“借来的”，俗话说“有借就有还”，但这里的问题就是什么时候还了，如果借来的工人刚完成一个任务就还回去，后来发现任务还有，那岂不是又要去借？这一来一往，老板肯定头也大死了。 合理的策略：既然借了，那就多借一会儿。直到“某一段”时间后，发现再也用不到这些工人时，便可以还回去了。这里的某一段时间便是keepAliveTime的含义，TimeUnit为keepAliveTime值的度量。 RejectedExecutionHandler 另一种情况便是，即使向老板借了工人，但是任务还是继续过来，还是忙不过来，这时整个队伍只好拒绝接受了。 RejectedExecutionHandler接口提供了对于拒绝任务的处理的自定方法的机会。在ThreadPoolExecutor中已经默认包含了4中策略，因为源码非常简单，这里直接贴出来。 CallerRunsPolicy：线程调用运行该任务的 execute 本身。此策略提供简单的反馈控制机制，能够减缓新任务的提交速度。123456public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125; 这个策略显然不想放弃执行任务。但是由于池中已经没有任何资源了，那么就直接使用调用该execute的线程本身来执行。 AbortPolicy：处理程序遭到拒绝将抛出运行时RejectedExecutionException1234public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException();&#125; 这种策略直接抛出异常，丢弃任务。 DiscardPolicy：不能执行的任务将被删除1234public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125; 这种策略和AbortPolicy几乎一样，也是丢弃任务，只不过他不抛出异常。 DiscardOldestPolicy：如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序（如果再次失败，则重复此过程）1234567public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125;&#125; 该策略就稍微复杂一些，在pool没有关闭的前提下首先丢掉缓存在队列中的最早的任务，然后重新尝试运行该任务。这个策略需要适当小心。 设想:如果其他线程都还在运行，那么新来任务踢掉旧任务，缓存在queue中，再来一个任务又会踢掉queue中最老任务。 总结keepAliveTime和maximumPoolSize及BlockingQueue的类型均有关系。如果BlockingQueue是无界的，那么永远不会触发maximumPoolSize，自然keepAliveTime也就没有了意义。 反之，如果核心数较小，有界BlockingQueue数值又较小，同时keepAliveTime又设的很小，如果任务频繁，那么系统就会频繁的申请回收线程。 怎么理解线程安全？线程安全就是多线程访问时，采用了加锁机制，当一个线程访问该类的某个数据时，进行保护，其他线程不能进行访问直到该线程读取完，其他线程才可使用。不会出现数据不一致或者数据污染。 线程不安全就是不提供数据访问保护，有可能出现多个线程先后更改数据造成所得到的数据是脏数据 安全性：比如一个 ArrayList 类，在添加一个元素的时候，它可能会有两步来完成：1. 在 Items[Size] 的位置存放此元素；2. 增大 Size 的值。在单线程运行的情况下，如果 Size = 0，添加一个元素后，此元素在位置 0，而且 Size=1；而如果是在多线程情况下，比如有两个线程，线程 A 先将元素存放在位置 0。但是此时 CPU 调度线程A暂停，线程 B 得到运行的机会。线程B也向此 ArrayList 添加元素，因为此时 Size 仍然等于 0 （注意哦，我们假设的是添加一个元素是要两个步骤哦，而线程A仅仅完成了步骤1），所以线程B也将元素存放在位置0。然后线程A和线程B都继续运行，都增加 Size 的值。那好，我们来看看 ArrayList 的情况，元素实际上只有一个，存放在位置 0，而 Size 却等于 2。这就是“线程不安全”了。 一个final修饰的属性，定义的时候没有初始化，在无参构造函数中初始化，可以吗，为什么static static修饰一个属性字段，那么这个属性字段将成为类本身的资源，public修饰为共有的，可以在类的外部通过test.a来访问此属性；在类内部任何地方可以使用。如果被修饰为private私有，那么只能在类内部使用。 如果属性被修饰为static静态类资源，那么这个字段永远只有一个，也就是说不管你new test()多少个类的对象，操作的永远都只是属于类的那一块内存资源。 final final 用于声明属性、方法和类，分别表示属性一旦被分配内存空间就必须初始化并且以后不可变；方法一旦定义必须有实现代码并且子类里不可被覆盖；类一旦定义不能被定义为抽象类或是接口，因为不可被继承。 被final修饰而没有被static修饰的类的属性变量只能在两种情况下初始化： 在它被定义的时候 1234567public class Test&#123; public final int a=0; private Test()&#123; &#125;&#125; 在构造函数里初始化 1234567public class Test&#123; public final int a; private Test()&#123; a=0; &#125;&#125; 同时被final和static修饰的类的属性变量只能在两种情况下初始化 在它被定义的时候 1234567public class Test&#123; public static final int a=0; private Test()&#123; &#125;&#125; 在类的静态块里初始化 123456public class Test&#123; public static final int a; static&#123; a=0; &#125;&#125; 当类的属性被同时被修饰为static和final的时候，他属于类的资源，那么就是类在被加载进内存的时候（也就是应用程序启动的时候）就要为属性分配内存，所以此时属性已经存在，它又被final修饰，所以必须在属性定义了以后就给其初始化值。而构造函数是在当类被实例化的时候才会执行，所以不能用构造函数。而static块是类被加载的时候执行，且只执行这一次，所以在static块中可以执行初始化。 HashMap，concurrentHashMap底实现序列化层实现实现了Serializable接口 Java中 Serializable 是 标示一个类是可以被 JDK 序列化和反序列化的，他只是一个接口并没有任何操作。 序列化，本质就是将内存里面的 Java 对象写入到流里面，还可以将流里面的Java序列化数据反序列化还原到实例对象。 当然，序列化的方法很多，常见的就是 JDK 序列化、JSON 序列化、还有 protobuffer 等等。 每一种框架，序列化和反序列化都是有一个统一的数据格式规范和算法。 什么是红黑树，什么是B-Tree，为什么HashMap中用红黑树不用其他树？树的概念前面有。 那么很多人就有疑问为什么是使用红黑树而不是AVL树，AVL树是完全平衡二叉树阿？ 最主要的一点是： 在CurrentHashMap中是加锁了的，实际上是读写锁，如果写冲突就会等待，如果插入时间过长必然等待时间更长，而红黑树相对AVL树他的插入更快！ 问题：为什么不使用AVL树而使用红黑树？红黑树和AVL树都是最常用的平衡二叉搜索树，它们的查找、删除、修改都是O(lgn) time AVL树和红黑树有几点比较和区别：（1）AVL树是更加严格的平衡，因此可以提供更快的查找速度，一般读取查找密集型任务，适用AVL树。（2）红黑树更适合于插入修改密集型任务。（3）通常，AVL树的旋转比红黑树的旋转更加难以平衡和调试。 总结： （1）AVL以及红黑树是高度平衡的树数据结构。它们非常相似，真正的区别在于在任何添加/删除操作时完成的旋转操作次数。 （2）两种实现都缩放为a O(lg N)，其中N是叶子的数量，但实际上AVL树在查找密集型任务上更快：利用更好的平衡，树遍历平均更短。另一方面，插入和删除方面，AVL树速度较慢：需要更高的旋转次数才能在修改时正确地重新平衡数据结构。 （3）在AVL树中，从根到任何叶子的最短路径和最长路径之间的差异最多为1。在红黑树中，差异可以是2倍。 （4）两个都给O（log n）查找，但平衡AVL树可能需要O（log n）旋转，而红黑树将需要最多两次旋转使其达到平衡（尽管可能需要检查O（log n）节点以确定旋转的位置）。旋转本身是O（1）操作，因为你只是移动指针。 计算密集型/IO密集型任务分别如何设置线程池的核心线程数和最大线程数，为什么这么设置？任务类型举例:CPU密集型: 例如,一般我们系统的静态资源,比如js,css等,会存在一个版本号,如 main.js?v0,每当用户访问这个资源的时候,会发送一个比对请求到服务端,比对本地静态文件版本和服务端的文件版本是否一致,不一致则更新.这种任务一般不占用大量IO,所以后台服务器可以快速处理,压力落在CPU上. I/O密集型:比方说近期我们做的万科CRM系统,常有大数据量的查询和批量插入操作,此时的压力主要在I/O上. 线程数与任务类型的关系:与CPU密集型的关系:一般情况下,CPU核心数 == 最大同时执行线程数.在这种情况下(设CPU核心数为n),大量客户端会发送请求到服务器,但是服务器最多只能同时执行n个线程. 设线程池工作队列长度为m,且m&gt;&gt;n,则此时会导致CPU频繁切换线程来执行(如果CPU使用的是FCFS,则不会频繁切换,如使用的是其他CPU调度算法,如时间片轮转法,最短时间优先,则可能会导致频繁的线程切换). 所以这种情况下,无需设置过大的线程池工作队列,(工作队列长度 = CPU核心数 || CPU核心数+1) 即可. 与I/O密集型的关系:1个线程对应1个方法栈,线程的生命周期与方法栈相同. 比如某个线程的方法栈对应的入站顺序为:controller()-&gt;service()-&gt;DAO(),由于DAO长时间的I/O操作,导致该线程一直处于工作队列,但它又不占用CPU,则此时有1个CPU是处于空闲状态的. 所以,这种情况下,应该加大线程池工作队列的长度(如果CPU调度算法使用的是FCFS,则无法切换),尽量不让CPU空闲下来,提高CPU利用率. 画一下Java 线程几个状态及状态之间互相转换的图？ 在Java中线程的状态一共被分成6种： 初始态：NEW创建一个Thread对象，但还未调用start()启动线程时，线程处于初始态。 运行态：RUNNABLE在Java中，运行态包括就绪态 和 运行态。 就绪态 该状态下的线程已经获得执行所需的所有资源，只要CPU分配执行权就能运行。 所有就绪态的线程存放在就绪队列中。 运行态 获得CPU执行权，正在执行的线程。 由于一个CPU同一时刻只能执行一条线程，因此每个CPU每个时刻只有一条运行态的线程。 阻塞态 当一条正在执行的线程请求某一资源失败时，就会进入阻塞态。 而在Java中，阻塞态专指请求锁失败时进入的状态。 由一个阻塞队列存放所有阻塞态的线程。 处于阻塞态的线程会不断请求资源，一旦请求成功，就会进入就绪队列，等待执行。 PS：锁、IO、Socket等都资源。 等待态 当前线程中调用wait、join、park函数时，当前线程就会进入等待态。 也有一个等待队列存放所有等待态的线程。 线程处于等待态表示它需要等待其他线程的指示才能继续运行。 进入等待态的线程会释放CPU执行权，并释放资源（如：锁） 终止态线程执行结束后的状态。 注意 wait()方法会释放CPU执行权 和 占有的锁。 sleep(long)方法仅释放CPU使用权，锁仍然占用；线程被放入超时等待队列，与yield相比，它会使线程较长时间得不到运行。 yield()方法仅释放CPU执行权，锁仍然占用，线程会被放入就绪队列，会在短时间内再次执行。 wait和notify必须配套使用，即必须使用同一把锁调用； wait和notify必须放在一个同步块中 调用wait和notify的对象必须是他们所处同步块的锁对象。 对线程池的理解，在项目中如何使用的，多个线程之间如何共享数据，多个进程之间如何共享数据？首先想到的是将共享数据设置为全局变量，并且用static修饰，但是static修饰的变量是类变量，生命周期太长了，占用内存。 方法一：多个线程对共享数据的操作是相同的，那么创建一个Runnable的子类对象，将这个对象作为参数传递给Thread的构造方法，此时因为多个线程操作的是同一个Runnable的子类对象，所以他们操作的是同一个共享数据。比如：买票系统，所以的线程的操作都是对票数减一的操作。 方法二：多个线程对共享数据的操作是不同的，将共享数据和操作共享数据的方法放在同一对象中，将这个对象作为参数传递给Runnable的子类，在子类中用该对象的方法对共享数据进行操作。如：生产者消费者。 方法三：多个线程对共享数据的操作是不同的， 用内部类的方式去实现，创建Runnable的子类作为内部类，将共享对象作为全局变量，在Runnable的子类中对共享数据进行操作。 方法四:ThreadLocal实现线程范围内数据的共享 设计模式怎么理解命令模式和观察者模式，手写一个观察者模式或者命令模式的代码，策略模式也行 命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。 意图：将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化。 主要解决：在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。 何时使用：在某些场合，比如要对行为进行”记录、撤销/重做、事务”等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将”行为请求者”与”行为实现者”解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。 如何解决：通过调用者调用接受者执行命令，顺序：调用者→接受者→命令。 应用实例：struts 1 中的 action 核心控制器 ActionServlet 只有一个，相当于 Invoker，而模型层的类会随着不同的应用有不同的模型类，相当于具体的 Command。 优点： 1、降低了系统耦合度。 2、新的命令可以很容易添加到系统中去。 缺点：使用命令模式可能会导致某些系统有过多的具体命令类。 使用场景：认为是命令的地方都可以使用命令模式，比如： 1、GUI 中每一个按钮都是一条命令。 2、模拟 CMD。 注意事项：系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作，也可以考虑使用命令模式，见命令模式的扩展。 我们首先创建作为命令的接口 Order，然后创建作为请求的 Stock 类。实体命令类 BuyStock 和 SellStock，实现了 Order 接口，将执行实际的命令处理。创建作为调用对象的类 Broker，它接受订单并能下订单。Broker 对象使用命令模式，基于命令的类型确定哪个对象执行哪个命令。CommandPatternDemo，我们的演示类使用 Broker 类来演示命令模式。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public interface Order &#123; void execute();&#125;public class Stock &#123; private String name = "ABC"; private int quantity = 10; public void buy()&#123; System.out.println("Stock [ Name: "+name+", Quantity: " + quantity +" ] bought"); &#125; public void sell()&#123; System.out.println("Stock [ Name: "+name+", Quantity: " + quantity +" ] sold"); &#125;&#125;public class BuyStock implements Order &#123; private Stock abcStock; public BuyStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; public void execute() &#123; abcStock.buy(); &#125;&#125;public class SellStock implements Order &#123; private Stock abcStock; public SellStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; public void execute() &#123; abcStock.sell(); &#125;&#125;import java.util.ArrayList;import java.util.List; public class Broker &#123; private List&lt;Order&gt; orderList = new ArrayList&lt;Order&gt;(); public void takeOrder(Order order)&#123; orderList.add(order); &#125; public void placeOrders()&#123; for (Order order : orderList) &#123; order.execute(); &#125; orderList.clear(); &#125;&#125;public class CommandPatternDemo &#123; public static void main(String[] args) &#123; Stock abcStock = new Stock(); BuyStock buyStockOrder = new BuyStock(abcStock); SellStock sellStockOrder = new SellStock(abcStock); Broker broker = new Broker(); broker.takeOrder(buyStockOrder); broker.takeOrder(sellStockOrder); broker.placeOrders(); &#125;&#125;Stock [ Name: ABC, Quantity: 10 ] boughtStock [ Name: ABC, Quantity: 10 ] sold 观察者模式，当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知它的依赖对象。观察者模式属于行为型模式。 意图：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 主要解决：一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 何时使用：一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决：使用面向对象技术，可以将这种依赖关系弱化。 关键代码：在抽象类里有一个 ArrayList 存放观察者们。 应用实例：1、拍卖的时候，拍卖师观察最高标价，然后通知给其他竞价者竞价。2、西游记里面悟空请求菩萨降服红孩儿，菩萨洒了一地水招来一个老乌龟，这个乌龟就是观察者，他观察菩萨洒水这个动作。 优点： 1、观察者和被观察者是抽象耦合的。 2、建立一套触发机制。 缺点：1、如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 2、如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 3、观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 使用场景：1、一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。2、一个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度。3、一个对象必须通知其他对象，而并不知道这些对象是谁。4、需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 实现：观察者模式使用三个类 Subject、Observer 和 Client。Subject 对象带有绑定观察者到 Client 对象和从 Client 对象解绑观察者的方法。我们创建 Subject 类、Observer 抽象类和扩展了抽象类 Observer 的实体类。ObserverPatternDemo，我们的演示类使用 Subject 和实体类对象来演示观察者模式。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import java.util.ArrayList;import java.util.List; public class Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;Observer&gt;(); private int state; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; notifyAllObservers(); &#125; public void attach(Observer observer)&#123; observers.add(observer); &#125; public void notifyAllObservers()&#123; for (Observer observer : observers) &#123; observer.update(); &#125; &#125; &#125;public abstract class Observer &#123; protected Subject subject; public abstract void update();&#125;public class BinaryObserver extends Observer&#123; public BinaryObserver(Subject subject)&#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println( "Binary String: " + Integer.toBinaryString( subject.getState() ) ); &#125;&#125;public class OctalObserver extends Observer&#123; public OctalObserver(Subject subject)&#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println( "Octal String: " + Integer.toOctalString( subject.getState() ) ); &#125;&#125;public class HexaObserver extends Observer&#123; public HexaObserver(Subject subject)&#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println( "Hex String: " + Integer.toHexString( subject.getState() ).toUpperCase() ); &#125;&#125;public class ObserverPatternDemo &#123; public static void main(String[] args) &#123; Subject subject = new Subject(); new HexaObserver(subject); new OctalObserver(subject); new BinaryObserver(subject); System.out.println("First state change: 15"); subject.setState(15); System.out.println("Second state change: 10"); subject.setState(10); &#125;&#125; 策略模式:在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。 意图：定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。 主要解决：在有多种算法相似的情况下，使用 if…else 所带来的复杂和难以维护。 何时使用：一个系统有许多许多类，而区分它们的只是他们直接的行为。 如何解决：将这些算法封装成一个一个的类，任意地替换。 应用实例：1、诸葛亮的锦囊妙计，每一个锦囊就是一个策略。 2、旅行的出游方式，选择骑自行车、坐汽车，每一种旅行方式都是一个策略。 3、JAVA AWT中的LayoutManager。 优点： 1、算法可以自由切换。2、避免使用多重条件判断。3、扩展性良好。 缺点：1、策略类会增多。2、所有策略类都需要对外暴露。 使用场景：1、如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。2、一个系统需要动态地在几种算法中选择一种。3、如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。 注意事项：如果一个系统的策略多于四个，就需要考虑使用混合模式，解决策略类膨胀的问题。 实现:我们将创建一个定义活动的 Strategy 接口和实现了 Strategy 接口的实体策略类。Context 是一个使用了某种策略的类。StrategyPatternDemo，我们的演示类使用 Context 和策略对象来演示 Context 在它所配置或使用的策略改变时的行为变化。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public interface Strategy &#123; public int doOperation(int num1, int num2);&#125;public class OperationAdd implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 + num2; &#125;&#125;public class OperationSubstract implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 - num2; &#125;&#125;public class OperationMultiply implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 * num2; &#125;&#125;public class Context &#123; private Strategy strategy; public Context(Strategy strategy)&#123; this.strategy = strategy; &#125; public int executeStrategy(int num1, int num2)&#123; return strategy.doOperation(num1, num2); &#125;&#125;public class StrategyPatternDemo &#123; public static void main(String[] args) &#123; Context context = new Context(new OperationAdd()); System.out.println("10 + 5 = " + context.executeStrategy(10, 5)); context = new Context(new OperationSubstract()); System.out.println("10 - 5 = " + context.executeStrategy(10, 5)); context = new Context(new OperationMultiply()); System.out.println("10 * 5 = " + context.executeStrategy(10, 5)); &#125;&#125; 设计模式在项目中哪个地方用到了，怎么使用的，能不能画一个你熟悉的设计模式的UML图，手写单例模式，手写静态内部类实现的单例模式。123456789101112public class Singleton &#123; private static class SingletonHolder &#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton ()&#123;&#125; public static final Singleton getInstance() &#123; return SingletonHolder.INSTANCE; &#125; &#125; 掌握哪些设计模式，常用哪些，项目中如何使用的，为什么用这个，不用那个？手写一个线程安全的单例模式 设计模式：工厂模式、抽象工厂模式、单例模式、建造者模式、原型模式、适配器模式、桥接模式、过滤器模式、组合模式、装饰器模式、外观模式、享元模式、代理模式、责任链模式、命令模式、解释器模式、迭代器模式、中介者模式、备忘录模式、观察者模式、状态模式、空对象模式、策略模式、模板模式、访问者模式、MVC模式、业务代表模式、组合实体模式、数据访问对象模式、前端控制器模式、拦截过滤器模式、服务定位器模式、传输对象模式。 线程安全的单例模式12345678910111213141516public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Data Redis与Redisson对比]]></title>
    <url>%2F2019%2F03%2F26%2FSpring%20Data%20Redis%E4%B8%8ERedisson%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[Spring Data Redis与Redisson对比Spring Data RedisSpring Data Redis是更大的Spring Data系列的一部分，可以从Spring应用程序轻松配置和访问Redis。它提供了与商店交互的低级和高级抽象，使用户免于基础设施问题。Spring Boot 从 2.0版本开始，将默认的Redis客户端Jedis替换问Lettuce。 特性 连接包作为多个Redis驱动程序/连接器的低级抽象（Jedis和Lettuce。不推荐支持JRedis和SRP。） 异常转换到Spring的便携式数据访问异常层次结构Redis的驱动程序例外 RedisTemplate，提供高级抽象，用于执行各种Redis操作，异常转换和序列化支持 Pubsub支持（例如消息驱动的POJO的MessageListenerContainer） Redis Sentinel和Redis Cluster支持 JDK，String，JSON和Spring Object / XML映射序列化程序 在Redis之上的JDK Collection实现 原子计数器支持classes 排序和流水线功能 专门支持SORT，SORT / GET模式和返回的批量值 Redis 实现了Spring 3.1缓存抽象 自动实现Repository接口，包括支持自定义查找程序方法@EnableRedisRepositories CDI对存储库的支持 使用在pom.xml中加入12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;&lt;/dependency&gt; 在application.yml中加入123456789101112spring: redis: database: 6 #Redis索引0~15，默认为0 host: 127.0.0.1 port: 6379 password: #密码（默认为空） pool: max-active: 8 #连接池最大连接数（使用负值表示没有限制） max-wait: -1ms #连接池最大阻塞等待时间（使用负值表示没有限制） max-idle: 5 #连接池中的最大空闲连接 min-idle: 0 #连接池中的最小空闲连接 timeout: 10000ms #连接超时时间（毫秒） 加入配置类123456789101112131415161718192021222324@Configuration@EnableCachingpublic class RedisConfiguration extends CachingConfigurerSupport &#123; /** * RedisTemplate配置 * * @param redisConnectionFactory redisConnectionFactory * @return RedisTemplate */ @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; // 配置redisTemplate RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); //key序列化 redisTemplate.setKeySerializer(new StringRedisSerializer()); //value序列化 redisTemplate.setValueSerializer(new GenericJackson2JsonRedisSerializer()); redisTemplate.afterPropertiesSet(); return redisTemplate; &#125;&#125; 代码使用12345678910111213141516171819202122232425262728@Autowiredprivate RedisTemplate redisTemplate;@Autowiredprivate RedisConnectionFactory redisConnectionFactory;@SuppressWarnings("unchecked")public void test()&#123; //设置键值对 redisTemplate.opsForValue().set("test:set1", "testValue1"); //设置键值对数组 redisTemplate.opsForSet().add("test:set2", "asdf"); //数据hash存入 redisTemplate.opsForHash().put("hash1", "name1", "lms1"); redisTemplate.opsForHash().put("hash1", "name2", "lms2"); redisTemplate.opsForHash().put("hash1", "name3", "lms3"); //获取 System.out.println(redisTemplate.opsForValue().get("test:set")); //hash获取 System.out.println(redisTemplate.opsForHash().get("hash1", "name1")); //发布、订阅消息（更多请参考 https://docs.spring.io/spring-data/data-redis/docs/current/reference/html/ String message = "dinghuang123@gmail.com"; byte[] msg = message.getBytes(); byte[] channel = message.getBytes(); redisConnectionFactory.getConnection().publish(msg, channel); redisTemplate.convertAndSend("hello!", "world");&#125; 如图所示 RedissonRedisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务。其中包括(BitSet, Set, Multimap, SortedSet, Map, List, Queue, BlockingQueue, Deque, BlockingDeque, Semaphore, Lock, AtomicLong, CountDownLatch, Publish / Subscribe, Bloom filter, Remote service, Spring cache, Executor service, Live Object service, Scheduler service) Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。能够完美的在云计算环境里使用，并且支持AWS ElastiCache主备版，AWS ElastiCache集群版，Azure Redis Cache和阿里云（Aliyun）的云数据库Redis版。Redisson底层采用的是Netty 框架。支持Redis 2.8以上版本，支持Java1.6+以上版本。 Redisson作为独立节点 可以用于独立执行其他节点发布到分布式执行服务 和 分布式调度任务服务 里的远程任务。 特性 复制的Redis服务器模式（还支持AWS ElastiCache和Azure Redis缓存）： 自动主服务器更改发现 群集Redis服务器模式（还支持AWS ElastiCache和Azure Redis缓存： 自动主从服务器发现 自动状态和拓扑更新 自动插槽更改发现 Sentinel Redis服务器模式： 自动主，从和服务器发现 自动状态和拓扑更新 掌握Slave Redis服务器模式 单Redis服务器模式 线程安全的实现 Reactive Streams API 异步 API 异步连接池 Lua脚本 分布式Java对象Object holder，Binary stream holder，Geospatial holder，BitSet，AtomicLong，AtomicDouble，PublishSubscribe，Bloom filter，HyperLogLog 分布式Java集合Map，Multimap，Set，List，SortedSet，ScoredSortedSet，LexSortedSet，Queue，Deque，Blocking Queue，Bounded Blocking Queue，Blocking Deque，Delayed Queue，Priority Queue，Priority Deque 分布式Java锁和同步器Lock，FairLock，MultiLock，RedLock，ReadWriteLock，Semaphore，PermitExpirableSemaphore，CountDownLatch 分布式服务远程服务，Live Object服务，Executor服务，Scheduler服务，MapReduce服务 Spring框架 Spring Cache实现- Spring Transaction API实现 Spring Data Redis集成 Spring Boot Starter实现 Hibernate Cache实现 Transactions API- XA Transaction API实现 JCache API（JSR-107）实现 Tomcat会话管理器实现 Spring Session实现 Redis流水线（命令批处理） 支持Android平台 支持自动重新连接 支持无法发送命令自动重试 支持OSGi 支持SSL 支持许多流行的编解码器（Jackson JSON，Avro，Smile，CBOR，MsgPack，Kryo，Amazon Ion，FST，LZ4，Snappy和JDK Serialization） 超过1800个单元测试 与spring-data-redis结合使用pom.xml加入依赖12345678910 &lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson-spring-data-21&lt;/artifactId&gt; &lt;version&gt;3.10.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;&lt;/dependency&gt; 在resources文件夹添加配置文件redisson.yml123456789101112131415161718192021222324252627#Redisson配置singleServerConfig: address: "redis://127.0.0.1:6379" password: null clientName: null database: 7 #选择使用哪个数据库0~15 idleConnectionTimeout: 10000 pingTimeout: 1000 connectTimeout: 10000 timeout: 3000 retryAttempts: 3 retryInterval: 1500 reconnectionTimeout: 3000 failedAttempts: 3 subscriptionsPerConnection: 5 subscriptionConnectionMinimumIdleSize: 1 subscriptionConnectionPoolSize: 50 connectionMinimumIdleSize: 32 connectionPoolSize: 64 dnsMonitoringInterval: 5000 #dnsMonitoring: falsethreads: 0nettyThreads: 0codec: class: "org.redisson.codec.JsonJacksonCodec"transportMode: "NIO" 注册RedissonConnectionFactory123456789101112131415@Configurationpublic class RedissonSpringDataConfig &#123; @Bean public RedissonConnectionFactory redissonConnectionFactory(RedissonClient redisson) &#123; return new RedissonConnectionFactory(redisson); &#125; @Bean(destroyMethod = "shutdown") public RedissonClient redisson(@Value("classpath:/redisson.yml") Resource configFile) throws IOException &#123; Config config = Config.fromYAML(configFile.getInputStream()); return Redisson.create(config); &#125; &#125; 代码使用123456789@Autowiredprivate RedissonClient redissonClient;@SuppressWarnings("unchecked")public void test()&#123; //设置键值对 RBucket&lt;String&gt; keyObj = redissonClient.getBucket("k1"); keyObj.set("v1236");&#125; 结论spring-data-redis 支持的基本能够满足对redis的操作，提供了2种客户端连接，也支持redis集群的模式。如果涉及到利用redis做分布式锁的话，redisson封装了更多的工具和基础原子对象进行操作，redisson是优先选择，其次redisson兼容了很多的框架，那么多star不是没有道理的= =。同时也可以通过redisson与RxJava结合，实现线程安全的异步任务等等。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servicecomb实践]]></title>
    <url>%2F2019%2F03%2F20%2FServicecomb%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[Servicecomb实践Git地址 Apache ServiceComb Pack 是华为开源的一个微服务应用的数据最终一致性解决方案。 关键特性 高可用：支持高可用的集群模式部署。 高可靠：所有的关键事务事件都持久化存储在数据库中。 高性能：事务事件是通过高性能gRPC来上报的，且事务的请求和响应消息都是通过Kyro进行序列化和反序列化。 低侵入：仅需2-3个注解和编写对应的补偿方法即可引入分布式事务。 部署简单：支持通过容器（Docker）进行快速部署和交付。 补偿机制灵活：支持前向恢复（重试）及后向恢复（补偿）功能。 扩展简单：基于Pack架构很容实现多种协调协议，目前支持TCC、Saga协议，未来还可以添加其他协议支持。 架构ServiceComb Pack 架构是由 alpha 和 omega组成，其中： alpha充当协调者的角色，主要负责对事务进行管理和协调。 omega是微服务中内嵌的一个agent，负责对调用请求进行拦截并向alpha上报事务事件。 下图展示了alpha, omega以及微服务三者的关系： 基础上我们除了实现saga协调协议以外，还实现了TCC协调协议。 详情可浏览ServiceComb Pack 设计文档。 Omega内部运行机制omega是微服务中内嵌的一个agent。当服务收到请求时，omega会将其拦截并从中提取请求信息中的全局事务id作为其自身的全局事务id（即Saga事件id），并提取本地事务id作为其父事务id。在预处理阶段，alpha会记录事务开始的事件；在后处理阶段，alpha会记录事务结束的事件。因此，每个成功的子事务都有一一对应的开始及结束事件。 服务间通信流程服务间通信的流程与Zipkin的类似。在服务生产方，omega会拦截请求中事务相关的id来提取事务的上下文。在服务消费方，omega会在请求中注入事务相关的id来传递事务的上下文。通过服务提供方和服务消费方的这种协作处理，子事务能连接起来形成一个完整的全局事务。 Saga 具体处理流程Saga处理场景是要求相关的子事务提供事务处理函数同时也提供补偿函数。Saga协调器alpha会根据事务的执行情况向omega发送相关的指令，确定是否向前重试或者向后恢复。 成功场景成功场景下，每个事务都会有开始和有对应的结束事件。 异常场景异常场景下，omega会向alpha上报中断事件，然后alpha会向该全局事务的其它已完成的子事务发送补偿指令，确保最终所有的子事务要么都成功，要么都回滚。 超时场景 (需要调整）超时场景下，已超时的事件会被alpha的定期扫描器检测出来，与此同时，该超时事务对应的全局事务也会被中断。 TCC 具体处理流程TCC(try-confirm-cancel)与Saga事务处理方式相比多了一个Try方法。事务调用的发起方来根据事务的执行情况协调相关各方进行提交事务或者回滚事务。 成功场景成功场景下， 每个事务都会有开始和对应的结束事件 异常场景异常场景下，事务发起方会向alpha上报异常事件，然后alpha会向该全局事务的其它已完成的子事务发送补偿指令，确保最终所有的子事务要么都成功，要么都回滚。 omega、alpha的TSL双向证书Saga 现在支持在omega和alpha服务之间采用 TLS 通信.同样客户端方面的认证（双向认证）。 准备证书 （Certificates）你可以用下面的命令去生成一个用于测试的自签名的证书。 如果你想采用双向认证的方式，只需要客户端证书。 1234567891011121314151617181920212223242526272829303132# Changes these CN's to match your hosts in your environment if needed.SERVER_CN=localhostCLIENT_CN=localhost # Used when doing mutual TLSecho Generate CA key:openssl genrsa -passout pass:1111 -des3 -out ca.key 4096echo Generate CA certificate:# Generates ca.crt which is the trustCertCollectionFileopenssl req -passin pass:1111 -new -x509 -days 365 -key ca.key -out ca.crt -subj "/CN=$&#123;SERVER_CN&#125;"echo Generate server key:openssl genrsa -passout pass:1111 -des3 -out server.key 4096echo Generate server signing request:openssl req -passin pass:1111 -new -key server.key -out server.csr -subj "/CN=$&#123;SERVER_CN&#125;"echo Self-signed server certificate:# Generates server.crt which is the certChainFile for the serveropenssl x509 -req -passin pass:1111 -days 365 -in server.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out server.crt echo Remove passphrase from server key:openssl rsa -passin pass:1111 -in server.key -out server.keyecho Generate client keyopenssl genrsa -passout pass:1111 -des3 -out client.key 4096echo Generate client signing request:openssl req -passin pass:1111 -new -key client.key -out client.csr -subj "/CN=$&#123;CLIENT_CN&#125;"echo Self-signed client certificate:# Generates client.crt which is the clientCertChainFile for the client (need for mutual TLS only)openssl x509 -passin pass:1111 -req -days 365 -in client.csr -CA ca.crt -CAkey ca.key -set_serial 01 -out client.crtecho Remove passphrase from client key:openssl rsa -passin pass:1111 -in client.key -out client.keyecho Converting the private keys to X.509:# Generates client.pem which is the clientPrivateKeyFile for the Client (needed for mutual TLS only)openssl pkcs8 -topk8 -nocrypt -in client.key -out client.pem# Generates server.pem which is the privateKeyFile for the Serveropenssl pkcs8 -topk8 -nocrypt -in server.key -out server.pem TLS为Alpha服务开启TLS1.为alpha-server修改application.yaml文件，在alpha.server部门增加ssl配置。12345678alpha: server: ssl: enable: true cert: server.crt key: server.pem mutualAuth: true clientCert: client.crt 将server.crt 和 server.pem 文件放到alpha-server的root 2目录。如果你想双向认证，合并所有client证书到一个client.crt文件,并把client.crt文件放到root目录. 重新启动alpha服务器. 为Omega启用TLS 获取CA证书串(chain), 如果你是将alpha服务运行在集群中，你可能需要去合并多个CA证书到一个文件中. 为客户端应用修改application.yaml文件, 在alpha.cluster 部分增加ssl配置. 123456789alpha: cluster: address: alpha-server.servicecomb.io:8080 ssl: enable: false certChain: ca.crt mutualAuth: false cert: client.crt key: client.pem 把ca.crt文件放到客户端应用程序的root目录 file under the client application root directory.如果你想用双向认证，仍需要把client.crt和client.pem放到root目录下. 重新启动客户端应用程序. 与Spring结合使用Saga中的Event简介12345678public enum EventType &#123; SagaStartedEvent, TxStartedEvent, TxEndedEvent, TxAbortedEvent, TxCompensatedEvent, SagaEndedEvent&#125; SagaStartedEvent: 代表Saga事务的开始，Alpha接受到该事件会保存整个saga事务的执行上下文，其中包括多个本地事务/补偿请求 TxStartedEvent: 本地事务开始事件，其中包含了本地事务执行的上下文（调用方法名，以及相关调用参数） TXEndedEvent: 本地事务结束事件 TxAbortedEvent: 本地事务执行失败事件，包含了事务执行失败的原因 TxCompensatedEvent: 本地事务补偿事件，Alpha会将本地事务执行的上下文传递给Omega，这样不需要Omega自己维护服务调用的状态。 SagaEndedEvent: 标志着saga事务请求的结束 成功场景下，全局事务事件SagaStartedEvent对应SagaEndedEvent ，每个子事务开始的事件TxStartedEvent都会有对应的结束事件TXEndedEvent。异常场景下，Omega会向Alpha上报中断事件TxAbortedEvent，然后Alpha会根据全局事务的执行情况， 想其它已成功的子事务(以完成TXEndedEvent)的服务发送补偿指令，以确保最终所有的子事务要么都成功，要么都回滚。超时场景下，已超时的事件会被alpha的定期扫描器检测出来，同时该超时事务对应的全局事务也会被中断。 用户发送Request请求调用业务方法(business logic) preIntercept向alpha发送TxStartedEvent 被AOP拦截的方法(business logic)被调用 当执行成功时postIntercept发送TxEndedEvent到alpha 最后业务方法向用户发送response 与Spring和Mysql结合使用项目地址 通过源码编译，克隆代码1git clone https://github.com/apache/servicecomb-pack.git 在alpha/alpha-server/pom.xml文件中加入mysql依赖1234&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt; 构建docker镜像12cd ./servicecomb-packmvn clean install -DskipTests -Pdocker 成功后如图所示1234[@dinghuangMacPro:~]$ docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEpack-web 0.3.0 77dedfe8e865 15 seconds ago 131MBalpha-server 0.3.0 3a34b8cd4224 38 seconds ago 144MB 启动mysql镜像，如果本地有的话创建库saga，用户saga，密码password，并执行数据库脚本schema-mysql.sql 启动alpha-server1docker run -d -p 8080:8080 -p 8090:8090 --link mysql:mysql.servicecomb.io -e JAVA_OPTS=-Dspring.profiles.active=mysql -e -Dspring.datasource.url=jdbc:mysql://127.0.0.1:3306/saga?useSSL=false alpha-server:0.3.0 启动对应的3个应用，分别说shop，order，hotel 访问api1curl -X POST http://127.0.0.1:8081/shop/userName/orderName/hotelName 事务解析请求流程示意图：用户发起请求到shop，shop分别调用order和hotel。 使用TCC模式，TCC原理图如图所示： 情况一：正常事务结束事务记录成功，订单酒店表都有数据。 情况二：父事件中调用订单成功后，出现异常123456789101112//父事务@TccStart(timeout = 2)@PostMapping("/shop_tcc/&#123;name&#125;/&#123;order&#125;/&#123;hotel&#125;")public String shopTcc(@PathVariable String name, @PathVariable String order, @PathVariable String hotel) &#123; //调用订单服务的请求 template.postForEntity("http://127.0.0.1:8082/order_tcc/&#123;name&#125;/&#123;order&#125;",null, String.class, name, order); //异常 postBooking(); //调用酒店服务的请求 template.postForEntity("http://127.0.0.1:8083/hotel_tcc/&#123;name&#125;/&#123;hotel&#125;",null, String.class, name, hotel); return name + " order " + order + "hotel " + hotel + " cars OK";&#125; 123456789101112131415//订单(酒店)中的代码逻辑@Transactional(rollbackFor = Exception.class)void cancel(OrderDO orderDO) &#123; orderRepository.deleteById(orderDO.getId());&#125;@Transactional(rollbackFor = Exception.class)void confirm(OrderDO orderDO) &#123; orderRepository.insert(orderDO);&#125;@Participate(confirmMethod = "confirm", cancelMethod = "cancel")@Transactional(rollbackFor = Exception.class)public void orderTcc(OrderDO orderDO) &#123;&#125; 数据库结果如图所示订单和商店的表都没有生成数据。 情况三：父事件中调用订单和酒店成功后，出现异常123456789101112//父事务@TccStart(timeout = 2)@PostMapping("/shop_tcc/&#123;name&#125;/&#123;order&#125;/&#123;hotel&#125;")public String shopTcc(@PathVariable String name, @PathVariable String order, @PathVariable String hotel) &#123; //调用订单服务的请求 template.postForEntity("http://127.0.0.1:8082/order_tcc/&#123;name&#125;/&#123;order&#125;",null, String.class, name, order); //调用酒店服务的请求 template.postForEntity("http://127.0.0.1:8083/hotel_tcc/&#123;name&#125;/&#123;hotel&#125;",null, String.class, name, hotel); //异常 postBooking(); return name + " order " + order + "hotel " + hotel + " cars OK";&#125; 数据如图所示：订单表与酒店表都没有产生数据 情况四：父事件超时123456789101112//父事务@TccStart(timeout = 2)@PostMapping("/shop_tcc/&#123;name&#125;/&#123;order&#125;/&#123;hotel&#125;")public String shopTcc(@PathVariable String name, @PathVariable String order, @PathVariable String hotel) throws InterruptedException &#123; //调用订单服务的请求 template.postForEntity("http://127.0.0.1:8082/order_tcc/&#123;name&#125;/&#123;order&#125;",null, String.class, name, order); //调用酒店服务的请求 template.postForEntity("http://127.0.0.1:8083/hotel_tcc/&#123;name&#125;/&#123;hotel&#125;",null, String.class, name, hotel); //超时 Thread.sleep(10000); return name + " order " + order + "hotel " + hotel + " cars OK";&#125; 发现TCC的timeout选项好像没有作用。。。。看了下源码，的确没有用到，源码如下ServiceComb在0.3.0加入了TCC的支持，所以有些功能还待完善把。 情况五：订单服务启动，酒店服务未启动关闭hotel服务，执行后数据如下：订单和酒店数据库都没有数据 情况六: 模拟运行过程中alpha服务挂起，订单、酒店、商店服务正常运行：订单、酒店、商店服务后来日志显示心跳连接失效请求数据返回错误信息，数据库表均未写入数据。 重新启动alpha服务，订单、酒店、商店服务重新连接到alpha，业务正常运行。 情况七: 模拟运行过程中alpha服务的mysql挂起，订单、酒店、商店服务正常运行：请求未进入业务逻辑之前，alpha服务报错，请求未执行。mysql重启成功后，alpha服务正常运行，请求数据正常执行。 总结ServiceComb对于数据最终一致性的解决现阶段0.3.0是满足业务逻辑的，但是对于失败重试、超时等功能这一块还不支持，后期应该会扩展。ServiceComb功能比较简单，但是可以通过对omega的事物id结合调用链追踪实现业务流程与事务的追溯。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式应用监控]]></title>
    <url>%2F2019%2F02%2F18%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%BA%94%E7%94%A8%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[分布式应用监控分布式系统已经诞生了很长时间，现代互联网公司规模都变得异常庞大，系统也变得越来越复杂，给监控工作带来了极大的难度：海量日志数据如何处理，服务如何追踪，如何高效定位故障缩短故障时常，常见的监控手段可以分为集中式日志系统（Logging），集中式度量系统（Metrics）和分布式追踪系统（Tracing）。 集中式日志系统集中式日志系统，选取了最具代表性的ELK ElasticsearchElasticsearch是个开源的分布式搜索引擎，提供搜索、分析、存储数据三大功能。它的特点有：分布式、自动发现、索引自动分片、索引副本机制、RESTful 风格接口、多数据源以及自动搜索负载等。 LogstashLogstash 是一个开源的动态数据收集处理管道，它可以同时从多个源中提取数据，对其进行转换，并且拥有可扩展的插件生态系统，能够与 Elasticsearch 产生强大的协同作用。 KibanaKibana是一个开源的分析与可视化平台，设计出来用于和Elasticsearch一起使用的。你可以用kibana搜索、查看存放在Elasticsearch中的数据。Kibana与Elasticsearch的交互方式是各种不同的图表、表格、地图等，直观的展示数据，从而达到高级的数据分析与可视化的目的。 BeatsBeats 是 ELK Stack 技术栈中负责单一用途数据采集并推送给 Logstash 或 Elasticsearch 的轻量级产品。包括： Filebeats：应用于日志收集场景的实现。 Metricbeat：轻量级的系统级性能指标监控工具。 Packetbeat：轻量级的网络数据包分析工具。 Winlogbeat：轻量级的 Windows 事件日志收集工具。 Heartbeat：心跳检测工具，主要监控服务的可用性。 安装修改虚拟机的内存限制1vi /etc/sysctl.conf 加入1vm.max_map_count=262144 sysctl -p查看设置 docker安装ELK12docker pull sebp/elkdocker run -p 5601:5601 -p 9200:9200 -p 5044:5044 -e ES_MIN_MEM=128m -e ES_MAX_MEM=1024m -it --name elk sebp/elk 输入网址http://&lt;your-host&gt;:5601可以看到下面的界面，则说明安装成功 配置使用1docker exec -it &lt;container-name&gt; /bin/bash 进入容器，执行命令1/opt/logstash/bin/logstash -e 'input &#123; stdin &#123; &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; ["localhost"] &#125; &#125;' 如果有错误信息1service logstash stop 当命令成功被执行后，看到：Successfully started Logstash API endpoint {:port=&gt;9600}信息后，输入：this is a dummy entry然后回车，模拟一条日志进行测试。 打开浏览器http://&lt;your-host&gt;:9200/_search?pretty，如图所示 打开浏览器，输入：http://&lt;your-host&gt;:5601 点击创建 看到如下界面，到此安装结束。 与java应用结合的日志分析系统可以通过Beats的Filebeats来实现，通过log4j将运行日志输出在文件中，通过Filebeats插件利用Logstash过滤并导入到Elasticsearch中，最后通过Kibana展示。 集中式度量系统PrometheusPrometheus是一个基于时间序列的数值数据的监控解决方案，这是一个开源项目，由前Google员工在SoundCloud启动，他们希望监控一个高度动态的容器环境，因为对传统的监控工具不甚满意，所以开发出Prometheus，并在上面进行工作。Prometheus解决了Devs如何监控高动态容器环境的问题。 例如我们想要获取所有的服务器上node_exporter暴露出来的数据，就必须有个程序去定时访问这些接口，如果想要增加或者修改这些接口，那么就需要有个配置文件来记录这些服务器的地址，如果想要访问历史的某个时间点的数据，那么就必须按照时间顺序存储获取到的指标和值。而如果想要将值绘制成图，也需要有代码去查询、计算和渲染。最后你可能还希望当服务器的某个指标超过一定的阈值时，向指定的接口发出告警信息。一切的一切其实都可以使用Prometheus来解决。 Prometheus检测mysql相关指标前提：本地安装了mysql 安装node-exporter12docker pull node-exporterdocker run -d -p 9100:9100 --cap-add SYS_TIME --net="host" --pid="host" -v "/:/host:ro,rslave"quay.io/prometheus/node-exporter --cap-add=SYS_TIME --path.rootfs /host 安装mysqld-exporter通过mysql命令界面创建相应角色并赋予权限12CREATE USER 'mysql_monitor'@'localhost' IDENTIFIED BY 'XXXXXXXX' WITH MAX_USER_CONNECTIONS 3;GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'mysql_monitor'@'localhost'; docker安装12docker pull mysqld-exporterdocker run -d -p 9104:9104 -e DATA_SOURCE_NAME="mysql_monitor:root@(127.0.0.1:3306)/" prom/mysqld-exporter 安装Prometheus创建文件prometheus.yml12345678910111213141516171819202122global: scrape_interval: 60s evaluation_interval: 60sscrape_configs: - job_name: prometheus static_configs: - targets: ['106.15.226.184:9090'] labels: instance: prometheus - job_name: linux static_configs: - targets: ['106.15.226.184:9100'] labels: instance: db1 - job_name: mysql static_configs: - targets: ['106.15.226.184:9104'] labels: instance: db1 docker启动12docker pull prometheussudo docker run -d -p 9090:9090 -v /root/conf/prometheus.yml:/usr/local/src/file/prometheus.yml quay.io/prometheus/prometheus --config.file=/usr/local/src/file/prometheus.yml 安装Grafana12docker pull grafana/grafanadocker run -d --name=grafana -p 3000:3000 grafana/grafana 打开http:x.x.x.x:9090如图所示，说明数据源管道agent启动成功 打开http://x.x.x.x:3000，配置Prometheus数据源 配置好数据源后，下载mysql监控模板，解压后，找到mysql开头的模板，导入，最后如图所示： CatCAT（Central Application Tracking）是一个实时和接近全量的监控系统，它侧重于对Java应用的监控，基本接入了美团上海侧所有核心应用。目前在中间件（MVC、RPC、数据库、缓存等）框架中得到广泛应用，为美团各业务线提供系统的性能指标、健康状况、监控告警等。 监控整体要求就是快速发现故障、快速定位故障以及辅助进行程序性能优化。为了做到这些，我们对监控系统的一些非功能做了如下的要求： 实时处理：信息的价值会随时间锐减，尤其是事故处理过程中。全量数据：最开始的设计目标就是全量采集，全量的好处有很多。高可用：所有应用都倒下了，需要监控还站着，并告诉工程师发生了什么，做到故障还原和问题定位。故障容忍：CAT本身故障不应该影响业务正常运转，CAT挂了，应用不该受影响，只是监控能力暂时减弱。高吞吐：要想还原真相，需要全方位地监控和度量，必须要有超强的处理吞吐能力。可扩展：支持分布式、跨IDC部署，横向扩展的监控系统。不保证可靠：允许消息丢失，这是一个很重要的trade-off，目前CAT服务端可以做到4个9的可靠性，可靠系统和不可靠性系统的设计差别非常大。CAT从开发至今，一直秉承着简单的架构就是最好的架构原则，主要分为三个模块：CAT-client、CAT-consumer、CAT-home。 Cat-client 提供给业务以及中间层埋点的底层SDK。Cat-consumer 用于实时分析从客户端提供的数据。Cat-home 作为用户给用户提供展示的控制端。在实际开发和部署中，Cat-consumer和Cat-home是部署在一个JVM内部，每个CAT服务端都可以作为consumer也可以作为home，这样既能减少整个层级结构，也可以增加系统稳定性。上图是CAT目前多机房的整体结构图，图中可见： 路由中心是根据应用所在机房信息来决定客户端上报的CAT服务端地址，目前美团有广州、北京、上海三地机房。每个机房内部都有独立的原始信息存储集群HDFS。CAT-home可以部署在一个机房也可以部署在多个机房，在最后做展示的时候，home会从consumer中进行跨机房的调用，将所有的数据合并展示给用户。实际过程中，consumer、home以及路由中心都是部署在一起的，每个服务端节点都可以充当任何一个角色。 安装使用Cat本文演示单机集群安装部署123git clone https://github.com/dianping/cat.gitcd dockerdocker-compose up 第一次运行以后，数据库中没有表结构，需要通过下面的命令创建表：1docker exec &lt;container_id&gt; bash -c "mysql -uroot -Dcat &lt; /init.sql" 依赖配置说明 datasources.xml CAT数据库配置，默认配置是mysql镜像，可以按需替换 docker-compose.yml 通过docker-compose启动的编排文件，文件中包含cat和mysql。可以屏蔽掉mysql的部分，并且修改cat的环境变量，改为真实的mysql连接信息。 client.xml CAT 初始化默认的路由列表，配置此文件可以将客户端数据上报指向到不同环境。 datasources.sh 辅助脚本，脚本作用时修改datasources.xml，使用环境变量中制定的mysql连接信息。（通过sed命令替换） Java 应用的集成参考博客需要指定 cat 专用的远程仓库123456789101112131415161718192021222324&lt;!-- %MAVEN_HOME%\conf\settings.xml --&gt;&lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;url&gt;http://repo1.maven.org/maven2&lt;/url&gt; &lt;/repository&gt; &lt;repository&gt; &lt;id&gt;unidal.nexus&lt;/id&gt; &lt;url&gt;http://unidal.org/nexus/content/repositories/releases/&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 加入依赖(pom.xml)1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.dianping.cat&lt;/groupId&gt; &lt;artifactId&gt;cat-client&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 添加过滤器 CatFilter123456789101112@Configurationpublic class CatFilterConfigure &#123; @Bean public FilterRegistrationBean catFilter() &#123; FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(new CatFilter()); registration.addUrlPatterns("/*"); registration.setName("cat-filter"); registration.setOrder(1); return registration; &#125;&#125; 添加注解12345678910@CatCacheTransactionpublic void test() &#123;&#125;@ResponseBody@RequestMapping("/hello")@CatHttpRequestTransaction(type = "URL", name = "/hello")public String hello() &#123; return "hello!";&#125; 更多集成 管理平台的使用控制台http://192.168.126.101:8080/cat帐号/密码: catadmin/catadmin 项目配置http://192.168.126.101:8080/cat/s/config?op=projects 相关文档部署文档: http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=deploy用户文档：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=user告警文档：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=alert集成文档：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=integration开发文档：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=develop设计文档：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=design常见问题：http://192.168.126.101:8080/cat/r/home?op=view&amp;docName=problem 实时查看http://192.168.126.101:8080/cat/r/t 分布式追踪系统ZipkinZipkin是一种分布式跟踪系统。它有助于收集解决微服务架构中的延迟问题所需的时序数据。它管理这些数据的收集和查找。Zipkin的设计基于Google Dapper论文。应用程序用于向Zipkin报告时序数据。Zipkin UI还提供了一个依赖关系图，显示了每个应用程序通过的跟踪请求数。如果要解决延迟问题或错误，可以根据应用程序，跟踪长度，注释或时间戳对所有跟踪进行筛选或排序。选择跟踪后，您可以看到每个跨度所需的总跟踪时间百分比，从而可以识别问题应用程序。 共有四个组件构成了 Zipkin： collector storage search web UI Zipkin Collector 一旦追踪数据抵达 Zipkin Collector 守护进程，Zipkin Collector 为了查询，会对其进行校验、存储和索引。 Storage Zipkin 最初是构建在将数据存储在 Cassandra 中，因为 Cassandra 易跨站，支持灵活的 schema，并且在 Twitter 内部被大规模使用。然而，我们将这个组件做成了可插拔式的。在 Cassandra 之外，我们原生支持 ElasticSearch 和 MySQL。可作为第三方扩展提供给其它后端。 Zipkin 查询服务 一旦数据被存储索引，我们就需要一种方式提取它。查询守护进程提供了一个简单的 JSON API 查询和获取追踪数据。API 的主要消费者就是 Web UI。 Web UI 我们创建了一个用户图形界面为追踪数据提供了一个漂亮的视图。Web UI 提供了基于服务、时间和标记（annotation）查看追中数据的方法。注意：UI 没有内置的身份认证功能。 安装部署参考前提条件：已经安装好ElasticSearch 安装zookeeper和kafka123docker pull wurstmeister/zookeeper docker pull wurstmeister/kafka 启动镜像12345docker run -d --name zookeeper --publish 2181:2181 --volume /etc/localtime:/etc/localtime zookeeper:latestdocker run -d --name kafka --publish 9092:9092 --link zookeeper --env KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 --env KAFKA_ADVERTISED_HOST_NAME=kafka所在宿主机的IP --env KAFKA_ADVERTISED_PORT=9092 --volume /etc/localtime:/etc/localtime wurstmeister/kafka:latestdocker run -d --name zipkin-server -p 9411:9411 -e "KAFKA_BOOTSTRAP_SERVERS=your-kafka-address" -e "STORAGE_TYPE=elasticsearch" -e "ES_HOSTS=your-es-host" -e "ES_INDEX=zipkin" -e "ES_INDEX_SHARDS=1" -e "ES_INDEX_REPLICAS=1" zipkin:latest 使用用maven新建springboot项目引入依赖，包括Spring Cloud Sleuth和Kafka传输的支持依赖Spring Stream Kafak以及web依赖。1234567891011121314&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-kafka&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 配置12345678910spring: application: name: service-producer # 配置应用名称 kafka: bootstrap-servers: localhost:9092 # 缓冲kafka地址 sleuth: sampler: percentage: 1 # 设置采样频率，默认为0.1，设置为全采样，便于观测，实际项目中根据具体情况设置server: port: 8080 类似的方法再新建一个项目然后写一个接口进行2个服务之间的通讯，触发调用链，可以在http://localhost:9411查看如下效果图：需要注意的是，我们使用的存储模块是ES，所以一段时间内的服务调用关系图是无法直接得到的（使用内存存储可以直接得到）。我们需要使用Zipkin官方提供的zipkin-dependencies来生成依赖关系图。12# ex to run the job to process yesterday's traces on OS/X$ STORAGE_TYPE=elasticsearch ES_HOSTS=your-es-host ES_INDEX=zipkin ES_NODES_WAN_ONLY=true java -jar zipkin-dependencies.jar `date -uv-1d +%F` PinpointPinpoint是一个开源的APM监控工具，我们可以通过pinpoint实时跟踪应用之间的调用、程序的响应时间以及服务器资源使用状态，可以在分布式环境中为没个调用生成代码级别的可视图并定位瓶颈点和失败点。Pinpoint的设计也是基于Google Dapper论文 安装部署参考123git clone https://github.com/naver/pinpoint-docker.gitcd Pinpoint-Dockerdocker-compose pull &amp;&amp; docker-compose up -d 如有问题，请修改相对路径为绝对路径12345... volumes: - /home/pinpoint/hbase - /home/pinpoint/zookeeper... 启动镜像,访问http://x.x.x.x:8079/hbase页面 http://x.x.x.x:16010/ SkywalkingSkywalking是一款优秀的国产 APM 工具，包括了分布式追踪、性能指标分析、应用和服务依赖分析等。通过在应用程序中添加 SkyWalking Agent，就可以将接口、服务、数据库、MQ等进行追踪，将追踪结果通过 HTTP 或 gRPC 发送到 SkyWalking Collecter，SkyWalking Collecter 经过分析和聚合，将结果存储到 Elasticsearch 或 H2，SkyWalking 同时提供了一个 SkyWalking UI 的可视化界面，UI 以 GraphQL + HTTP 方式获取存储数据进行展示。 安装部署参考博客 使用拷贝apache-skywalking-apm-incubating目录下的agent目录到应用程序位置，探针包含整个目录，请不要改变目录结构 java程序启动时，增加JVM启动参数，-javaagent:/path/to/agent/skywalking-agent.jar。参数值为skywalking-agent.jar的绝对路径 agent探针配置，简单修改下agent.application_code即可1234567891011121314151617181920212223242526272829303132# 当前的应用编码，最终会显示在webui上。# 建议一个应用的多个实例，使用有相同的application_code。请使用英文agent.application_code=Your_ApplicationName# 每三秒采样的Trace数量# 默认为负数，代表在保证不超过内存Buffer区的前提下，采集所有的Trace# agent.sample_n_per_3_secs=-1# 设置需要忽略的请求地址# 默认配置如下# agent.ignore_suffix=.jpg,.jpeg,.js,.css,.png,.bmp,.gif,.ico,.mp3,.mp4,.html,.svg# 探针调试开关，如果设置为true，探针会将所有操作字节码的类输出到/debugging目录下# skywalking团队可能在调试，需要此文件# agent.is_open_debugging_class = true# 对应Collector的config/application.yml配置文件中 agent_server/jetty/port 配置内容# 例如：# 单节点配置：SERVERS="127.0.0.1:8080" # 集群配置：SERVERS="10.2.45.126:8080,10.2.45.127:7600" collector.servers=127.0.0.1:10800# 日志文件名称前缀logging.file_name=skywalking-agent.log# 日志文件最大大小# 如果超过此大小，则会生成新文件。# 默认为300Mlogging.max_file_size=314572800# 日志级别，默认为DEBUG。logging.level=DEBUG 一切正常的话，稍后就可以在skywalking ui看到了。 JaegerUber开源的Jaeger用于监控和排除基于微服务的分布式系统，包括： 分布式上下文传播 分布式事务监控 根本原因分析 服务依赖性分析 性能/延迟优化 安装部署all-in-one 是Uber官方打包好的镜像，可以直接部署使用，但是只能用于测试环境，不能用于线上，因为它把数据放入了内存。 12docker run -d -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 -p5775:5775/udp -p6831:6831/udp -p6832:6832/udp \ -p5778:5778 -p16686:16686 -p14268:14268 -p9411:9411 jaegertracing/all-in-one:latest 通过 http://localhost:16686 可以在浏览器查看 Jaeger的后台 正常安装参考 使用参考 分布式链路追踪技术对比来自博文 cat由大众点评开源，基于Java开发的实时应用监控平台，包括实时应用监控，业务监控 。 集成方案是通过 代码埋点的方式来实现监控，比如： 拦截器，注解，过滤器等。 对代码的侵入性很大，集成成本较高。支持技术栈： dubbo spring mvc ,spring aop ,springmvc-url spring boot mybatis log4j , logback playframework http请求 风险较大。 zipkin由Twitter团队开源， Zipkin是一个分布式的跟踪系统。它有助于收集数据需要解决潜在的问题在市微服架构的时机。它管理数据的收集和查找 . 该产品结合spring-cloud-sleuth使用较为简单， 集成很方便。 但是功能较简单。 支持技术栈： spring cloud 以上是结合spring-cloud-sleuth支持的技术栈 pinpoint由韩国团队naver团队开源，针对大规模分布式系统用链路监控，使用java写的工具。灵感来自短小精悍，帮助分析系统的总 体结构和内部组件如何被调用在分布式应用提供了一个很好的解决方案。 使用java探针字节码增加技术，实现对整个应用的监控 。 对应用零侵入 支持技术栈： Tomcat 6+,Jetty 8/9,JBoss 6,Resin 4,Websphere 6+,Vertx 3.3+ Spring, Spring Boot (Embedded Tomcat, Jetty) HTTP Client 3.x/4.x, HttpConnector, GoogleHttpClient, OkHttpClient, NingAsyncHttpClient Thrift, Dubbo mysql, oracle, mssql, cubrid,PostgreSQL, maria arcus, memcached, redis, cassandra MyBatis DBCP, DBCP2, HIKARICP gson, Jackson, Json Lib log4j, Logback skywalking2015年由个人吴晟（华为开发者）开源 ， 2017年加入Apache孵化器。 针对分布式系统的应用性能监控系统，特别针对微服务、cloud native和容器化(Docker, Kubernetes, Mesos)架构， 其核心是个分布式追踪系统。 使用java探针字节码增加技术，实现对整个应用的监控 。对应用零侵入 支持技术栈 Tomcat7+ , resin3+, jetty spring boot ,spring mvc strtuts2 spring RestTemplete ,spring-cloud-feign okhttp , httpClient msyql ,oracle , H2 , sharding-jdbc,PostgreSQL dubbo,dubbox ,motan, gRpc , rocketMq , kafla redis, mongoDB,memcached , elastic-job , Netflix Eureka , Hystric 总结模拟了三种并发用户：500，750，1000。使用jmeter测试，每个线程发送30个请求，设置思考时间为10ms。使用的采样率为1，即100%，这边与生产可能有差别。 pinpoint默认的采样率为20，即50%，通过设置agent的配置文件改为100%。zipkin默认也是1。组合起来，一共有12种。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TestNG测试框架与rest-assured结合]]></title>
    <url>%2F2019%2F01%2F24%2FTestNG%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6%E4%B8%8Erest-assured%E7%BB%93%E5%90%88%2F</url>
    <content type="text"><![CDATA[TestNG官网 TestNG简介 TestNG是一个受JUnit和NUnit启发的测试框架，但引入了一些新功能，使其功能更强大，相对于JUnit来说，xml的配置使的testNG对于不同测试之间的依赖程度有更好的把控性。 rest-assured简介在Java中测试和验证REST服务比在Ruby和Groovy等动态语言中更难。REST Assured将使用这些语言的简单性带入了Java域。 TestNG测试框架与rest-assured结合项目地址：https://github.com/dinghuang/testNGExample 上面实现了模拟用户登录以及rest-assured的高级用法，同时可以通过命令行直接生成报告，报告中对http请求增加了过滤，会在报告中展示请求信息，可以通过xml解析直接获取，还实现了多个suit通过mvn命令直接运行。目前在Choerodon中已经增加了TestNG的支持，用户可以直接推到gitlab，gitlab中的runner会在ci中打包并运行测试jar包，把报告解析并提取请求信息生成测试用例。 项目的关键代码就不一一说了，项目中有注释，不懂的+我VX:742041978]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubernetes学习（一）之认识Kubernetes]]></title>
    <url>%2F2019%2F01%2F12%2FKubernetes%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%E4%B9%8B%E8%AE%A4%E8%AF%86Kubernetes%2F</url>
    <content type="text"><![CDATA[Kubernetes学习（一）之认识KubernetesKubernetes概念简介Kubernetes是一个跨主机集群的 开源的容器调度平台，它可以自动化应用容器的部署、扩展和操作 , 提供以容器为中心的基础架构。结合docker可以提供持续开发，持续部署的功能，我现在所从事开发的Choerodon就是基于这一套架构开发的企业级数字服务平台，具有敏捷化的应用交付和自动化的运营管理的特点。这里介绍的版本是v1.13 新的方式是通过部署容器方式实现，每个容器之间互相隔离，每个容器有自己的文件系统 ，容器之间进程不会相互影响，能区分计算资源。相对于虚拟机，容器能快速部署，由于容器与底层设施、机器文件系统解耦的，所以它能在不同云、不同版本操作系统间进行迁移。 容器占用资源少、部署快，每个应用可以被打包成一个容器镜像，每个应用与容器间成一对一关系也使容器有更大优势，使用容器可以在build或release 的阶段，为应用创建容器镜像，因为每个应用不需要与其余的应用堆栈组合，也不依赖于生产环境基础结构，这使得从研发到测试、生产能提供一致环境。类似地，容器比虚机轻量、更“透明”，这更便于监控和管理。 组件 Master组件Kubernetes 主要由以下几个核心（Master）组件组成，Master组件提供集群的管理控制中心。Master组件可以在集群中任何节点上运行。但是为了简单起见，通常在一台VM/机器上启动所有Master组件，并且不会在此VM/机器上运行用户容器。请参考构建高可用群集以来构建multi-master-VM。 kube-apiserverkube-apiserver。 etcdetcd是Kubernetes提供默认的存储系统，保存所有集群数据，使用时需要为etcd数据提供备份计划。 kube-scheduler主服务器上的组件，用于监视未创建节点的新创建的pod，并选择一个节点供其运行。 调度决策所考虑的因素包括个人和集体资源需求，硬件/软件/策略约束，亲和力和反亲和性规范，数据位置，工作负载间干扰和最后期限。 kube-controller-managerkube-controller-manager运行管理控制器，它们是集群中处理常规任务的后台线程。逻辑上，每个控制器是一个单独的进程，但为了降低复杂性，它们都被编译成单个二进制文件，并在单个进程中运行。负责维护集群的状态，比如故障检测、自动扩展、滚动更新等。 这些控制器包括： 节点（Node）控制器。 副本（Replication）控制器：负责维护系统中每个副本中的pod。 端点（Endpoints）控制器：填充Endpoints对象（即连接Services＆Pods）。- Service Account和Token控制器：为新的Namespace 创建默认帐户访问API Token。 cloud-controller-manager云控制器管理器负责与底层云提供商的平台交互。云控制器管理器是Kubernetes版本1.6中引入的，目前还是Alpha的功能。 云控制器管理器仅运行云提供商特定的（controller loops）控制器循环。可以通过将--cloud-provider flag设置为external启动kube-controller-manager ，来禁用控制器循环。 cloud-controller-manager 具体功能： 节点（Node）控制器 路由（Route）控制器 Service控制器 卷（Volume）控制器 节点（Node）组件节点组件运行在Node，提供Kubernetes运行时环境，以及维护Pod。 kubeletkubelet是主要的节点代理，它会监视已分配给节点的pod，负责维护容器的生命周期，同时也负责 Volume（CVI）和网络（CNI）的管理，具体功能： 安装Pod所需的volume。 下载Pod的Secrets。 Pod中运行的 docker（或experimentally，rkt）容器。 定期执行容器健康检查。 通过在必要时创建镜像pod，将pod状态报告回系统的其余部分。 将节点的状态返回到系统的其余部分。 kube-proxykube-proxy通过在主机上维护网络规则并执行连接转发来实现Kubernetes服务抽象。负责为 Service 提供 cluster 内部的服务发现和负载均衡。 Container Runtime容器运行时是负责运行容器的软件。 Kubernetes支持多种运行时：Docker，rkt，runc和任何OCI运行时规范实现。 插件插件（addon）是实现集群pod和Services功能的 。PodDeployments，ReplicationController等进行管理。Namespace 插件对象是在kube-system Namespace中创建。有关可用插件的扩展列表，请参阅插件。 DNS虽然不严格要求使用插件，但Kubernetes集群都应该具有DNS集群。群集 DNS是一个DNS服务器，能够为 Kubernetes services提供 DNS记录。由Kubernetes启动的容器自动将这个DNS服务器包含在他们的DNS searches中。 用户界面仪表板是Kubernetes集群的基于Web的通用UI。它允许用户管理和解决群集中运行的应用程序以及群集本身。 容器资源监测容器资源监控提供一个UI浏览监控数据。 Cluster-level LoggingCluster-level logging，负责保存容器日志，搜索/查看日志。 supervisordsupervisord是一个轻量级的监控系统，用于保障kubelet和docker运行。 fluentdfluentd是一个守护进程，可提供cluster-level logging。 The Kubernetes APIAPI约定文档中描述了总体API约定 API参考中描述了API端点，资源类型和示例。 Controlling API Access文档中讨论了对API的远程访问。 Kubernetes API还可用作系统声明性配置架构的基础。 kubectl命令行工具可用于创建，更新，删除和获取API对象。 Kubernetes还根据API资源存储其序列化状态（当前在etcd中）。 Kubernetes本身被分解为多个组件，通过其API进行交互。 API更改 OpenAPI和Swagger定义 API版本控制 API组 启用API组 启用组中的资源 API更改根据我们的经验，任何成功的系统都需要随着新用例的出现或现有用例的变化而增长和变化。因此，我们希望Kubernetes API能够不断变化和发展。但是，我们打算在很长一段时间内不破坏与现有客户端的兼容性。通常，可以预期频繁添加新的API资源和新的资源字段。消除资源或字段将需要遵循API弃用策略。 OpenAPI和Swagger定义使用OpenAPI记录完整的API详细信息。 从Kubernetes 1.10开始，Kubernetes API服务器通过/openapi/ v2端点提供OpenAPI规范。通过设置HTTP标头指定请求的格式： Header Possible Values Accept application/json, application/com.github.proto-openapi.spec.v2@v1.0+protobuf (the default content-type is application/json for / or not passing this header) Accept-Encoding gzip (not passing this header is acceptable) 在1.14之前，格式分离的端点（/swagger.json,/swagger-2.0.0.json,/swagger-2.0.0.pb-v1,/swagger-2.0.0.pb-v1.gz）为OpenAPI提供服务不同格式的规范。这些端点已弃用，将在Kubernetes 1.14中删除。 获取OpenAPI规范的示例： Before 1.10 Starting with Kubernetes 1.10 GET /swagger.json GET /openapi/v2 Accept: application/json GET /swagger-2.0.0.pb-v1 GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf GET /swagger-2.0.0.pb-v1.gz GET /openapi/v2 Accept: application/com.github.proto-openapi.spec.v2@v1.0+protobuf Accept-Encoding: gzip Kubernetes为API实现了另一种基于Protobuf的序列化格式，主要用于集群内通信，在设计提案中有记录，每个模式的IDL文件都位于定义API对象的Go包中。 在1.14之前，Kubernetes apiserver还公开了一个API，可用于检索/ swaggerapi上的Swagger v1.2 Kubernetes API规范。该端点已弃用，将在Kubernetes 1.14中删除。 API版本控制为了更容易消除字段或重构资源表示，Kubernetes支持多个API版本，每个API版本位于不同的API路径，例如/api/v1或/apis/extensions/v1beta1。 我们选择在API级别而不是在资源或字段级别进行版本化，以确保API提供清晰，一致的系统资源和行为视图，并允许控制对生命末端和/或实验API的访问。 JSON和Protobuf序列化模式遵循相同的模式更改指南 - 以下所有描述都涵盖两种格式。 请注意，API版本控制和软件版本控制仅间接相关。 API和发布版本控制提议描述了API版本控制和软件版本控制之间的关系。 不同的API版本意味着不同级别的稳定性和支持。 API更改文档中更详细地描述了每个级别的标准。他们总结在这里： Alpha level: 版本名称包含alpha（例如v1alpha1）。 可能是马车。启用该功能可能会暴露错误。默认情况下禁用。 可随时删除对功能的支持，恕不另行通知。 API可能会在以后的软件版本中以不兼容的方式更改，恕不另行通知。 由于错误风险增加和缺乏长期支持，建议仅在短期测试集群中使用。 Beta level:: 版本名称包含beta（例如v2beta3）。 代码经过了充分测试。启用该功能被认为是安全的。默认情况下启用。 虽然细节可能会有所变化，但不会删除对整体功能的支持。 在随后的beta版或稳定版中，对象的模式和/或语义可能以不兼容的方式发生变化。发生这种情况时，我们将提供迁移到下一版本的说明。这可能需要删除，编辑和重新创建API对象。编辑过程可能需要一些思考。对于依赖该功能的应用程序，这可能需要停机时间。 建议仅用于非关键业务用途，因为后续版本中可能存在不兼容的更改。如果您有多个可以独立升级的群集，您可以放宽此限制。 请尝试我们的测试版功能并提供反馈！一旦他们退出测试版，我们可能无法进行更多更改。 Stable level: 该版本名称是vX这里X是一个整数。 许多后续版本的已发布软件中将出现稳定版本的功能。 API组为了更容易扩展Kubernetes API，我们实现了API组。API组在REST路径和apiVersion序列化对象的字段中指定。 目前有几个API组正在使用中： 核心组，常常被称为遗留组，是在REST路径/api/v1和用途apiVersion: v1。 命名组处于REST路径/apis/$GROUP_NAME/$VERSION，并使用apiVersion: $GROUP_NAME/$VERSION （例如apiVersion: batch/v1）。在Kubernetes API参考中可以看到支持的API组的完整列表。 使用自定义资源扩展API有两种受支持的路径： CustomResourceDefinition 适用于具有非常基本CRUD需求的用户。 需要完整Kubernetes API语义的用户可以实现自己的apiserver并使用聚合器 使其无缝地为客户端。 启用API组默认情况下启用某些资源和API组。可以通过设置--runtime-config apiserver 来启用或禁用它们。--runtime-config接受逗号分隔值。例如：要禁用批处理/ v1，请设置 --runtime-config=batch/v1=false，以启用批处理/ v2alpha1，设置--runtime-config=batch/v2alpha1。该标志接受逗号分隔的一组key = value对，描述了apiserver的运行时配置。 重要信息：启用或禁用组或资源需要重新启动apiserver和controller-manager以获取--runtime-config更改。 启用组中的资源默认情况下启用DaemonSet，Deployments，HorizontalPodAutoscalers，Ingresses，Jobs和ReplicaSet。可以通过设置--runtime-configapiserver 来启用其他扩展资源。--runtime-config接受逗号分隔值。例如：要禁用部署和入口，请设置 --runtime-config=extensions/v1beta1/deployments=false,extensions/v1beta1/ingresses=false 与Kubernetes对象一起工作了解Kubernetes对象了解Kubernetes对象Kubernetes对象是Kubernetes系统中的持久实体。Kubernetes使用这些实体来表示集群的状态。具体来说，他们可以描述： 容器化应用正在运行(以及在哪些节点上) 这些应用可用的资源 关于这些应用如何运行的策略，如重新策略，升级和容错Kubernetes对象是“record of intent”，一旦创建了对象，Kubernetes系统会确保对象存在。通过创建对象，可以有效地告诉Kubernetes系统你希望集群的工作负载是什么样的。 要使用Kubernetes对象（无论是创建，修改还是删除），都需要使用Kubernetes API。例如，当使用kubectl命令管理工具时，CLI会为提供Kubernetes API调用。你也可以直接在自己的程序中使用Kubernetes API，您还可以使用其中一个客户端库在您自己的程序中直接使用Kubernetes API。 对象（Object）规范和状态每个Kubernetes对象都包含两个嵌套对象字段，用于管理Object的配置：Object Spec和Object Status。Spec描述了对象所需的状态 - 希望Object具有的特性，Status描述了对象的实际状态，并由Kubernetes系统提供和更新。 例如，通过Kubernetes Deployment 来表示在集群上运行的应用的对象。创建Deployment时，可以设置Deployment Spec，来指定要运行应用的三个副本。Kubernetes系统将读取Deployment Spec，并启动你想要的三个应用实例 - 来更新状态以符合之前设置的Spec。如果这些实例中有任何一个失败（状态更改），Kuberentes系统将响应Spec和当前状态之间差异来调整，这种情况下，将会开始替代实例。 有关object spec、status和metadata更多信息，请参考“Kubernetes API Conventions”。 描述Kubernetes对象在Kubernetes中创建对象时，必须提供描述其所需Status的对象Spec，以及关于对象（如name）的一些基本信息。当使用Kubernetes API创建对象（直接或通过kubectl）时，该API请求必须将该信息作为JSON包含在请求body中。通常，可以将信息提供给kubectl .yaml文件，在进行API请求时，kubectl将信息转换为JSON。 以下示例是一个.yaml文件，显示Kubernetes Deployment所需的字段和对象Spec：1234567891011121314151617181920#application/deployment.yamlapiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用上述.yaml文件创建Deployment，是通过在kubectl中使用kubectl create命令来实现。将该.yaml文件作为参数传递。如下例子：12$ kubectl create -f https://k8s.io/examples/application/deployment.yaml --recorddeployment.apps/nginx-deployment created 必填字段对于要创建的Kubernetes对象的yaml文件，需要为以下字段设置值： apiVersion - 创建对象的Kubernetes API 版本 kind - 要创建什么样的对象？ metadata- 具有唯一标示对象的数据，包括 name（字符串）、UID和Namespace（可选项）您还需要提供对象规范字段。对象规范的精确格式对于每个Kubernetes对象都是不同的，并且包含特定于该对象的嵌套字段。 Kubernetes API Reference可以帮助您找到可以使用Kubernetes创建的所有对象的规范格式。例如，可以在此处找到Pod对象的spec格式，可以在此处找到Deployment对象的spec格式。 nameKubernetes REST API中的所有对象都由Name和UID明确标识。 对于非唯一的用户提供的属性，Kubernetes提供标签和注释。 有关名称和UID的精确语法规则，请参阅标识符设计文档。 Names UIDs Names客户端提供的字符串，用于引用资源URL中的对象，例如/api/v1/pods/some-name。 只有给定类型的一个对象一次可以有一个给定的名称。但是，如果删除该对象，则可以创建具有相同名称的新对象。 按照惯例，Kubernetes资源的名称应最多为253个字符，并且由小写字母数字字符组成-，并且.，但某些资源具有更具体的限制。 UIDsKubernetes系统生成的字符串，用于唯一标识对象。 在Kubernetes集群的整个生命周期中创建的每个对象都具有不同的UID。它旨在区分类似实体的历史事件。 NamespacesKubernetes支持由同一物理集群支持的多个虚拟集群。这些虚拟集群称为名称空间。 何时使用多个命名空间 使用命名空间 命名空间和DNS 并非所有对象都在命名空间中 何时使用多个命名空间命名空间旨在用于多个用户分布在多个团队或项目中的环境中。对于具有几个到几十个用户的集群，您根本不需要创建或考虑名称空间。当您需要它们提供的功能时，请开始使用命名空间。 命名空间提供名称范围。资源名称在名称空间中必须是唯一的，而不是跨名称空间。 命名空间是一种在多个用户之间划分群集资源的方法（通过资源配额）。 在Kubernetes的未来版本中，默认情况下，同一名称空间中的对象将具有相同的访问控制策略。 没有必要使用多个名称空间来分隔略有不同的资源，例如同一软件的不同版本：使用标签来区分同一名称空间中的资源。 使用命名空间名称空间的管理指南文档中描述了名称空间的创建和删除。 查看名称空间您可以使用以下命令列出集群中的当前名称空间：12345$ kubectl get namespacesNAME STATUS AGEdefault Active 1dkube-system Active 1dkube-public Active 1d Kubernetes以三个初始名称空间开头： default 没有其他命名空间的对象的默认命名空间 kube-system Kubernetes系统创建的对象的命名空间 kube-public此命名空间是自动创建的，并且所有用户（包括未经过身份验证的用户）都可以读取。此命名空间主要用于群集使用，以防某些资源在整个群集中可见且可公开读取。此命名空间的公共方面只是一个约定，而不是一个要求。 设置请求的命名空间要临时设置请求的命名空间，请使用该--namespace标志。 例如：12$ kubectl --namespace=&lt;insert-namespace-name-here&gt; run nginx --image=nginx$ kubectl --namespace=&lt;insert-namespace-name-here&gt; get pods 设置命名空间首选项您可以在该上下文中为所有后续kubectl命令永久保存命名空间。 123$ kubectl config set-context $(kubectl config current-context) --namespace=&lt;insert-namespace-name-here&gt;# Validate it$ kubectl config view | grep namespace: 命名空间和DNS创建服务时，它会创建相应的DNS条目。此条目是表单&lt;service-name&gt;.&lt;namespace-name&gt;.svc.cluster.local，这意味着如果容器只是使用&lt;service-name&gt;，它将解析为命名空间本地的服务。这对于在多个名称空间（如开发，分段和生产）中使用相同的配置非常有用。如果要跨命名空间访问，则需要使用完全限定的域名（FQDN）。 并非所有对象都在命名空间中大多数Kubernetes资源（例如pod，服务，复制控制器等）都在某些名称空间中。但是，命名空间资源本身并不在命名空间中。并且低级资源（例如节点和persistentVolumes）不在任何名称空间中。 要查看哪些Kubernetes资源在命名空间中，哪些不在：12345# In a namespace$ kubectl api-resources --namespaced=true# Not in a namespace$ kubectl api-resources --namespaced=false Labels and Selectors标签是附加到对象（例如pod）的键/值对。标签旨在用于指定对用户有意义且相关的对象的标识属性，但不直接暗示核心系统的语义。标签可用于组织和选择对象的子集。标签可以在创建时附加到对象，随后可以随时添加和修改。每个对象都可以定义一组键/值标签。每个Key对于给定对象必须是唯一的。123456"metadata": &#123; "labels": &#123; "key1" : "value1", "key2" : "value2" &#125;&#125; 标签允许高效的查询和监视，非常适合在UI和CLI中使用。应使用注释记录非识别信息。 动机 语法和字符集 标签选择器 API 动机标签使用户能够以松散耦合的方式将他们自己的组织结构映射到系统对象，而无需客户端存储这些映射。 服务部署和批处理流水线通常是多维实体（例如，多个分区或部署，多个释放轨道，多个层，每层多个微服务）。管理通常需要交叉操作，这打破了严格的层次表示的封装，特别是由基础设施而不是用户确定的严格的层次结构。 示例标签： &quot;release&quot; : &quot;stable&quot;，&quot;release&quot; : &quot;canary&quot; &quot;environment&quot; : &quot;dev&quot;，&quot;environment&quot; : &quot;qa&quot;，&quot;environment&quot; : &quot;production&quot; &quot;tier&quot; : &quot;frontend&quot;，&quot;tier&quot; : &quot;backend&quot;，&quot;tier&quot; : &quot;cache&quot; &quot;partition&quot; : &quot;customerA&quot;， &quot;partition&quot; : &quot;customerB&quot; &quot;track&quot; : &quot;daily&quot;， &quot;track&quot; : &quot;weekly&quot;这些只是常用标签的例子; 你可以自由地制定自己的约定。请记住，标签Key对于给定对象必须是唯一的。 语法和字符集标签是键/值对。有效标签键有两个段：可选前缀和名称，用斜杠（/）分隔。名称段是必需的，必须是63个字符或更少，以字母数字字符（[a-z0-9A-Z]）开头和结尾，带有破折号（-），下划线（_），点（.）和字母数字之间。前缀是可选的。如果指定，前缀必须是DNS子域：由点（.）分隔的一系列DNS标签，总共不超过253个字符，后跟斜杠（/）。 如果省略前缀，则假定标签Key对用户是私有的。自动化系统组件（例如kube-scheduler，kube-controller-manager，kube-apiserver，kubectl，或其他第三方自动化），它添加标签终端用户对象都必须指定一个前缀。 在kubernetes.io/和k8s.io/前缀保留给Kubernetes核心组件。 有效标签值必须为63个字符或更少，并且必须为空或以字母数字字符（[a-z0-9A-Z]）开头和结尾，并带有短划线（-），下划线（_），点（.）和字母数字。 标签选择器与名称和UID不同，标签不提供唯一性。通常，我们希望许多对象携带相同的标签。 通过标签选择器，客户端/用户可以识别一组对象。标签选择器是Kubernetes中的核心分组原语。 目前，API支持两种类型的选择：基于平等，和基于集的。标签选择器可以由逗号分隔的多个要求组成。在多个要求的情况下，必须满足所有要求，因此逗号分隔符充当逻辑AND（&amp;&amp;）运算符。 空或非指定选择器的语义取决于上下文，使用选择器的API类型应记录它们的有效性和含义。 注意：对于某些API类型（例如ReplicaSet），两个实例的标签选择器不得在命名空间内重叠，或者控制器可以将其视为冲突的指令，并且无法确定应存在多少副本。 基于平等的要求基于平等或不平等的要求允许按标签键和值进行过滤。匹配对象必须满足所有指定的标签约束，尽管它们也可能有其他标签。三种操作都承认=，==，!=。前两个代表平等（简单地说是同义词），而后者代表不平等。例如：12environment = productiontier != frontend 前者选择密钥等于environment和值等于的所有资源production。后者选择密钥等于tier和值不同的frontend所有资源，以及没有带tier密钥标签的所有资源。可以过滤使用逗号运算符production排除的资源frontend：environment=production,tier!=frontend 基于等同的标签要求的一种使用场景是Pods指定节点选择标准。例如，下面的示例Pod选择标签为“ accelerator=nvidia-tesla-p100”的节点。12345678910111213apiVersion: v1kind: Podmetadata: name: cuda-testspec: containers: - name: cuda-test image: "k8s.gcr.io/cuda-vector-add:v0.1" resources: limits: nvidia.com/gpu: 1 nodeSelector: accelerator: nvidia-tesla-p100 基于集合的要求基于集合的标签要求允许根据一组值过滤密钥。三种操作的支持：in，notin和exists（仅密钥标识符）。例如：1234environment in (production, qa)tier notin (frontend, backend)partition!partition 第一个示例选择键等于environment和值等于production或的所有资源qa。第二个示例选择密钥等于tier和除了frontend和之外的值的backend所有资源，以及没有带tier密钥标签的所有资源。第三个例子选择所有资源，包括带密钥的标签partition; 没有检查值。第四个示例选择没有带键的标签的所有资源partition; 没有检查值。类似地，逗号分隔符充当AND运算符。因此，使用partition密钥（无论值）和environment不同的 过滤资源qa都可以实现partition,environment notin (qa)。基于集合标签选择器是一种平等的一般形式，因为environment=production它等同于environment in (production); 同样的!=和notin。 基于集合的需求可以与基于相等的需求相结合。例如：partition in (customerA, customerB),environment!=qa。 APILIST和WATCH过滤LIST和WATCH操作可以指定标签选择器来过滤使用查询参数返回的对象集。这两个要求都是允许的（在此处显示为出现在URL查询字符串中）： 基于平等的要求：?labelSelector=environment%3Dproduction,tier%3Dfrontend 基于集合的要求：?labelSelector=environment+in+%28production%2Cqa%29%2Ctier+in+%28frontend%29 两种标签选择器样式都可用于通过REST客户端列出或查看资源。例如，靶向apiserver与kubectl和使用基于平等-一个可写：1$ kubectl get pods -l environment=production,tier=frontend 或使用基于集合的要求：1$ kubectl get pods -l 'environment in (production),tier in (frontend)' 如前所述，基于集合的要求更具表现力。例如，他们可以在值上实现OR运算符：1$ kubectl get pods -l 'environment in (production, qa)' 或限制负匹配通过存在操作者：1$ kubectl get pods -l 'environment,environment notin (frontend)' 在API对象中设置引用 某些Kubernetes对象（例如services和replicationcontrollers）也使用标签选择器来指定其他资源集，例如pod。 服务和ReplicationControllerservice使用标签选择器定义目标的一组pod 。类似地，replicationcontroller应该管理的pod的数量也用标签选择器定义。 两个对象的标签选择器在使用映射定义json或yaml文件中定义，并且仅支持基于等同的需求选择器：123"selector": &#123; "component" : "redis",&#125; 要么12selector: component: redis 这个选择器（分别以json或yaml格式）相当于component=redis或component in (redis)。 支持基于集合的需求的资源较新的资源，如Job，Deployment，Replica Set，和Daemon Set，支持基于集合的要求也是如此。123456selector: matchLabels: component: redis matchExpressions: - &#123;key: tier, operator: In, values: [cache]&#125; - &#123;key: environment, operator: NotIn, values: [dev]&#125; matchLabels是对的地图{key,value}。一个单一的{key,value}在matchLabels地图相当于一个元件matchExpressions，其key字段是“key”，则operator是“In”和values阵列仅包含“value”。matchExpressions是一个pod选择器要求列表。有效的运算符包括In，NotIn，Exists和DoesNotExist。在In和NotIn的情况下，设置的值必须是非空的。所有的要求，从两者matchLabels和matchExpressionsAND一起 - 他们必须满足，以匹配。 选择节点集用于选择标签的一个用例是约束pod可以调度的节点集。有关更多信息，请参阅有关节点选择的文档。 Annotations您可以使用Kubernetes注释将任意非标识元数据附加到对象。工具和库等客户端可以检索此元数据。 将元数据附加到对象 语法和字符集 将元数据附加到对象您可以使用标签或注释将元数据附加到Kubernetes对象。标签可用于选择对象和查找满足特定条件的对象集合。相反，注释不用于识别和选择对象。注释中的元数据可以是小的或大的，结构化的或非结构化的，并且可以包括标签不允许的字符。 注释（如标签）是键/值映射123456"metadata": &#123; "annotations": &#123; "key1" : "value1", "key2" : "value2" &#125;&#125; 以下是可以在注释中记录的一些信息示例： 由声明性配置层管理的字段。将这些字段作为注释附加，可以将它们与客户端或服务器设置的默认值以及自动生成的字段和自动调整大小或自动调整系统设置的字段区分开来。 构建，发布或映像信息，如时间戳，版本ID，git分支，PR编号，镜像哈希和仓库地址。 指向日志记录，监视，分析或审计存储库的指针。 可用于调试目的的客户端库或工具信息：例如，名称，版本和构建信息。 用户或工具/系统出处信息，例如来自其他生态系统组件的相关对象的URL。 轻量推出工具元数据：例如，配置或检查点。 负责人的电话或寻呼机号码，或指定可在何处找到该信息的目录条目，例如团队网站。 从最终用户到实现的指令，用于修改行为或使用非标准功能。 您可以将此类信息存储在外部数据库或目录中，而不是使用注释，但这会使生成用于部署，管理，内省等的共享客户端库和工具变得更加困难。 语法和字符集注释是键/值对。有效的注释键有两个段：可选的前缀和名称，用斜杠（/）分隔。名称段是必需的，必须是63个字符或更少，以字母数字字符（[a-z0-9A-Z]）开头和结尾，带有破折号（-），下划线（_），点（.）和字母数字之间。前缀是可选的。如果指定，前缀必须是DNS子域：由点（.）分隔的一系列DNS标签，总共不超过253个字符，后跟斜杠（/）。 如果省略前缀，则假定注释密钥对用户是私有的。自动化系统组件（例如kube-scheduler，kube-controller-manager，kube-apiserver，kubectl，或其他第三方自动化）的添加注释到最终用户的对象都必须指定一个前缀。 在kubernetes.io/和k8s.io/前缀保留给Kubernetes核心组件。 Field Selectors 支持的字段 支持操作 链式选择器 多种资源类型 字段选择器允许您根据一个或多个资源字段的值选择Kubernetes资源。以下是一些示例字段选择器查询： metadata.name=my-service metadata.namespace!=default status.phase=Pending 此kubectl命令选择status.phase字段值为的所有Pod Running：1$ kubectl get pods --field-selector status.phase=Running 注意：字段选择器本质上是资源过滤器。默认情况下，不应用选择器/过滤器，这意味着将选择指定类型的所有资源。这使以下kubectl查询等效：12$ kubectl get pods$ kubectl get pods --field-selector "" 支持的字段支持的字段选择器因Kubernetes资源类型而异。所有资源类型都支持metadata.name和metadata.namespace字段。使用不受支持的字段选择器会产生错误。例如：12$ kubectl get ingress --field-selector foo.bar=bazError from server (BadRequest): Unable to find "ingresses" that match label selector "", field selector "foo.bar=baz": "foo.bar" is not a known field selector: only "metadata.name", "metadata.namespace" 支持操作您可以使用=，==以及!=与现场选择操作（=和==意思是一样的）。kubectl例如，此命令选择不在default命名空间中的所有Kubernetes服务：1$ kubectl get services --field-selector metadata.namespace!=default 链式选择器与标签和其他选择器一样，字段选择器可以作为逗号分隔列表链接在一起。此kubectl命令选择status.phase不相等Running且spec.restartPolicy字段等于的所有Pod Always：1$ kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always 多种资源类型您可以跨多种资源类型使用字段选择器。此kubectl命令选择不在default命名空间中的所有Statefulsets和Services ：1$ kubectl get statefulsets,services --field-selector metadata.namespace!=default Recommended Labels您可以使用比kubectl和仪表板更多的工具来可视化和管理Kubernetes对象。一组通用的标签允许工具以互操作的方式工作，以所有工具都能理解的通用方式描述对象。 除支持工具外，推荐标签还以可查询的方式描述应用程序。 标签 应用程序和应用程序实例 例子元数据围绕应用程序的概念进行组织。Kubernetes不是一个服务平台（PaaS），也没有或强制执行正式的应用程序概念。相反，应用程序是非正式的，并使用元数据进 应用程序包含的内容的定义是松散的。 注意：这些是推荐标签。它们使管理应用程序变得更容易，但对于任何核心工具都不是必需的。 共享标签和注释共享一个共同的前缀：app.kubernetes.io。没有前缀的标签对用户是私有的。共享前缀可确保共享标签不会干扰自定义用户标签。 标签为了充分利用这些标签，应将它们应用于每个资源对象。 键 描述 例 类型 app.kubernetes.io/name 应用程序的名称 string mysql app.kubernetes.io/instance 标识应用程序实例的唯一名称 string wordpress-abcxzy app.kubernetes.io/version 应用程序的当前版本（例如，语义版本，修订版哈希等） string 5.7.21 app.kubernetes.io/component 架构中的组件 string database app.kubernetes.io/part-of 此级别的更高级别应用程序的名称 string wordpress app.kubernetes.io/managed-by 该工具用于管理应用程序的操作 string helm 要说明这些标签的运行情况，请考虑以下StatefulSet对象：12345678910apiVersion: apps/v1kind: StatefulSetmetadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/version: "5.7.21" app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress app.kubernetes.io/managed-by: helm 应用程序和应用程序实例应用程序可以一次或多次安装到Kubernetes集群中，在某些情况下，可以安装在同一名称空间中。例如，wordpress可以不止一次安装，其中不同的网站是wordpress的不同安装。 应用程序的名称和实例名称分别记录。例如，在WordPress具有app.kubernetes.io/name的wordpress，同时它有一个实例名，被表示为app.kubernetes.io/instance具有值 wordpress-abcxzy。这使得应用程序的应用程序和实例可以识别。应用程序的每个实例都必须具有唯一的名称。 例子为了说明使用这些标签的不同方式，以下示例具有不同的复杂性。 一种简单的无状态服务考虑使用Deployment和Service对象部署的简单无状态服务的情况。以下两个代码段表示如何以最简单的形式使用标签。 本Deployment是用来监督运行应用程序本身的豆荚。1234567apiVersion: apps/v1kind: Deploymentmetadata: labels: app.kubernetes.io/name: myservice app.kubernetes.io/instance: myservice-abcxzy... 将Service用于公开应用程序。1234567apiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/name: myservice app.kubernetes.io/instance: myservice-abcxzy... 使用数据库的Web应用程序考虑一个稍微复杂的应用程序：使用Helm安装的使用数据库（MySQL）的Web应用程序（WordPress）。以下代码段说明了用于部署此应用程序的对象的开始。 以下Deployment内容用于WordPress：1234567891011apiVersion: apps/v1kind: Deploymentmetadata: labels: app.kubernetes.io/name: wordpress app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/version: "4.9.4" app.kubernetes.io/managed-by: helm app.kubernetes.io/component: server app.kubernetes.io/part-of: wordpress... 将Service用于公开WordPress的：1234567891011apiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/name: wordpress app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/version: "4.9.4" app.kubernetes.io/managed-by: helm app.kubernetes.io/component: server app.kubernetes.io/part-of: wordpress... MySQL作为一个StatefulSet包含它的元数据和它所属的更大的应用程序公开：1234567891011apiVersion: apps/v1kind: StatefulSetmetadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/managed-by: helm app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress app.kubernetes.io/version: "5.7.21"... 将Service用于公开MySQL作为WordPress的部分：1234567891011apiVersion: v1kind: Servicemetadata: labels: app.kubernetes.io/name: mysql app.kubernetes.io/instance: wordpress-abcxzy app.kubernetes.io/managed-by: helm app.kubernetes.io/component: database app.kubernetes.io/part-of: wordpress app.kubernetes.io/version: "5.7.21"... 使用MySQL StatefulSet，Service您会注意到有关MySQL和Wordpress的信息，包括更广泛的应用程序。 对象管理使用kubectlKubernetes对象管理该kubectl命令行工具支持多种不同的方法来创建和管理Kubernetes对象。本文档概述了不同的方法。 管理技巧 命令式命令 势在必行的对象配置 声明性对象配置 管理技巧 警告：应仅使用一种技术管理Kubernetes对象。对同一对象的混合和匹配技术会导致未定义的行为。 Management technique 操作 推荐环境 Supported writers Learning curve Imperative commands Live objects Development projects 1+ Lowest Imperative object configuration Individual files Production projects 1 Moderate Declarative object configuration Directories of files Production projects 1+ Highest 命令式命令使用命令性命令时，用户直接在群集中的活动对象上操作。用户将kubectl命令的操作作为参数或标志提供。 这是在集群中启动或运行一次性任务的最简单方法。由于此技术直接在活动对象上运行，因此它不提供先前配置的历史记录。 例子通过创建Deployment对象来运行nginx容器的实例：1kubectl run nginx --image nginx 使用不同的语法执行相同的操作：1kubectl create deployment nginx --image nginx 权衡与对象配置相比的优点： 命令简单易学，易记。 命令只需要一个步骤即可对集群进行更改。 与对象配置相比的缺点： 命令不与更改审核过程集成。 命令不提供与更改关联的审计跟踪。 除了活动之外，命令不提供记录源。 命令不提供用于创建新对象的模板。 势在必行的对象配置在命令式对象配置中，kubectl命令指定操作（创建，替换等），可选标志和至少一个文件名。指定的文件必须包含YAML或JSON格式的对象的完整定义。 有关 对象定义的更多详细信息，请参阅API参考。 警告：replace命令式命令将现有规范替换为新提供的规范，删除对配置文件中缺少的对象的所有更改。此方法不应与其配置文件独立更新的资源类型一起使用。LoadBalancer例如，类型的服务使其externalIPs字段独立于群集的配置而更新。 例子创建配置文件中定义的对象：1kubectl create -f nginx.yaml 删除两个配置文件中定义的对象：1kubectl delete -f nginx.yaml -f redis.yaml 通过覆盖实时配置来更新配置文件中定义的对象：1kubectl replace -f nginx.yaml 权衡与命令式命令相比的优点： 对象配置可以存储在诸如Git的源控制系统中。 对象配置可以与进程集成，例如在推送和审计跟踪之前查看更改。 对象配置提供了用于创建新对象的模板。 与命令式命令相比的缺点： 对象配置需要对对象模式有基本的了解。 对象配置需要编写YAML文件的附加步骤。 与声明对象配置相比的优点： 命令式对象配置行为更简单，更易于理解。 从Kubernetes 1.5版开始，命令式对象配置更加成熟。 与声明对象配置相比的缺点： 命令对象配置最适合文件，而不是目录。 活动对象的更新必须反映在配置文件中，否则在下次更换时会丢失。 声明性对象配置使用声明性对象配置时，用户对本地存储的对象配置文件进行操作，但是用户不定义要对文件执行的操作。每个对象自动检测创建，更新和删除操作kubectl。这使得能够处理目录，其中可能需要不同对象的不同操作。 注意：声明性对象配置保留其他编写者所做的更改，即使更改未合并回对象配置文件也是如此。这可以通过使用patchAPI操作来仅写入观察到的差异，而不是使用replace API操作来替换整个对象配置。 例子处理目录中的所有对象配置文件configs，并创建或修补活动对象。您可以先diff查看要进行的更改，然后应用： 12kubectl diff -f configs/kubectl apply -f configs/ 递归处理目录：12kubectl diff -R -f configs/kubectl apply -R -f configs/ 权衡与命令式对象配置相比的优点： 即使它们未合并回配置文件，也会保留直接对活动对象所做的更改。 声明性对象配置更好地支持对目录进行操作并自动检测每个对象的操作类型（创建，修补，删除）。 与命令式对象配置相比的缺点： 声明性对象配置更难以调试，并在意外时理解结果。 使用diff的部分更新会创建复杂的合并和修补操作。 使用命令式命令管理Kubernetes对象可以使用命令kubectl行工具中内置的命令性命令直接创建，更新和删除Kubernetes对象。本文档说明了如何组织这些命令以及如何使用它们来管理实时对象。 权衡 如何创建对象 如何更新对象 如何删除对象 如何查看对象 使用set命令在创建之前修改对象 使用–edit修改之前创建的对象 权衡该kubectl工具支持三种对象管理： 命令式命令 势在必行的对象配置 声明性对象配置 有关每种对象管理 的优缺点的讨论，请参阅Kubernetes对象管理。 如何创建对象该kubectl工具支持动词驱动的命令，用于创建一些最常见的对象类型。这些命令被命名为不熟悉Kubernetes对象类型的用户可识别。 run：创建一个新的Deployment对象以在一个或多个Pod中运行Container。 expose：创建一个新的服务对象，以跨Pod调整流量负载。 autoscale：创建新的Autoscaler对象以自动水平扩展控制器，例如部署。 该kubectl工具还支持由对象类型驱动的创建命令。这些命令支持更多对象类型，并且更明确地表达了它们的意图，但要求用户知道他们打算创建的对象的类型。 create &lt;objecttype&gt; [&lt;subtype&gt;] &lt;instancename&gt; 某些对象类型具有您可以在create命令中指定的子类型。例如，Service对象有几个子类型，包括ClusterIP，LoadBalancer和NodePort。这是一个使用子类型NodePort创建服务的示例：1kubectl create service nodeport &lt;myservicename&gt; 在前面的示例中，该create service nodeport命令称为命令的子create service命令。 您可以使用该-h标志来查找子命令支持的参数和标志：1kubectl create service nodeport -h 如何更新对象该kubectl命令支持一些常见更新操作的动词驱动命令。命名这些命令是为了使不熟悉Kubernetes对象的用户能够在不知道必须设置的特定字段的情况下执行更新： scale：通过更新控制器的副本计数，水平缩放控制器以添加或删除Pod。 annotate：在对象中添加或删除注释。 label：在对象中添加或删除标签。 该kubectl命令还支持由对象的一个方面驱动的更新命令。设置此方面可以为不同的对象类型设置不同的字段： set ：设置对象的一个方面。 注意：在Kubernetes 1.5版中，并非每个动词驱动的命令都有一个关联的方面驱动命令。 该kubectl工具支持这些直接更新实时对象的其他方法，但是它们需要更好地理解Kubernetes对象模式。 edit：通过在编辑器中打开其配置，直接编辑活动对象的原始配置。 patch：使用补丁字符串直接修改活动对象的特定字段。有关修补程序字符串的更多详细信息，请参阅API约定中的修补程序部分 。 如何删除对象您可以使用该delete命令从群集中删除对象： delete &lt;type&gt;/&lt;name&gt; 注意：您可以使用kubectl delete命令式命令和命令式对象配置。不同之处在于传递给命令的参数。要 kubectl delete用作命令性命令，请将要删除的对象作为参数传递。这是一个传递名为nginx的Deployment对象的示例： 1kubectl delete deployment/nginx 如何查看对象有几个命令用于打印有关对象的信息： get：打印有关匹配对象的基本信息。使用get -h查看选项列表。 describe：打印有关匹配对象的聚合详细信息。 logs：为在Pod中运行的容器打印stdout和stderr。 使用set命令在创建之前修改对象有些对象字段没有可在create命令中使用的标志。在一些案件中，可以使用的组合 set并create指定对象创建前场的值。这是通过将create命令的输出传递给 set命令，然后返回到create命令来完成的。这是一个例子： 1kubectl create service clusterip my-svc --clusterip="None" -o yaml --dry-run | kubectl set selector --local -f - 'environment=qa' -o yaml | kubectl create -f - 该kubectl create service -o yaml --dry-run命令为服务创建配置，但将其作为YAML打印到stdout，而不是将其发送到Kubernetes API服务器。 该kubectl set selector --local -f - -o yaml命令从stdin读取配置，并将更新的配置作为YAML写入stdout。 该kubectl create -f -命令使用stdin提供的配置创建对象。 使用–edit修改之前创建的对象您可以kubectl create --edit在创建对象之前对其进行任意更改。这是一个例子：12kubectl create service clusterip my-svc --clusterip="None" -o yaml --dry-run &gt; /tmp/srv.yamlkubectl create --edit -f /tmp/srv.yaml 该kubectl create service命令为服务创建配置并将其保存到/tmp/srv.yaml。该kubectl create --edit命令在创建对象之前打开配置文件以进行编辑。 使用配置文件管理Kubernetes对象可以使用kubectl 命令行工具以及使用YAML或JSON编写的对象配置文件来创建，更新和删除Kubernetes对象。本文档介绍了如何使用配置文件定义和管理对象。 权衡 如何创建对象 如何更新对象 如何删除对象 如何查看对象 限制 在不保存配置的情况下从URL创建和编辑对象 从命令式命令迁移到命令式对象配置 定义控制器选择器和PodTemplate标签 权衡该kubectl工具支持三种对象管理： 命令式命令 势在必行的对象配置 声明性对象配置 有关每种对象管理 的优缺点的讨论，请参阅Kubernetes对象管理。 如何创建对象您可以使用kubectl create -f从配置文件创建对象。 有关详细信息，请参阅kubernetes API参考。 kubectl create -f &lt;filename|url&gt; 如何更新对象 警告：使用该replace命令更新对象会删除配置文件中未指定的规范的所有部分。这不应该与规范部分由集群管理的对象一起使用，例如类型服务LoadBalancer，其中externalIPs字段独立于配置文件进行管理。必须将独立管理的字段复制到配置文件中以防止replace丢弃它们。 您可以使用kubectl replace -f根据配置文件更新活动对象。 kubectl replace -f &lt;filename|url&gt; 如何删除对象您可以使用kubectl delete -f删除配置文件中描述的对象。 kubectl delete -f &lt;filename|url&gt; 如何查看对象您可以使用它kubectl get -f来查看有关配置文件中描述的对象的信息。 kubectl get -f &lt;filename|url&gt; -o yaml 该-o yaml标志指定打印完整对象配置。使用kubectl get -h查看选项列表。 限制create，replace和delete命令工作得很好，当每个对象的配置完全确定并记录在它的配置文件。但是，当更新活动对象并且更新未合并到其配置文件中时，更新将在下次replace 执行时丢失。如果控制器（例如HorizontalPodAutoscaler）直接对活动对象进行更新，则会发生这种情况。这是一个例子： 您可以从配置文件创建对象。 另一个源通过更改某个字段来更新对象。 您从配置文件中替换该对象。步骤2中其他来源所做的更改将丢失。 如果需要支持同一对象的多个编写器，则可以使用它kubectl apply来管理对象。 在不保存配置的情况下从URL创建和编辑对象假设您具有对象配置文件的URL。您可以 kubectl create --edit在创建对象之前用于更改配置。这对于指向可由读者修改的配置文件的教程和任务特别有用。 1kubectl create -f &lt;url&gt; --edit 从命令式命令迁移到命令式对象配置 从命令式命令迁移到命令式对象配置涉及几个手动步骤。将活动对象导出到本地对象配置文件： 1kubectl get &lt;kind&gt;/&lt;name&gt; -o yaml --export &gt; &lt;kind&gt;_&lt;name&gt;.yaml 从对象配置文件中手动删除状态字段。 对于后续对象管理，请replace专门使用。 1kubectl replace -f &lt;kind&gt;_&lt;name&gt;.yaml 定义控制器选择器和PodTemplate标签 警告：强烈建议不要更新控制器上的选择器。 推荐的方法是定义一个仅由控制器选择器使用的单个不可变PodTemplate标签，没有其他语义含义。 示例标签：1234567selector: matchLabels: controller-selector: "extensions/v1beta1/deployment/nginx"template: metadata: labels: controller-selector: "extensions/v1beta1/deployment/nginx" 使用配置文件声明管理Kubernetes对象可以通过在目录中存储多个对象配置文件并使用kubectl apply根据需要递归创建和更新这些对象来创建，更新和删除Kubernetes对象。此方法保留对活动对象的写入，而不将更改合并回对象配置文件。kubectl diff还可以预览apply将要进行的更改。 权衡 在你开始之前 如何创建对象 如何更新对象 如何删除对象 如何查看对象 如何应用计算差异并合并更改 默认字段值 如何更改配置文件和直接命令式编写器之间字段的所有权 改变管理方法 定义控制器选择器和PodTemplate标签 权衡该kubectl工具支持三种对象管理： 命令式命令 势在必行的对象配置 声明性对象配置 有关每种对象管理 的优缺点的讨论，请参阅Kubernetes对象管理。 在你开始之前声明性对象配置需要牢固地理解Kubernetes对象定义和配置。如果您还没有阅读并填写以下文件： 使用命令式命令管理Kubernetes对象 使用配置文件管理Kubernetes对象 以下是本文档中使用的术语的定义： 对象配置文件/配置文件：定义Kubernetes对象配置的文件。本主题说明如何将配置文件传递给kubectl apply。配置文件通常存储在源代码管理中，例如Git。 实时对象配置/实时配置：Kubernetes集群观察到的对象的实时配置值。这些保存在Kubernetes集群存储中，通常是etcd。 声明性配置writer / declarative writer：对活动对象进行更新的人员或软件组件。本主题中提到的实时编写器会更改对象配置文件并运行kubectl apply以编写更改。 如何创建对象使用kubectl apply创建的所有对象，除了那些已经存在，通过配置文件在指定的目录中定义：1kubectl apply -f &lt;directory&gt;/ 这将kubectl.kubernetes.io/last-applied-configuration: &#39;{...}&#39;在每个对象上设置注释。注释包含用于创建对象的对象配置文件的内容。 注意：添加-R标志以递归处理目录。 以下是对象配置文件的示例：1234567891011121314151617181920#application/simple_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx minReadySeconds: 5 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 运行kubectl diff以打印将要创建的对象：1kubectl diff -f https://k8s.io/examples/application/simple_deployment.yaml 注意：diff使用服务器端干运行，需要启用kube-apiserver。 使用kubectl apply以下方法创建对象1kubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml 使用kubectl get以下方式打印实时配置1kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 输出显示kubectl.kubernetes.io/last-applied-configuration注释已写入实时配置，并且与配置文件匹配：123456789101112131415161718192021222324252627282930313233343536kind: Deploymentmetadata: annotations: # ... # This is the json representation of simple_deployment.yaml # It was written by kubectl apply when the object was created kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"minReadySeconds":5,"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.7.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: # ... minReadySeconds: 5 selector: matchLabels: # ... app: nginx template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.7.9 # ... name: nginx ports: - containerPort: 80 # ... # ... # ... # ... 如何更新对象您还可以使用kubectl apply更新目录中定义的所有对象，即使这些对象已存在。此方法可实现以下目标： 设置实时配置中配置文件中显示的字段。 清除实时配置中从配置文件中删除的字段。 12kubectl diff -f &lt;directory&gt;/kubectl apply -f &lt;directory&gt;/ 注意：添加-R标志以递归处理目录。 这是一个示例配置文件：1234567891011121314151617181920#application/simple_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx minReadySeconds: 5 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用kubectl apply以下方法创建对象1kubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml 注意：出于说明的目的，上述命令引用单个配置文件而不是目录。 使用kubectl get以下方式打印实时配置1kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 输出显示kubectl.kubernetes.io/last-applied-configuration注释已写入实时配置，并且与配置文件匹配：123456789101112131415161718192021222324252627282930313233343536kind: Deploymentmetadata: annotations: # ... # This is the json representation of simple_deployment.yaml # It was written by kubectl apply when the object was created kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"minReadySeconds":5,"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.7.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: # ... minReadySeconds: 5 selector: matchLabels: # ... app: nginx template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.7.9 # ... name: nginx ports: - containerPort: 80 # ... # ... # ... # ... 使用，直接更新replicas实时配置中的字段kubectl scale。这不使用kubectl apply：1kubectl scale deployment/nginx-deployment --replicas=2 使用kubectl get以下方式打印实时配置1kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 输出显示该replicas字段已设置为2，并且last-applied-configuration注释不包含replicas字段：1234567891011121314151617181920212223242526272829303132333435apiVersion: apps/v1kind: Deploymentmetadata: annotations: # ... # note that the annotation does not contain replicas # because it was not updated through apply kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"minReadySeconds":5,"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.7.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: replicas: 2 # written by scale # ... minReadySeconds: 5 selector: matchLabels: # ... app: nginx template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.7.9 # ... name: nginx ports: - containerPort: 80 # ... 更新simple_deployment.yaml配置文件以将映像更改 nginx:1.7.9为nginx:1.11.9，并删除该minReadySeconds字段：12345678910111213141516171819#application/update_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.11.9 # update the image ports: - containerPort: 80 应用对配置文件所做的更改：12kubectl diff -f https://k8s.io/examples/application/update_deployment.yamlkubectl apply -f https://k8s.io/examples/application/update_deployment.yaml 使用kubectl get以下方式打印实时配置1kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 输出显示实时配置的以下更改： 该replicas字段保留2的值kubectl scale。这是可能的，因为它从配置文件中省略。该image场已被更新，以nginx:1.11.9从nginx:1.7.9。该last-applied-configuration批注已经更新了新的形象。该minReadySeconds领域已被清除。该last-applied-configuration注释不再包含minReadySeconds字段。 1234567891011121314151617181920212223242526272829303132333435363738apiVersion: apps/v1kind: Deploymentmetadata: annotations: # ... # The annotation contains the updated image to nginx 1.11.9, # but does not contain the updated replicas to 2 kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.11.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: replicas: 2 # Set by `kubectl scale`. Ignored by `kubectl apply`. # minReadySeconds cleared by `kubectl apply` # ... selector: matchLabels: # ... app: nginx template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.11.9 # Set by `kubectl apply` # ... name: nginx ports: - containerPort: 80 # ... # ... # ... # ... 警告：混合kubectl apply与势在必行对象配置命令 create和replace不支持。这是因为create 并replace没有保留kubectl.kubernetes.io/last-applied-configuration 的是kubectl apply用来计算更新。 如何删除对象删除管理对象有两种方法kubectl apply。 推荐的： kubectl delete -f &lt;filename&gt;建议的方法是使用命令式命令手动删除对象，因为它更明确地删除了什么，并且不太可能导致用户无意中删除了某些内容1kubectl delete -f &lt;filename&gt; 替代方案： kubectl apply -f &lt;directory/&gt; --prune -l your=label只有在你知道自己在做什么的情况下才能使用它。 警告： kubectl apply --prune处于alpha状态，后续版本中可能会引入向后不兼容的更改。 警告：使用此命令时必须小心，以免意外删除对象。 作为替代方法kubectl delete，您可以使用它kubectl apply来识别从目录中删除配置文件后要删除的对象。--prune 对API服务器应用查询以匹配一组标签的所有对象，并尝试将返回的活动对象配置与对象配置文件进行匹配。如果对象与查询匹配，并且目录中没有配置文件，并且它具有last-applied-configuration注释，则会将其删除。1kubectl apply -f &lt;directory/&gt; --prune -l &lt;labels&gt; 警告：只应对包含对象配置文件的根目录运行prune。如果对象被指定的标签选择器查询返回-l 并且未出现在子目录中，则对子目录运行会导致无意中删除对象。 如何查看对象您可以使用kubectl getwith -o yaml来查看活动对象的配置： 1kubectl get -f &lt;filename|url&gt; -o yaml 如何应用计算差异并合并更改 注意：补丁是一种更新操作，其范围限定为对象的特定字段而不是整个对象。这样可以仅更新对象上的特定字段集，而无需先读取对象。 当kubectl apply一个对象更新实时配置，它通过发送补丁请求API服务器这样做。该补丁定义了作用于活动对象配置的特定字段的更新。该kubectl apply命令使用配置文件，实时配置和实时配置中last-applied-configuration存储的注释来计算此修补程序请求 。 合并补丁计算该kubectl apply命令将配置文件的内容写入 kubectl.kubernetes.io/last-applied-configuration注释。这用于标识已从配置文件中删除的字段，需要从实时配置中清除。以下是用于计算应删除或设置哪些字段的步骤： 计算要删除的字段。这些是last-applied-configuration配置文件中存在和丢失的字段。 计算要添加或设置的字段。这些是配置文件中存在的字段，其值与实时配置不匹配。 这是一个例子。假设这是Deployment对象的配置文件：12345678910111213141516171819#application/update_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.11.9 # update the image ports: - containerPort: 80 另外，假设这是同一Deployment对象的实时配置：1234567891011121314151617181920212223242526272829303132333435apiVersion: apps/v1kind: Deploymentmetadata: annotations: # ... # note that the annotation does not contain replicas # because it was not updated through apply kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"minReadySeconds":5,"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.7.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: replicas: 2 # written by scale # ... minReadySeconds: 5 selector: matchLabels: # ... app: nginx template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.7.9 # ... name: nginx ports: - containerPort: 80 # ... 以下是将通过以下方式执行的合并计算kubectl apply： 通过读取值last-applied-configuration并将它们与配置文件中的值进行比较来计算要删除的字段 。清除字段在本地对象配置文件中显式设置为null，无论它们是否出现在last-applied-configuration。在此示例中，minReadySeconds出现在 last-applied-configuration注释中，但未出现在配置文件中。 Action：minReadySeconds`从实时配置中清除。 通过从配置文件中读取值并将它们与实时配置中的值进行比较来计算要设置的字段。在此示例中，image配置文件中的值与实时配置中的值不匹配。Action：设置image实时配置中的值。 设置last-applied-configuration注释以匹配配置文件的值。 将来自1,2,3的结果合并到API服务器的单个补丁请求中。 以下是合并的实时配置：1234567891011121314151617181920212223242526272829303132333435363738apiVersion: apps/v1kind: Deploymentmetadata: annotations: # ... # The annotation contains the updated image to nginx 1.11.9, # but does not contain the updated replicas to 2 kubectl.kubernetes.io/last-applied-configuration: | &#123;"apiVersion":"apps/v1","kind":"Deployment", "metadata":&#123;"annotations":&#123;&#125;,"name":"nginx-deployment","namespace":"default"&#125;, "spec":&#123;"selector":&#123;"matchLabels":&#123;"app":nginx&#125;&#125;,"template":&#123;"metadata":&#123;"labels":&#123;"app":"nginx"&#125;&#125;, "spec":&#123;"containers":[&#123;"image":"nginx:1.11.9","name":"nginx", "ports":[&#123;"containerPort":80&#125;]&#125;]&#125;&#125;&#125;&#125; # ...spec: selector: matchLabels: # ... app: nginx replicas: 2 # Set by `kubectl scale`. Ignored by `kubectl apply`. # minReadySeconds cleared by `kubectl apply` # ... template: metadata: # ... labels: app: nginx spec: containers: - image: nginx:1.11.9 # Set by `kubectl apply` # ... name: nginx ports: - containerPort: 80 # ... # ... # ... # ... 如何合并不同类型的字段配置文件中的特定字段如何与实时配置合并取决于字段的类型。有几种类型的字段： primitive：字符串，整数或布尔类型的字段。例如，image和replicas是原始字段。行动：替换。 map，也称为object：类型为map的字段或包含子字段的复杂类型。例如labels， annotations，spec并且metadata是所有map。Action：合并元素或子字段。 list：包含可以是基本类型或映射的项列表的字段。例如containers，ports和args是列表。行动：变化。 当kubectl apply更新map或列表字段，它通常不更换整个领域，而是更新各个子元素。例如，在合并spec部署时，spec不会替换整个部署。相反，比较和合并spec诸如的子字段replicas。 将更改合并到基本字段将更改合并到基本字段 注意： -用于“不适用”，因为未使用该值。 对象配置文件中的字段 实时对象配置中的字段 最后应用配置中的字段 行动 是 是 - 设置为配置文件值。 是 没有 - 将实时设置为本地配置。 没有 - - 从实时配置中清除。 没有 - 没有 没做什么。保持实时价值。 合并对地图字段的更改通过比较地图的每个子字段或元素来合并表示地图的字段： 注意： -用于“不适用”，因为未使用该值。 键入对象配置文件 键入实时对象配置 最后应用配置中的字段 行动 是 是 - 比较子字段值。 是 没有 - 将实时设置为本地配置。 没有 - 是 从实时配置中删除。 没有 - 没有 没做什么。保持实时价值。 合并类型列表字段的更改将更改合并到列表使用以下三种策略之一： 替换列表。 合并复杂元素列表中的各个元素。 合并原始元素列表。 战略的选择是基于每个领域。 替换列表将列表视为与原始字段相同。替换或删除整个列表。这保留了订购。 例如：使用kubectl apply更新args一个pod里的一个Container的field。这会将args实时配置中的值设置为配置文件中的值。args之前已添加到实时配置的任何元素都将丢失。args配置文件中定义的元素的顺序将保留在实时配置中。1234567891011# last-applied-configuration value args: ["a", "b"]# configuration file value args: ["a", "c"]# live configuration args: ["a", "b", "d"]# result after merge args: ["a", "c"] 说明：合并使用配置文件值作为新列表值。 合并复杂元素列表中的各个元素：将列表视为映射，并将每个元素的特定字段视为键。添加，删除或更新单个元素。这不会保留排序。 此合并策略在每个字段上使用一个名为a的特殊标记patchMergeKey。patchMergeKey是在Kubernetes源代码中的每个字段中定义： types.go 当合并映射的列表，指定的字段作为patchMergeKey对于给定的元素被用于像该元素的映射键。 例如：使用kubectl apply更新containers一PodSpec的field。这将列表合并为好像是每个元素都被键入的映射name。123456789101112131415161718192021222324252627282930313233343536373839404142# last-applied-configuration value containers: - name: nginx image: nginx:1.10 - name: nginx-helper-a # key: nginx-helper-a; will be deleted in result image: helper:1.3 - name: nginx-helper-b # key: nginx-helper-b; will be retained image: helper:1.3# configuration file value containers: - name: nginx image: nginx:1.10 - name: nginx-helper-b image: helper:1.3 - name: nginx-helper-c # key: nginx-helper-c; will be added in result image: helper:1.3# live configuration containers: - name: nginx image: nginx:1.10 - name: nginx-helper-a image: helper:1.3 - name: nginx-helper-b image: helper:1.3 args: ["run"] # Field will be retained - name: nginx-helper-d # key: nginx-helper-d; will be retained image: helper:1.3# result after merge containers: - name: nginx image: nginx:1.10 # Element nginx-helper-a was deleted - name: nginx-helper-b image: helper:1.3 args: ["run"] # Field was retained - name: nginx-helper-c # Element was added image: helper:1.3 - name: nginx-helper-d # Element was ignored image: helper:1.3 说明： 名为“nginx-helper-a”的容器已删除，因为配置文件中没有出现名为“nginx-helper-a”的容器。 名为“nginx-helper-b”的容器保留args 了实时配置中的更改。kubectl apply能够识别实时配置中的“nginx-helper-b”与配置文件中的“nginx-helper-b”相同，即使它们的字段具有不同的值（args配置文件中没有）。这是因为patchMergeKey字段值（名称）在两者中都是相同的。 添加了名为“nginx-helper-c”的容器，因为实时配置中没有出现具有该名称的容器，但配置文件中出现了具有该名称的容器。 保留名为“nginx-helper-d”的容器，因为在最后应用的配置中没有出现具有该名称的元素。 合并原始元素列表从Kubernetes 1.5开始，不支持合并原始元素列表。 注意：为给定字段选择的上述策略中的哪一个由types.go中的patchStrategy标记控制。如果没有为类型列表的字段指定patchStrategy，则替换列表。 默认字段值如果在创建对象时未指定某些字段，则API服务器会将某些字段设置为实时配置中的默认值。 这是部署的配置文件。该文件未指定strategy：1234567891011121314151617181920#application/simple_deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deploymentspec: selector: matchLabels: app: nginx minReadySeconds: 5 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 使用kubectl apply以下方法创建对象1kubectl apply -f https://k8s.io/examples/application/simple_deployment.yaml 使用kubectl get以下方式打印实时配置1kubectl get -f https://k8s.io/examples/application/simple_deployment.yaml -o yaml 输出显示API服务器在实时配置中将多个字段设置为默认值。配置文件中未指定这些字段。12345678910111213141516171819202122232425262728293031323334apiVersion: apps/v1kind: Deployment# ...spec: selector: matchLabels: app: nginx minReadySeconds: 5 replicas: 1 # defaulted by apiserver strategy: rollingUpdate: # defaulted by apiserver - derived from strategy.type maxSurge: 1 maxUnavailable: 1 type: RollingUpdate # defaulted apiserver template: metadata: creationTimestamp: null labels: app: nginx spec: containers: - image: nginx:1.7.9 imagePullPolicy: IfNotPresent # defaulted by apiserver name: nginx ports: - containerPort: 80 protocol: TCP # defaulted by apiserver resources: &#123;&#125; # defaulted by apiserver terminationMessagePath: /dev/termination-log # defaulted by apiserver dnsPolicy: ClusterFirst # defaulted by apiserver restartPolicy: Always # defaulted by apiserver securityContext: &#123;&#125; # defaulted by apiserver terminationGracePeriodSeconds: 30 # defaulted by apiserver# ... 在修补程序请求中，默认字段不会被重新默认，除非它们作为修补程序请求的一部分被明确清除。这可能会导致基于其他字段的值默认的字段出现意外行为。稍后更改其他字段时，除非明确清除，否则不会更新默认值。 因此，建议在配置文件中显式定义服务器默认的某些字段，即使所需的值与服务器默认值匹配也是如此。这样可以更轻松地识别不会被服务器重新默认的冲突值。 例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# last-applied-configurationspec: template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80# configuration filespec: strategy: type: Recreate # updated value template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80# live configurationspec: strategy: type: RollingUpdate # defaulted value rollingUpdate: # defaulted value derived from type maxSurge : 1 maxUnavailable: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80# result after merge - ERROR!spec: strategy: type: Recreate # updated value: incompatible with rollingUpdate rollingUpdate: # defaulted value: incompatible with "type: Recreate" maxSurge : 1 maxUnavailable: 1 template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 说明： 用户无需定义即可创建部署strategy.type。 服务器默认strategy.type为RollingUpdate默认 strategy.rollingUpdate值。 用户更改strategy.type为Recreate。该strategy.rollingUpdate值保持在其默认的值，但服务器期望他们被清除。如果strategy.rollingUpdate最初在配置文件中定义了值，则更清楚的是它们需要被删除。 应用失败，因为strategy.rollingUpdate未清除。该strategy.rollingupdate 字段不能与被定义strategy.type的Recreate。 建议：应在对象配置文件中明确定义这些字段： 工作负载上的选择器和PodTemplate标签，例如Deployment，StatefulSet，Job，DaemonSet，ReplicaSet和ReplicationController 部署部署策略 如何清除其他编写者设置的服务器默认字段或字段可以通过将其值设置为null然后应用配置文件来清除未出现在配置文件中的字段。对于服务器默认的字段，这会触发重新默认值。 如何更改配置文件和直接命令式编写器之间字段的所有权这些是您应该用来更改单个对象字段的唯一方法： 使用kubectl apply。 直接写入实时配置而不修改配置文件：例如，使用kubectl scale。 将所有者从直接命令式编写器更改为配置文件将该字段添加到配置文件中。对于现场，停止对未经过的实时配置的直接更新kubectl apply。 将所有者从配置文件更改为直接命令式编写器从Kubernetes 1.5开始，将字段的所有权从配置文件更改为命令式编写器需要手动步骤： 从配置文件中删除该字段。 从kubectl.kubernetes.io/last-applied-configuration活动对象上的注释中删除该字段。 改变管理方法应该一次只使用一种方法管理Kubernetes对象。可以从一种方法切换到另一种方法，但这是一种手动过程。 注意：使用命令式删除和声明式管理是可以的。 从命令式命令管理迁移到声明性对象配置从命令式命令管理迁移到声明性对象配置涉及几个手动步骤： 将活动对象导出到本地配置文件： 1kubectl get &lt;kind&gt;/&lt;name&gt; -o yaml --export &gt; &lt;kind&gt;_&lt;name&gt;.yaml status从配置文件中手动删除该字段。 注意：此步骤是可选的，因为kubectl apply不会更新状态字段 即使它存在于配置文件中。 kubectl.kubernetes.io/last-applied-configuration在对象上设置注释： 1kubectl replace --save-config -f &lt;kind&gt;_&lt;name&gt;.yaml 更改kubectl apply用于专门管理对象的进程。 从命令式对象配置迁移到声明性对象配置 kubectl.kubernetes.io/last-applied-configuration在对象上设置注释： 1kubectl replace --save-config -f &lt;kind&gt;_&lt;name&gt;.yaml 更改kubectl apply用于专门管理对象的进程。 定义控制器选择器和PodTemplate标签 警告：强烈建议不要更新控制器上的选择器。 推荐的方法是定义一个仅由控制器选择器使用的单个不可变PodTemplate标签，没有其他语义含义。 例：1234567selector: matchLabels: controller-selector: "extensions/v1beta1/deployment/nginx"template: metadata: labels: controller-selector: "extensions/v1beta1/deployment/nginx" Kubernetes Architecture节点节点是Kubernetes中的工作机器，以前称为一个 minion。节点可以是VM或物理机，具体取决于集群。每个节点都包含运行pods所需的服务，并由主组件管理。节点上的服务包括container runtime，kubelet和kube-proxy。有关更多详细信息，请参阅 体系结构设计文档中的Kubernetes节点部分。 节点状态 管理 API对象 节点状态节点的状态包含以下信息： 地址 条件 容量 信息 下面详细描述每个部分。 地址这些字段的使用取决于您的云提供商或裸机配置。 HostName：节点内核报告的主机名。可以通过kubelet--hostname-override参数覆盖。 ExternalIP：通常是可从外部路由的节点的IP地址（可从群集外部获得）。 InternalIP：通常仅在群集内可路由的节点的IP地址。 条件该conditions字段描述了所有Running节点的状态。 节点条件 描述 OutOfDisk True 如果节点上的可用空间不足以添加新的pod，否则 False Ready True如果节点是健康的并准备好接受pod，False如果节点不健康且不接受pod，并且Unknown节点控制器在最后一次没有从节点听到node-monitor-grace-period（默认为40秒） MemoryPressure True如果节点存储器上存在压力 - 即节点存储器是否为低; 除此以外False PIDPressure True如果进程存在压力 - 也就是说，如果节点上有太多进程; 除此以外False DiskPressure True如果磁盘大小存在压力 - 即磁盘容量低; 除此以外False NetworkUnavailable True 如果没有正确配置节点的网络，否则 False 节点条件表示为JSON对象。例如，以下响应描述了健康节点。123456"conditions": [ &#123; "type": "Ready", "status": "True" &#125;] 如果就绪状态的状态保持Unknown或False超过pod-eviction-timeout，则会将参数传递给kube-controller-manager，并且节点控制器会调度节点上的所有Pod以进行删除。默认逐出超时持续时间为五分钟。在某些情况下，当节点无法访问时，apiserver无法与节点上的kubelet通信。在重新建立与apiserver的通信之前，不能将删除pod的决定传送到kubelet。同时，计划删除的pod可以继续在分区节点上运行。 在1.5之前的Kubernetes版本中，节点控制器会从apiserver中强制删除这些无法访问的pod。但是，在1.5及更高版本中，节点控制器不会强制删除容器，直到确认它们已停止在群集中运行。您可以看到可能在无法访问的节点上运行的Pod处于Terminating或Unknown状态。如果节点永久离开群集，如果Kubernetes无法从底层基础架构推断出，则群集管理员可能需要手动删除节点对象。从Kubernetes中删除节点对象会导致节点上运行的所有Pod对象从apiserver中删除，并释放它们的名称。 在版本1.12中，TaintNodesByCondition功能被提升为beta版，因此节点生命周期控制器会自动创建表示条件的 taints 。类似地，调度程序在考虑节点时忽略条件;相反，它会查看Node的污点和Pod的容忍度。 现在，用户可以在旧的调度模型和更灵活的新调度模型之间进行选择。根据旧型号，可以安排没有任何容忍度的Pod。但是可以在该节点上安排容忍特定节点的污点的Pod。 警告：启用此功能会在观察到条件和创建污点之间产生一个小延迟。此延迟通常小于一秒，但它可以增加成功安排但被kubelet拒绝的Pod的数量。 容量描述节点上可用的资源：CPU，内存以及可以在节点上调度的最大pod数。 信息有关节点的一般信息，例如内核版本，Kubernetes版本（kubelet和kube-proxy版本），Docker版本（如果使用），操作系统名称。信息由Kubelet从节点收集。 管理与pod和服务不同，Kubernetes本身并不创建节点：它由Google Compute Engine等云提供商在外部创建，或者存在于物理或虚拟机池中。因此，当Kubernetes创建节点时，它会创建一个表示节点的对象。创建后，Kubernetes会检查节点是否有效。例如，如果您尝试从以下内容创建节点：12345678910&#123; "kind": "Node", "apiVersion": "v1", "metadata": &#123; "name": "10.240.79.157", "labels": &#123; "name": "my-first-k8s-node" &#125; &#125;&#125; Kubernetes在内部创建节点对象（表示），并通过基于metadata.name字段的运行状况检查来验证节点。如果节点有效 - 即，如果所有必需的服务都在运行 - 它有资格运行pod。否则，对于任何群集活动，它将被忽略，直到它变为有效。 注意： Kubernetes保留无效节点的对象，并不断检查它是否有效。您必须显式删除Node对象才能停止此过程。 目前，有三个组件与Kubernetes节点接口交互：节点控制器，kubelet和kubectl。 节点控制器节点控制器是Kubernetes主组件，它管理节点的各个方面。 节点控制器在节点的生命周期中具有多个角色。第一种是在注册时为节点分配CIDR块（如果打开了CIDR分配）。 第二个是使节点控制器的内部节点列表与云提供商的可用计算机列表保持同步。在云环境中运行时，只要节点不健康，节点控制器就会询问云提供商该节点的VM是否仍然可用。如果不是，则节点控制器从其节点列表中删除该节点。 第三是监测节点的健康状况。节点控制器负责在节点变得无法访问时将NodeStatus的NodeReady条件更新为ConditionUnknown（即节点控制器由于某种原因停止接收心跳，例如由于节点关闭），然后从节点中驱逐所有pod （如果节点仍然无法访问，则使用正常终止）。（默认超时为40 --node-monitor-period秒，开始报告ConditionUnknown，之后5米开始驱逐pod。）节点控制器每秒检查每个节点的状态。 在1.13之前的Kubernetes版本中，NodeStatus是节点的心跳。从Kubernetes 1.13开始，节点租用功能作为alpha功能引入（功能门NodeLease， KEP-0009）。启用节点租用功能时，每个节点都有一个关联的Lease对象 kube-node-lease由节点定期更新的命名空间，NodeStatus和节点租约都被视为来自节点的心跳。节点租约经常更新，而NodeStatus仅在有一些更改或经过足够时间时从节点报告为主节点（默认值为1分钟，这比不可达节点的默认超时40秒）。由于节点租约比NodeStatus轻得多，因此从可伸缩性和性能角度来看，此功能使节点心跳显着降低。 在Kubernetes 1.4中，我们更新了节点控制器的逻辑，以便在大量节点到达主站时遇到问题时更好地处理案例（例如，因为主站有网络问题）。从1.4开始，节点控制器在决定pod驱逐时查看集群中所有节点的状态。 在大多数情况下，节点控制器将驱逐率限制为每秒 --node-eviction-rate（默认值0.1），这意味着它不会每10秒从多个节点驱逐pod。 当给定可用区中的节点变得不健康时，节点逐出行为会发生变化。节点控制器同时检查区域中节点的百分比是否不健康（NodeReady条件是ConditionUnknown或ConditionFalse）。如果不健康节点的比例至少为 --unhealthy-zone-threshold（默认为0.55），则驱逐率降低：如果群集较小（即小于或等于--large-cluster-size-threshold节点 - 默认为50）则停止驱逐，否则驱逐率降低为 --secondary-node-eviction-rate（默认0.01）每秒。每个可用区域实施这些策略的原因是因为一个可用区域可能从主服务器分区而其他可用区域保持连接。如果您的群集未跨越多个云提供商可用区域，则只有一个可用区域（整个群集）。 在可用区域之间传播节点的一个关键原因是，当整个区域出现故障时，工作负载可以转移到健康区域。因此，如果区域中的所有节点都不健康，则节点控制器以正常速率驱逐--node-eviction-rate。角落情况是所有区域完全不健康（即群集中没有健康的节点）。在这种情况下，节点控制器假定主连接存在一些问题，并在某些连接恢复之前停止所有驱逐。 从Kubernetes 1.6开始，NodeController还负责驱逐在具有NoExecute污点的节点上运行的pod，当pod不能容忍taints时。此外，作为默认禁用的alpha功能，NodeController负责添加与节点无法访问或未就绪等节点问题相对应的污点。 有关污点和alpha功能的详细信息，请参阅此文档NoExecute。 从版本1.8开始，节点控制器可以负责创建表示节点条件的污点。这是1.8版的alpha功能。 节点自注册当kubelet标志--register-node为true（默认值）时，kubelet将尝试向API服务器注册自己。这是大多数发行版使用的首选模式。 对于自行注册，可以使用以下选项启动kubelet： --kubeconfig - 凭证路径，以向apiserver验证自身。 --cloud-provider - 如何与云提供商交谈以阅读有关自身的元数据。 --register-node - 自动注册API服务器。 --register-with-taints- 使用给定的taints列表注册节点（以逗号分隔&lt;key&gt;=&lt;value&gt;:&lt;effect&gt;）。No-op如果register-node是假的。 --node-ip - 节点的IP地址。 --node-labels- 在群集中注册节点时添加的标签（请参阅1.13+中NodeRestriction准入插件强制执行的标签限制）。 --node-status-update-frequency - 指定kubelet将节点状态发布到master的频率。 当节点授权模式和 NodeRestriction录取插件的启用，kubelets仅被授权创建/修改自己的节点资源。 手动节点管理集群管理员可以创建和修改节点对象。 如果管理员希望手动创建节点对象，请设置kubelet标志 --register-node=false。 管理员可以修改节点资源（无论设置如何--register-node）。修改包括在节点上设置标签并将其标记为不可调度。 节点上的标签可以与pod上的节点选择器结合使用以控制调度，例如，将pod限制为仅有资格在节点的子集上运行。 将节点标记为不可调度可防止将新pod调度到该节点，但不会影响节点上的任何现有pod。这在节点重启等之前作为准备步骤很有用。例如，要标记节点不可调度，请运行以下命令：1kubectl cordon $NODENAME 注意：由DaemonSet控制器创建的Pod绕过Kubernetes调度程序，不遵守节点上的不可调度属性。这假设守护进程属于机器，即使它在准备重新启动时正在耗尽应用程序。 节点容量节点的容量（cpus的数量和内存量）是节点对象的一部分。通常，节点在创建节点对象时注册自己并报告其容量。如果您正在进行手动节点管理，则需要在添加节点时设置节点容量。 Kubernetes调度程序确保节点上的所有pod都有足够的资源。它检查节点上容器请求的总和不大于节点容量。它包括由kubelet启动的所有容器，但不包括由容器运行时直接启动的容器，也不包括在容器外部运行的任何进程。 如果要为非Pod进程显式保留资源，请按照本教程 为系统守护程序保留资源。 API对象Node是Kubernetes REST API中的顶级资源。有关API对象的更多详细信息，请参见： Node API对象。 主节点通信本文档对master（实际上是apiserver）和Kubernetes集群之间的通信路径进行了编目。目的是允许用户自定义其安装以强化网络配置，以便群集可以在不受信任的网络（或云提供商上的完全公共IP）上运行。 群集到Master 掌握群集 群集到Master从集群到主服务器的所有通信路径都在apiserver处终止（其他主服务器组件均未设计为公开远程服务）。在典型部署中，apiserver被配置为在安全HTTPS端口（443）上侦听远程连接，其中启用了一种或多种形式的客户端认证。 应启用一种或多种授权形式，尤其是 在允许匿名请求 或服务帐户令牌的情况下。 应为节点配置群集的公共根证书，以便它们可以安全地连接到apiserver以及有效的客户端凭据。例如，在默认GKE部署中，提供给kubelet的客户端凭证采用客户端证书的形式。请参阅 kubelet TLS bootstrapping 以自动配置kubelet客户端证书。 希望连接到apiserver的Pod可以通过利用服务帐户安全地执行此操作，以便Kubernetes在实例化时自动将公共根证书和有效的承载令牌注入到pod中。该kubernetes服务（在所有名称空间中）配置有虚拟IP地址，该地址被重定向（通过kube-proxy）到apiserver上的HTTPS端点。 主组件还通过安全端口与群集服务器通信。 因此，默认情况下，从群集（节点和节点上运行的节点）到主节点的连接的默认操作模式是安全的，可以在不受信任和/或公共网络上运行。 掌握群集从主服务器（apiserver）到集群有两条主要通信路径。第一个是从apiserver到kubelet进程，它在集群中的每个节点上运行。第二种是通过apiserver的代理功能从apiserver到任何节点，pod或服务。 kubelet的保护者从apiserver到kubelet的连接用于： 获取pod的日志。 附加（通过kubectl）到运行的pod。 提供kubelet的端口转发功能。 这些连接终止于kubelet的HTTPS端点。默认情况下，apiserver不会验证kubelet的服务证书，这会使连接受到中间人攻击，并且 不安全地运行在不受信任的和/或公共网络上。 要验证此连接，请使用该--kubelet-certificate-authority标志为apiserver提供根证书包，以用于验证kubelet的服务证书。 如果无法做到这一点，请 在apiserver和kubelet之间使用SSH隧道，以避免连接不受信任或公共网络。 最后， 应启用Kubelet身份验证和/或授权以保护kubelet API。 节点，pod和服务的apiserver从apiserver到节点，pod或服务的连接默认为纯HTTP连接，因此既未经过身份验证也未加密。它们可以通过前缀https:到API URL中的节点，pod或服务名称在安全HTTPS连接上运行，但它们不会验证HTTPS端点提供的证书，也不会提供客户端凭据，因此在连接将被加密时，它不会提供任何诚信保证。这些连接目前在不受信任和/或公共网络上运行是不安全的。 云控制器管理器的基础概念最初创建云控制器管理器（CCM）概念（不要与二进制混淆），以允许特定于云的供应商代码和Kubernetes核心彼此独立地发展。云控制器管理器与其他主组件（如Kubernetes控制器管理器，API服务器和调度程序）一起运行。它也可以作为Kubernetes插件启动，在这种情况下它运行在Kubernetes之上。 云控制器管理器的设计基于一种插件机制，允许新的云提供商通过使用插件轻松地与Kubernetes集成。有计划在Kubernetes上加入新的云提供商，以及将云提供商从旧模型迁移到新的CCM模型。 本文档讨论了云控制器管理器背后的概念，并提供了有关其相关功能的详细信息。 这是没有云控制器管理器的Kubernetes集群的架构： 设计 CCM的组成部分 CCM的功能 插件机制 授权 供应商实施 群集管理 设计在上图中，Kubernetes和云提供商通过几个不同的组件集成： Kubelet Kubernetes控制器经理 Kubernetes API服务器 CCM整合了前三个组件中的所有依赖于云的逻辑，以创建与云的单一集成点。CCM的新架构如下所示： CCM的组成部分CCM打破了Kubernetes控制器管理器（KCM）的一些功能，并将其作为一个单独的进程运行。具体来说，它打破了KCM中依赖于云的控制器。KCM具有以下依赖于云的控制器循环： 节点控制器 音量控制器 路线控制器 服务控制器 在1.9版中，CCM运行前面列表中的以下控制器： 节点控制器 路线控制器 服务控制器 此外，它还运行另一个名为PersistentVolumeLabels控制器的控制器。此控制器负责在GCP和AWS云中创建的PersistentVolumes上设置区域和区域标签。 注意：故意选择音量控制器不属于CCM。由于涉及复杂性并且由于现有的努力抽象出供应商特定的卷逻辑，因此决定不将卷控制器移动到CCM。 使用CCM支持卷的最初计划是使用Flex卷来支持可插拔卷。然而，正在计划一项名为CSI的竞争性工作来取代Flex。 考虑到这些动态，我们决定在CSI准备好之前进行中间止差测量。 CCM的功能CCM从依赖于云提供商的Kubernetes组件继承其功能。本节基于这些组件构建。 1. Kubernetes控制器经理CCM的大部分功能来自KCM。如上一节所述，CCM运行以下控制循环： 节点控制器 路线控制器 服务控制器 PersistentVolumeLabels控制器 节点控制器节点控制器负责通过从云提供商获取有关在集群中运行的节点的信息来初始化节点。节点控制器执行以下功能： 使用特定于云的区域/区域标签初始化节点。 使用特定于云的实例详细信息初始化节点，例如，类型和大小。 获取节点的网络地址和主机名。 如果节点无响应，请检查云以查看该节点是否已从云中删除。如果已从云中删除该节点，请删除Kubernetes Node对象。 路线控制器Route控制器负责适当地配置云中的路由，以便Kubernetes集群中不同节点上的容器可以相互通信。路径控制器仅适用于Google Compute Engine群集。 服务控制器服务控制器负责监听服务创建，更新和删除事件。根据Kubernetes中当前的服务状态，它配置云负载均衡器（如ELB或Google LB）以反映Kubernetes中的服务状态。此外，它还确保云负载平衡器的服务后端是最新的。 PersistentVolumeLabels控制器PersistentVolumeLabels控制器在创建AWS EBS / GCE PD卷时应用标签。这消除了用户手动设置这些卷上的标签的需要。 这些标签对于pod的计划至关重要，因为这些卷仅限于在它们所在的区域/区域内工作。使用这些卷的任何Pod都需要在同一区域/区域中进行调度。 PersistentVolumeLabels控制器专门为CCM创建; 也就是说，在创建CCM之前它不存在。这样做是为了将Kubernetes API服务器（它是一个许可控制器）中的PV标记逻辑移动到CCM。它不在KCM上运行。 2. Kubelet节点控制器包含kubelet的依赖于云的功能。在引入CCM之前，kubelet负责使用特定于云的详细信息（如IP地址，区域/区域标签和实例类型信息）初始化节点。CCM的引入已将此初始化操作从kubelet转移到CCM。 在这个新模型中，kubelet初始化一个没有特定于云的信息的节点。但是，它会为新创建的节点添加污点，使节点不可调度，直到CCM使用特定于云的信息初始化节点。然后它消除了这种污点。 3. Kubernetes API服务器PersistentVolumeLabels控制器将Kubernetes API服务器的依赖于云的功能移动到CCM，如前面部分所述。 插件机制云控制器管理器使用Go接口允许插入任何云的实现。具体来说，它使用此处定义的CloudProvider接口。 上面突出显示的四个共享控制器的实现，以及一些脚手架以及共享的cloudprovider接口，将保留在Kubernetes核心中。特定于云提供商的实现将在核心之外构建，并实现核心中定义的接口。 有关开发插件的更多信息，请参阅开发Cloud Controller Manager。 授权本节分解了CCM执行其操作时各种API对象所需的访问权限。 节点控制器Node控制器仅适用于Node对象。它需要完全访问get，list，create，update，patch，watch和delete Node对象。 V1 /节点： Get List Create Update Patch Watch Delete 路线控制器路由控制器侦听Node对象创建并适当地配置路由。它需要访问Node对象。 V1 /节点： Get 服务控制器服务控制器侦听Service对象创建，更新和删除事件，然后适当地为这些服务配置端点。 要访问服务，它需要列表和监视访问权限。要更新服务，它需要修补和更新访问权限。 要为服务设置端点，需要访问create，list，get，watch和update。 V1 /服务： List Get Watch Patch Update PersistentVolumeLabels控制器PersistentVolumeLabels控制器侦听PersistentVolume（PV）创建事件，然后更新它们。该控制器需要访问以获取和更新PV。 V1 / PersistentVolume： Get List Watch Update 其他CCM核心的实现需要访问以创建事件，并且为了确保安全操作，它需要访问以创建ServiceAccounts。 V1 /事件： Create Patch Update V1 / ServiceAccount： Create CCM的RBAC ClusterRole如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859apiVersion: rbac.authorization.k8s.io/v1kind: ClusterRolemetadata: name: cloud-controller-managerrules:- apiGroups: - "" resources: - events verbs: - create - patch - update- apiGroups: - "" resources: - nodes verbs: - '*'- apiGroups: - "" resources: - nodes/status verbs: - patch- apiGroups: - "" resources: - services verbs: - list - patch - update - watch- apiGroups: - "" resources: - serviceaccounts verbs: - create- apiGroups: - "" resources: - persistentvolumes verbs: - get - list - update - watch- apiGroups: - "" resources: - endpoints verbs: - create - get - list - watch - update 供应商实施以下云提供商已实施CCM： Digital Ocean Oracle Azure GCE AWS 群集管理此处提供了有关配置和运行CCM的完整说明 容器镜像您创建Docker镜像并将其推送到仓库，然后在Kubernetes的pod中引用它。 image容器的属性支持与docker命令相同的语法，包括私有仓库和标记。 更新镜像 用清单构建多架构镜像 使用私人仓库 更新镜像默认拉取策略IfNotPresent会导致Kubelet跳过拉动镜像（如果已存在）。如果您想总是强制Docker拉动，可以执行以下操作之一： 将imagePullPolicy容器设置为Always。 省略imagePullPolicy并使用它:latest作为要使用的镜像的标记。 省略imagePullPolicy要使用的镜像和标记。 启用AlwaysPullImages准入控制器。 请注意，您应该避免使用:latest标记，有关详细信息，请参阅配置的最佳实践。 用清单构建多架构图像Docker CLI现在支持以下命令docker manifest中包含的子命令create，annotate并push。这些命令可用于构建和推送清单。您可以使用docker manifest inspect查看清单。 请在此处查看docker文档，请参阅我们在构建工具中如何使用它的示例&amp;i=nope&amp;files=&amp;repos=)。 这些命令完全依赖于Docker CLI，并且完全在Docker CLI上实现。您需要编辑$HOME/.docker/config.json和设置experimental密钥，enabled或者只需在调用CLI命令时将DOCKER_CLI_EXPERIMENTAL环境变量设置为enabled。 注意：请使用Docker 18.06或更高版本，以下版本有错误或不支持实验命令行选项。示例会在containerd下导致问题。 如果您在上传陈旧的清单时遇到问题，只需清理旧的清单$HOME/.docker/manifests即可重新开始。 对于Kubernetes，我们通常使用带后缀的镜像-$(ARCH)。为了向后兼容，请生成带有后缀的旧镜像。我们的想法是生成pause具有所有拱形清单的说明镜像，并说出pause-amd64哪些向后兼容旧配置或YAML文件，这些文件可能硬编码带有后缀的镜像。 使用私人仓库私人仓库管理可能需要密钥才能从中读取图像。凭证可以通过多种方式提供： 使用Google Container Registry Per-cluster 在Google Compute Engine或Google Kubernetes Engine上自动配置 所有pod都可以读取项目的私有仓库 使用AWS EC2容器仓库（ECR） 使用IAM角色和策略来控制对ECR存储库的访问 自动刷新ECR登录凭据 使用Azure容器仓库（ACR） 使用IBM Cloud Container Registry 配置节点以验证私有仓库 所有pod都可以读取任何已配置的私有仓库 需要集群管理员进行节点配置 预拉镜像 所有pod都可以使用节点上缓存的任何镜像 需要root权限才能设置所有节点 在Pod上指定ImagePullSecrets 只有提供自己密钥的pod才能访问私有仓库 下面更详细地描述每个选项。 使用Google Container Registry在Google Compute Engine（GCE）上运行时，Kubernetes对Google Container Registry（GCR）提供原生支持。如果您在GCE或Google Kubernetes Engine上运行群集，只需使用完整的镜像名称（例如gcr.io/my_project/image：tag）。 群集中的所有pod都具有此仓库中镜像的读取权限。 kubelet将使用实例的Google服务帐户向GCR进行身份验证。实例上的服务帐户将具有一个 https://www.googleapis.com/auth/devstorage.read_only，因此它可以从项目的GCR中提取，但不能推送。 使用AWS EC2 Container Registry当节点是AWS EC2实例时，Kubernetes对AWS EC2 Container Registry具有本机支持。 只需ACCOUNT.dkr.ecr.REGION.amazonaws.com/imagename:tag在Pod定义中使用完整的图像名称（例如）。 可以创建pod的群集的所有用户都可以运行使用ECR仓库中任何镜像的pod。 kubelet将获取并定期刷新ECR凭据。它需要以下权限才能执行此操作： ecr:GetAuthorizationToken ecr:BatchCheckLayerAvailability ecr:GetDownloadUrlForLayer ecr:GetRepositoryPolicy ecr:DescribeRepositories ecr:ListImages ecr:BatchGetImage 要求： 您必须使用kubelet版本v1.2.0或更新版本。（例如run /usr/bin/kubelet --version=true）。 如果您的节点位于区域A中且您的注册表位于不同的区域B中，则需要v1.3.0更新版本或更新版本。 ECR必须在您所在的地区提供 故障排除： 验证上述所有要求。 us-west-2在工作站上获取$ REGION（例如）凭据。SSH进入主机并使用这些信用卡手动运行Docker。它有用吗？ 验证kubelet是否正在运行--cloud-provider=aws。 检查kubelet日志（例如journalctl -u kubelet）以获取日志行，例如： plugins.go:56] Registering credential provider: aws-ecr-key provider.go:91] Refreshing cache for provider: *aws_credentials.ecrProvider 使用Azure容器仓库（ACR）使用Azure容器仓库时， 您可以使用管理员用户或服务主体进行身份验证。在任何一种情况下，身份验证都通过标准Docker身份验证完成 这些说明假定使用 azure-cli命令行工具。 您首先需要创建一个仓库并生成凭据，完整的文档可以在Azure容器仓库文档中找到。 创建容器仓库后，您将使用以下凭据登录： DOCKER_USER ：服务主体或管理员用户名 DOCKER_PASSWORD：服务主体密码或管理员用户密码 DOCKER_REGISTRY_SERVER： ${some-registry-name}.azurecr.io DOCKER_EMAIL：${some-email-address} 填好这些变量后，您可以配置Kubernetes Secret并使用它来部署Pod。 使用IBM Cloud Container RegistryIBM Cloud Container Registry提供了一个多租户私有镜像仓库，您可以使用它来安全地存储和共享Docker镜像。默认情况下，集成的漏洞顾问会扫描私有仓库中的镜像，以检测安全问题和潜在漏洞。IBM Cloud帐户中的用户可以访问您的镜像，也可以创建令牌以授予对仓库命名空间的访问权限。 要安装IBM Cloud Container Registry CLI插件并为镜像创建命名空间，请参阅IBM Cloud Container Registry入门。 您可以使用IBM Cloud Container Registry将容器从IBM Cloud公共镜像和私有镜像部署到defaultIBM Cloud Kubernetes Service集群的命名空间中。要将容器部署到其他名称空间，或使用来自其他IBM Cloud Container Registry区域或IBM Cloud帐户的镜像，请创建Kubernetes imagePullSecret。有关更多信息，请参阅从镜像构建容器。 配置节点以验证私有仓库 注意：如果您在Google Kubernetes Engine上运行，则.dockercfg每个节点上都会有一个包含Google Container Registry凭据的节点。你不能使用这种方法。 注意：如果您在AWS EC2上运行并且正在使用EC2容器仓库（ECR），则每个节点上的kubelet将管理和更新ECR登录凭据。你不能使用这种方法 注意：如果您可以控制节点配置，则此方法是合适的。它不能可靠地在GCE和任何其他进行自动节点替换的云提供商上运行。 Docker将私有仓库的密钥存储在$HOME/.dockercfg或$HOME/.docker/config.json文件中。如果您将相同的文件放在下面的搜索路径列表中，则kubelet会在拉取镜像时将其用作凭据提供程序。 {--root-dir:-/var/lib/kubelet}/config.json {cwd of kubelet}/config.json ${HOME}/.docker/config.json /.docker/config.json {--root-dir:-/var/lib/kubelet}/.dockercfg {cwd of kubelet}/.dockercfg ${HOME}/.dockercfg /.dockercfg 注意：您可能必须HOME=/root在环境文件中明确设置kubelet。 以下是配置节点以使用私有仓库的建议步骤。在此示例中，在桌面/笔记本电脑上运行这些： docker login [server]针对要使用的每组凭据运行。这更新$HOME/.docker/config.json。 $HOME/.docker/config.json在编辑器中查看以确保它仅包含您要使用的凭据。 获取节点列表，例如： 如果你想要这些名字： nodes=$(kubectl get nodes -o jsonpath=&#39;{range.items[*].metadata}{.name} {end}&#39;) 如果你想获得IP： nodes=$(kubectl get nodes -o jsonpath=&#39;{range .items[*].status.addresses[?(@.type==&quot;ExternalIP&quot;)]}{.address} {end}&#39;) 将本地复制.docker/config.json到上面的搜索路径列表之一。 例如： for n in $nodes; do scp ~/.docker/config.json root@$n:/var/lib/kubelet/config.json; done 通过创建使用私有镜像的pod进行验证，例如：12345678910111213kubectl create -f - &lt;&lt;EOFapiVersion: v1kind: Podmetadata: name: private-image-test-1spec: containers: - name: uses-private-image image: $PRIVATE_IMAGE_NAME imagePullPolicy: Always command: [ "echo", "SUCCESS" ]EOFpod/private-image-test-1 created 如果一切正常，那么过了一会儿，你应该看到：12kubectl logs private-image-test-1SUCCESS 如果失败了，那么你会看到：12kubectl describe pods/private-image-test-1 | grep "Failed" Fri, 26 Jun 2015 15:36:13 -0700 Fri, 26 Jun 2015 15:39:13 -0700 19 &#123;kubelet node-i2hq&#125; spec.containers&#123;uses-private-image&#125; failed Failed to pull image "user/privaterepo:v1": Error: image user/privaterepo:v1 not found 您必须确保群集中的所有节点都具有相同的节点.docker/config.json。否则，pod将在某些节点上运行，而无法在其他节点上运行。例如，如果使用节点自动缩放，则每个实例模板都需要包含.docker/config.json或装载包含它的驱动器。 将私有仓库项添加到任何私有仓库中后，所有pod都将具有对镜像的读访问权限.docker/config.json。 预拉图像 注意：如果您在Google Kubernetes Engine上运行，则.dockercfg每个节点上都会有一个包含Google Container Registry凭据的节点。你不能使用这种方法。 注意：如果您可以控制节点配置，则此方法是合适的。它不能可靠地在GCE和任何其他进行自动节点替换的云提供商上运行。 默认情况下，kubelet将尝试从指定的仓库中提取每个镜像。但是，如果imagePullPolicy容器的属性设置为IfNotPresent或Never，则使用本地镜像（分别优先或排他）。 如果您希望依赖预先提取的镜像作为仓库身份验证的替代，则必须确保群集中的所有节点都具有相同的预拉镜像。 这可以用于预加载某些镜像以提高速度，或者作为对私有仓库进行身份验证的替代方法。 所有pod都可以读取任何预拉镜像。 在Pod上指定ImagePullSecrets 注意：此方法目前是Google Kubernetes Engine，GCE以及自动创建节点的任何云提供商的推荐方法。 Kubernetes支持在pod上指定仓库项。 使用Docker配置创建机密运行以下命令，替换相应的大写值：12kubectl create secret docker-registry myregistrykey --docker-server=DOCKER_REGISTRY_SERVER --docker-username=DOCKER_USER --docker-password=DOCKER_PASSWORD --docker-email=DOCKER_EMAILsecret/myregistrykey created. 如果需要访问多个仓库，则可以为每个仓库创建一个秘密。 在为Pods提取镜像时，Kubelet会将任何内容合并imagePullSecrets为一个虚拟内容.docker/config.json。 Pod只能在自己的命名空间中引用镜像拉取秘密，因此每个命名空间需要执行一次此过程。 绕过kubectl会产生秘密如果由于某种原因，您需要单个项目中的多个项目.docker/config.json或需要上述命令未给出的控制，那么您可以使用json或yaml创建一个秘密。 务必： 设置数据项的名称 .dockerconfigjson base64编码docker文件并粘贴该字符串，不间断作为字段的值 data[&quot;.dockerconfigjson&quot;] 设置type为kubernetes.io/dockerconfigjson 例：12345678apiVersion: v1kind: Secretmetadata: name: myregistrykey namespace: awesomeappsdata: .dockerconfigjson: UmVhbGx5IHJlYWxseSByZWVlZWVlZWVlZWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGx5eXl5eXl5eXl5eXl5eXl5eXl5eSBsbGxsbGxsbGxsbGxsbG9vb29vb29vb29vb29vb29vb29vb29vb29vb25ubm5ubm5ubm5ubm5ubm5ubm5ubm5ubmdnZ2dnZ2dnZ2dnZ2dnZ2dnZ2cgYXV0aCBrZXlzCg==type: kubernetes.io/dockerconfigjson 如果收到错误消息error: no objects passed to create，则可能表示base64编码的字符串无效。如果收到类似的错误消息Secret &quot;myregistrykey&quot; is invalid: data[.dockerconfigjson]: invalid value ...，则表示数据已成功取消base64编码，但无法解析为.docker/config.json文件。 参考Pod上的imagePullSecrets现在，您可以通过向imagePullSecrets pod定义添加一个部分来创建引用该秘密的pod。1234567891011apiVersion: v1kind: Podmetadata: name: foo namespace: awesomeappsspec: containers: - name: foo image: janedoe/awesomeapp:v1 imagePullSecrets: - name: myregistrykey 需要对使用私有仓库的每个pod执行此操作。 但是，可以通过在serviceAccount资源中设置imagePullSecrets来自动设置此字段。检查将ImagePullSecrets添加到服务帐户以获取详细说明。 您可以将其与每个节点结合使用.docker/config.json。凭证将被合并。这种方法适用于Google Kubernetes Engine。 用例有许多配置私有仓库的解决方案。以下是一些常见用例和建议的解决方案。 群集仅运行非专有（例如开源）镜像。无需隐藏镜像。 在Docker hub上使用公共镜像。 无需配置。 在GCE / Google Kubernetes Engine上，自动使用本地镜像来提高速度和可用性。 群集运行一些专有镜像，这些镜像像应隐藏给公司外部的人员，但对所有群集用户可见。 使用托管的私有Docker仓库。 它可能托管在Docker Hub或其他地方。 如上所述，在每个节点上手动配置.docker / config.json。 或者，使用开放读取访问权限在防火墙后面运行内部私有仓库。 不需要Kubernetes配置。 或者，在使用GCE / Google Kubernetes Engine时，请使用该项目的Google Container Registry。 与集群自动调节相比，它可以比手动节点配置更好地工作。 或者，在更改节点配置不方便的群集上，请使用imagePullSecrets。 具有专有镜像的集群，其中一些需要更严格的访问控制。 确保AlwaysPullImages准入控制器处于活动状态。否则，所有Pod都可能访问所有镜像。 将敏感数据移动到“秘密”资源中，而不是将其打包在镜像中。 一个多租户群集，每个租户都需要拥有私有仓库。 确保AlwaysPullImages准入控制器处于活动状态。否则，所有租户的所有Pod都可能访问所有图像。 运行需要授权的私有仓库。 为每个租户生成仓库凭据，保密，并为每个租户命名空间填充机密。 租户将这个秘密添加到每个命名空间的imagePullSecrets。 容器环境变量此页面描述Container环境中Container可用的资源。 容器环境Kubernetes Container环境为容器提供了几个重要资源： 文件系统，是镜像和一个或多个卷的组合。 有关Container本身的信息。 有关群集中其他对象的信息。 容器信息Container 的主机名是运行Container的Pod的名称。它可以通过 libc中的hostname命令或 gethostname函数调用获得。 Pod名称和命名空间可通过向下API作为环境变量使用 。 Pod定义中的用户定义环境变量也可用于Container，Docker镜像中静态指定的任何环境变量也是如此。 群集信息创建Container时运行的所有服务的列表可作为环境变量用于该Container。这些环境变量与Docker链接的语法相匹配。 对于名为foo的映射到名为bar的Container 的服务，定义了以下变量：12FOO_SERVICE_HOST=&lt;the host the service is running on&gt;FOO_SERVICE_PORT=&lt;the port the service is running on&gt; 服务具有专用IP地址，如果启用了DNS插件，则可通过DNS使用Container 。 运行时类特征状态： Kubernetes v1.12该页面描述了RuntimeClass资源和运行时选择机制。 此功能目前处于alpha状态，意思是：版本名称包含alpha（例如v1alpha1）。可能是马车。启用该功能可能会暴露错误。默认情况下禁用。可随时删除对功能的支持，恕不另行通知。API可能会在以后的软件版本中以不兼容的方式更改，恕不另行通知。由于错误风险增加和缺乏长期支持，建议仅在短期测试集群中使用。 运行时类RuntimeClass是一个alpha功能，用于选择用于运行pod容器的容器运行时配置。 建立作为早期的alpha功能，必须采取一些额外的设置步骤才能使用RuntimeClass功能： 启用RuntimeClass功能门（在apiservers＆kubelets上，需要1.12+版本） 安装RuntimeClass CRD 在节点上配置CRI实现（取决于运行时） 创建相应的RuntimeClass资源 1.启用RuntimeClass feature gate有关启用feature gates的说明，请参见feature gates。必须在apiservers和kubelet上启用RuntimeClass功能门。 2.安装RuntimeClass CRDRuntimeClass CustomResourceDefinition（CRD）可以在Kubernetes git repo的addons目录中找到：kubernetes / cluster / addons / runtimeclass / runtimeclass_crd.yaml 安装CRD kubectl apply -f runtimeclass_crd.yaml。 3.在节点上配置CRI实现使用RuntimeClass进行选择的配置取决于CRI实现。有关如何配置的信息，请参阅CRI实现的相应文档。由于这是一个alpha功能，并非所有CRI都支持多个RuntimeClasses。 注意： RuntimeClass当前假定整个集群中的同类节点配置（这意味着所有节点的配置方式与容器运行时相同）。任何异构性（变化的配置）必须通过调度功能独立于RuntimeClass进行管理（请参阅将Pod分配给节点）。 配置具有相应的RuntimeHandler名称，由RuntimeClass引用。RuntimeHandler必须是有效的DNS 1123子域（字母数字+ -和.字符）。 4.创建相应的RuntimeClass资源步骤3中的配置设置应各自具有关联的RuntimeHandler名称，用于标识配置。对于每个RuntimeHandler（以及可选的空””处理程序），创建相应的RuntimeClass对象。 RuntimeClass资源当前只有2个重要字段：RuntimeClass name（metadata.name）和RuntimeHandler（spec.runtimeHandler）。对象定义如下所示：1234567apiVersion: node.k8s.io/v1alpha1 # RuntimeClass is defined in the node.k8s.io API groupkind: RuntimeClassmetadata: name: myclass # The name the RuntimeClass will be referenced by # RuntimeClass is a non-namespaced resourcespec: runtimeHandler: myconfiguration # The name of the corresponding CRI configuration 注意：建议将RuntimeClass写入操作（create / update / patch / delete）限制为群集管理员。这通常是默认值。有关详细信息，请参阅授权概述。 用法为集群配置RuntimeClasses后，使用它们非常简单。runtimeClassName在Pod规范中指定a 。例如：1234567apiVersion: v1kind: Podmetadata: name: mypodspec: runtimeClassName: myclass # ... 这将指示Kubelet使用命名的RuntimeClass来运行此pod。如果命名的RuntimeClass不存在，或者CRI无法运行相应的处理程序，则pod将进入 Failed终端阶段。查找错误消息的相应事件。 如果未runtimeClassName指定，则将使用默认的RuntimeHandler，这相当于禁用RuntimeClass功能时的行为。 容器生命周期钩子此页面描述了kubelet管理的容器如何使用Container生命周期钩子框架来运行在管理生命周期中由事件触发的代码。 概观 集装箱挂钩 概观类似于许多具有组件生命周期钩子的编程语言框架，例如Angular，Kubernetes为Containers提供了生命周期钩子。钩子使Container能够了解其管理生命周期中的事件，并在执行相应的生命周期钩子时运行在处理程序中实现的代码。 容器钩子有两个暴露给容器的钩子： PostStart 在创建容器后立即执行此挂钩。但是，无法保证挂钩将在容器ENTRYPOINT之前执行。没有参数传递给处理程序。 PreStop 在容器终止之前立即调用此挂钩。它是阻塞的，意味着它是同步的，所以它必须在删除容器的调用之前完成。没有参数传递给处理程序。 终止行为的更详细描述可以在终端中找到 。 钩子处理程序实现容器可以通过实现和注册该钩子的处理程序来访问钩子。可以为Container实现两种类型的钩子处理程序： Exec - 执行特定命令，例如pre-stop.sh，在Container的cgroups和名称空间内。命令消耗的资源将根据Container计算。 HTTP - 对Container上的特定端点执行HTTP请求。 钩子处理程序执行调用Container生命周期管理挂钩时，Kubernetes管理系统会在为该挂钩注册的Container中执行处理程序。 钩子处理程序调用在包含Container的Pod的上下文中是同步的。这意味着对于一个PostStart钩子，Container ENTRYPOINT和钩子异步发射。但是，如果挂钩运行或挂起太长时间，则Container无法达到某种running状态。 PreStop钩子的行为类似。如果钩子在执行期间挂起，则Pod阶段将保持Terminating状态并在terminationGracePeriodSecondspod结束后被杀死。如果一个 PostStart或PreStophook失败，则会终止Container。 用户应使其钩子处理程序尽可能轻量级。但是，有些情况下，长时间运行的命令是有意义的，例如在停止Container之前保存状态。 挂钩送货保证钩子传递至少是一次，这意味着可以为任何给定事件多次调用钩子，例如for PostStart或PreStop。由钩子实现来正确处理这个问题。 通常，只进行单次交付。例如，如果HTTP挂钩接收器关闭且无法获取流量，则不会尝试重新发送。然而，在一些罕见的情况下，可能会发生双重递送。例如，如果一个kubelet在发送一个钩子的过程中重新启动，那么在该kubelet重新启动后可能会重新发送一个钩子。 调试Hook处理程序在Pod事件中不公开Hook处理程序的日志。如果处理程序由于某种原因失败，它会广播一个事件。因为PostStart，这是FailedPostStartHook事件，因为PreStop这是FailedPreStopHook事件。您可以通过运行来查看这些事件kubectl describe pod &lt;pod_name&gt;。以下是运行此命令的一些事件输出示例：123456789101112Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 1m 1m 1 &#123;default-scheduler &#125; Normal Scheduled Successfully assigned test-1730497541-cq1d2 to gke-test-cluster-default-pool-a07e5d30-siqd 1m 1m 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Pulling pulling image "test:1.0" 1m 1m 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Created Created container with docker id 5c6a256a2567; Security:[seccomp=unconfined] 1m 1m 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Pulled Successfully pulled image "test:1.0" 1m 1m 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Started Started container with docker id 5c6a256a2567 38s 38s 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Killing Killing container with docker id 5c6a256a2567: PostStart handler: Error executing in Docker Container: 1 37s 37s 1 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Normal Killing Killing container with docker id 8df9fdfd7054: PostStart handler: Error executing in Docker Container: 1 38s 37s 2 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; Warning FailedSync Error syncing pod, skipping: failed to "StartContainer" for "main" with RunContainerError: "PostStart handler: Error executing in Docker Container: 1" 1m 22s 2 &#123;kubelet gke-test-cluster-default-pool-a07e5d30-siqd&#125; spec.containers&#123;main&#125; Warning FailedPostStartHook WorkloadsPodsPod概述此页面概述Pod了Kubernetes对象模型中最小的可部署对象。 了解Pods 使用Pods Pod模板 了解Pods一个pod是在创建或部署Kubernetes对象模型Kubernetes-最小最简单的单元的基本构建块。Pod表示群集上正在运行的进程。 Pod封装了一个应用程序容器（或者，在某些情况下，多个容器），存储资源，一个唯一的网络IP以及控制容器应该如何运行的选项。Pod表示部署单元：Kubernetes中的单个应用程序实例，可能包含单个容器或少量紧密耦合且共享资源的容器。 Docker是Kubernetes Pod中最常用的容器运行时，但Pods也支持其他容器运行时。 Kubernetes集群中的Pod可以以两种主要方式使用： 运行单个容器的Pod。“one-container-per-Pod”模型是最常见的Kubernetes用例; 在这种情况下，您可以将Pod视为单个容器的包装，而Kubernetes直接管理Pod而不是容器。 运行多个需要协同工作的容器的Pod。Pod可以封装由多个共址容器组成的应用程序，这些容器紧密耦合并需要共享资源。这些共处一地的容器可能形成一个统一的服务单元 - 一个容器从共享卷向公众提供文件，而一个单独的“sidecar”容器刷新或更新这些文件。Pod将这些容器和存储资源作为单个可管理实体包装在一起。 该Kubernetes博客对pod用例一些额外的信息。有关更多信息，请参阅： 分布式系统工具包：复合容器的模式 容器设计模式 每个Pod都用于运行给定应用程序的单个实例。如果要水平扩展应用程序（例如，运行多个实例），则应使用多个Pod，每个实例一个。在Kubernetes中，这通常被称为复制。复制Pod通常由称为Controller的抽象创建和管理。有关更多信息，请参阅Pod和控制器。 Pod如何管理多个容器Pod旨在支持多个协作流程（作为容器），形成一个有凝聚力的服务单元。Pod中的容器自动位于群集中的同一物理或虚拟机上，并共同调度。容器可以共享资源和依赖关系，彼此通信，并协调它们何时以及如何终止。 请注意，在单个Pod中对多个共存和共同管理的容器进行分组是一个相对高级的用例。您应该仅在容器紧密耦合的特定实例中使用此模式。例如，您可能有一个容器充当共享卷中文件的Web服务器，以及一个单独的“sidecar”容器，用于从远程源更新这些文件，如下图所示： pod diagram Pod为其组成容器提供两种共享资源：网络和存储。 联网 每个Pod都分配有唯一的IP地址。Pod中的每个容器都共享网络命名空间，包括IP地址和网络端口。Pod内的容器可以使用相互通信localhost。当Pod中的容器与Pod 外部的实体通信时，它们必须协调它们如何使用共享网络资源（例如端口）。 存储 Pod可以指定一组共享存储卷。Pod中的所有容器都可以访问共享卷，允许这些容器共享数据。如果需要重新启动其中一个容器，则卷还允许Pod中的持久数据存活。见卷上Kubernetes如何实现一个pod里的共享存储更多的信息。 使用Pods你很少直接在Kubernetes - 甚至是单身Pod中创建单独的Pod。这是因为Pods被设计为相对短暂的一次性实体。当创建Pod（由您直接创建或由Controller间接创建）时，它将被安排在群集中的节点上运行。Pod保留在该节点上，直到进程终止，pod对象被删除，pod 因资源不足而被驱逐，或者Node失败。 注意：不应将重新启动Pod重新启动Pod中的容器。Pod本身不会运行，但是容器运行的环境会持续存在，直到删除为止。 pod本身不能自我修复。如果将Pod调度到失败的节点，或者调度操作本身失败，则删除Pod; 同样，由于缺乏资源或节点维护，Pod将无法在驱逐中存活。Kubernetes使用更高级别的抽象，称为Controller，它处理管理相对可处理的Pod实例的工作。因此，虽然可以直接使用Pod，但在Kubernetes中使用Controller管理pod更为常见。见pod和控制器上Kubernetes如何使用控制器来实现pod缩放和愈合的更多信息。 pod和控制器Controller可以为您创建和管理多个Pod，处理复制和部署，并在集群范围内提供自我修复功能。例如，如果节点发生故障，Controller可能会通过在不同节点上安排相同的替换来自动替换Pod。 包含一个或多个pod的控制器的一些示例包括： 部署 StatefulSet DaemonSet 通常，控制器使用您提供的Pod模板来创建它负责的Pod。 Pod模板Pod模板是pod规范，包含在其他对象中，例如 Replication Controllers，Jobs和 DaemonSets。控制器使用Pod模板制作实际的pod。下面的示例是Pod的简单清单，其中包含一个打印消息的容器。1234567891011apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo Hello Kubernetes! &amp;&amp; sleep 3600'] pod模板不是指定所有副本的当前所需状态，而是像cookie 切割机。切割 cookie后，cookie与切割机无关。没有“量子纠缠”。对模板的后续更改甚至切换到新模板对已创建的pod没有直接影响。类似地，随后可以直接更新由复制控制器创建的pod。这与pod有意对比，pod确实指定了属于pod的所有容器的当前所需状态。这种方法从根本上简化了系统语义并增加了原语的灵活性。 Podspods是可以创建和管理Kubernetes计算的最小可部署单元。 什么是Pod？ pod的动机 pod的使用 考虑的替代方案 pod的耐久性（或缺乏） 终止pod pod容器的特权模式 API对象 什么是Pod？一个pod（如在whales或pea pod中）是一组一个或多个容器（如Docker容器），具有共享存储/网络，以及如何运行容器的规范。pod的内容始终位于同一位置并共同调度，并在共享上下文中运行。pod模拟特定于应用程序的“逻辑主机” - 它包含一个或多个相对紧密耦合的应用程序容器 - 在预容器世界中，在同一物理或虚拟机上执行意味着在同一逻辑主机上执行。 虽然Kubernetes支持的容器运行时间多于Docker，但Docker是最常见的运行时，它有助于用Docker术语描述pod。 pod的共享上下文是一组Linux命名空间，cgroup，以及可能的隔离方面 - 与隔离Docker容器相同的东西。在pod的上下文中，各个应用程序可能会应用进一步的子隔离。 Pod中的容器共享IP地址和端口空间，并且可以通过它们找到彼此localhost。他们还可以使用标准的进程间通信（如SystemV信号量或POSIX共享内存）相互通信。不同pod中的容器具有不同的IP地址，并且在没有特殊配置的情况下无法通过IPC进行通信 。这些容器通常通过Pod IP地址相互通信。 pod中的应用程序还可以访问共享卷，共享卷被定义为pod的一部分，可以安装到每个应用程序的文件系统中。 就Docker构造而言，pod被建模为一组具有共享命名空间和共享卷的Docker容器 。 与单个应用程序容器一样，pod被认为是相对短暂的（而不是持久的）实体。正如在pod的生命周期中所讨论的，创建pod，分配唯一ID（UID），并调度到它们保留的节点，直到终止（根据重启策略）或删除。如果节点终止，则在超时期限之后，将调度计划到该节点的Pod进行删除。给定的pod（由UID定义）不会“重新安排”到新节点; 相反，它可以被相同的pod替换，如果需要，甚至可以使用相同的名称，但是使用新的UID（有关更多详细信息，请参阅复制控制器）。 当某些东西被认为具有与容量相同的生命周期时，例如卷，这意味着只要该容器（具有该UID）存在就存在。如果由于任何原因删除了该pod，即使创建了相同的替换，相关的东西（例如卷）也会被销毁并重新创建。 pod图一个多容器窗格，包含文件提取程序和Web服务器，该服务器使用持久卷在容器之间共享存储。 pod的动机管理Pod是多个合作过程模式的模型，形成了一个有凝聚力的服务单元。它们通过提供比其组成应用程序集更高级别的抽象来简化应用程序部署和管理。Pod用作部署，水平扩展和复制的单元。对容器中的容器自动处理共置（共同调度），共享命运（例如终止），协调复制，资源共享和依赖关系管理。 资源共享和沟通Pod可以实现其成员之间的数据共享和通信。 pod中的应用程序都使用相同的网络命名空间（相同的IP和端口空间），因此可以相互“找到”并使用它们进行通信localhost。因此，pod中的应用程序必须协调它们对端口的使用。每个pod在平面共享网络空间中具有IP地址，该网络空间与网络上的其他物理计算机和pod完全通信。 主机名设置为pod中应用程序容器的pod名称。关于网络的更多细节。 除了定义在pod中运行的应用程序容器之外，pod还指定了一组共享存储卷。卷使数据能够在容器重新启动后继续存在，并在容器内的应用程序之间共享。 pod的使用Pod可用于托管垂直集成的应用程序堆栈（例如LAMP），但其主要动机是支持共址，共同管理的帮助程序，例如： 内容管理系统，文件和数据加载器，本地缓存管理器等。 日志和检查点备份，压缩，旋转，快照等 数据变更观察者，日志零售商，日志和监控适配器，活动发布者等。 代理，网桥和适配器 控制器，管理器，配置器和更新器 通常，单个pod不用于运行同一应用程序的多个实例。 有关更长的说明，请参阅分布式系统工具包：复合容器的模式。 考虑的替代方案为什么不在一个（Docker）容器中运行多个程序？ 透明度。使基础架构内的容器对基础架构可见，使基础架构能够为这些容器提供服务，例如进程管理和资源监视。这为用户提供了许多便利。 解耦软件依赖关系。各个容器可以独立地进行版本化，重建和重新部署。Kubernetes甚至有一天可能会支持单个容器的实时更新。 便于使用。用户无需运行自己的流程管理器，担心信号和退出代码传播等。 效率。由于基础设施承担更多责任，因此集装箱的重量可以更轻。 为什么不支持基于亲和力的容器协同调度？ 这种方法可以提供协同定位，但不会提供pod的大部分好处，例如资源共享，IPC，保证命运共享和简化管理。 pod的耐久性（或缺乏）pod不应被视为耐用实体。它们将无法在调度故障，节点故障或其他驱逐（例如由于缺乏资源）或节点维护的情况下存活。 通常，用户不需要直接创建pod。他们应该几乎总是使用控制器，即使是singletons，例如， 部署。控制器提供集群范围的自我修复，以及复制和部署管理。像StatefulSet这样的控制器 也可以为有状态的pod提供支持。 使用集合API作为主要的面向用户的原语在集群调度系统中相对常见，包括Borg，Marathon，Aurora和Tupperware。 Pod作为基元公开，以便于： 调度程序和控制器可插拔性 支持pod级操作，无需通过控制器API“代理”它们 pod生命周期与控制器生命周期的解耦，例如引导 控制器和服务的分离 - 端点控制器只是监视pod 具有集群级功能的Kubelet级功能的清晰组合 - Kubelet实际上是“pod控制器” 高可用性应用程序，它们将期望在终止之前更换pod，并且肯定在删除之前，例如在计划驱逐或图像预取的情况下。 终止pod因为pod表示集群中节点上的正在运行的进程，所以允许这些进程在不再需要时优雅地终止（与使用KILL信号猛烈杀死并且没有机会清理）非常重要。用户应该能够请求删除并知道进程何时终止，但也能够确保删除最终完成。当用户请求删除pod时，系统会在允许pod强制终止之前记录预期的宽限期，并将TERM信号发送到每个容器中的主进程。宽限期到期后，KILL信号将发送到这些进程，然后从API服务器中删除该pod。如果在等待进程终止时重新启动Kubelet或容器管理器， 一个示例流程： 用户发送删除Pod的命令，默认宽限期（30秒） API服务器中的Pod随着时间的推移而更新，其中Pod被视为“死”以及宽限期。 在客户端命令中列出时，Pod显示为“终止” （与3同时）当Kubelet看到Pod已被标记为终止，因为已经设置了2中的时间，它开始了pod关闭过程。 如果其中一个Pod的容器定义了一个preStop挂钩，则会在容器内部调用它。如果在preStop宽限期到期后钩子仍在运行，则以小（2秒）延长的宽限期调用步骤2。 容器被发送TERM信号。请注意，并非Pod中的所有容器都会同时收到TERM信号，并且preStop如果它们关闭的顺序很重要，则每个容器都需要一个钩子。 （与3同时）Pod从端点列表中删除以进行维护，并且不再被视为复制控制器的运行pod集的一部分。缓慢关闭的窗格无法继续提供流量，因为负载平衡器（如服务代理）会将其从旋转中移除。 当宽限期到期时，仍然在Pod中运行的任何进程都将被SIGKILL杀死。 Kubelet将通过设置宽限期0（立即删除）完成删除API服务器上的Pod。Pod从API中消失，不再从客户端可见。 默认情况下，所有删除在30秒内都是正常的。该kubectl delete命令支持--grace-period=&lt;seconds&gt;允许用户覆盖默认值并指定其自己的值的选项。值0force删除 pod。在kubectl版本&gt; = 1.5时，必须指定一个额外的标志--force一起--grace-period=0，以执行力的缺失。 强制删除pod强制删除pod被定义为立即从群集状态和etcd删除pod。当执行强制删除时，许可证持有者不会等待来自kubelet的确认该pod已在其运行的节点上终止。它会立即删除API中的pod，以便可以使用相同的名称创建新的pod。在节点上，设置为立即终止的pod在被强制终止之前仍将被给予一个小的宽限期。 强制删除可能对某些pod有潜在危险，应谨慎执行。如果是StatefulSet pod，请参阅任务文档以从StatefulSet中删除 Pod 。 pod容器的特权模式从Kubernetes v1.1开始，pod中的任何容器都可以使用容器规范中的privileged标志启用特权模式SecurityContext。这对于想要使用Linux功能（如操作网络堆栈和访问设备）的容器非常有用。容器内的进程获得与容器外部进程可用的几乎相同的权限。使用特权模式，将网络和卷插件编写为不需要编译到kubelet的独立窗格应该更容易。 如果主服务器正在运行Kubernetes v1.1或更高版本，并且节点运行的版本低于v1.1，那么api-server将接受新的特权pod，但不会启动。他们将处于待决状态。如果用户呼叫kubectl describe pod FooPodName，用户可以查看pod处于暂挂状态的原因。describe命令输出中的events表将说：1Error validating pod "FooPodName"."FooPodNamespace" from api, ignoring: spec.containers[0].securityContext.privileged: forbidden '&lt;*&gt;(0xc2089d3248)true' 如果主服务器运行的版本低于v1.1，则无法创建特权pod。如果用户尝试创建具有特权容器的pod，则用户将收到以下错误：1The Pod "FooPodName" is invalid. spec.containers[0].securityContext.privileged: forbidden '&lt;*&gt;(0xc20b222db0)true' API对象Pod是Kubernetes REST API中的顶级资源。有关API对象的更多详细信息，请参阅： Pod API对象。 Pod生命周期该页面描述了Pod的生命周期。 Pod阶段 Pod条件 容器探针 Pod和Container状态 Pod准备gate 重启政策 Pod寿命 例子 Pod阶段Pod的status字段是 PodStatus 对象，它有一个phase字段。 Pod的阶段是Pod在其生命周期中的简单，高级摘要。该阶段不是对Container或Pod状态的全面观察汇总，也不是一个综合状态机。 Pod阶段值的数量和含义受到严密保护。除了这里记录的内容之外，没有任何关于具有给定phase值的Pod的假设。 以下是可能的值phase： 值 描述 Pending Pod已被Kubernetes系统接受，但尚未创建一个或多个Container图像。这包括计划之前的时间以及通过网络下载图像所花费的时间，这可能需要一段时间。 Running Pod已绑定到节点，并且已创建所有Container。至少有一个Container仍在运行，或者正在启动或重新启动。 Succeeded Pod中的所有容器都已成功终止，并且不会重新启动。 Failed Pod中的所有容器都已终止，并且至少有一个Container已终止失败。也就是说，Container要么退出非零状态，要么被系统终止。 Unknown 由于某种原因，无法获得Pod的状态，这通常是由于与Pod的主机通信时出错。 Pod条件Pod有一个PodStatus，它有一个PodConditions数组， Pod已经或没有通过它。PodCondition数组的每个元素都有六个可能的字段： 该lastProbeTime字段提供上次探测Pod条件的时间戳。 该lastTransitionTime字段提供Pod最后从一个状态转换到另一个状态的时间戳。 该message字段是人类可读的消息，指示有关转换的详细信息。 该reason字段是该条件最后一次转换的唯一，单字，CamelCase原因。 该status字段是一个字符串，可能的值为“ True”，“ False”和“ Unknown”。 该type字段是一个包含以下可能值的字符串： PodScheduled：Pod已被安排到一个节点; Ready：Pod可以提供请求，应该添加到所有匹配服务的负载平衡池中; Initialized：所有init容器 都已成功启动; Unschedulable：调度程序现在无法调度Pod，例如由于缺少资源或其他限制; ContainersReady：Pod中的所有容器都已准备就绪。 容器探针一个探头是通过周期性地执行的诊断kubelet 上的容器。为了执行诊断，kubelet调用Container实现的 Handler。有三种类型的处理程序： ExecAction：在Container内执行指定的命令。如果命令以状态代码0退出，则认为诊断成功。 TCPSocketAction：对指定端口上的Container的IP地址执行TCP检查。如果端口打开，则诊断被认为是成功的。 HTTPGetAction：对指定端口和路径上的Container的IP地址执行HTTP Get请求。如果响应的状态代码大于或等于200且小于400，则认为诊断成功。 每个探针都有三个结果之一： 成功：Container通过了诊断。 失败：容器未通过诊断。 未知：诊断失败，因此不应采取任何措施。 在运行容器时，kubelet可以选择性地执行和响应两种探测器： livenessProbe：指示Container是否正在运行。如果活动探测失败，则kubelet会杀死Container，并且Container将受其重启策略的约束。如果Container未提供活动探测，则默认状态为Success。 readinessProbe：指示Container是否已准备好为请求提供服务。如果准备就绪探测失败，则端点控制器会从与Pod匹配的所有服务的端点中删除Pod的IP地址。初始延迟之前的默认准备状态是Failure。如果Container未提供就绪探测，则默认状态为Success。 什么时候应该使用活力或准备探针？如果您的Container中的进程在遇到问题或变得不健康时能够自行崩溃，则您不一定需要活动探测器; kubelet将根据Pod的内容自动执行正确的操作restartPolicy。 如果您希望在探测失败时杀死并重新启动Container，则指定活动探测，并指定restartPolicyAlways或OnFailure。 如果您只想在探测成功时开始向Pod发送流量，请指定准备探测。在这种情况下，准备情况探测可能与活动探测相同，但规范中存在准备探测意味着Pod将在不接收任何流量的情况下启动，并且仅在探测开始成功后才开始接收流量。 如果Container需要在启动期间处理大型数据，配置文件或迁移，请指定就绪性探针。 如果您希望Container能够自行维护，您可以指定一个就绪探针，用于检查特定于就绪状态的端点，该端点与活动探针不同。 请注意，如果您只想在删除Pod时排除请求，则不一定需要准备探测; 在删除时，无论准备情况探测是否存在，Pod都会自动将其置于未准备状态。Pod在等待Pod中的容器停止时仍处于未准备状态。 有关如何设置活动或准备情况探测的详细信息，请参阅 配置活动和准备探测。 Pod和Container状态有关Pod容器状态的详细信息，请参阅 PodStatus 和 ContainerStatus。请注意，报告为Pod状态的信息取决于当前的 ContainerState。 Pod准备gate特征状态： Kubernetes v1.12 此功能目前处于测试状态 为了通过注入额外的反馈或信号来增加Pod准备的可扩展性PodStatus，Kubernetes 1.11引入了一个名为Pod ready ++的功能。您可以使用新的字段ReadinessGate中PodSpec指定波德准备进行评估附加条件。如果Kubernetes在status.conditionsPod 的字段中找不到这样的条件，则条件的状态默认为“ False”。以下是一个例子：12345678910111213141516171819Kind: Pod...spec: readinessGates: - conditionType: "www.example.com/feature-1"status: conditions: - type: Ready # this is a builtin PodCondition status: "True" lastProbeTime: null lastTransitionTime: 2018-01-01T00:00:00Z - type: "www.example.com/feature-1" # an extra PodCondition status: "False" lastProbeTime: null lastTransitionTime: 2018-01-01T00:00:00Z containerStatuses: - containerID: docker://abcd... ready: true... 新Pod条件必须符合Kubernetes 标签密钥格式。由于该kubectl patch命令仍然不支持修补对象状态，因此必须PATCH使用其中一个KubeClient库通过操作注入新的Pod条件。 随着新Pod条件的引入，只有 当以下两个语句都成立时，才会评估Pod是否就绪： Pod中的所有容器都已准备就绪。 指定的所有条件ReadinessGates均为“ True”。 为了便于对Pod准备评估进行此更改，ContainersReady引入了一个新的Pod条件 来捕获旧的Pod Ready条件。 在K8s 1.11中，作为alpha功能，必须通过将PodReadinessGates 功能门设置 为true 来明确启用“Pod Ready ++”功能。 在K8s 1.12中，默认情况下启用该功能。 重启政策PodSpec的restartPolicy字段可能包含Always，OnFailure和Never。默认值为Always。 restartPolicy适用于Pod中的所有容器。restartPolicy仅指由同一节点上的kubelet重新启动Container。由kubelet重新启动的已退出容器将以指数退避延迟（10秒，20秒，40秒……）重新启动，上限为五分钟，并在成功执行十分钟后重置。正如Pods文档中所讨论的 ，一旦绑定到节点，Pod将永远不会被反弹到另一个节点。 Pod寿命一般来说，pod不会消失，直到有人摧毁它们。这可能是人或控制者。此规则的唯一例外是具有phase成功或失败超过一定持续时间（由terminated-pod-gc-thresholdmaster确定）的Pod将过期并自动销毁。 有三种控制器可供选择： 使用Job for Pods预期终止，例如批量计算。作业仅适用于 restartPolicy等于OnFailure或Never的Pod。 对不希望终止的Pod（例如，Web服务器）使用ReplicationController， ReplicaSet或 Deployment。ReplicationControllers仅适用于具有restartPolicyAlways的Pod。 使用需要为每台计算机运行一个的Pod的DaemonSet，因为它们提供特定于计算机的系统服务。 所有三种类型的控制器都包含PodTemplate。建议创建适当的控制器并让它创建Pod，而不是自己直接创建Pod。这是因为Pods单独对机器故障没有弹性，但是控制器是。 如果节点死亡或与群集的其余部分断开连接，Kubernetes会应用策略phase将丢失节点上的所有Pod设置为Failed。 例子高级活动探测示例活动探测由kubelet执行，因此所有请求都在kubelet网络名称空间中进行。12345678910111213141516171819202122232425apiVersion: v1kind: Podmetadata: labels: test: liveness name: liveness-httpspec: containers: - args: - /server image: k8s.gcr.io/liveness livenessProbe: httpGet: # when "host" is not defined, "PodIP" will be used # host: my-host # when "scheme" is not defined, "HTTP" scheme will be used. Only "HTTP" and "HTTPS" are allowed # scheme: HTTPS path: /healthz port: 8080 httpHeaders: - name: X-Custom-Header value: Awesome initialDelaySeconds: 15 timeoutSeconds: 1 name: liveness 示例状态 Pod正在运行并有一个Container。集装箱出口成功。 记录完成事件。 如果restartPolicy是： 始终：重启容器; Pod phase保持运行状态。 OnFailure：Pod phase成功。 从不：Pod phase成功。 Pod正在运行并有一个Container。容器退出失败。 记录失败事件。 如果restartPolicy是： 始终：重启容器; Pod phase保持运行状态。 OnFailure：重启容器; Pod phase保持运行状态。 从不：Pod phase变得失败。 Pod正在运行并有两个容器。容器1出现故障。 记录失败事件。 如果restartPolicy是： 始终：重启容器; Pod phase保持运行状态。 OnFailure：重启容器; Pod phase保持运行状态。 从不：不要重启容器; Pod phase保持运行状态。 如果Container 1未运行，并且Container 2退出： 记录失败事件。 如果restartPolicy是： 始终：重启容器; Pod phase保持运行状态。 OnFailure：重启容器; Pod phase保持运行状态。 从不：Pod phase变得失败。 Pod正在运行并有一个Container。容器耗尽内存。 记录失败事件。 记录OOM事件。 如果restartPolicy是： 始终：重启容器; Pod phase保持运行状态。 OnFailure：重启容器; Pod phase保持运行状态。 从不：记录失败事件; Pod phase保持运行状态。 Pod正在运行，磁盘已经死亡。 杀死所有容器。 记录适当的事件。 Pod phase变得失败。 如果在控制器下运行，Pod将在其他位置重新创建。 Pod正在运行，其节点已分段。 杀死所有容器。 记录适当的事件。 Pod phase变得失败。 如果在控制器下运行，Pod将在其他位置重新创建。 初始容器此页面提供了Init Containers的概述，它是在应用程序容器之前运行的专用容器，可以包含应用程序映像中不存在的实用程序或设置脚本。 了解Init容器 Init容器可以用于什么？ 详细的行为 支持和兼容性 了解Init容器一个pod能够在其内运行的应用程序的多个容器，但它也可以有一个或多个初始化容器，该容器的应用容器启动之前运行。 Init容器与常规容器完全相同，除了： 他们总是跑完成。 每个人必须在下一个启动之前成功完成。 如果Init容器的Init容器失败，Kubernetes会重复重启Pod，直到Init容器成功。但是，如果Pod具有restartPolicyNever，则不会重新启动。 要将Container指定为Init容器，请将initContainersPodSpec上的字段添加 为应用程序数组旁边的Container类型的JSON containers数组。init容器的状态在.status.initContainerStatuses字段中作为容器状态的数组返回（类似于.status.containerStatuses字段）。 与常规容器的差异Init Containers支持应用容器的所有字段和功能，包括资源限制，卷和安全设置。但是，Init容器的资源请求和限制的处理方式略有不同，这些内容在下面的参考资料中有说明。此外，Init Containers不支持就绪探针，因为它们必须在Pod准备好之前运行完成。 如果为Pod指定了多个Init容器，则按顺序一次运行一个Container。每一个都必须在下一次运行之前成功。当所有Init容器都运行完成后，Kubernetes会初始化Pod并像往常一样运行应用程序容器。 Init容器可以用于什么？由于Init Containers具有来自应用容器的单独镜像，因此它们对于启动相关代码具有一些优势： 出于安全原因，它们可以包含并运行不希望包含在应用容器镜像中的实用程序。 它们可以包含应用程序镜像中不存在的用于设置的实用程序或自定义代码。例如，没有必要使镜像FROM的另一个镜像只使用像工具 sed，awk，python，或dig在安装过程中。 应用程序映像构建器和部署者角色可以独立工作，而无需共同构建单个应用程序镜像。 他们使用Linux命名空间，以便他们从应用程序容器中获得不同的文件系统视图。因此，他们可以访问应用容器无法访问的秘密。 它们在任何应用程序容器启动之前运行完成，而应用程序容器并行运行，因此Init容器提供了一种简单的方法来阻止或延迟应用容器的启动，直到满足一组前置条件。 例子以下是有关如何使用Init Containers的一些想法： 等待使用shell命令创建服务，例如： 我在{1..100}; 做睡觉1; 如果挖我的服务; 然后退出0; 网络连接; 完成; 退出1 使用以下命令从向下API向远程服务器注册此Pod： curl -X POST http：// $ MANAGEMENT_SERVICE_HOST：$ MANAGEMENT_SERVICE_PORT / register -d’instal = $（）IP = $（）” 等待一段时间，然后使用类似命令启动app Container sleep 60。 将git存储库克隆到卷中。 将值放入配置文件并运行模板工具以动态生成主应用程序Container的配置文件。例如，将POD_IP值放在配置中，并使用Jinja生成主应用程序配置文件。 可以在StatefulSets文档 和Production Pods指南中找到更详细的用法示例。 初始容器正在使用中以下针对Kubernetes 1.5的yaml文件概述了一个具有两个Init容器的简单Pod。第一个等待，myservice第二个等待mydb。一旦两个容器完成，Pod就会开始。123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myapp annotations: pod.beta.kubernetes.io/init-containers: '[ &#123; "name": "init-myservice", "image": "busybox", "command": ["sh", "-c", "until nslookup myservice; do echo waiting for myservice; sleep 2; done;"] &#125;, &#123; "name": "init-mydb", "image": "busybox", "command": ["sh", "-c", "until nslookup mydb; do echo waiting for mydb; sleep 2; done;"] &#125; ]'spec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo The app is running! &amp;&amp; sleep 3600'] Kubernetes 1.6中有一种新语法，尽管旧的注释语法仍适用于1.6和1.7。新语法必须用于1.8或更高版本。我们已将Init Containers的声明移至spec：123456789101112131415161718apiVersion: v1kind: Podmetadata: name: myapp-pod labels: app: myappspec: containers: - name: myapp-container image: busybox command: ['sh', '-c', 'echo The app is running! &amp;&amp; sleep 3600'] initContainers: - name: init-myservice image: busybox command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;'] - name: init-mydb image: busybox command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done;'] 1.5语法仍适用于1.6，但我们建议使用1.6语法。在Kubernetes 1.6中，Init Containers在API中成为了一个领域。beta注释在1.6和1.7中仍然受到尊重，但在1.8或更高版本中不受支持。 下面YAML文件概述了mydb与myservice服务：12345678910111213141516171819kind: ServiceapiVersion: v1metadata: name: myservicespec: ports: - protocol: TCP port: 80 targetPort: 9376---kind: ServiceapiVersion: v1metadata: name: mydbspec: ports: - protocol: TCP port: 80 targetPort: 9377 可以使用以下命令启动和调试此Pod：12345678910111213141516171819202122232425262728293031323334353637383940$ kubectl create -f myapp.yamlpod/myapp-pod created$ kubectl get -f myapp.yamlNAME READY STATUS RESTARTS AGEmyapp-pod 0/1 Init:0/2 0 6m$ kubectl describe -f myapp.yamlName: myapp-podNamespace: default[...]Labels: app=myappStatus: Pending[...]Init Containers: init-myservice:[...] State: Running[...] init-mydb:[...] State: Waiting Reason: PodInitializing Ready: False[...]Containers: myapp-container:[...] State: Waiting Reason: PodInitializing Ready: False[...]Events: FirstSeen LastSeen Count From SubObjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 16s 16s 1 &#123;default-scheduler &#125; Normal Scheduled Successfully assigned myapp-pod to 172.17.4.201 16s 16s 1 &#123;kubelet 172.17.4.201&#125; spec.initContainers&#123;init-myservice&#125; Normal Pulling pulling image "busybox" 13s 13s 1 &#123;kubelet 172.17.4.201&#125; spec.initContainers&#123;init-myservice&#125; Normal Pulled Successfully pulled image "busybox" 13s 13s 1 &#123;kubelet 172.17.4.201&#125; spec.initContainers&#123;init-myservice&#125; Normal Created Created container with docker id 5ced34a04634; Security:[seccomp=unconfined] 13s 13s 1 &#123;kubelet 172.17.4.201&#125; spec.initContainers&#123;init-myservice&#125; Normal Started Started container with docker id 5ced34a04634$ kubectl logs myapp-pod -c init-myservice # Inspect the first init container$ kubectl logs myapp-pod -c init-mydb # Inspect the second init container 一旦我们启动mydb和myservice服务，我们就可以看到Init Containers完成并myapp-pod创建了：123456$ kubectl create -f services.yamlservice/myservice createdservice/mydb created$ kubectl get -f myapp.yamlNAME READY STATUS RESTARTS AGEmyapp-pod 1/1 Running 0 9m 这个例子非常简单，但应该为您创建自己的Init容器提供一些灵感。 详细的行为在Pod启动期间，初始化网络和卷后，初始容器将按顺序启动。每个Container必须在下一个Container启动之前成功退出。如果Container由于运行时未能启动或因故障退出，则根据Pod重试restartPolicy。但是，如果将Pod restartPolicy设置为Always，则Init Containers将使用 RestartPolicyOnFailure。 在Ready所有Init容器都成功之前，Pod不能。Init容器上的端口不在服务下聚合。正在初始化的Pod处于Pending状态，但应将条件Initializing设置为true。 如果重新启动 Pod，则必须再次执行所有Init Containers。 Init容器规范的更改仅限于容器镜像字段。更改Init Container镜像字段相当于重新启动Pod。 由于Init Containers可以重新启动，重试或重新执行，因此Init Container代码应该是幂等的。特别是，EmptyDirs 应该为输出文件已经存在的可能性准备写入文件的代码。 Init Containers具有应用Container的所有字段。但是，Kubernetes禁止readinessProbe使用，因为Init Containers无法定义与完成不同的准备情况。这在验证期间强制执行。 使用activeDeadlineSeconds上podlivenessProbe的容器，以防止初始化容器从永远失败。活动截止日期包括Init Containers。 Pod中每个应用程序和Init容器的名称必须是唯一的; 任何与另一个名称共享名称的Container都会引发验证错误。 资源给定Init Containers的排序和执行，适用以下资源使用规则： 在所有Init Containers上定义的任何特定资源请求或限制的最高值是有效的init请求/限制 Pod 对资源的有效请求/限制是以下值中的较高者： 资源的所有应用容器请求/限制的总和 资源的有效init请求/限制 调度是基于有效的请求/限制完成的，这意味着Init Containers可以预留在Pod生命周期内未使用的初始化资源。 Pod的有效QoS层的QoS层是Init Containers和app容器的QoS层。 根据有效的Pod请求和限制应用配额和限制。 Pod级别cgroup基于有效的Pod请求和限制，与调度程序相同。 Pod重启原因Pod可以重新启动，导致重新执行Init Containers，原因如下： 用户更新PodSpec，导致Init容器映像发生更改。App Container图像更改仅重新启动应用程序Container。 Pod基础架构容器重新启动。这种情况并不常见，必须由对节点具有root访问权限的人员来完成。 Pod中的所有容器都被终止，同时restartPolicy设置为Always，强制重新启动，并且Init Container完成记录由于垃圾回收而丢失。 支持和兼容性具有Apiserver 1.6.0或更高版本的群集支持使用该.spec.initContainers字段的Init Containers 。以前的版本使用alpha或beta注释支持Init Containers。该.spec.initContainers字段还镜像为alpha和beta注释，以便Kubelet 1.3.0或更高版本可以执行Init Containers，因此版本1.6 apiserver可以安全地回滚到1.5.x版，而不会丢失现有创建的pod的Init Container功能。 在Apiserver和Kubelet 1.8.0或更高版本中，删除了对alpha和beta注释的支持，需要从不推荐的注释转换到 .spec.initContainers字段。 此功能已在1.6中退出测试版。可以在应用程序containers阵列旁边的PodSpec中指定Init容器。beta注释值仍将受到尊重并覆盖PodSpec字段值，但是，它们在1.6和1.7中已弃用。在1.8中，不再支持注释，必须将其转换为PodSpec字段。 Pod Preset此页面提供PodPresets的概述，PodPresets是在创建时将特定信息注入pod的对象。信息可以包括秘密，卷，卷安装和环境变量。 了解Pod预设 这个怎么运作 启用Pod预设 了解Pod预设Pod Preset是一种API资源，用于在创建时将其他运行时需求注入Pod。您可以使用标签选择器 指定应用给定Pod预设的Pod。 使用Pod预设允许pod模板作者不必显式提供每个pod的所有信息。这样，使用特定服务的pod模板的作者不需要知道有关该服务的所有详细信息。 有关背景的更多信息，请参阅PodPreset的设计方案。 这个怎么运作Kubernetes提供了一个准入控制器（PodPreset），当启用时，它将Pod Presets应用于传入的pod创建请求。发生pod创建请求时，系统会执行以下操作： 检索所有PodPresets可用的。 检查任何标签选择器是否PodPreset与正在创建的pod上的标签匹配。 尝试将所定义的各种资源合并PodPreset到正在创建的Pod中。 出错时，抛出一个记录pod上合并错误的事件，并创建pod 而不从中注入任何资源PodPreset。 注释生成的修改后的Pod规范，以指示它已被修改PodPreset。注释是形式的 podpreset.admission.kubernetes.io/podpreset-&lt;pod-preset name&gt;: &quot;&lt;resource version&gt;&quot;。 每个Pod可以匹配零个或多个Pod Presets; 并且每个PodPreset都可以应用于零个或多个pod。当 PodPreset应用于一个或多个Pod时，Kubernetes会修改Pod规范。对于更改Env，EnvFrom和 VolumeMounts，Kubernetes修改在波德所有容器容器规范; 对于更改Volume，Kubernetes修改Pod规范。 注意： Pod Preset能够.spec.containers在适当的时候修改Pod规范中的字段。没有从POD预置资源定义将被应用到initContainers外地。 禁用特定Pod的Pod预设在某些情况下，您希望Pod不会被任何Pod Preset突变改变。在这些情况下，您可以在表单的Pod Spec中添加注释：podpreset.admission.kubernetes.io/exclude: &quot;true&quot;。 启用Pod预设要在群集中使用Pod Presets，您必须确保以下内容： 您已启用API类型settings.k8s.io/v1alpha1/podpreset。例如，这可以通过包含settings.k8s.io/v1alpha1=true在--runtime-configAPI服务器的选项中来完成。在minikube中，--extra-config=apiserver.runtime-config=settings.k8s.io/v1alpha1=true在启动集群时添加此标志 。 您已启用准入控制器PodPreset。执行此操作的一种方法是包含PodPreset在--enable-admission-plugins为API服务器指定的选项值中。在minikube中，--extra-config=apiserver.enable-admission-plugins=Initializers,NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,PodPreset 在启动集群时添加此标志 。 您已通过PodPreset在将使用的命名空间中创建对象来定义Pod预设。 中断本指南适用于想要构建高可用性应用程序的应用程序所有者，因此需要了解Pod可能发生的中断类型。 它也适用于希望执行自动群集操作的群集管理员，例如升级和自动缩放群集。 自愿和非自愿中断 处理中断 中断预算如何运作 PDB示例 分离群集所有者和应用程序所有者角色 如何在群集上执行破坏性操作 自愿和非自愿中断在有人（一个人或一个控制器）摧毁它们，或者存在不可避免的硬件或系统软件错误之前，Pod不会消失。 我们将这些不可避免的案例称为对应用程序的非自愿中断。例如： 支持节点的物理机的硬件故障 集群管理员错误地删除了VM（实例） 云提供商或虚拟机管理程序故障使虚拟机消失 内核恐慌 由于群集网络分区，节点从群集中消失 由于节点资源不足而导致pod被驱逐。 除资源不足外，大多数用户都应熟悉所有这些条件; 它们不是Kubernetes特有的。 我们将其他案件称为自愿中断。其中包括应用程序所有者启动的操作和群集管理员启动的操作。典型应用程序所有者操作包 删除管理pod的部署或其他控制器 更新部署的pod模板导致重新启动 直接删除pod（例如意外） 群集管理员操作包括：- 耗尽节点进行修复或升级。 从群集中排出节点以缩小群集（了解群集自动缩放 ）。 从节点中删除pod以允许其他内容适合该节点。 这些操作可以由集群管理员直接执行，也可以由集群管理员或集群主机提供商自动运行。 请咨询您的集群管理员或咨询您的云提供商或分发文档，以确定是否为您的集群启用了任何自愿中断源。如果未启用，则可以跳过创建Pod中断预算。 处理中断以下是一些缓解非自愿中断的方法： 确保您的pod 请求所需的资源。 如果需要更高的可用性，请复制应用程序。（了解运行复制的 无状态 和有状态应用程序。） 为了在运行复制的应用程序时获得更高的可用性，可以跨机架（使用反关联）或跨区域（如果使用 多区域群集）分布应用程序 。 自愿中断的频率各不相同。在基本的Kubernetes集群上，根本没有自愿中断。但是，您的群集管理员或托管服务提供商可能会运行一些导致自愿中断的其他服务。例如，推出节点软件更新可能会导致自愿中断。此外，群集（节点）自动缩放的某些实现可能会导致自动中断以进行碎片整理和压缩节点。您的集群管理员或托管服务提供商应记录预期的自愿中断级别（如果有）。 Kubernetes提供的功能可以帮助您在频繁的自愿中断的同时运行高可用性应用程序。我们将这组功能称为 中断预算。 中断预算如何运作应用程序所有者可以PodDisruptionBudget为每个应用程序创建一个对象（PDB）。PDB限制复制应用程序的pod的数量，这些pod与自愿中断同时发生故障。例如，基于仲裁的应用程序希望确保运行的副本数量永远不会低于仲裁所需的数量。Web前端可能希望确保服务负载的副本数量永远不会低于总数的某个百分比。 集群管理器和托管提供商应使用通过调用Eviction API 而不是直接删除pod来遵守Pod Disruption Budgets的工具。示例是kubectl drain命令和Kubernetes-on-GCE集群升级脚本（cluster/gce/upgrade.sh）。 当集群管理员想要耗尽节点时，他们使用该kubectl drain命令。该工具试图驱逐机器上的所有pod。可以暂时拒绝逐出请求，并且该工具定期重试所有失败的请求，直到所有pod终止，或者直到达到可配置的超时。 PDB指定应用程序可以容忍的副本数量，相对于预期的副本数量。例如，具有部署.spec.replicas: 5应该在任何给定时间具有5个pod。如果其PDB允许一次有4个，则Eviction API将允许一次自动中断一个而不是两个pod。 组成应用程序的pod组使用标签选择器指定，与应用程序控制器使用的标签选择器相同（部署，有状态集等）。 “预期”数量的pod是根据.spec.replicaspods控制器计算出来的。使用.metadata.ownerReferences对象的pod从pod中发现控制器。 PDB不能防止非自愿中断发生，但它们确实违背了预算。 由于滚动升级到应用程序而被删除或不可用的Pod确实会计入中断预算，但是在执行滚动升级时，控制器（如部署和有状态集）不受PDB限制 - 在应用程序更新期间处理故障在控制器规范中。（了解有关更新部署的信息。） 当吊舱使用驱逐API逐出，它是正常终止（见 terminationGracePeriodSeconds在PodSpec。） PDB示例考虑具有3个节点的群集中，node-1通过node-3。群集正在运行多个应用程序。其中一人有3个副本最初称 pod-a，pod-b和pod-c。pod-x还示出了另一个没有PDB的不相关的pod。最初，pod的布局如下： 节点-1 节点-2- 节点-3- pod-a 可用 pod-b 可用 pod-c 可用 pod-x 可用 所有3个pod都是部署的一部分，它们共同拥有一个PDB，要求所有3个pod中至少有2个可用。 例如，假设集群管理员想要重新启动到新的内核版本来修复内核中的错误。群集管理员首先尝试node-1使用该kubectl drain命令消耗。该工具试图驱逐pod-a和pod-x。这立即成功。两个pod同时进入该terminating。这使集群处于以下状态 节点-1 耗尽 节点-2- 节点-3- pod-a 终止 pod-b 可用 pod-c 可用 pod-x 终止 部署注意到其中一个pod正在终止，因此它会创建一个名为的替换pod-d。由于node-1是封锁的，它落在另一个节点上。还创造pod-y了一些替代品pod-x。 （注意：对于一个StatefulSet，pod-a它将被称为类似的东西pod-1，需要在它被替换之前完全终止，也可以被调用，pod-1但是可以创建不同的UID。否则，该示例也适用于StatefulSet。） 现在集群处于以下状态： 节点-1 耗尽 节点-2- 节点-3- pod-a 终止 pod-b 可用 pod-c 可用 pod-x 终止 pod-b 开始 POD-Y 在某些时候，pod终止，集群看起来像这样： 节点-1 耗尽 节点-2- 节点-3- pod-b 可用 pod-c 可用 pod-b 开始 POD-Y 此时，如果一个不耐烦的集群管理员试图耗尽，node-2或者 node-3排除命令将阻塞，因为部署只有2个可用的pod，并且其PDB至少需要2.经过一段时间后，pod-d变为可用。 群集状态现在看起来像这样： 节点-1 耗尽 节点-2- 节点-3- pod-b 可用 pod-c 可用 pod-b 可用 POD-Y 现在，集群管理员试图耗尽node-2。drain命令将尝试以某种顺序驱逐两个pod，pod-b先说然后再说 pod-d。它将成功驱逐pod-b。但是，当它试图逐出时pod-d，它将被拒绝，因为这将只留下一个可用于部署的pod。 部署创建了pod-b被叫的替代品pod-e。因为集群中没有足够的资源来安排 pod-e排水将再次阻塞。群集可能最终处于此状态： 节点-1 耗尽 节点-2- 节点-3- 没有节点 pod-b 可用 pod-c 可用 pod-e 待定 pod-b 可用 POD-Y 此时，集群管理员需要将节点添加回集群以继续升级。 你可以看到Kubernetes如何改变发生中断的速度，根据： 应用程序需要多少个副本 优雅地关闭实例需要多长时间 启动新实例需要多长时间 控制器的类型 集群的资源容量 分离群集所有者和应用程序所有者角色通常，将群集管理器和应用程序所有者视为彼此知之甚少的单独角色很有用。在这些情况下，这种职责分离可能有意义： 当有许多应用程序团队共享Kubernetes集群时，角色有自然的专业化 当第三方工具或服务用于自动化集群管理时 Pod Disruption Budgets通过在角色之间提供接口来支持这种角色分离。 如果您的组织中没有这样的责任分离，则可能不需要使用Pod Disruption Budgets。 如何在群集上执行破坏性操作如果您是群集管理员，并且需要对群集中的所有节点执行中断操作，例如节点或系统软件升级，则可以使用以下选项： 在升级期间接受停机时间。 故障转移到另一个完整的副本群集。 没有停机时间，但对于重复的节点以及人类协调切换的努力可能都是昂贵的。 编写容错中断应用程序并使用PDB。 没有停机时间。 最小的资源重复。 允许更多自动化群集管理。 编写容忍破坏性的应用程序很棘手，但容忍自愿中断的工作很大程度上与支持自动缩放和容忍非自愿中断的工作重叠。 控制器ReplicaSetReplicaSet是下一代复制控制器。现在ReplicaSet和 Replication Controller之间的唯一区别是选择器支持。ReplicaSet支持新的基于集合的选择器要求，如标签用户指南中所述， 而Replication Controller仅支持基于等同的选择器要求。 如何使用ReplicaSet 何时使用ReplicaSet 例 编写副本集规范 使用ReplicaSet ReplicaSet的替代品 如何使用ReplicaSet大多数kubectl支持复制控制器的命令也支持ReplicaSet。rolling-update命令是一个例外 。如果您想要滚动更新功能，请考虑使用部署。此外， rolling-update命令是必需的，而Deployments是声明性的，因此我们建议通过rollout命令使用Deployments 。 虽然ReplicaSet可以独立使用，但今天它主要被 Deployments用作协调pod创建，删除和更新的机制。使用“部署”时，您不必担心管理它们创建的副本集。部署拥有并管理其ReplicaSet。 何时使用ReplicaSetReplicaSet确保在任何给定时间运行指定数量的pod副本。但是，Deployment是一个更高级别的概念，它管理ReplicaSet并为pod提供声明性更新以及许多其他有用的功能。因此，除非您需要自定义更新编排或根本不需要更新，否则我们建议使用部署而不是直接使用ReplicaSet。 这实际上意味着您可能永远不需要操作ReplicaSet对象：改为使用Deployment，并在spec部分中定义您的应用程序。 例123456789101112131415161718192021222324252627282930313233343536373839#controllers/frontend.yamlapiVersion: apps/v1kind: ReplicaSetmetadata: name: frontend labels: app: guestbook tier: frontendspec: # modify replicas according to your case replicas: 3 selector: matchLabels: tier: frontend matchExpressions: - &#123;key: tier, operator: In, values: [frontend]&#125; template: metadata: labels: app: guestbook tier: frontend spec: containers: - name: php-redis image: gcr.io/google_samples/gb-frontend:v3 resources: requests: cpu: 100m memory: 100Mi env: - name: GET_HOSTS_FROM value: dns # If your cluster config does not include a dns service, then to # instead access environment variables to find service host # info, comment out the 'value: dns' line above, and uncomment the # line below. # value: env ports: - containerPort: 80 将此清单保存frontend.yaml到Kubernetes集群并将其提交到Kubernetes集群应该创建已定义的ReplicaSet及其管理的pod。123456789101112131415161718192021222324252627282930313233343536$ kubectl create -f http://k8s.io/examples/controllers/frontend.yamlreplicaset.apps/frontend created$ kubectl describe rs/frontendName: frontendNamespace: defaultSelector: tier=frontend,tier in (frontend)Labels: app=guestbook tier=frontendAnnotations: &lt;none&gt;Replicas: 3 current / 3 desiredPods Status: 3 Running / 0 Waiting / 0 Succeeded / 0 FailedPod Template: Labels: app=guestbook tier=frontend Containers: php-redis: Image: gcr.io/google_samples/gb-frontend:v3 Port: 80/TCP Requests: cpu: 100m memory: 100Mi Environment: GET_HOSTS_FROM: dns Mounts: &lt;none&gt; Volumes: &lt;none&gt;Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 1m 1m 1 &#123;replicaset-controller &#125; Normal SuccessfulCreate Created pod: frontend-qhloh 1m 1m 1 &#123;replicaset-controller &#125; Normal SuccessfulCreate Created pod: frontend-dnjpy 1m 1m 1 &#123;replicaset-controller &#125; Normal SuccessfulCreate Created pod: frontend-9si5l$ kubectl get podsNAME READY STATUS RESTARTS AGEfrontend-9si5l 1/1 Running 0 1mfrontend-dnjpy 1/1 Running 0 1mfrontend-qhloh 1/1 Running 0 1m 编写副本集规范与所有其他Kubernetes API对象，一个ReplicaSet需要apiVersion，kind和metadata领域。有关使用清单的一般信息，请参阅使用kubectl进行对象管理。 ReplicaSet还需要一个.spec部分。 Pod模板这.spec.template是唯一必需的领域.spec。这.spec.template是一个 pod模板。它与pod具有完全相同的架构 ，除了它是嵌套的并且没有apiVersion或kind。 除了pod的必填字段外，ReplicaSet中的pod模板还必须指定适当的标签和适当的重新启动策略。 对于标签，请确保不与其他控制器重叠。有关更多信息，请参阅pod选择器。 对于重新启动策略，唯一允许的值.spec.template.spec.restartPolicy是Always，这是默认值。 对于本地容器重新启动，ReplicaSet委托给节点上的代理程序，例如Kubelet或Docker。 Pod选择器该.spec.selector字段是标签选择器。ReplicaSet使用与选择器匹配的标签管理所有pod。它不区分它创建或删除的pod以及另一个人或进程创建或删除的pod。这允许替换ReplicaSet而不影响正在运行的pod。 在.spec.template.metadata.labels必须匹配.spec.selector，否则会被API被拒绝。 在Kubernetes 1.9中，apps/v1ReplicaSet类型的API版本是当前版本，默认情况下已启用。apps/v1beta2不推荐使用API版本。 此外，您通常不应创建任何标签与此选择器匹配的pod，可以直接与另一个ReplicaSet一起创建，也可以与其他控制器（如Deployment）一起创建。如果这样做，ReplicaSet会认为它创建了其他pod。Kubernetes并没有阻止你这样做。 如果最终有多个具有重叠选择器的控制器，则必须自己管理删除。 副本集上的标签ReplicaSet本身可以有标签（.metadata.labels）。通常，您可以将它们设置为相同.spec.template.metadata.labels。但是，允许它们不同，并且.metadata.labels不会影响ReplicaSet的行为。 副本您可以通过设置指定应同时运行的pod数量.spec.replicas。在任何时间运行的数字可能更高或更低，例如，如果副本只是增加或减少，或者如果正常关闭吊舱，并且提前开始更换。 如果未指定.spec.replicas，则默认为1。 使用ReplicaSet删除ReplicaSet及其Pod要删除ReplicaSet及其所有Pod，请使用kubectl delete。该垃圾收集器在默认情况下会自动删除所有相关的荚。 使用REST API或client-go库时，必须设置propagationPolicy为Background或Foreground删除选项。例如：1234kubectl proxy --port=8080curl -X DELETE 'localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend' \&gt; -d '&#123;"kind":"DeleteOptions","apiVersion":"v1","propagationPolicy":"Foreground"&#125;' \&gt; -H "Content-Type: application/json" 仅删除副本集您可以删除副本集，而不会影响使用kubectl delete该--cascade=false选项的任何pod 。使用REST API或client-go库时，必须设置propagationPolicy为Orphan，例如：1234kubectl proxy --port=8080curl -X DELETE 'localhost:8080/apis/extensions/v1beta1/namespaces/default/replicasets/frontend' \&gt; -d '&#123;"kind":"DeleteOptions","apiVersion":"v1","propagationPolicy":"Orphan"&#125;' \&gt; -H "Content-Type: application/json" 删除原始文件后，您可以创建一个新的ReplicaSet来替换它。只要旧的和新.spec.selector的相同，那么新的将采用旧的豆荚。但是，它不会做任何努力使现有的pod匹配一个新的，不同的pod模板。要以受控方式将pod更新为新规范，请使用滚动更新。 从副本集隔离pod可以通过更改标签来从ReplicaSet的目标集中删除Pod。此技术可用于从服务中删除pod以进行调试，数据恢复等。以这种方式删除的Pod将自动替换（假设副本的数量也未更改）。 缩放副本集只需更新.spec.replicas字段即可轻松扩展或缩小ReplicaSet 。ReplicaSet控制器确保具有匹配标签选择器的所需数量的pod可用且可操作。 ReplicaSet作为水平Pod自动缩放器目标ReplicaSet也可以是 Horizontal Pod Autoscalers (HPA)的目标 。也就是说，HPA可以自动缩放ReplicaSet。以下是针对我们在上一个示例中创建的ReplicaSet的示例HPA。123456789101112#controllers/hpa-rs.yaml apiVersion: autoscaling/v1kind: HorizontalPodAutoscalermetadata: name: frontend-scalerspec: scaleTargetRef: kind: ReplicaSet name: frontend minReplicas: 3 maxReplicas: 10 targetCPUUtilizationPercentage: 50 将此清单保存hpa-rs.yaml到Kubernetes集群并将其提交到Kubernetes集群应该创建定义的HPA，该HPA根据复制的pod的CPU使用情况自动调整目标ReplicaSet。1kubectl create -f https://k8s.io/examples/controllers/hpa-rs.yaml 或者，您可以使用该kubectl autoscale命令来完成相同的操作（并且它更容易！）1kubectl autoscale rs frontend --max=10 ReplicaSet的替代品部署（推荐）Deployment是一个更高级别的API对象，它以类似的方式更新其底层ReplicaSet及其Pod kubectl rolling-update。如果您需要此滚动更新功能，则建议进行部署，因为kubectl rolling-update它们不同于声明式，服务器端，并具有其他功能。有关使用部署运行无状态应用程序的更多信息，请阅读使用部署运行无状态应用程序。 Bare Pods与用户直接创建pod的情况不同，ReplicaSet会替换因任何原因而被删除或终止的pod，例如在节点故障或破坏性节点维护（例如内核升级）的情况下。因此，即使您的应用程序只需要一个pod，我们也建议您使用ReplicaSet。可以想象它与流程主管类似，只是它监控多个节点上的多个pod而不是单个节点上的单个进程。ReplicaSet将本地容器重新启动委派给节点上的某个代理程序（例如，Kubelet或Docker）。 Job对于预期会自行终止的pod（即批处理作业），请使用Job而不是ReplicaSet。 DaemonSetDaemonSet对于提供机器级功能的pod，例如机器监视或机器日志记录，请使用ReplicaSet而不是ReplicaSet。这些pod的生命周期与机器生命周期相关：pod需要在其他pod启动之前在机器上运行，并且当机器准备好重新启动/关闭时可以安全终止。 ReplicationController 注意：现在建议使用配置ReplicaSet的Deployment来设置复制。 ReplicationController确保pod副本的指定数量的在任何一个时间运行。换句话说，ReplicationController确保一个pod或一组同类pod总是可用。 ReplicationController的工作原理 运行示例ReplicationController 编写ReplicationController规范 使用ReplicationControllers 常见的使用模式 编写复制程序 ReplicationController的职责 API对象 ReplicationController的替代品 欲获得更多信息 ReplicationController的工作原理如果存在太多pod，则ReplicationController将终止额外的pod。如果太少，ReplicationController将启动更多pod。与手动创建的pod不同，ReplicationController维护的pod在失败，删除或终止时会自动替换。例如，在内核升级等破坏性维护之后，会在节点上重新创建pod。因此，即使应用程序只需要一个pod，也应该使用ReplicationController。ReplicationController类似于进程管理程序，但是ReplicationController不是监视单个节点上的各个进程，而是监视多个节点上的多个pod。 在讨论中，ReplicationController通常缩写为“rc”或“rcs”，并且作为kubectl命令中的快捷方式。 一个简单的例子是创建一个ReplicationController对象，以无限期地可靠地运行Pod的一个实例。更复杂的用例是运行复制服务的几个相同副本，例如Web服务器。 运行示例ReplicationController此示例ReplicationController配置运行nginx Web服务器的三个副本。1234567891011121314151617181920#controllers/replication.yaml apiVersion: v1kind: ReplicationControllermetadata: name: nginxspec: replicas: 3 selector: app: nginx template: metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 通过下载示例文件然后运行此命令来运行示例作业：12$ kubectl create -f https://k8s.io/examples/controllers/replication.yamlreplicationcontroller/nginx created 使用以下命令检查ReplicationController的状态：1234567891011121314151617181920212223$ kubectl describe replicationcontrollers/nginxName: nginxNamespace: defaultSelector: app=nginxLabels: app=nginxAnnotations: &lt;none&gt;Replicas: 3 current / 3 desiredPods Status: 0 Running / 3 Waiting / 0 Succeeded / 0 FailedPod Template: Labels: app=nginx Containers: nginx: Image: nginx Port: 80/TCP Environment: &lt;none&gt; Mounts: &lt;none&gt; Volumes: &lt;none&gt;Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- ---- ------ ------- 20s 20s 1 &#123;replication-controller &#125; Normal SuccessfulCreate Created pod: nginx-qrm3m 20s 20s 1 &#123;replication-controller &#125; Normal SuccessfulCreate Created pod: nginx-3ntk0 20s 20s 1 &#123;replication-controller &#125; Normal SuccessfulCreate Created pod: nginx-4ok8v 这里创建了三个pod，但没有一个正在运行，可能是因为正在拉动图像。稍后，相同的命令可能会显示： 1Pods Status: 3 Running / 0 Waiting / 0 Succeeded / 0 Failed 要以机器可读的形式列出属于ReplicationController的所有pod，可以使用如下命令：123 $ pods=$(kubectl get pods --selector=app=nginx --output=jsonpath=&#123;.items..metadata.name&#125;)echo $podsnginx-3ntk0 nginx-4ok8v nginx-qrm3m 这里，选择器与ReplicationController的选择器相同（在kubectl describe输出中看到 ，并以不同的形式显示replication.yaml。该--output=jsonpath选项指定一个表达式，它只从返回列表中的每个pod获取名称。 编写ReplicationController规范与所有其他Kubernetes配置，一个ReplicationController需要apiVersion，kind和metadata领域。有关使用配置文件的一般信息，请参阅对象管理。 ReplicationController还需要一个.spec部分。 Pod模板这.spec.template是唯一必需的领域.spec。 这.spec.template是一个pod模板。它与pod具有完全相同的架构，除了它是嵌套的并且没有apiVersion或kind。 除了Pod的必需字段之外，ReplicationController中的pod模板还必须指定适当的标签和适当的重新启动策略。对于标签，请确保不要与其他控制器重叠。请参阅pod选择器。 只允许.spec.template.spec.restartPolicy等于Always，如果未指定，则为默认值。 对于本地容器重新启动，ReplicationControllers委托给节点上的代理程序，例如Kubelet或Docker。 ReplicationController上的标签ReplicationController本身可以有labels（.metadata.labels）。通常，您可以将它们设置为相同.spec.template.metadata.labels; 如果.metadata.labels未指定，则默认为.spec.template.metadata.labels。但是，允许它们不同，并且.metadata.labels不会影响ReplicationController的行为。 Pod选择器该.spec.selector字段是标签选择器。ReplicationController管理具有与选择器匹配的标签的所有pod。它不区分它创建或删除的pod以及另一个人或进程创建或删除的pod。这允许在不影响正在运行的pod的情况下替换ReplicationController。 如果指定，则.spec.template.metadata.labels必须等于.spec.selector，否则将被API拒绝。如果.spec.selector未指定，则默认为.spec.template.metadata.labels。 此外，您通常不应创建任何标签与此选择器匹配的pod，可以直接创建，与另一个ReplicationController或其他控制器（如Job）匹配。如果这样做，ReplicationController会认为它创建了其他pod。Kubernetes并没有阻止你这样做。 如果最终有多个具有重叠选择器的控制器，则必须自己管理删除（见下文）。 多个副本您可以通过设置.spec.replicas要同时运行的窗格数来指定应同时运行的窗格数。在任何时间运行的数字可能更高或更低，例如，如果副本只是增加或减少，或者如果正常关闭吊舱，并且提前开始更换。 如果未指定.spec.replicas，则默认为1。 使用ReplicationControllers删除ReplicationController及其Pod要删除ReplicationController及其所有pod，请使用kubectl delete。在删除ReplicationController本身之前，Kubectl会将ReplicationController缩放为零并等待它删除每个pod。如果此kubectl命令被中断，则可以重新启动它。 使用REST API或转到客户端库时，需要显式执行这些步骤（将副本扩展为0，等待窗格删除，然后删除ReplicationController）。 仅删除ReplicationController您可以删除ReplicationController而不影响其任何pod。 使用kubectl，指定--cascade=false选项kubectl delete。 使用REST API或转到客户端库时，只需删除ReplicationController对象即可。 删除原始文件后，您可以创建一个新的ReplicationController来替换它。只要旧的和新.spec.selector的相同，那么新的将采用旧的pod。但是，它不会做任何努力使现有的pod匹配一个新的，不同的pod模板。要以受控方式将pod更新为新规范，请使用滚动更新。 从ReplicationController中隔离pod可以通过更改标签来从ReplicationController的目标集中删除Pod。此技术可用于从服务中删除pod以进行调试，数据恢复等。以这种方式删除的Pod将自动替换（假设副本的数量也未更改）。 常见的使用模式重新安排如上所述，无论您是要保持运行1个pod还是1000个，ReplicationController都将确保存在指定数量的pod，即使在节点发生故障或pod终止时（例如，由于另一个控制剂）。 缩放通过简单地更新replicas字段，ReplicationController可以手动或通过自动缩放控制代理轻松扩展或缩小副本数量。 滚动更新ReplicationController旨在通过逐个替换pod来促进对服务的滚动更新。 如＃1353中所述，建议的方法是创建一个具有1个副本的新ReplicationController，逐个扩展新的（+1）和旧（-1）控制器，然后在它达到0个副本后删除旧控制器。无论意外故障如何，这都可以预测更新pod的集合。 理想情况下，滚动更新控制器会考虑应用程序准备情况，并确保在任何给定时间内有足够数量的pod可以高效地运行。 这两个ReplicationControllers需要创建具有至少一个区分标签的pod，例如pod的主容器的image标签，因为它通常是图像更新，可以激发滚动更新。 滚动更新在客户端工具中实现 kubectl rolling-update。访问kubectl rolling-update任务以获得更具体的示例。 多个发行tracks除了在滚动更新正在进行时运行多个版本的应用程序之外，通常使用多个版本跟踪长时间运行多个版本，甚至连续运行多个版本。轨道将按标签区分。 例如，服务可能会定位所有pod tier in (frontend), environment in (prod)。现在说你有10个复制的pod组成这个层。但是你希望能够’canary’这个组件的新版本。您可以replicas为大部分副本设置一个设置为9 的ReplicationController ，带有标签tier=frontend, environment=prod, track=stable，另一个replicas设置为1的带有标签的ReplicationController 用于canarytier=frontend, environment=prod, track=canary。现在该服务涵盖了canary和non-canary pods。但是你可以分别搞乱ReplicationControllers来测试，监视结果等。 将ReplicationControllers与Services一起使用多个ReplicationControllers可以位于单个服务之后，例如，某些流量转到旧版本，有些流量转到新版本。 ReplicationController永远不会自行终止，但预计它不会像服务一样长寿。服务可以由多个ReplicationControllers控制的pod组成，并且预计可以在服务的生命周期内创建和销毁许多ReplicationController（例如，执行运行服务的pod的更新）。服务本身及其客户端都应该忽略维护服务pod的ReplicationControllers。 编写复制程序由ReplicationController创建的Pod旨在是可互换的和语义相同的，尽管它们的配置可能随着时间的推移变得异构。这显然适用于复制的无状态服务器，但ReplicationControllers也可用于维护主选，分片和工作池应用程序的可用性。此类应用程序应使用动态工作分配机制，例如RabbitMQ工作队列，而不是静态/一次性定制每个pod的配置，这被视为反模式。执行的任何pod自定义，例如资源的垂直自动调整（例如，cpu或内存），应由另一个在线控制器进程执行，与ReplicationController本身不同。 ReplicationController的职责ReplicationController只是确保所需数量的pod与其标签选择器匹配并且可以运行。目前，只有已终止的广告连播从其计数中排除。将来，可以考虑系统提供的准备情况和其他信息，我们可以对替换策略添加更多控制，并且我们计划发出可以由外部客户使用的事件，以实现任意复杂的替换和/或扩展下行政策。 ReplicationController永远受限于这种狭隘的责任。它本身不会执行准备就绪或活力探测。它不是执行自动缩放，而是由外部自动缩放器控制（如＃492中所述），这将改变其replicas字段。我们不会将调度策略（例如，传播）添加到ReplicationController。它也不应该验证控制的pod与当前指定的模板匹配，因为这会妨碍自动调整大小和其他自动化过程。同样，完成期限，排序依赖性，配置扩展和其他功能属于其他地方。我们甚至计划分析批量pod创建的机制（＃170）。 ReplicationController旨在成为可组合的构建块原语。我们希望在它和其他补充原语之上构建更高级别的API和/或工具，以便将来用户使用。kubectl目前支持的“宏”操作（运行，缩放，滚动更新）是概念验证的例子。例如，我们可以想象像Asgard管理ReplicationControllers，自动缩放器，服务，调度策略，canary等。 API对象复制控制器是Kubernetes REST API中的顶级资源。有关API对象的更多详细信息，请访问： ReplicationController API对象。 ReplicationController的替代品ReplicaSetReplicaSet是支持新的基于集合的标签选择器的下一代ReplicationController 。它主要用作Deployment协调pod创建，删除和更新的机制。请注意，除非您需要自定义更新编排或根本不需要更新，否则我们建议您使用“部署”而不是直接使用“副本集”。 部署（推荐）Deployment是一个更高级别的API对象，它以类似的方式更新其基础副本集及其Pod kubectl rolling-update。如果您需要此滚动更新功能，则建议进行部署，因为kubectl rolling-update它们不同于声明式，服务器端，并具有其他功能。 pod与用户直接创建pod的情况不同，ReplicationController替换因任何原因而被删除或终止的pod，例如在节点故障或破坏性节点维护（例如内核升级）的情况下。因此，即使您的应用程序只需要一个pod，我们也建议您使用ReplicationController。可以想象它与流程主管类似，只是它监控多个节点上的多个pod而不是单个节点上的单个进程。ReplicationController将本地容器重新启动委派给节点上的某个代理（例如，Kubelet或Docker）。 jobJob对于预期会自行终止的pod（即批处理作业），请使用而不是ReplicationController。 DaemonSetDaemonSet对于提供机器级功能的pod，例如机器监视或机器日志记录，请使用而不是ReplicationController。这些pod的生命周期与机器生命周期相关：pod需要在其他pod启动之前在机器上运行，并且当机器准备好重新启动/关闭时可以安全终止。 欲获得更多信息读取运行无状态AP复制控制器。 部署一个部署控制器提供声明更新pod和 ReplicaSets。 您在Deployment对象中描述了所需的状态，Deployment控制器以受控速率将实际状态更改为所需状态。您可以定义部署以创建新的ReplicaSet，或者删除现有的部署并使用新的部署采用所有资源。 注意：您不应管理部署所拥有的ReplicaSet。应通过操作Deployment对象来涵盖所有用例。如果您的用例未在下面介绍，请考虑在主Kubernetes存储库中打开一个问题。 用例 创建部署 更新部署 回滚部署 扩展部署 暂停和恢复部署 部署状态 清理政策 用例 编写部署规范 部署的替代方案 用例以下是部署的典型用例： 创建部署以部署副本集。ReplicaSet在后台创建Pod。检查卷展栏的状态以查看它是否成功。 通过更新Deployment的PodTemplateSpec来声明 Pod 的新状态。创建一个新的ReplicaSet，Deployment部署管理以受控速率将Pod从旧ReplicaSet移动到新ReplicaSet。每个新的ReplicaSet都会更新Deployment的修订版。 如果部署的当前状态不稳定，则回滚到早期的部署修订版。每次回滚都会更新Deployment的修订版。 扩展部署以促进更多负载。 暂停部署以将多个修复程序应用于其PodTemplateSpec，然后恢复它以启动新的部署。 使用部署的状态作为卷展栏卡住的指示符。 清理不再需要的旧ReplicaSet。 创建部署以下是部署的示例。它创建一个ReplicaSet来调出三个Pod nginx：12345678910111213141516171819202122#controllers/nginx-deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata: name: nginx-deployment labels: app: nginxspec: replicas: 3 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.7.9 ports: - containerPort: 80 在这个例子中： nginx-deployment创建名为的部署，由.metadata.name字段指示。 部署创建三个复制的Pod，由replicas字段指示。 该selector字段定义了Deployment如何找到要管理的Pod。在这种情况下，您只需选择Pod模板（app: nginx）中定义的标签。但是，只要Pod模板本身满足规则，就可以使用更复杂的选择规则。 注意： matchLabels是{key，value}对的映射。matchLabels映射中的单个{key，value} 等效matchExpressions于其元素，其键字段为“key”，运算符为“In”，值数组仅包含“value”。要求是AND。 该template字段包含以下子字段： app: nginx使用该labels字段标记Pod 。 Pod模板的规范或.template.spec字段表示Pod 运行一个容器nginx，该容器在版本1.7.9下运行nginx Docker Hub映像。 创建一个容器并nginx使用该name字段命名。 nginx在版本运行图像1.7.9。 打开端口，80以便容器可以发送和接受流量。 要创建此部署，请运行以下命令：1kubectl create -f https://k8s.io/examples/controllers/nginx-deployment.yaml 注意：您可以指定--record标志以写入在资源批注中执行的命令kubernetes.io/change-cause。它对于将来的内省非常有用，例如，可以查看每个Deployment修订版中执行的命令。 接下来，运行kubectl get deployments。输出类似于以下内容：12NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 3 0 0 0 1s 检查群集中的“部署”时，将显示以下字段： NAME 列出群集中的部署名称。 DESIRED显示应用程序的所需副本数，您在创建部署时定义这些副本。这是理想的状态。 CURRENT 显示当前正在运行的副本数量。 UP-TO-DATE 显示已更新以实现所需状态的副本数。 AVAILABLE 显示用户可以使用的应用程序副本数。 AGE 显示应用程序运行的时间。 请注意每个字段中的值如何与Deployment规范中的值相对应： 根据.spec.replicas字段，所需副本的数量为3 。 根据.status.replicas字段，当前副本的数量为0 。 根据.status.updatedReplicas字段，最新副本的数量为0 。 根据.status.availableReplicas字段，可用副本的数量为0 。 要查看“部署”卷展栏状态，请运行kubectl rollout status deployment.v1.apps/nginx-deployment。此命令返回以下输出：12Waiting for rollout to finish: 2 out of 3 new replicas have been updated...deployment.apps/nginx-deployment successfully rolled out kubectl get deployments几秒钟后再次运行：12NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 3 3 3 3 18s 请注意，Deployment已创建所有三个副本，并且所有副本都是最新的（它们包含最新的Pod模板）并且可用（Pod状态至少为Deployment的.spec.minReadySeconds字段值准备就绪）。 要查看rs部署创建的ReplicaSet（），请运行kubectl get rs：12NAME DESIRED CURRENT READY AGEnginx-deployment-2035384211 3 3 3 18s 请注意，ReplicaSet的名称始终格式为[DEPLOYMENT-NAME]-[POD-TEMPLATE-HASH-VALUE]。创建部署时会自动生成哈希值。 要查看为每个pod自动生成的标签，请运行kubectl get pods --show-labels。返回以下输出：1234NAME READY STATUS RESTARTS AGE LABELSnginx-deployment-2035384211-7ci7o 1/1 Running 0 18s app=nginx,pod-template-hash=2035384211nginx-deployment-2035384211-kzszj 1/1 Running 0 18s app=nginx,pod-template-hash=2035384211nginx-deployment-2035384211-qqcnn 1/1 Running 0 18s app=nginx,pod-template-hash=2035384211 创建的ReplicaSet确保始终有三个Pod nginx在运行。 注意：您必须在部署中指定适当的选择器和Pod模板标签（在本例中 app: nginx）。不要将标签或选择器与其他控制器（包括其他部署和StatefulSet）重叠。Kubernetes不会阻止您重叠，如果多个控制器具有重叠的选择器，那么这些控制器可能会发生冲突并出现意外行为。 Pod-template-hash标签 注意：请勿更改此标签。 pod-template-hash部署控制器将标签添加到部署创建或采用的每个ReplicaSet。 此标签可确保部署的子ReplicaSet不重叠。它是通过散列PodTemplateReplicaSet并使用生成的散列作为添加到ReplicaSet选择器，Pod模板标签以及ReplicaSet可能具有的任何现有Pod中的标签值生成的。 更新部署 注意：当且仅当部署的pod模板（即.spec.template）更改时，才会触发Deployment的部署，例如，如果更新模板的标签或容器图像。其他更新（例如扩展部署）不会触发部署。 假设您现在想要更新nginx Pod以使用nginx:1.9.1镜像而不是nginx:1.7.9图像。12$ kubectl --record deployment.apps/nginx-deployment set image deployment.v1.apps/nginx-deploymentnginx=nginx:1.9.1 image updated 或者，您可以edit部署和改变.spec.template.spec.containers[0].image从nginx:1.7.9到nginx:1.9.1： 12$ kubectl edit deployment.v1.apps/nginx-deploymentdeployment.apps/nginx-deployment edited 要查看卷展栏状态，请运行：123$ kubectl rollout status deployment.v1.apps/nginx-deploymentWaiting for rollout to finish: 2 out of 3 new replicas have been updated...deployment.apps/nginx-deployment successfully rolled out 部署成功后，您可能需要get部署：123$ kubectl get deploymentsNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 3 3 3 3 36s 最新副本的数量表示Deployment已将副本更新为最新配置。当前副本表示此部署管理的副本总数，可用副本表示可用的当前副本数。 您可以运行kubectl get rs以查看部署通过创建新的ReplicaSet并将其扩展到3个副本来更新Pod，以及将旧的ReplicaSet缩减为0个副本。1234$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-1564180365 3 3 3 6snginx-deployment-2035384211 0 0 0 36s get pods现在运行应该只显示新的Pod：12345$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-deployment-1564180365-khku8 1/1 Running 0 14snginx-deployment-1564180365-nacti 1/1 Running 0 14snginx-deployment-1564180365-z9gth 1/1 Running 0 14s 下次要更新这些Pod时，只需再次更新Deployment的pod模板。 部署可以确保在更新时只有一定数量的Pod可能会关闭。默认情况下，它确保至少比所需的Pod数量少25％（最大不可用25％）。 部署还可以确保在所需数量的Pod之上只能创建一定数量的Pod。默认情况下，它确保最多比所需数量的Pod多25％（最大浪涌25％）。 例如，如果仔细查看上面的部署，您将看到它首先创建了一个新的Pod，然后删除了一些旧的Pod并创建了新的Pod。在有足够数量的新Pod出现之前，它不会杀死旧的Pod，并且在足够数量的旧Pod被杀之前不会创建新的Pod。它确保可用Pod的数量至少为2，并且Pod的总数最多为4。12345678910111213141516171819202122232425262728293031323334353637$ kubectl describe deploymentsName: nginx-deploymentNamespace: defaultCreationTimestamp: Thu, 30 Nov 2017 10:56:25 +0000Labels: app=nginxAnnotations: deployment.kubernetes.io/revision=2Selector: app=nginxReplicas: 3 desired | 3 updated | 3 total | 3 available | 0 unavailableStrategyType: RollingUpdateMinReadySeconds: 0RollingUpdateStrategy: 25% max unavailable, 25% max surgePod Template: Labels: app=nginx Containers: nginx: Image: nginx:1.9.1 Port: 80/TCP Environment: &lt;none&gt; Mounts: &lt;none&gt; Volumes: &lt;none&gt;Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailableOldReplicaSets: &lt;none&gt;NewReplicaSet: nginx-deployment-1564180365 (3/3 replicas created)Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 2m deployment-controller Scaled up replica set nginx-deployment-2035384211 to 3 Normal ScalingReplicaSet 24s deployment-controller Scaled up replica set nginx-deployment-1564180365 to 1 Normal ScalingReplicaSet 22s deployment-controller Scaled down replica set nginx-deployment-2035384211 to 2 Normal ScalingReplicaSet 22s deployment-controller Scaled up replica set nginx-deployment-1564180365 to 2 Normal ScalingReplicaSet 19s deployment-controller Scaled down replica set nginx-deployment-2035384211 to 1 Normal ScalingReplicaSet 19s deployment-controller Scaled up replica set nginx-deployment-1564180365 to 3 Normal ScalingReplicaSet 14s deployment-controller Scaled down replica set nginx-deployment-2035384211 to 0 在这里，您可以看到，当您第一次创建部署时，它创建了一个ReplicaSet（nginx-deployment-2035384211）并直接将其扩展到3个副本。更新部署时，它创建了一个新的ReplicaSet（nginx-deployment-1564180365）并将其扩展为1，然后将旧的ReplicaSet缩小为2，这样至少有2个Pod可用，最多创建了4个Pod一直。然后，它继续使用相同的滚动更新策略向上和向下扩展新旧ReplicaSet。最后，您将在新的ReplicaSet中拥有3个可用副本，并将旧的ReplicaSet缩小为0。 Rollover (aka multiple updates in-flight)每次部署控制器观察到新的部署对象时，如果没有现有的ReplicaSet，则会创建ReplicaSet以显示所需的Pod。现有的ReplicaSet控制其标签匹配.spec.selector但模板不匹配的Pod .spec.template按比例缩小。最终，新的ReplicaSet将缩放到，.spec.replicas并且所有旧的ReplicaSet将缩放为0。 如果在现有部署过程中更新部署，则部署将根据更新创建新的ReplicaSet并开始向上扩展，并将翻转之前正在扩展的ReplicaSet - 它会将其添加到其列表中旧的ReplicaSet和将开始缩小它。 例如，假设您创建了一个部署以创建5个副本nginx:1.7.9，但是nginx:1.9.1当仅创建了3个副本时，则更新部署以创建5个副本nginx:1.7.9。在这种情况下，部署将立即开始杀死nginx:1.7.9它创建的3个Pod，并将开始创建 nginx:1.9.1Pod。nginx:1.7.9在更改课程之前，它不会等待创建5个副本。 标签选择器更新通常不鼓励进行标签选择器更新，建议您事先规划选择器。在任何情况下，如果您需要执行标签选择器更新，请务必小心谨慎，并确保您已掌握所有含义。 注意：在API版本中apps/v1，部署的标签选择器在创建后是不可变的。 选择器添加要求使用新标签更新部署规范中的pod模板标签，否则将返回验证错误。此更改是非重叠的，这意味着新选择器不会选择使用旧选择器创建的ReplicaSet和Pod，从而导致孤立所有旧ReplicaSet并创建新的ReplicaSet。 选择器更新 - 即更改选择器键中的现有值 - 导致与添加相同的行为。 选择器删除 - 即从部署选择器中删除现有密钥 - 不需要对pod模板标签进行任何更改。没有现有的ReplicaSet是孤立的，并且未创建新的ReplicaSet，但请注意，已删除的标签仍存在于任何现有的Pod和ReplicaSet中。 回滚部署有时您可能想要回滚部署; 例如，当部署不稳定时，例如崩溃循环。默认情况下，所有Deployment的卷展栏历史记录都保留在系统中，以便您可以随时回滚（可以通过修改修订历史记录限制来更改）。 注意：触发Deployment的部署时会创建Deployment的修订版。这意味着当且仅当部署的pod模板（.spec.template）发生更改时才会创建新修订，例如，如果更新模板的标签或容器图像。其他更新（例如扩展部署）不会创建部署版本，因此您可以方便地同时进行手动或自动扩展。这意味着当您回滚到早期版本时，仅回滚Deployment的pod模板部分。 假设您在更新部署时输入了拼写错误，方法是将图像名称nginx:1.91替换为nginx:1.9.1： 12$ kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.91 --record=truedeployment.apps/nginx-deployment image updated 推出将被卡住。12$ kubectl rollout status deployment.v1.apps/nginx-deploymentWaiting for rollout to finish: 1 out of 3 new replicas have been updated... 按Ctrl-C可停止上面的卷展状态监视。有关卡片推出的更多信息， 请在此处阅读更多信息。 您将看到旧副本的数量（nginx-deployment-1564180365和nginx-deployment-2035384211）为2，新副本（nginx-deployment-3066724191）为1。12345$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-1564180365 3 3 3 25snginx-deployment-2035384211 0 0 0 36snginx-deployment-3066724191 1 1 0 6s 查看创建的Pod，您将看到由新ReplicaSet创建的1 Pod陷入图像拉环。123456$ kubectl get podsNAME READY STATUS RESTARTS AGEnginx-deployment-1564180365-70iae 1/1 Running 0 25snginx-deployment-1564180365-jbqqo 1/1 Running 0 25snginx-deployment-1564180365-hysrc 1/1 Running 0 25snginx-deployment-3066724191-08mng 0/1 ImagePullBackOff 0 6s 注意： Deployment控制器将自动停止错误的卷展栏，并将停止扩展新的ReplicaSet。这取决于maxUnavailable您指定的rollingUpdate参数（特别是）。默认情况下，Kubernetes将值设置为25％。 1234567891011121314151617181920212223242526272829303132333435363738$ kubectl describe deploymentName: nginx-deploymentNamespace: defaultCreationTimestamp: Tue, 15 Mar 2016 14:48:04 -0700Labels: app=nginxSelector: app=nginxReplicas: 3 desired | 1 updated | 4 total | 3 available | 1 unavailableStrategyType: RollingUpdateMinReadySeconds: 0RollingUpdateStrategy: 25% max unavailable, 25% max surgePod Template: Labels: app=nginx Containers: nginx: Image: nginx:1.91 Port: 80/TCP Host Port: 0/TCP Environment: &lt;none&gt; Mounts: &lt;none&gt; Volumes: &lt;none&gt;Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True ReplicaSetUpdatedOldReplicaSets: nginx-deployment-1564180365 (3/3 replicas created)NewReplicaSet: nginx-deployment-3066724191 (1/1 replicas created)Events: FirstSeen LastSeen Count From SubobjectPath Type Reason Message --------- -------- ----- ---- ------------- -------- ------ ------- 1m 1m 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled up replica set nginx-deployment-2035384211 to 3 22s 22s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 1 22s 22s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 2 22s 22s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 2 21s 21s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 1 21s 21s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled up replica set nginx-deployment-1564180365 to 3 13s 13s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled down replica set nginx-deployment-2035384211 to 0 13s 13s 1 &#123;deployment-controller &#125; Normal ScalingReplicaSet Scaled up replica set nginx-deployment-3066724191 to 1 要解决此问题，您需要回滚到稳定的以前版本的Deployment。 检查部署的部署历史记录首先，检查此部署的修订版：123456$ kubectl rollout history deployment.v1.apps/nginx-deploymentdeployments "nginx-deployment"REVISION CHANGE-CAUSE1 kubectl create --filename=https://k8s.io/examples/controllers/nginx-deployment.yaml --record=true2 kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true3 kube ctl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.91 --record=true CHANGE-CAUSEkubernetes.io/change-cause在创建时从部署批注复制到其修订版。您可以CHANGE-CAUSE通过以下方式指定消息： 注释部署 kubectl annotate deployment.v1.apps/nginx-deployment kubernetes.io/change-cause=&quot;image updated to 1.9.1&quot; 附加--record标志以保存kubectl对资源进行更改的命令。 手动编辑资源的清单。 要进一步查看每个修订的详细信息，请运行：1234567891011121314$ kubectl rollout history deployment.v1.apps/nginx-deployment --revision=2deployments "nginx-deployment" revision 2 Labels: app=nginx pod-template-hash=1159050644 Annotations: kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=true Containers: nginx: Image: nginx:1.9.1 Port: 80/TCP QoS Tier: cpu: BestEffort memory: BestEffort Environment Variables: &lt;none&gt; No volumes. 回滚到以前的版本现在，您已决定撤消当前的卷展栏并回滚到上一版本：12$ kubectl rollout undo deployment.v1.apps/nginx-deploymentdeployment.apps/nginx-deployment 或者，您可以通过在--to-revision以下位置指定回滚到特定修订：12$ kubectl rollout undo deployment.v1.apps/nginx-deployment --to-revision=2deployment.apps/nginx-deployment 有关与推出相关的命令的更多详细信息，请阅读kubectl rollout。 部署现在回滚到以前的稳定版本。如您所见，DeploymentRollback从Deployment控制器生成用于回滚到版本2 的事件。12345678910111213141516171819202122232425262728293031323334353637383940414243444546$ kubectl get deployment nginx-deploymentNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 3 3 3 3 30m$ kubectl describe deployment nginx-deploymentName: nginx-deploymentNamespace: defaultCreationTimestamp: Sun, 02 Sep 2018 18:17:55 -0500Labels: app=nginxAnnotations: deployment.kubernetes.io/revision=4 kubernetes.io/change-cause=kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1 --record=trueSelector: app=nginxReplicas: 3 desired | 3 updated | 3 total | 3 available | 0 unavailableStrategyType: RollingUpdateMinReadySeconds: 0RollingUpdateStrategy: 25% max unavailable, 25% max surgePod Template: Labels: app=nginx Containers: nginx: Image: nginx:1.9.1 Port: 80/TCP Host Port: 0/TCP Environment: &lt;none&gt; Mounts: &lt;none&gt; Volumes: &lt;none&gt;Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailableOldReplicaSets: &lt;none&gt;NewReplicaSet: nginx-deployment-c4747d96c (3/3 replicas created)Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 12m deployment-controller Scaled up replica set nginx-deployment-75675f5897 to 3 Normal ScalingReplicaSet 11m deployment-controller Scaled up replica set nginx-deployment-c4747d96c to 1 Normal ScalingReplicaSet 11m deployment-controller Scaled down replica set nginx-deployment-75675f5897 to 2 Normal ScalingReplicaSet 11m deployment-controller Scaled up replica set nginx-deployment-c4747d96c to 2 Normal ScalingReplicaSet 11m deployment-controller Scaled down replica set nginx-deployment-75675f5897 to 1 Normal ScalingReplicaSet 11m deployment-controller Scaled up replica set nginx-deployment-c4747d96c to 3 Normal ScalingReplicaSet 11m deployment-controller Scaled down replica set nginx-deployment-75675f5897 to 0 Normal ScalingReplicaSet 11m deployment-controller Scaled up replica set nginx-deployment-595696685f to 1 Normal DeploymentRollback 15s deployment-controller Rolled back deployment "nginx-deployment" to revision 2 Normal ScalingReplicaSet 15s deployment-controller Scaled down replica set nginx-deployment-595696685f to 0 扩展部署您可以使用以下命令扩展部署：12$ kubectl scale deployment.v1.apps/nginx-deployment --replicas=10deployment.apps/nginx-deployment scaled 假设在群集中启用了水平pod自动缩放，则可以为Deployment设置自动缩放器，并根据现有Pod的CPU利用率选择要运行的最小和最大Pod数。 12$ kubectl autoscale deployment.v1.apps/nginx-deployment --min=10 --max=15 --cpu-percent=80deployment.apps/nginx-deployment scaled 比例缩放RollingUpdate Deployments支持同时运行多个版本的应用程序。当您或自动扩展器扩展正在部署（正在进行或暂停）的RollingUpdate部署时，部署控制器将平衡现有活动副本集（具有Pod的副本集）中的其他副本，以降低风险。这称为比例缩放。 例如，您正在运行具有10个副本的部署，maxSurge = 3和maxUnavailable = 2。123$ kubectl get deployNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 10 10 10 10 50s 您更新到一个新的映像，该映像恰好在集群内部无法解析。12$ kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:sometagdeployment.apps/nginx-deployment image updated 图像更新使用ReplicaSet nginx-deployment-1989198191开始新的部署，但由于maxUnavailable您在上面提到的要求而被阻止 。1234$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-1989198191 5 5 0 9snginx-deployment-618515232 8 8 8 1m 然后出现一个新的部署扩展请求。自动缩放器将部署副本增加到15.部署控制器需要决定在哪里添加这些新的5个副本。如果您没有使用比例缩放，则所有5个都将添加到新的ReplicaSet中。通过比例缩放，您可以在所有ReplicaSet上传播其他副本。具有最多副本的ReplicaSets和较低比例的较大比例将转到具有较少副本的ReplicaSet。任何剩余物都会添加到具有最多副本的ReplicaSet中。零副本的ReplicaSet不会按比例放大。 在上面的示例中，3个副本将添加到旧的ReplicaSet中，2个副本将添加到新的ReplicaSet中。假设新副本变得健康，推出过程最终应将所有副本移动到新的ReplicaSet。1234567$ kubectl get deployNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx-deployment 15 18 7 8 7m$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-deployment-1989198191 7 7 0 7mnginx-deployment-618515232 11 11 11 7m 暂停和恢复部署您可以在触发一个或多个更新之前暂停部署，然后恢复它。这将允许您在暂停和恢复之间应用多个修复，而不会触发不必要的部署。 例如，使用刚刚创建的部署：123456$ kubectl get deployNAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGEnginx 3 3 3 3 1m$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-2142116321 3 3 3 1m 通过运行以下命令暂停：12$ kubectl rollout pause deployment.v1.apps/nginx-deploymentdeployment.apps/nginx-deployment paused 然后更新部署的映像：12$ kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.9.1deployment.apps/nginx-deployment image updated 请注意，没有新的卷展栏开始：12345678$ kubectl rollout history deployment.v1.apps/nginx-deploymentdeployments "nginx"REVISION CHANGE-CAUSE1 &lt;none&gt;$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-2142116321 3 3 3 2m 您可以根据需要进行更多更新，例如，更新将使用的资源：12$ kubectl set resources deployment.v1.apps/nginx-deployment -c=nginx --limits=cpu=200m,memory=512Mideployment.apps/nginx-deployment resource requirements updated 暂停之前部署的初始状态将继续其功能，但只要部署暂停，部署的新更新将不会产生任何影响。 最后，恢复部署并观察一个新的ReplicaSet，提供所有新的更新：1234567891011121314151617181920212223$ kubectl rollout resume deployment.v1.apps/nginx-deploymentdeployment.apps/nginx-deployment resumed$ kubectl get rs -wNAME DESIRED CURRENT READY AGEnginx-2142116321 2 2 2 2mnginx-3926361531 2 2 0 6snginx-3926361531 2 2 1 18snginx-2142116321 1 2 2 2mnginx-2142116321 1 2 2 2mnginx-3926361531 3 2 1 18snginx-3926361531 3 2 1 18snginx-2142116321 1 1 1 2mnginx-3926361531 3 3 1 18snginx-3926361531 3 3 2 19snginx-2142116321 0 1 1 2mnginx-2142116321 0 1 1 2mnginx-2142116321 0 0 0 2mnginx-3926361531 3 3 3 20s^C$ kubectl get rsNAME DESIRED CURRENT READY AGEnginx-2142116321 0 0 0 2mnginx-3926361531 3 3 3 28s 注意：在恢复暂停部署之前，无法回滚暂停部署。 部署状态部署在其生命周期中进入各种状态。它可以前进，同时推出新ReplicaSet，也可以是完整的，也可以不取得进展。 进步部署当执行以下任务之一时，Kubernetes将部署标记为进度： 部署创建一个新的ReplicaSet。 部署正在扩展其最新的ReplicaSet。 部署正在缩减其旧的ReplicaSet。 新Pod已准备就绪或可用（至少准备MinReadySeconds）。 您可以使用监视部署的进度kubectl rollout status。 完成部署Kubernetes 在具有以下特征时将部署标记为完成： 与部署关联的所有副本都已更新为您指定的最新版本，这意味着您已请求的任何更新已完成。 可以使用与部署关联的所有副本。 没有旧的部署副本正在运行。 您可以使用检查部署是否已完成kubectl rollout status。如果卷展栏成功完成，则kubectl rollout status返回零退出代码。 12345$ kubectl rollout status deployment.v1.apps/nginx-deploymentWaiting for rollout to finish: 2 of 3 updated replicas are available...deployment.apps/nginx-deployment successfully rolled out$ echo $?0 部署失败您的部署可能会在尝试部署其最新的ReplicaSet时遇到困难，而无需完成。这可能是由于以下一些因素造成的： 配额不足 准备探针失败 图像拉错误 权限不足 限制范围 应用程序运行时配置错误 检测此情况的一种方法是在部署规范中指定截止时间参数:(.spec.progressDeadlineSeconds）。.spec.progressDeadlineSeconds表示部署控制器在指示（在“部署”状态中）部署进度已停止之前等待的秒数。 以下kubectl命令设置规范progressDeadlineSeconds以使控制器报告在10分钟后缺少部署进度： 12$ kubectl patch deployment.v1.apps/nginx-deployment -p '&#123;"spec":&#123;"progressDeadlineSeconds":600&#125;&#125;'deployment.apps/nginx-deployment patched 超过截止日期后，Deployment控制器会向Deployment部署一个具有以下属性的DeploymentCondition .status.conditions： 类型=进展 状态=假 原因= ProgressDeadlineExceeded 有关状态条件的更多信息，请参阅Kubernetes API约定。 注意：除了报告状态条件之外，Kubernetes不对停顿的部署采取任何操作 Reason=ProgressDeadlineExceeded。更高级别的协调器可以利用它并相应地采取相应措施，例如，将部署回滚到其先前版本。 注意：如果您暂停部署，Kubernetes不会根据您指定的截止日期检查进度。您可以安全地在部署和暂停期间暂停部署，而不会触发超出截止日期的条件。 由于您设置的超时时间较短或者由于任何其他可被视为瞬态的错误，您可能会遇到部署的暂时性错误。例如，假设您的配额不足。如果您描述部署，您将注意到以下部分： 123456789$ kubectl describe deployment nginx-deployment&lt;...&gt;Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True ReplicaSetUpdated ReplicaFailure True FailedCreate&lt;...&gt; 如果您运行kubectl get deployment nginx-deployment -o yaml，部署状态可能如下所示：12345678910111213141516171819202122232425status: availableReplicas: 2 conditions: - lastTransitionTime: 2016-10-04T12:25:39Z lastUpdateTime: 2016-10-04T12:25:39Z message: Replica set "nginx-deployment-4262182780" is progressing. reason: ReplicaSetUpdated status: "True" type: Progressing - lastTransitionTime: 2016-10-04T12:25:42Z lastUpdateTime: 2016-10-04T12:25:42Z message: Deployment has minimum availability. reason: MinimumReplicasAvailable status: "True" type: Available - lastTransitionTime: 2016-10-04T12:25:39Z lastUpdateTime: 2016-10-04T12:25:39Z message: 'Error creating: pods "nginx-deployment-4262182780-" is forbidden: exceeded quota: object-counts, requested: pods=1, used: pods=3, limited: pods=2' reason: FailedCreate status: "True" type: ReplicaFailure observedGeneration: 3 replicas: 2 unavailableReplicas: 2 最终，一旦超出部署进度截止日期，Kubernetes将更新状态和进度条件的原因：123456Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing False ProgressDeadlineExceeded ReplicaFailure True FailedCreate 您可以通过缩小部署，缩小可能正在运行的其他控制器或增加命名空间中的配额来解决配额不足的问题。如果您满足配额条件，然后部署控制器完成“部署”卷展栏，您将看到部署状态更新成功条件（Status=True和Reason=NewReplicaSetAvailable）。12345Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable Type=Available与Status=True您的部署具有最小可用性手段。最低可用性由部署策略中指定的参数决定。Type=Progressing和 Status=True表示您的部署正处于推出过程中并且正在进行中或已成功完成其进度并且所需的最小新副本可用（请参阅详细信息的条件原因 - 在我们的情况下 Reason=NewReplicaSetAvailable意味着部署完成）。 您可以使用检查部署是否未能进展kubectl rollout status。kubectl rollout status 如果部署已超过进度截止日期，则返回非零退出代码。 12345$ kubectl rollout status deployment.v1.apps/nginx-deploymentWaiting for rollout to finish: 2 out of 3 new replicas have been updated...error: deployment "nginx" exceeded its progress deadline$ echo $?1 在失败的部署上运行适用于完整部署的所有操作也适用于失败的部署。如果需要在“部署”窗格模板中应用多个调整，可以向上/向下缩放，回滚到以前的版本，甚至可以暂停它。 清理政策您可以.spec.revisionHistoryLimit在部署中设置字段，以指定要保留此部署的旧ReplicaSet数。其余的将在后台进行垃圾收集。默认情况下，它是10。 注意：将此字段显式设置为0将导致清理部署的所有历史记录，从而部署将无法回滚。 用例Canary部署如果要使用部署将发布部署到用户或服务器的子集，则可以按照管理资源中描述的canary模式创建多个部署，每个版本一个 。 编写部署规范与所有其他Kubernetes CONFIGS，部署需求apiVersion，kind以及metadata各个领域。有关使用配置文件的一般信息，请参阅部署应用程序，配置容器以及使用kubectl管理资源文档。 部署还需要一个.spec部分。 Pod模板这.spec.template是唯一必需的领域.spec。 这.spec.template是一个pod模板。它与Pod具有完全相同的架构，除了它是嵌套的并且没有 apiVersion或kind。 除了Pod的必填字段外，部署中的pod模板还必须指定适当的标签和适当的重新启动策略。对于标签，请确保不要与其他控制器重叠。见选择器）。 只允许.spec.template.spec.restartPolicy等于Always，如果未指定，则为默认值。 副本.spec.replicas是一个可选字段，指定所需Pod的数量。默认为1。 选择.spec.selector是一个可选字段，用于指定 此部署所针对的Pod 的标签选择器。 .spec.selector必须匹配.spec.template.metadata.labels，否则它将被API拒绝。 在API版本apps/v1，.spec.selector并且.metadata.labels不默认.spec.template.metadata.labels，如果没有设置。所以必须明确设置它们。另请注意，.spec.selector在创建部署后，它是不可变的apps/v1。 部署可以终止其标签与选择器匹配的Pod，如果它们的模板不同.spec.template或者此类Pod的总数超过.spec.replicas。.spec.template如果Pod 的数量小于所需的数量，它会调出新的Pod 。 注意：您不应通过创建另一个部署或通过创建另一个控制器（如ReplicaSet或ReplicationController）来创建其标签与此选择器匹配的其他pod。如果您这样做，第一个部署认为它创建了这些其他pod。Kubernetes并没有阻止你这样做。 如果您有多个具有重叠选择器的控制器，控制器将相互争斗并且行为不正确。 战略.spec.strategy指定用于替换旧Pod的策略。 .spec.strategy.type可以是“重新创建”或“RollingUpdate”。“RollingUpdate”是默认值。 重新创建部署所有现有的Pod都会在创建新的Pod之前被杀死.spec.strategy.type==Recreate。 滚动更新部署部署时会以滚动更新 方式更新Pod .spec.strategy.type==RollingUpdate。您可以指定maxUnavailable并maxSurge控制滚动更新过程。 maxUnavailable .spec.strategy.rollingUpdate.maxUnavailable是一个可选字段，指定更新过程中可用的最大Pod数。该值可以是绝对数（例如，5）或所需Pod的百分比（例如，10％）。通过四舍五入计算绝对数字的百分比。如果.spec.strategy.rollingUpdate.maxSurge为0，则该值不能为0.默认值为25％。 例如，当此值设置为30％时，旧的ReplicaSet可以在滚动更新开始时立即按比例缩小到所需Pod的70％。准备好新的Pod后，可以进一步缩小旧的ReplicaSet，然后扩展新的ReplicaSet，确保在更新期间始终可用的Pod总数至少是所需Pod的70％。 Max Surge .spec.strategy.rollingUpdate.maxSurge是一个可选字段，指定可以在所需数量的Pod上创建的最大Pod数。该值可以是绝对数（例如，5）或所需Pod的百分比（例如，10％）。如果MaxUnavailable为0，则该值不能为0.绝对数量是通过向上舍入的百分比计算的。默认值为25％。 例如，当此值设置为30％时，可以在滚动更新开始时立即按比例放大新的ReplicaSet，这样旧的和新的Pod的总数不会超过所需Pod的130％。一旦旧的Pod被杀死，新的ReplicaSet可以进一步扩展，确保在更新期间随时运行的Pod总数最多为所需Pod的130％。 进度截止日期.spec.progressDeadlineSeconds是一个可选字段，指定在系统报告部署失败进度之前等待部署进度的秒数 - 表示为带有Type=Progressing，Status=False。的条件。以及Reason=ProgressDeadlineExceeded资源的状态。部署控制器将继续重试部署。将来，一旦实现自动回滚，部署控制器将在观察到这种情况后立即回滚部署。 如果指定，则此字段必须大于.spec.minReadySeconds。 Min Ready Seconds.spec.minReadySeconds是一个可选字段，指定新创建的Pod应该在没有任何容器崩溃的情况下准备好的最小秒数，以使其可用。默认为0（Pod一旦准备好就会被视为可用）。要了解有关何时认为Pod已准备就绪的详细信息，请参阅容器探测器。 回滚现场.spec.rollbackTo已被弃用的API版本extensions/v1beta1和apps/v1beta1，并在API版本不再支持开始apps/v1beta2。相反，应该使用回滚到先前版本中的kubectl rollout undo介绍。 修订历史限制部署的修订历史记录存储在它控制的副本集中。 .spec.revisionHistoryLimit是一个可选字段，指定要保留以允许回滚的旧ReplicaSet的数量。其理想值取决于新部署的频率和稳定性。如果未设置此字段，则默认情况下将保留所有旧的ReplicaSet，消耗资源etcd并拥挤输出kubectl get rs。每个Deployment修订版的配置都存储在其ReplicaSet中; 因此，一旦删除旧的ReplicaSet，您将无法回滚到该部署版本。 更具体地说，将此字段设置为零意味着将清除所有具有0副本的旧ReplicaSet。在这种情况下，无法撤消新的“部署”卷展栏，因为它的修订历史记录已清除。 已暂停.spec.paused是一个可选的布尔字段，用于暂停和恢复部署。暂停部署与未暂停部署之间的唯一区别是，暂停部署的PodTemplateSpec的任何更改都不会触发新的部署，只要它暂停即可。默认情况下，部署在创建时不会暂停。 部署的替代方案kubectl滚动更新kubectl rolling update以类似的方式更新Pod和ReplicationControllers。但建议使用部署，因为它们是声明性的，服务器端，并且具有其他功能，例如即使在滚动更新完成后回滚到任何先前的修订版。]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>Kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS上安装Shadowsocks客户端]]></title>
    <url>%2F2019%2F01%2F11%2FCentOS%E4%B8%8A%E5%AE%89%E8%A3%85Shadowsocks%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[CentOS上安装Shadowsocks客户端Shadowsocks简介Shadowsocks，是一种加密的传输方式（一种基于 Socks5 代理方式的网络数据加密传输包）；SS 是目前主流的科学上网方式，是目前最稳定最好用的科学上网工具之一。 安装安装pippip是Python的包管理工具，我们接下来是使用pip安装的Shadowsocks。 通过yum管理工具安装： 1yum install -y pip 镜像库没有这个包，那么可以手动安装: 12curl "https://bootstrap.pypa.io/get-pip.py" -o "get-pip.py"python get-pip.py 安装Shadowsocks客户端12pip install --upgrade pippip install shadowsocks 新建配置文件vi /etc/shadowsocks.json：12345678910&#123;"server":"x.x.x.x","server_port":25247,"local_address": "127.0.0.1","local_port":25252,"password":"123456","timeout":1000,"method":"aes-256-cfb","workers": 10&#125; 编写启动服务vi /etc/systemd/system/shadowsocks.service:123456789[Unit]Description=shadowsocks[Service]TimeoutStartSec=30ExecStart=/usr/bin/sslocal -c /etc/shadowsocks.json[Install]WantedBy=multi-user.target 启动服务systemctl start shadowsocks，运行 curl --socks5 127.0.0.1:25252 http://httpbin.org/ip ， 返回你ss服务器ip，则说明Shadowsocks客户端启动成功。 使用Privoxy把shadowsocks转换为Http代理Privoxy简介Privoxy是一个代理辅助工具，这里用Privoxy把Shadowsocks socks5代理转换为http代理。可以作为kubernetes的docker容器需要访问google的服务，也同时可以作为命令行的代理，本实例用作命令行代理。 安装使用yum安装：1yum install privoxy -y 修改配置文件vi /etc/privoxy/config，加入一行代码12forward-socks5 / 127.0.0.1:25252 .listen-address 127.0.0.1:8118 #这里的ip也可以是k8s的ip 启动服务systemctl start privoxy，执行命令curl -x localhost:8118 google.com，返回数据则表示服务启动成功 全局设置编辑文件vi /etc/profile：12export http_proxy=http://127.0.0.1:8118export https_proxy=http://127.0.0.1:8118 使配置生效1source /etc/profile 测试代码curl www.google.com，返回数据则成功设置全局命令行代理]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Frp内网穿透反向代理的端口转发实现本地服务器]]></title>
    <url>%2F2019%2F01%2F07%2F%E5%9F%BA%E4%BA%8EFrp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[基于frp内网穿透反向代理的端口转发实现本地服务器frp简介frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议。 利用处于内网或防火墙后的机器，对外网环境提供 http 或 https 服务。 对于 http, https 服务支持基于域名的虚拟主机，支持自定义域名绑定，使多个域名可以共用一个80端口。 利用处于内网或防火墙后的机器，对外网环境提供 tcp 和 udp 服务，例如在家里通过 ssh 访问处于公司内网环境内的主机。 使用准备条件公网服务器一台，内网服务器一台，公网服务器绑定域名1个。 开始搭建公网服务器ssh连接到公网服务器上，新建目录 1mkdir -p /usr/local/frp 根据对应的操作系统及架构，从 Release 页面下载最新版本的程序。 1wget https://github.com/fatedier/frp/releases/download/v0.22.0/frp_0.22.0_linux_arm64.tar.gz 解压 1tar -zxvf frp_0.22.0_linux_arm64.tar.gz 首先删掉frpc、frpc.ini两个文件，然后再进行配置修改frps.ini文件，这里使用了最简化的配置： 1234567891011# frps.ini[common]bind_port = 7000vhost_http_port = 6081max_pool_count = 20allow_ports = 2000-3000,6081,4000-50000 #端口白名单dashboard_port = 7500dashboard_user = admindashboard_pwd = admintoken = 123456 #客户端也要配置一样的tokenauthentication_timeout = 90000 #超时时间，如果客户端遇到服务启动认证失败，大概率是时区问题，服务器设置一下就好了 保存然后启动服务1./frps -c ./frps.ini 这是前台启动，后台启动命令为 1nohup ./frps -c ./frps.ini &amp; 可以通过访问http://xx.xx.xx.xx:7500/static/#/proxies/tcp访问frp服务的监控界面，账号密码与上面配置的一致。 内网服务器根据对应的操作系统及架构，从 Release 页面下载最新版本的程序。 1wget https://github.com/fatedier/frp/releases/download/v0.22.0/frp_0.22.0_linux_arm64.tar.gz 解压 1tar -zxvf frp_0.22.0_linux_arm64.tar.gz 首先删掉frpc、frpc.ini两个文件，然后再进行配置修改 frpc.ini 文件。 123456789101112131415161718# frpc.ini[common]server_addr = xx.xx.xx.xx #公网ip地址server_port = 7000token = 123456 #公网通过ssh访问内部服务器[ssh]type = tcp #连接协议local_ip = 127.0.0.1local_port = 22 #ssh默认端口号remote_port = 6000 #自定义的访问内部ssh端口号 #公网访问内部web服务器以http方式[web]type = http #访问协议local_port = 8081 #内网web服务的端口号custom_domains = strongcat.top #所绑定的公网服务器域名，一级、二级域名都可以 保存然后执行启动 1./frpc -c ./frpc.ini 这是前台启动，后台启动命令为 1nohup ./frpc -c ./frpc.ini &amp; 认证超时解决办法一般认证超时的原因是由于2个服务器之间时间不同，可以通过命令tzselect修改时区，按照步骤设置时区1$ tzselect 同步服务器时间123sudo yum install ntptimedatectl set-timezone Asia/Shanghaitimedatectl set-ntp yes 查看时间确保同步timedatectl 开机自启动我用的是centOS7的操作系统，为了防止因为网络或者重启问题Frp失效，所以写了一个开机启动服务，公网服务器配置： 12345678910111213[Unit]Description=frp[Service]TimeoutStartSec=30Type=simpleExecStart=/root/frp/frp_0.22.0_linux_386/frps -c /root/frp/frp_0.22.0_linux_386/frps.iniExecStop=/bin/kill $MAINPIDRestart=on-failureRestartSec=60s[Install]WantedBy=multi-user.target 内网服务器配置：123456789101112131415[Unit]Description=frpAfter=network.targetWants=network.target[Service]TimeoutStartSec=30Type=simpleExecStart=/root/frp/frp_0.22.0_linux_386/frpc -c /root/frp/frp_0.22.0_linux_386/frpc.iniExecStop=/bin/kill $MAINPIDRestart=on-failureRestartSec=60s[Install]WantedBy=multi-user.target 文件保存到/etc/systemd/system/frp.service中，并执行systemctl daemon-reload，systemctl start frp,开机启动systemctl enable frp 外网ssh访问内网服务器（直接使用配置里面数据演示） 1ssh -oPort=6000 root@x.x.x.x 将 www.strongcat.top 的域名 A 记录解析到 IP x.x.x.x，如果服务器已经有对应的域名，也可以将 CNAME 记录解析到服务器原先的域名。 通过浏览器访问 http://www.yourdomain.com:8080 即可访问到处于内网机器上的 web 服务。 有些系统默认自带防火墙，需要开通端口 123firewall-cmd --zone=public --add-port=6000/tcp --permanent systemctl stop firewalld.service systemctl start firewalld.service 如果遇到authorization timeout错误的话，需要进行2个服务器之间的时间同步。2边服务器都执行下面的命令：1234567891011#下载ntpdateyum install -y ntpdate#调整时区为上海，也就是北京时间+8区cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtimeyes | cp -f /usr/share/zoneinfo/Asia/Shanghai /etc/localtime#使用NTP来同步时间ntpdate us.pool.ntp.org#定时同步时间（每隔10分钟同步时钟）crontab -l &gt;/tmp/crontab.bakecho "*/10 * * * * /usr/sbin/ntpdate us.pool.ntp.org | logger -t NTP" &gt;&gt; /tmp/crontab.bakcrontab /tmp/crontab.bak 如果是像我这种笔记本的话，可以设置系统关闭盖子的动作1vim /etc/systemd/logind.conf 12345678910111213HandlePowerKey 按下电源键后的行为，默认power offHandleSleepKey 按下挂起键后的行为，默认suspendHandleHibernateKey 按下休眠键后的行为，默认hibernateHandleLidSwitch 合上笔记本盖后的行为，默认suspendignore 忽略，跳过power off 关机eboot 重启halt 挂起suspend shell内建指令，可暂停目前正在执行的shell。若要恢复，则必须使用SIGCONT信息。所有的进程都会暂停，但不是消失（halt是进程关闭）hibernate 让笔记本进入休眠状态hybrid-sleep 混合睡眠，主要是为台式机设计的，是睡眠和休眠的结合体，当你选择Hybird时，系统会像休眠一样把内存里的数据从头到尾复制到硬盘里 ，然后进入睡眠状态，即内存和CPU还是活动的，其他设置不活动，这样你想用电脑时就可以快速恢复到之前的状态了，笔记本一般不用这个功能。lock 仅锁屏，计算机继续工作。 更多指令可以参考这篇博客 最后重新加载服务使配置生效1systemctl restart systemd-logind 进阶（配合nginx实现域名转发）购买域名购买域名，国内需要备案，然后再阿里云中添加域名，创建域名解析，如图所示 安装nginx1docker pull nginx 新建文件nginx.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; # frp的接收http请求的反向代理 server &#123; listen 80; server_name *.strongsickcat.com strongsickcat.com; location / &#123; # 7071端口即为frp监听的http端口 proxy_pass http://127.0.0.1:8080; proxy_set_header Host $host:80; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection "upgrade"; proxy_connect_timeout 7d; proxy_send_timeout 7d; proxy_read_timeout 7d; &#125; # 防止爬虫抓取 if ($http_user_agent ~* "360Spider|JikeSpider|Spider|spider|bot|Bot|2345Explorer|curl|wget|webZIP|qihoobot|Baiduspider|Googlebot|Googlebot-Mobile|Googlebot-Image|Mediapartners-Google|Adsbot-Google|Feedfetcher-Google|Yahoo! Slurp|Yahoo! Slurp China|YoudaoBot|Sosospider|Sogou spider|Sogou web spider|MSNBot|ia_archiver|Tomato Bot|NSPlayer|bingbot") &#123; return 403; &#125; &#125;&#125; docker启动nginx1docker run -p 80:80 --name mynginx -v $PWD/www:/www -v $PWD/nginx.conf:/etc/nginx/nginx.conf -v $PWD/logs:/wwwlogs -d nginx 附上frp客户端与服务端配置123456789101112#frps.ini[common]bind_port = 7000max_pool_count = 20allow_ports = 4000-50000dashboard_port = 7500dashboard_user = admindashboard_pwd = 742041978token = 2524668868authentication_timeout = 900vhost_http_port = 8080subdomain_host = strongsickcat.com 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#客户端 frpc.ini[common]server_addr = 106.15.226.184server_port = 7000token = 2524668868admin_addr = 127.0.0.1admin_port = 7400[ssh]type = tcplocal_ip = 127.0.0.1local_port = 22remote_port = 6000[test_static_file]type = tcpremote_port = 16001plugin = static_fileplugin_local_path = /root/fileplugin_strip_prefix = staticplugin_http_user = adminplugin_http_passwd = 742041978[kibana]type = http# local_port代表你想要暴露给外网的本地web服务端口local_port = 5601# subdomain 在全局范围内要确保唯一，每个代理服务的subdomain不能重名，否则会影响正常使用。# 客户端的subdomain需和服务端的subdomain_host配合使用subdomain = kibana[elasticsearch]type = httplocal_port = 9200subdomain = elasticsearch[mysql]type = tcplocal_port = 3306remote_port = 13306[prometheus]type = httplocal_port = 9090subdomain = prometheus[prometheus-linux]type = tcplocal_port = 9100remote_port = 9100[prometheus-mysql]type = tcplocal_port = 9104remote_port = 9104[grafana]type = httplocal_port = 3000subdomain = grafana[prometheusa]type = tcplocal_port = 9090remote_port = 9090 按照我的配置文件，可以直接通过子域名访问kibana服务http://kibana.strongsickcat.com:8080]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Selenium测试框架]]></title>
    <url>%2F2019%2F01%2F04%2FSelenium%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[Selenium官网 Selenium简介Selenium可以对浏览器进行自动化测试。它主要用于自动化Web应用程序以进行测试，但当然不仅限于此。无聊的基于Web的管理任务也可以自动化。 Selenium得到了一些最大的浏览器供应商的支持，这些供应商已采取（或正在采取）将Selenium作为其浏览器本机部分的步骤。它也是无数其他浏览器自动化工具，API和框架的核心技术。支持多种语言，在java中可以作为自动化测试框架，在python中可以模拟页面用户点击对自动化爬虫进行补充。 支持的浏览器： Selenium使用Selenium提供了一种非常简单的开发方式，例如用Chrome开发的话，去开发者工具下载Katalon Selenium IDE，如图所示。 开始录制录制过程中，IDE会自动帮我们把命令行插入到测试用例中，包括： 单击链接 输入值 从下拉框选择数据 单击按钮或者选择框点击开始录制，在最上方输入网站域名，后期可以通过更换域名来实现不同域名下的应用的测试。 使用上下文菜单添加验证和断言使用Selenium IDE录制，转到显示测试应用程序的浏览器，然后右键单击页面上的任意位置。您将看到一个显示验证和/或断言命令的上下文菜单。Selenium命令有三种“风格”：动作，访问器和断言。 动作是通常操纵应用程序状态的命令。他们执行“点击此链接”和“选择该选项”之类的操作。如果操作失败或出错，则停止执行当前测试。 访问者检查应用程序的状态并将结果存储在变量中，例如“storeTitle”。它们还用于自动生成断言。 断言与访问器类似，但它们验证应用程序的状态是否符合预期。示例包括“确保页面标题为X”和“验证是否选中此复选框”。 脚本语法命令很简单，由2个参数构成： verifyText //div//a[2] Login 这些参数并不总是必需的;这取决于命令。在某些情况下，两者都是必需的，在其他情况下需要一个参数，而在另一些情况下，命令可能根本不需要参数。这里有几个例子： chooseCancelOnNextPrompt pause 500 type id=phone (555) 666-7066 type id=address1 ${myVariableAddress} 命令参考描述了每个命令的参数要求。 参数有所不同，但它们通常是： Locators用于标识页面内UI元素的定位器。 text patterns用于验证或声明预期页面内容的文本模式。 text patterns or selenium variables文本模式或selenium变量，用于在输入字段中输入文本或从选项列表中选择选项。常用的Selenium命令 open 打开url页面 click 执行单击操作，并可选择等待加载新页面。 verifyTitle/assertTitle 验证预期的页面标题。 verifyTextPresent 验证预期文本是否在页面上的某个位置。 verifyText 验证预期文本及其相应的HTML标记出现在页面上。 verifyTable 验证表的预期内容。 验证页面元素断言与验证的选择 assert 错误后会不继续执行并中断当前的测试用例 verify 错误后会继续执行的最佳用途是对测试命令进行逻辑分组，并使用“assert”后跟一个或多个“verify”测试命令启动每个组。一个例子如下： verifyElementPresent Command Target Value verifyElementPresent //div/p/img 此命令验证页面上是否存在由&lt;img&gt; HTML标记的存在指定的图像，并且它遵循&lt;div&gt;标记和&lt;p&gt;标记。第一个（也是唯一的）参数是一个定位器，用于告诉Selenese命令如何查找元素。verifyElementPresent可用于检查页面中是否存在任何HTML标记。您可以检查链接，段落，分区&lt;div&gt;等是否存在。以下是一些示例。 Command Target Value verifyElementPresent //div/p verifyElementPresent //div/a verifyElementPresent id=Login verifyElementPresent link=Go to Marketing Research verifyElementPresent //a[2] verifyElementPresent //head/title verifyText必须在测试文本及其UI元素时使用verifyText。 verifyText必须使用定位器。如果选择XPath或DOM定位器，则可以验证特定文本是否显示在页面上相对于页面上其他UI组件的特定位置。Command | Target | Value—|— |—verifyText |//table/tr/td/div/p | This is my text and it occurs right after the div inside the table. 定位元素对于许多Selenium命令，需要一个目标。此目标标识Web应用程序内容中的元素，并包含位置策略，后跟位置格式为locatorType = location。在许多情况下可以省略定位器类型。下面解释各种定位器类型，每个定位器类型都有示例。 按标识符定位例如，页面源可以具有id和name属性，如下所示：12345678910&lt;html&gt; &lt;body&gt; &lt;form id="loginForm"&gt; &lt;input name="username" type="text" /&gt; &lt;input name="password" type="password" /&gt; &lt;input name="continue" type="submit" value="Login" /&gt; &lt;input name="continue" type="button" value="Clear" /&gt; &lt;/form&gt; &lt;/body&gt;&lt;html&gt; 以下定位器策略将返回上面由行号指示的HTML片段中的元素： identifier=loginForm (3) identifier=password (5) identifier=continue (6) continue (6)由于定位器的标识符类型是默认值，因此上面的前三个示例中的标识符=不是必需的。 通过id定位 id=loginForm (3) 通过名称定位 name=username (4) name=continue value=Clear (7) name=continue Clear (7) name=continue type=button (7) 与某些类型的XPath和DOM定位器不同，上面三种类型的定位器允许Selenium测试UI元素，而与其在页面上的位置无关。因此，如果页面结构和组织被更改，测试仍将通过。您可能想也可能不想测试页面结构是否发生变化。在Web设计者经常更改页面但其功能必须经过回归测试的情况下，通过id和name属性进行测试，或者通过任何HTML属性进行测试变得非常重要。 由于只有xpath定位符以“//”开头，因此在指定XPath定位符时不必包含xpath =标签。 xpath=/html/body/form[1] (3) - 绝对路径（如果HTML仅稍微更改，则会中断） //form[1] (3) - HTML中的第一个表单元素 xpath=//form[@id=’loginForm’] (3) - 表单元素，其属性名为“id”，值为“loginForm” xpath=//form[input/@name=’username’] (3) - 带有输入子元素的第一个表单元素，其属性名为“name”，值为“username” //input[@name=’username’] (4) - 第一个输入元素，其属性名为“name”，值为“username” //form[@id=’loginForm’]/input[1] (4) - 表单元素的第一个输入子元素，其属性名为“id”，值为“loginForm” //input[@name=’continue’][@type=’button’] (7) -输入名为’name’的属性和值’continue’以及名为’type’的属性和值’button’ //form[@id=’loginForm’]/input[4] (7) - 表单元素的第四个输入子元素，其属性名为“id”，值为“loginForm” 主要的语法参考Xpath可以使用浏览器的devtools复制XPath： 通过链接文本查找超链接 这是一种使用链接文本在网页中查找超链接的简单方法。如果存在具有相同文本的两个链接，则将使用第一个匹配。1234567&lt;html&gt; &lt;body&gt; &lt;p&gt;Are you sure you want to do this?&lt;/p&gt; &lt;a href="continue.html"&gt;Continue&lt;/a&gt; &lt;a href="cancel.html"&gt;Cancel&lt;/a&gt;&lt;/body&gt;&lt;html&gt; link=Continue (4) link=Cancel (5) 通过CSS定位 12345678910&lt;html&gt; &lt;body&gt; &lt;form id="loginForm"&gt; &lt;input class="required" name="username" type="text" /&gt; &lt;input class="required passfield" name="password" type="password" /&gt; &lt;input name="continue" type="submit" value="Login" /&gt; &lt;input name="continue" type="button" value="Clear" /&gt; &lt;/form&gt;&lt;/body&gt;&lt;html&gt; css=form#loginForm (3) css=input[name=”username”] (4) css=input.required[type=”text”] (4) css=input.passfield (5) css=#loginForm input[type=”button”] (7) css=#loginForm input:nth-child(2) (5) 可以参考 the W3C publication 没有明确的设定选择器的话，将会默认使用id选择器 存储命令和Selenium变量可以使用Selenium变量在脚本开头存储常量。此外，当与数据驱动的测试设计（在后面的部分中讨论）结合使用时，Selenium变量可用于存储从命令行，从另一个程序或从文件传递到测试程序的值。 plain store命令是许多存储命令中最基本的命令，可用于在selenium变量中简单地存储常量值。它需要两个参数，即要存储的文本值和一个selenium变量。在为变量选择名称时，请使用仅包含字母数字字符的标准变量命名约定。 Command Target Value store paul@mysite.org userName 稍后在脚本中，将需要使用变量的存储值。要访问变量的值，请将变量括在大括号（{}）中，并在其前面加上美元符号。 Command Target Value verifyText //div/p ${userName} 变量的常见用途是存储输入字段的输入 Command Target Value type id=login ${userName} storeText StoreText对应于verifyText。它使用定位器来标识特定的页面文本。如果找到该文本，则存储在变量中。 StoreText可用于从正在测试的页面中提取文本。 echo命令可以用来打印变量 Alerts, Popups, and Multiple Windows123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;!DOCTYPE HTML&gt;&lt;html&gt;&lt;head&gt; &lt;script type="text/javascript"&gt; function output(resultText)&#123; document.getElementById('output').childNodes[0].nodeValue=resultText; &#125; function show_confirm()&#123; var confirmation=confirm("Chose an option."); if (confirmation==true)&#123; output("Confirmed."); &#125; else&#123; output("Rejected!"); &#125; &#125; function show_alert()&#123; alert("I'm blocking!"); output("Alert is gone."); &#125; function show_prompt()&#123; var response = prompt("What's the best web QA tool?","Selenium"); output(response); &#125; function open_window(windowName)&#123; window.open("newWindow.html",windowName); &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;input type="button" id="btnConfirm" onclick="show_confirm()" value="Show confirm box" /&gt; &lt;input type="button" id="btnAlert" onclick="show_alert()" value="Show alert" /&gt; &lt;input type="button" id="btnPrompt" onclick="show_prompt()" value="Show prompt" /&gt; &lt;a href="newWindow.html" id="lnkNewWindow" target="_blank"&gt;New Window Link&lt;/a&gt; &lt;input type="button" id="btnNewNamelessWindow" onclick="open_window()" value="Open Nameless Window" /&gt; &lt;input type="button" id="btnNewNamedWindow" onclick="open_window('Mike')" value="Open Named Window" /&gt; &lt;br /&gt; &lt;span id="output"&gt; &lt;/span&gt;&lt;/body&gt;&lt;/html&gt; Command Description assertFoo(pattern) 如果模式与弹出窗口的文本不匹配，则抛出错误 assertFooPresent 如果弹出窗口不可用则抛出错误 assertFooNotPresent 如果存在任何弹出窗口则抛出错误 storeFoo(variable) 将弹出文本存储在变量中 storeFooPresent(variable) 将弹出窗口的文本存储在变量中并返回true或false 在Selenium下运行时，不会显示JavaScript弹出窗口。这是因为函数调用实际上是由Selenium自己的JavaScript在运行时覆盖的。但是，仅仅因为你看不到弹出窗口并不意味着你不必处理它。要处理弹出窗口，必须调用其assertFoo（模式）函数。如果您未能断言是否存在弹出窗口，则您的下一个命令将被阻止，您将收到类似于以下错误的错误[错误]错误error] Error: There was an unexpected Confirmation! [Chose an option.] Alerts让我们从Alerts开始，因为它们是最简单的弹出窗口。首先，在浏览器中打开上面的HTML示例，然后单击“Show alert”按钮。您会注意到，在您关闭警报后，页面上会显示“警报已消失。”文本。现在使用Selenium IDE录制完成相同的步骤，并在关闭警报后验证是否添加了文本。您的测试看起来像这样： Command Target value open / click btnAlert assertAlert I’m blocking! verifyTextPresent Alert is gone. 您可能会想“这很奇怪，我从未试图断言该警报。”但这是Selenium-IDE处理并为您关闭警报。如果您删除该步骤并重播测试，您将获得以下内容 [error] Error: There was an unexpected Alert! [I&#39;m blocking!]. 如果您只想声明警报存在但是不知道或不关心它包含哪个文本，则可以使用assertAlertPresent。这将返回true或false，错误地停止测试。 Confirmations确认的行为与警报的行为大致相同，其中assertConfirmation和assertConfirmationPresent提供与其警报对应物相同的特征。但是，默认情况下，Selenium会在弹出确认时选择“确定”。尝试单击示例页面中的“显示确认框”按钮，但单击弹出窗口中的“取消”按钮，然后断言输出文本。您的测试可能如下所示： Command Target value open / click btnAlert chooseCancelOnNextConfirmation assertConfirmation Choose an option. verifyTextPresent Rejected chooseCancelOnNextConfirmation函数告诉Selenium所有后续确认都应该返回false。可以通过调用chooseOkOnNextConfirmation来重置它。 可能会注意到您无法重播此测试，因为Selenium抱怨存在未经处理的确认。这是因为Selenium-IDE记录的事件顺序导致click和chooseCancelOnNextConfirmation被置于错误的顺序（如果考虑它就有意义，Selenium在打开确认之前无法知道正在取消）切换这两个命令，你的测试运行正常。 Prompts提示的行为与警报的行为大致相同，其中assertPrompt和assertPromptPresent提供与其警报对应项相同的特征。默认情况下，Selenium会在弹出提示时等待您输入数据。尝试单击示例页面中的“显示提示”按钮，然后在提示中输入“Selenium”。测试可能如下所示： Command Target value open / answerOnNextPrompt Selenium! click id=btnPrompt assertPrompt What’s the best web QA tool? verifyTextPresent Selenium! 如果在提示中选择取消，您可能会注意到answerOnNextPrompt只显示空白目标。 Selenium对取消和提示上的空白条目基本上是一样的。 调试断点要设置断点，请选择一个命令，单击鼠标右键，然后从上下文菜单中选择“切换断点”。然后单击“运行”按钮以从开始到断点运行测试用例。从测试用例的中间位置到结束位置运行测试用例或者到达起始点之后的断点有时也很有用。例如，假设您的测试用例首先登录到网站，然后执行一系列测试，并且您正在尝试调试其中一个测试。但是，您只需要登录一次，但是在开发测试时需要不断重新运行测试。您可以登录一次，然后从测试用例的登录部分之后的起点运行测试用例。这将阻止您每次重新运行测试用例时都必须手动注销。 按步骤执行测试要一次执行一个测试用例（“step through”），只需重复按此按钮。 Find Button“查找”按钮用于查看当前显示的网页（在浏览器中）中当前选定的Selenium命令中使用的UI元素。在为命令的第一个参数构建定位器时，这非常有用（请参阅定位元素一节）。它可以与标识网页上UI元素的任何命令一起使用，例如，单击，单击和等待，键入，以及某些断言和验证命令等。 从表视图中，选择具有locator参数的任何命令。单击“查找”按钮。现在查看网页：应该有一个明亮的绿色矩形，包围locator参数指定的元素。 Java中应用Selenium项目地址 我在本地录制了一个简单的脚本，选择导出到java+junit，类似下面：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class SearchGoogle &#123; private WebDriver driver; private boolean acceptNextAlert = true; private StringBuffer verificationErrors = new StringBuffer(); private SeleniumConfigure seleniumConfigure = SeleniumConfigureParse.getSeleniumConfigure(); @Before public void setUp() &#123; driver = DriverUtil.getDriver(); driver .manage().window().maximize();//全屏 driver.manage().timeouts().implicitlyWait(30, TimeUnit.SECONDS); &#125; @Test public void testSearchGoogle() &#123; driver.get(seleniumConfigure.getBaseUrl()); driver.findElement(By.name("q")).click(); driver.findElement(By.name("q")).clear(); driver.findElement(By.name("q")).sendKeys("google"); driver.findElement(By.name("q")).sendKeys(Keys.ENTER); &#125; @After public void tearDown() &#123; driver.quit(); String verificationErrorString = verificationErrors.toString(); if (!"".equals(verificationErrorString)) &#123; fail(verificationErrorString); &#125; &#125; private boolean isElementPresent(By by) &#123; try &#123; driver.findElement(by); return true; &#125; catch (NoSuchElementException e) &#123; return false; &#125; &#125; private boolean isAlertPresent() &#123; try &#123; driver.switchTo().alert(); return true; &#125; catch (NoAlertPresentException e) &#123; return false; &#125; &#125; private String closeAlertAndGetItsText() &#123; try &#123; Alert alert = driver.switchTo().alert(); String alertText = alert.getText(); if (acceptNextAlert) &#123; alert.accept(); &#125; else &#123; alert.dismiss(); &#125; return alertText; &#125; finally &#123; acceptNextAlert = true; &#125; &#125;&#125; 新建项目，pom.xml如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283 &lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;choerodon&lt;/groupId&gt; &lt;artifactId&gt;selenium&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.seleniumhq.selenium&lt;/groupId&gt; &lt;artifactId&gt;selenium-server&lt;/artifactId&gt; &lt;version&gt;3.14.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.yaml/snakeyaml --&gt; &lt;dependency&gt; &lt;groupId&gt;org.yaml&lt;/groupId&gt; &lt;artifactId&gt;snakeyaml&lt;/artifactId&gt; &lt;version&gt;1.23&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt; &lt;!--&lt;dependency&gt;--&gt; &lt;!--&lt;groupId&gt;org.projectlombok&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;lombok&lt;/artifactId&gt;--&gt; &lt;!--&lt;version&gt;1.18.4&lt;/version&gt;--&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; &lt;!--&lt;/dependency&gt;--&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0-M3&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.surefire&lt;/groupId&gt; &lt;artifactId&gt;surefire-junit47&lt;/artifactId&gt; &lt;version&gt;3.0.0-M3&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;basedir&#125;/output&lt;/outputDirectory&gt; &lt;outputName&gt;测试报告&lt;/outputName&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--&lt;plugin&gt;--&gt; &lt;!--&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;--&gt; &lt;!--&lt;artifactId&gt;maven-site-plugin&lt;/artifactId&gt;--&gt; &lt;!--&lt;version&gt;2.1&lt;/version&gt;--&gt; &lt;!--&lt;configuration&gt;--&gt; &lt;!--&lt;outputDirectory&gt;$&#123;basedir&#125;/output&lt;/outputDirectory&gt;--&gt; &lt;!--&lt;outputName&gt;测试报告&lt;/outputName&gt;--&gt; &lt;!--&lt;/configuration&gt;--&gt; &lt;!--&lt;/plugin&gt;--&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 与Docker结合 使用远程的驱动服务来测试，目前只支持Chrome和FireFox，本地如果要起服务，请在docker中执行下面的命令启动服务 123docker pull elgalu/seleniumdocker run -d --name=grid -p 4444:24444 -p 5900:25900 -e TZ="Asia/Shanghai" -e MAX_INSTANCES=20 -e MAX_SESSIONS=20 -v /Users/dinghuang/Documents/Tool/selenium/shm:/dev/shm --privileged elgalu/seleniumdocker exec grid wait_all_done 30s 可以在http://localhost:4444/grid/console中查看详情 关闭服务命令： 12docker exec grid stopdocker stop grid 在JAVA代码中，可以通过远程的docker容器启动浏览器进行测试 1webDriver = new RemoteWebDriver(new URL("http://localhost:4444/wd/hub"), browser);]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在GitHub Page使用HEXO搭建博客]]></title>
    <url>%2F2018%2F09%2F21%2F%E5%A6%82%E4%BD%95%E5%9C%A8GitHub%20Page%E4%BD%BF%E7%94%A8HEXO%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[如何在使用GitHub Page搭建HEXO博客项目地址 准备工作 安装Git 安装Node.js 注册Github账号 创建新的仓库 名称必须为 用户名.github.io 添加本地电脑的SSH认证，如图所示在本地命令工具中输入ssh-keygen -t rsa -C &quot;Github的注册邮箱地址&quot;一路回车之后会得到两个文件：id_rsa和id_rsa.pub，然后用带格式的编辑器（比方说notepad++或者sublime）打开id_rsa.pub，复制里面的所有内容，然粘贴到KEY里面。 安装HEXO 打开命令行工具npm install -g hexo-cli 安装 Hexo 完成后，分步执行（即输入代码之后敲回车）下列命令，Hexo 将会在指定文件夹中新建所需要的文件。hexo init &lt;folder&gt;在文件夹内执行npm install 成功后，博客项目成功初始化 配置NEXT主题 安装NEXT主题 mkdir themes/nextcurl -s https://api.github.com/repos/iissnan/hexo-theme-next/releases/latest | grep tarball_url | cut -d &#39;&quot;&#39; -f 4 | wget -i - -O- | tar -zx -C themes/next --strip-components=1修改站点配置文件_config.yml12345678910111213141516title: 一只病猫subtitle: 静坐常思己过，闲谈莫论人非description: 学习、生活、闲谈、足球author: 强壮的病猫language: zh-Hanstimezone: Asia/Shanghaitheme: nexturl: https://dinghuang.github.io/deploy: type: git repo: https://github.com/dinghuang/dinghuang.github.io.git branch: master#开启swiftype搜索，后面的id在swiftype官网申请，[具体操作][3]swiftype_key: HcRPHRrBuwozvgUoLNyX#要放到仓库的静态资源都放在source文件夹中，.md会被转换成HTML，所以这里要忽略skip_render: README.md 配置NEXT主题设置主题配置文件./themes/next/_config.yml，可以参考本项目的配置。NEXT强大之处在于继承了很多第三方服务插件，不过类似评论搜索功能的插件被墙了，外网是可以用的。具体参考 设置标签分类参考链接，在文章开头，引入：12345title: 设计模式date: 2018-07-18 09:43:00tags: - JAVAcategories: JAVA 更多配置请参考官方文档 提交 输入命令npm install hexo-deployer-git --save 创建文章hexo new &quot;你想要的文章标题填在这个双引号里&quot; 文章会生成在./source/_posts/设计模式.md进行修改后hexo clean ; hexo genarate 然后输入hexo deploy此时文章已经成功部署。]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VPS搭建SS]]></title>
    <url>%2F2018%2F09%2F08%2FVPS%E6%90%AD%E5%BB%BASS%2F</url>
    <content type="text"><![CDATA[购买VPS服务器声明：本教程仅供学习用 购买地址 推荐vultr的原因是，vultr支持支付宝、服务器较多，价格虽然不算便宜，但是网速稳定。各个机房速度测试，直接ping 域名地理位置 官方测试服务器ip 下载测试文件123456789101112131415Frankfurt, DE fra-de-ping.vultr.com 100M 1000MAmsterdam, NL ams-nl-ping.vultr.com 100M 1000MParis, France par-fr-ping.vultr.com 100M 1000MLondon, UK lon-gb-ping.vultr.com 100M 1000MSingapore sgp-ping.vultr.com 100M 1000MNew York (NJ) nj-us-ping.vultr.com 100M 1000MTokyo, Japan hnd-jp-ping.vultr.com 100M 1000MChicago, Illinois il-us-ping.vultr.com 100M 1000MAtlanta, Georgia ga-us-ping.vultr.com 100M 1000MMiami, Florida fl-us-ping.vultr.com 100M 1000MSeattle, Washington wa-us-ping.vultr.com 100M 1000MDallas, Texas tx-us-ping.vultr.com 100M 1000MSilicon Valley, California sjo-ca-us-ping.vultr.com 100M 1000MLos Angeles, California lax-ca-us-ping.vultr.com 100M 1000MSydney, Australia syd-au-ping.vultr.com 100M 1000M 经过测试，大陆地区，Tokyo的速度是最快的，延迟在50ms左右。 搭建ShadowSocksR服务ssh连接购买的服务器ssh -p22 root@xx.xx.xx.xx搭建ssr服务wget --no-check-certificate https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocksR.shchmod +x shadowsocksR.sh./shadowsocksR.sh 2&gt;&amp;1 | tee shadowsocksR.log根据提示输入相关配置相关指令：卸载: ./shadowsocksR.sh uninstall启动：/etc/init.d/shadowsocks start停止：/etc/init.d/shadowsocks stop重启：/etc/init.d/shadowsocks restart状态：/etc/init.d/shadowsocks status配置文件路径：/etc/shadowsocks.json日志文件路径：/var/log/shadowsocks.log代码安装目录：/usr/local/shadowsocks如果要配置多个用户，多个端口，打开配置文件路径，修改如下：1234567891011121314151617&#123; "server":"0.0.0.0", "server_ipv6":"[::]", "server_port":9001, "local_address":"127.0.0.1", "local_port":1080, "port_password":&#123; "9001":"123456", "9002":"123456", "9003":"123456" &#125;, "timeout":300, "method":"aes-256-cfb", "protocol":"origin", "obfs":"plain", "fast_open":false&#125; 设置相关端口后要在防火墙打开相关端口的通讯，Centos默认使用firewall命令，如下所示：sudo firewall-cmd --zone=public --add-port=3000/tcp --permanentsudo firewall-cmd --reloadfirewall-cmd --list-all 优化网络1.系统层面vi /etc/sysctl.conf 123456789101112131415161718192021222324252627282930313233343536373839404142# max open filesfs.file-max = 1024000# max read buffernet.core.rmem_max = 67108864# max write buffernet.core.wmem_max = 67108864# default read buffernet.core.rmem_default = 65536# default write buffernet.core.wmem_default = 65536# max processor input queuenet.core.netdev_max_backlog = 4096# max backlognet.core.somaxconn = 4096# resist SYN flood attacksnet.ipv4.tcp_syncookies = 1# reuse timewait sockets when safenet.ipv4.tcp_tw_reuse = 1# turn off fast timewait sockets recyclingnet.ipv4.tcp_tw_recycle = 0# short FIN timeoutnet.ipv4.tcp_fin_timeout = 30# short keepalive timenet.ipv4.tcp_keepalive_time = 1200# outbound port rangenet.ipv4.ip_local_port_range = 10000 65000# max SYN backlognet.ipv4.tcp_max_syn_backlog = 4096# max timewait sockets held by system simultaneouslynet.ipv4.tcp_max_tw_buckets = 5000# TCP receive buffernet.ipv4.tcp_rmem = 4096 87380 67108864# TCP write buffernet.ipv4.tcp_wmem = 4096 65536 67108864# turn on path MTU discoverynet.ipv4.tcp_mtu_probing = 1# for high-latency networknet.ipv4.tcp_congestion_control = htcp# forward ipv4net.ipv4.ip_forward = 1 保存生效sysctl -p其中最后的hybla是为高延迟网络（如美国，欧洲）准备的算法，需要内核支持，测试内核是否支持，在终端输入：sysctl net.ipv4.tcp_available_congestion_control如果结果中有hybla，则证明你的内核已开启hybla，如果没有hybla，可以用命令modprobe tcp_hybla开启。 对于低延迟的网络（如日本，香港等），可以使用htcp，可以非常显著的提高速度，首先使用modprobe tcp_htcp开启，再将net.ipv4.tcp_congestion_control = hybla改为net.ipv4.tcp_congestion_control = htcp，建议EC2日本用户使用这个算法。 2.TCP优化1.修改文件句柄数限制如果是ubuntu/centos均可修改/etc/sysctl.conf找到fs.file-max这一行，修改其值为1024000，并保存退出。然后执行sysctl -p使其生效修改vi /etc/security/limits.conf文件，加入 12* soft nofile 512000* hard nofile 1024000 针对centos,还需要修改vi /etc/pam.d/common-session文件，加入session required pam_limits.so 2.修改vi /etc/profile文件，加入ulimit -SHn 1024000然后重启服务器执行ulimit -n，查询返回1024000即可。 sysctl.conf报错解决方法修复modprobe的：12rm -f /sbin/modprobe ln -s /bin/true /sbin/modprobe 修复sysctl的：12rm -f /sbin/sysctl ln -s /bin/true /sbin/sysctl 3.软件辅助优化软件辅助优化都得参考系统内核，查看是否适用，如果不适用，可以修改系统内核。 2.1 锐速 锐速是TCP底层加速软件,官方已停止推出永久免费版本,但网上有破解版可以继续使用。需要购买的话先到锐速官网注册帐号,并确认内核版本是否支持锐速的版本。 一键安装速锐破解版 wget -N --no-check-certificate https://github.com/91yun/serverspeeder/raw/master/serverspeeder.sh &amp;&amp; bash serverspeeder.sh一键卸载 chattr -i /serverspeeder/etc/apx* &amp;&amp; /serverspeeder/bin/serverSpeeder.sh uninstall -f设置 12345Enter your accelerated interface(s) [eth0]: eth0Enter your outbound bandwidth [1000000 kbps]: 1000000Enter your inbound bandwidth [1000000 kbps]: 1000000Configure shortRtt-bypass [0 ms]: 0Auto load ServerSpeeder on linux start-up? [n]:y 是否开机自启Run ServerSpeeder now? [y]:y #是否现在启动执行lsmod，看到有appex0模块即说明锐速已正常安装并启动。 至此，安装就结束了，但还有后续配置。修改vi /serverspeeder/etc/config文件的几个参数以使锐速更好的工作 123456accppp="1" #加速PPTP、L2TP V-P-N；设为1表示开启，设为0表示关闭advinacc="1" #高级入向加速开关；设为 1 表示开启，设为 0 表示关闭；开启此功能可以得到更好的流入方向流量加速效果；maxmode="1" #最大传输模式；设为 1 表示开启；设为 0 表示关闭；开启后会进一步提高加速效果，但是可能会降低有效数据率。rsc="1" #网卡接收端合并开关；设为 1 表示开启，设为 0 表示关闭；在有些较新的网卡驱动中，带有 RSC 算法的，需要打开该功能。l2wQLimit="512 4096" #从 LAN 到 WAN 加速引擎在缓冲池充满和空闲时分别能够缓存的数据包队列的长度的上限；该值设置的高会获得更好的加速效果，但是会消耗更多的内存w2lQLimit="512 4096" #从 WAN 到 LAN 加速引擎在缓冲池充满和空闲时分别能够缓存的数据包队列的长度的上限；该值设置的高会获得更好的加速效果，但是会消耗更多的内存 重读配置以使配置生效/serverspeeder/bin/serverSpeeder.sh reload 查看锐速当前状态/serverspeeder/bin/serverSpeeder.sh stats 查看所有命令/serverspeeder/bin/serverSpeeder.sh help 停止/serverspeeder/bin/serverSpeeder.sh stop 启动/serverspeeder/bin/serverSpeeder.sh start 重启锐速/serverspeeder/bin/serverSpeeder.sh restart 2.1 安装Google BBR 要求内核版本4.13.5-1.el7.elrepo.x86_64 以上12rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpmyum --enablerepo=elrepo-kernel install kernel-ml -y 检查内核是否更新rpm -qa | grep kernel启动grub2-set-default 1重启shutdown -r now查看是否生效uname -r安装Google BBR123echo 'net.core.default_qdisc=fq' | sudo tee -a /etc/sysctl.confecho 'net.ipv4.tcp_congestion_control=bbr' | sudo tee -a /etc/sysctl.confsysctl -p 检查是否安装成功sysctl net.ipv4.tcp_available_congestion_control执行命令后，看是否是提示“net.ipv4.tcp_available_congestion_control = bbr cubic reno”执行命令，是否提示bbrlsmod | grep bbr]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式]]></title>
    <url>%2F2018%2F07%2F18%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[菜鸟教程文档 设计模式设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。 设计模式是一套被反复使用的、多数人知晓的、经过分类编目的、代码设计经验的总结。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。 毫无疑问，设计模式于己于他人于系统都是多赢的，设计模式使代码编制真正工程化，设计模式是软件工程的基石，如同大厦的一块块砖石一样。项目中合理地运用设计模式可以完美地解决很多问题，每种模式在现实中都有相应的原理来与之对应，每种模式都描述了一个在我们周围不断重复发生的问题，以及该问题的核心解决方案，这也是设计模式能被广泛应用的原因。 代码案例 1.创建型模式这些设计模式提供了一种在创建对象的同时隐藏创建逻辑的方式，而不是使用 new 运算符直接实例化对象。这使得程序在判断针对某个给定实例需要创建哪些对象时更加灵活。 1.1. 工厂模式主要解决：主要解决接口选择的问题。 何时使用：我们明确地计划不同条件下创建不同实例时。 优点： 一个调用者想创建一个对象，只要知道其名称就可以了 扩展性高，如果想增加一个产品，只要扩展一个工厂类就可以 屏蔽产品的具体实现，调用者只关心产品的接口 缺点：每次增加一个产品时，都需要增加一个具体类和对象实现工厂，使得系统中类的个数成倍增加，在一定程度上增加了系统的复杂度，同时也增加了系统具体类的依赖。这并不是什么好事。 如何解决：让其子类实现工厂接口，返回的也是一个抽象的产品。 使用场景： 1、日志记录器：记录可能记录到本地硬盘、系统事件、远程服务器等，用户可以选择记录日志到什么地方。 2、数据库访问，当用户不知道最后系统采用哪一类数据库，以及数据库可能有变化时。 3、设计一个连接服务器的框架，需要三个协议，”POP3”、”IMAP”、”HTTP”，可以把这三个作为产品类，共同实现一个接口。 注意事项：作为一种创建类模式，在任何需要生成复杂对象的地方，都可以使用工厂方法模式。有一点需要注意的地方就是复杂对象适合使用工厂模式，而简单对象，特别是只需要通过 new 就可以完成创建的对象，无需使用工厂模式。如果使用工厂模式，就需要引入一个工厂类，会增加系统的复杂度。 1234567891011121314151617181920212223242526272829303132public interface Car &#123; void run();&#125;public class ExpensiveCar implements Car &#123; @Override public void run() &#123; System.out.println("expensiveCar.run"); &#125;&#125;public class LitterCar implements Car &#123; @Override public void run() &#123; System.out.println("littleCard.run"); &#125;&#125;public class CarFactory &#123; public Car getCar(String type) &#123; if (type == null) &#123; return null; &#125; if (type.equals("litterCar")) &#123; return new LitterCar(); &#125; else if (type.equals("ExpensiveCar")) &#123; return new ExpensiveCar(); &#125; return null; &#125;&#125; 1.2. 抽象工厂模式主要解决：主要解决接口选择的问题。 何时使用：系统的产品有多于一个的产品族，而系统只消费其中某一族的产品。 优点：当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。 缺点：产品族扩展非常困难，要增加一个系列的某一产品，既要在抽象的 Creator 里加代码，又要在具体的里面加代码。 使用场景： 1、QQ 换皮肤，一整套一起换。 2、生成不同操作系统的程序。 注意事项：产品族难扩展，产品等级易扩展。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public interface Car &#123; void run();&#125;public class ExpensiveCar implements Car &#123; @Override public void run() &#123; System.out.println("expensiveCar.run"); &#125;&#125;public class LitterCar implements Car &#123; @Override public void run() &#123; System.out.println("littleCard.run"); &#125;&#125;public interface Passengers &#123; void getCar();&#125;public class Man implements Passengers &#123; @Override public void getCar() &#123; System.out.println("man.getCar"); &#125;&#125;public class Woman implements Passengers &#123; @Override public void getCar() &#123; System.out.println("man.getCar"); &#125;&#125;public abstract class AbstractFactory &#123; public abstract Passengers getPassengers(String user); public abstract Car getCar(String car);&#125;public class CarFactory extends AbstractFactory&#123; @Override public Passengers getPassengers(String user) &#123; return null; &#125; @Override public Car getCar(String type) &#123; if (type == null) &#123; return null; &#125; if (type.equals("litterCar")) &#123; return new LitterCar(); &#125; else if (type.equals("ExpensiveCar")) &#123; return new ExpensiveCar(); &#125; return null; &#125;&#125;public class PassengerFactory extends AbstractFactory &#123; @Override public Passengers getPassengers(String user) &#123; if (user == null) &#123; return null; &#125; if (user.equals("man")) &#123; return new Man(); &#125; else if (user.equals("woman")) &#123; return new Woman(); &#125; return null; &#125; @Override public Car getCar(String car) &#123; return null; &#125;&#125;public class FactoryProducer &#123; public static AbstractFactory getFactory(String choice) &#123; if (choice.equalsIgnoreCase("Car")) &#123; return new CarFactory(); &#125; else if (choice.equalsIgnoreCase("Passenger")) &#123; return new PassengerFactory(); &#125; return null; &#125;&#125; 1.3. 单例模式主要解决：一个全局使用的类频繁地创建与销毁。 何时使用：当您想控制实例数目，节省系统资源的时候。 优点： 在内存里只有一个实例，减少了内存的开销，尤其是频繁的创建和销毁实例（比如管理学院首页页面缓存） 避免对资源的多重占用（比如写文件操作） 缺点：没有接口，不能继承，与单一职责原则冲突，一个类应该只关心内部逻辑，而不关心外面怎么样来实例化。 使用场景： 要求生产唯一序列号。 WEB 中的计数器，不用每次刷新都在数据库里加一次，用单例先缓存起来。 创建的一个对象需要消耗的资源过多，比如 I/O 与数据库的连接等。 注意事项：getInstance() 方法中需要使用同步锁 synchronized (Singleton.class) 防止多线程同时进入造成 instance 被多次实例化。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205/** * 饿汉式 * 是否 Lazy 初始化：否 * &lt;p&gt; * 是否多线程安全：是 * &lt;p&gt; * 实现难度：易 * &lt;p&gt; * 描述：这种方式比较常用，但容易产生垃圾对象。 * 优点：没有加锁，执行效率会提高。 * 缺点：类加载时就初始化，浪费内存。 * 它基于 classloader 机制避免了多线程的同步问题，不过，instance 在类装载时就实例化，虽然导致类装载的原因有很多 * 种，在单例模式中大多数都是调用 getInstance 方法， 但是也不能确定有其他的方式（或者其他的静态方法）导致类装载， * 这时候初始化 instance 显然没有达到 lazy loading 的效果。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public class User &#123; private static User user = new User(); //让构造函数私有化，这样该类不会被实例化 private User() &#123; &#125; public static User getUser() &#123; return user; &#125; public void showMessage() &#123; System.out.println("What???"); &#125;&#125;/** * 懒汉式，线程不安全 * 是否 Lazy 初始化：是 * &lt;p&gt; * 是否多线程安全：否 * &lt;p&gt; * 实现难度：易 * &lt;p&gt; * 描述：这种方式是最基本的实现方式，这种实现最大的问题就是不支持多线程。因为没有加锁 synchronized，所以严格意义上它并不算单例模式。 * 这种方式 lazy loading 很明显，不要求线程安全，在多线程不能正常工作。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public class User &#123; private static User user; //让构造函数私有化，这样该类不会被实例化 private User() &#123; &#125; public static User getUser() &#123; if (user == null) &#123; System.out.println("no user"); user = new User(); &#125; return user; &#125; public void showMessage() &#123; System.out.println("What???"); &#125;&#125;/** * 懒汉式，线程安全 * 是否 Lazy 初始化：是 * &lt;p&gt; * 是否多线程安全：是 * &lt;p&gt; * 实现难度：易 * &lt;p&gt; * 描述：这种方式具备很好的 lazy loading，能够在多线程中很好的工作，但是，效率很低，99% 情况下不需要同步。 * 优点：第一次调用才初始化，避免内存浪费。 * 缺点：必须加锁 synchronized 才能保证单例，但加锁会影响效率。 * getInstance() 的性能对应用程序不是很关键（该方法使用不太频繁）。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public class User &#123; private static User user; //让构造函数私有化，这样该类不会被实例化 private User() &#123; &#125; public static synchronized User getUser() &#123; if (user == null) &#123; System.out.println("no User"); user = new User(); &#125; return user; &#125; public void showMessage() &#123; System.out.println("What???"); &#125;&#125;/** * 双检锁/双重校验锁（DCL，即 double-checked locking） * JDK 版本：JDK1.5 起 * &lt;p&gt; * 是否 Lazy 初始化：是 * &lt;p&gt; * 是否多线程安全：是 * &lt;p&gt; * 实现难度：较复杂 * &lt;p&gt; * 描述：这种方式采用双锁机制，安全且在多线程情况下能保持高性能。 * getInstance() 的性能对应用程序很关键。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public class User &#123; private static User user; //让构造函数私有化，这样该类不会被实例化 private User() &#123; &#125; public static User getUser() &#123; if (user == null) &#123; synchronized (User.class) &#123; if (user == null) &#123; System.out.println("no User"); user = new User(); &#125; &#125; &#125; return user; &#125; public void showMessage() &#123; System.out.println("What???"); &#125;&#125;/** * 登记式/静态内部类 * 是否 Lazy 初始化：是 * &lt;p&gt; * 是否多线程安全：是 * &lt;p&gt; * 实现难度：一般 * &lt;p&gt; * 描述：这种方式能达到双检锁方式一样的功效，但实现更简单。对静态域使用延迟初始化，应使用这种方式而不是双检锁方式 * 。这种方式只适用于静态域的情况，双检锁方式可在实例域需要延迟初始化时使用。 * 这种方式同样利用了 classloader 机制来保证初始化 instance 时只有一个线程，它跟第 3 种方式不同的是： * 第 3 种方式只要 Singleton 类被装载了，那么 instance 就会被实例化（没有达到 lazy loading 效果） * ，而这种方式是 Singleton 类被装载了，instance 不一定被初始化。因为 SingletonHolder 类没有被主动使用， * 只有通过显式调用 getInstance 方法时，才会显式装载 SingletonHolder 类，从而实例化 instance。想象一下， * 如果实例化 instance 很消耗资源，所以想让它延迟加载，另外一方面，又不希望在 Singleton 类加载 * 时就实例化，因为不能确保 Singleton 类还可能在其他的地方被主动使用从而被加载，那么这个时候实 * 例化 instance 显然是不合适的。这个时候，这种方式相比第 3 种方式就显得很合理。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public class User &#123; private static class UserHolder &#123; private static final User user = new User(); &#125; private User() &#123; &#125; public static final User getUser() &#123; return UserHolder.user; &#125;&#125;public class SingletonTest &#123; public static void main(String[] args) &#123; //不合法的构造函数 //编译时错误：构造函数 User() 是私有的// User user = new User(); Runnable runnable = () -&gt; &#123; //枚举单例// User.USER.sendMessage(); User user = User.getUser(); user.showMessage(); &#125;; IntStream.range(0, 100) .forEach(i -&gt; &#123; Thread thread = new Thread(runnable); thread.start(); &#125;); &#125;&#125; 一般情况下，不建议使用懒汉方式，建议使用饿汉方式。只有在要明确实现 lazy loading 效果时，才会使用登记方式。如果涉及到反序列化创建对象时，可以尝试使用枚举方式。如果有其他特殊的需求，可以考虑使用双检锁方式。 1.4. 建造者模式建造者模式（Builder Pattern）使用多个简单的对象一步一步构建成一个复杂的对象。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 一个 Builder 类会一步一步构造最终的对象。该 Builder 类是独立于其他对象的。 主要解决：主要解决在软件系统中，有时候面临着”一个复杂对象”的创建工作，其通常由各个部分的子对象用一定的算法构成；由于需求的变化，这个复杂对象的各个部分经常面临着剧烈的变化，但是将它们组合在一起的算法却相对稳定。 何时使用：一些基本部件不会变，而其组合经常变化的时候。 如何解决：将变与不变分离开。 应用实例： 去肯德基，汉堡、可乐、薯条、炸鸡翅等是不变的，而其组合是经常变化的，生成出所谓的”套餐” JAVA 中的 StringBuilder 优点： 建造者独立，易扩展 便于控制细节风险 缺点： 产品必须有共同点，范围有限制 如内部变化复杂，会有很多的建造类 使用场景： 需要生成的对象具有复杂的内部结构 需要生成的对象内部属性本身相互依赖 注意事项：与工厂模式的区别是：建造者模式更加关注与零件装配的顺序。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126public interface Product &#123; public String name(); public float price(); public Production production();&#125;public interface Production &#123; public String production();&#125;public class Hand implements Production&#123; @Override public String production() &#123; return "hand"; &#125;&#125;public class Machine implements Production &#123; @Override public String production() &#123; return "Machine"; &#125;&#125;public abstract class Windows implements Product&#123; @Override public Production production()&#123; return new Hand(); &#125; @Override public abstract float price();&#125;public abstract class Mac implements Product&#123; @Override public Production production()&#123; return new Machine(); &#125; @Override public abstract float price();&#125;public class WindowsSystem extends Windows&#123; @Override public String name() &#123; return "windowsSystem"; &#125; @Override public float price() &#123; return 25.0f; &#125;&#125;public class MacSystem extends Mac &#123; @Override public String name() &#123; return "macSystem"; &#125; @Override public float price() &#123; return 30.0f; &#125;&#125;public class SystemProduct &#123; private List&lt;Product&gt; products = new ArrayList&lt;&gt;(); public void addProduct(Product product) &#123; products.add(product); &#125; public float getCost() &#123; float cost = 0.0f; for (Product product : products) &#123; cost += product.price(); &#125; return cost; &#125; public void showProducts() &#123; for (Product product : products) &#123; System.out.print("Product : " + product.name()); System.out.print(",Production : " + product.production().production()); System.out.println(", Price : " + product.price()); &#125; &#125;&#125;public class SystemProductBuilder &#123; public SystemProduct prepareMacSystem() &#123; SystemProduct systemProduct = new SystemProduct(); systemProduct.addProduct(new MacSystem()); return systemProduct; &#125; public SystemProduct prepareWindowsSystem() &#123; SystemProduct systemProduct = new SystemProduct(); systemProduct.addProduct(new WindowsSystem()); return systemProduct; &#125;&#125;public class BuilderTest &#123; public static void main(String[] args) &#123; SystemProductBuilder systemProductBuilder = new SystemProductBuilder(); SystemProduct windows = systemProductBuilder.prepareMacSystem(); System.out.println("windows product"); windows.showProducts(); System.out.println("Total Cost: " + windows.getCost()); SystemProduct allSystem = systemProductBuilder.prepareAllSystem(); System.out.println("allSystem"); allSystem.showProducts(); System.out.println("Total Cost: " + allSystem.getCost()); &#125;&#125; 1.5. 原型模式原型模式（Prototype Pattern）是用于创建重复的对象，同时又能保证性能。这种类型的设计模式属于创建型模式，它提供了一种创建对象的最佳方式。 这种模式是实现了一个原型接口，该接口用于创建当前对象的克隆。当直接创建对象的代价比较大时，则采用这种模式。例如，一个对象需要在一个高代价的数据库操作之后被创建。我们可以缓存该对象，在下一个请求时返回它的克隆，在需要的时候更新数据库，以此来减少数据库调用。 主要解决：在运行期建立和删除原型。 何时使用： 当一个系统应该独立于它的产品创建，构成和表示时 当要实例化的类是在运行时刻指定时，例如，通过动态装载 为了避免创建一个与产品类层次平行的工厂类层次时 当一个类的实例只能有几个不同状态组合中的一种时。建立相应数目的原型并克隆它们可能比每次用合适的状态手工实例化该类更方便一些 如何解决：利用已有的一个原型对象，快速地生成和原型对象一样的实例。 应用实例： 细胞分裂 JAVA 中的 Object clone() 方法 优点： 性能提高 逃避构造函数的约束 缺点： 配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类不是很难，但对于已有的类不一定很容易，特别当一个类引用不支持串行化的间接对象，或者引用含有循环结构的时候 必须实现 Cloneable 接口 使用场景： 资源优化场景 类初始化需要消化非常多的资源，这个资源包括数据、硬件资源等 性能和安全要求的场景 通过 new 产生一个对象需要非常繁琐的数据准备或访问权限，则可以使用原型模式 一个对象多个修改者的场景 一个对象需要提供给其他对象访问，而且各个调用者可能都需要修改其值时，可以考虑使用原型模式拷贝多个对象供调用者使用 在实际项目中，原型模式很少单独出现，一般是和工厂方法模式一起出现，通过 clone的方法创建一个对象，然后由工厂方法提供给调用者。原型模式已经与 Java 融为浑然一体，大家可以随手拿来使用 注意事项：与通过对一个类进行实例化来构造新对象不同的是，原型模式是通过拷贝一个现有对象生成新对象的。浅拷贝实现 Cloneable，重写，深拷贝是通过实现 Serializable 读取二进制流。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697/** * 创建一个抽象类 Prototype 和扩展了 Prototype 类的实体类。下一步是定义类 PrototypeCache，该类把 Prototype * 对象存储在一个 Hashtable 中，并在请求的时候返回它们的克隆。 * * @author dinghuang123@gmail.com * @since 2018/7/18 */public abstract class Prototype implements Cloneable&#123; private String id; private String type; abstract void operation(); public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getType() &#123; return type; &#125; public void setType(String type) &#123; this.type = type; &#125; @Override public Object clone()&#123; Object clone = null; try&#123; clone = super.clone(); &#125;catch (CloneNotSupportedException e)&#123; e.printStackTrace(); &#125; return clone; &#125;&#125;public class PrototypeOne extends Prototype &#123; public PrototypeOne()&#123; type = "prototypeOne"; &#125; @Override void operation() &#123; System.out.println("Inside PrototypeOne::draw() method."); &#125;&#125;public class PrototypeTwo extends Prototype &#123; public PrototypeTwo() &#123; type = "prototypeTwo"; &#125; @Override void operation() &#123; System.out.println("Inside PrototypeTwo::draw() method."); &#125;&#125;public class PrototypeCache &#123; private static Hashtable&lt;String,Prototype&gt; propertyMap = new Hashtable&lt;&gt;(); public static Prototype getProperType(String id)&#123; Prototype cachePrototype = propertyMap.get(id); return (Prototype) cachePrototype.clone(); &#125; public static void loadCache() &#123; PrototypeOne prototypeOne = new PrototypeOne(); prototypeOne.setId("1"); propertyMap.put(prototypeOne.getId(),prototypeOne); PrototypeTwo prototypeTwo = new PrototypeTwo(); prototypeTwo.setId("2"); propertyMap.put(prototypeTwo.getId(),prototypeTwo); &#125;&#125;public class PrototypeTest &#123; public static void main(String[] args) &#123; PrototypeCache.loadCache(); PrototypeOne prototypeOne = (PrototypeOne) PrototypeCache.getProperType("1"); System.out.println("Prototype : " + prototypeOne.getType()); PrototypeTwo prototypeTwo = (PrototypeTwo) PrototypeCache.getProperType("2"); System.out.println("Prototype : " + prototypeTwo.getType()); &#125;&#125; 2.结构型模式这些设计模式关注类和对象的组合。继承的概念被用来组合接口和定义组合对象获得新功能的方式。 2.1. 适配器模式适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。 这种模式涉及到一个单一的类，该类负责加入独立的或不兼容的接口功能。举个真实的例子，读卡器是作为内存卡和笔记本之间的适配器。您将内存卡插入读卡器，再将读卡器插入笔记本，这样就可以通过笔记本来读取内存卡。 我们通过下面的实例来演示适配器模式的使用。其中，音频播放器设备只能播放 mp3 文件，通过使用一个更高级的音频播放器来播放 vlc 和 mp4 文件。 主要解决：主要解决在软件系统中，常常要将一些”现存的对象”放到新的环境中，而新环境要求的接口是现对象不能满足的。 何时使用： 系统需要使用现有的类，而此类的接口不符合系统的需要 想要建立一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作，这些源类不一定有一致的接口 通过接口转换，将一个类插入另一个类系中（比如老虎和飞禽，现在多了一个飞虎，在不增加实体的需求下，增加一个适配器，在里面包容一个虎对象，实现飞的接口） 如何解决：继承或依赖（推荐）。 应用实例： 美国电器 110V，中国 220V，就要有一个适配器将 110V 转化为 220V JAVA JDK 1.1 提供了 Enumeration 接口，而在 1.2 中提供了 Iterator 接口，想要使用 1.2 的JDK，则要将以前系统的 Enumeration 接口转化为 Iterator 接口，这时就需要适配器模式 在 LINUX 上运行 WINDOWS 程序 JAVA 中的 jdbc 优点： 可以让任何两个没有关联的类一起运行 提高了类的复用 增加了类的透明度 灵活性好 缺点： 过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是A接口，其实内部被适配成了B接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构 由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类 使用场景：有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。 注意事项：适配器不是在详细设计时添加的，而是解决正在服役的项目的问题。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public interface MediaPlayer &#123; public void play(String audioType, String fileName);&#125;public interface AdvancedMediaPlayer &#123; public void playVlc(String fileName); public void playMp4(String fileName);&#125;public class VlcPlayer implements AdvancedMediaPlayer &#123; @Override public void playVlc(String fileName) &#123; System.out.println("Playing vlc file. Name: " + fileName); &#125; @Override public void playMp4(String fileName) &#123; //do nothing &#125;&#125;public class Mp4Player implements AdvancedMediaPlayer &#123; @Override public void playVlc(String fileName) &#123; //do Nothing &#125; @Override public void playMp4(String fileName) &#123; System.out.println("Playing mp4 file. Name: " + fileName); &#125;&#125;public class MediaAdapter implements MediaPlayer &#123; AdvancedMediaPlayer advancedMusicPlayer; public MediaAdapter(String audioType) &#123; if (audioType.equalsIgnoreCase("vlc")) &#123; advancedMusicPlayer = new VlcPlayer(); &#125; else if (audioType.equalsIgnoreCase("mp4")) &#123; advancedMusicPlayer = new Mp4Player(); &#125; &#125; @Override public void play(String audioType, String fileName) &#123; if (audioType.equalsIgnoreCase("vlc")) &#123; advancedMusicPlayer.playVlc(fileName); &#125; else if (audioType.equalsIgnoreCase("mp4")) &#123; advancedMusicPlayer.playMp4(fileName); &#125; &#125;&#125;public class AudioPlayer implements MediaPlayer &#123; MediaAdapter mediaAdapter; @Override public void play(String audioType, String fileName) &#123; //播放 mp3 音乐文件的内置支持 if(audioType.equalsIgnoreCase("mp3"))&#123; System.out.println("Playing mp3 file. Name: "+ fileName); &#125; //mediaAdapter 提供了播放其他文件格式的支持 else if(audioType.equalsIgnoreCase("vlc") || audioType.equalsIgnoreCase("mp4"))&#123; mediaAdapter = new MediaAdapter(audioType); mediaAdapter.play(audioType, fileName); &#125; else&#123; System.out.println("Invalid media. "+ audioType + " format not supported"); &#125; &#125;&#125;public class AdapterTest &#123; public static void main(String[] args) &#123; AudioPlayer audioPlayer = new AudioPlayer(); audioPlayer.play("mp3", "beyond the horizon.mp3"); audioPlayer.play("mp4", "alone.mp4"); audioPlayer.play("vlc", "far far away.vlc"); audioPlayer.play("avi", "mind me.avi"); &#125;&#125; 2.2. 桥接模式桥接（Bridge）是用于把抽象化与实现化解耦，使得二者可以独立变化。这种类型的设计模式属于结构型模式，它通过提供抽象化和实现化之间的桥接结构，来实现二者的解耦。 这种模式涉及到一个作为桥接的接口，使得实体类的功能独立于接口实现类。这两种类型的类可被结构化改变而互不影响。 主要解决：在有多种可能会变化的情况下，用继承会造成类爆炸问题，扩展起来不灵活。 何时使用：实现系统可能有多个角度分类，每一种角度都可能变化。 如何解决：把这种多角度分类分离出来，让它们独立变化，减少它们之间耦合。 应用实例： 猪八戒从天蓬元帅转世投胎到猪，转世投胎的机制将尘世划分为两个等级，即：灵魂和肉体，前者相当于抽象化，后者相当于实现化。生灵通过功能的委派，调用肉体对象的功能，使得生灵可以动态地选择 墙上的开关，可以看到的开关是抽象的，不用管里面具体怎么实现的 优点： 抽象和实现的分离 优秀的扩展能力 实现细节对客户透明 缺点：桥接模式的引入会增加系统的理解与设计难度，由于聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程。 使用场景： 如果一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性，避免在两个层次之间建立静态的继承联系，通过桥接模式可以使它们在抽象层建立一个关联关系 对于那些不希望使用继承或因为多层次继承导致系统类的个数急剧增加的系统，桥接模式尤为适用 一个类存在两个独立变化的维度，且这两个维度都需要进行扩展 注意事项：对于两个独立变化的维度，使用桥接模式再适合不过了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public interface DrawAPI &#123; public void drawCircle(int radius, int x, int y);&#125;public class RedCircle implements DrawAPI &#123; @Override public void drawCircle(int radius, int x, int y) &#123; System.out.println("Drawing Circle[ color: red, radius: " + radius +", x: " +x+", "+ y +"]"); &#125;&#125;public class GreenCircle implements DrawAPI &#123; @Override public void drawCircle(int radius, int x, int y) &#123; System.out.println("Drawing Circle[ color: green, radius: " + radius + ", x: " + x + ", " + y + "]"); &#125;&#125;public abstract class Shape &#123; protected DrawAPI drawAPI; protected Shape(DrawAPI drawAPI) &#123; this.drawAPI = drawAPI; &#125; public abstract void draw();&#125;public class Circle extends Shape &#123; private int x, y, radius; public Circle(int x, int y, int radius, DrawAPI drawAPI) &#123; super(drawAPI); this.x = x; this.y = y; this.radius = radius; &#125; @Override public void draw() &#123; drawAPI.drawCircle(radius, x, y); &#125;&#125;public class BridgeTest &#123; public static void main(String[] args) &#123; Shape redCircle = new Circle(100, 100, 10, new RedCircle()); Shape greenCircle = new Circle(100, 100, 10, new GreenCircle()); redCircle.draw(); greenCircle.draw(); &#125;&#125; 2.3. 桥接模式过滤器模式（Filter Pattern）或标准模式（Criteria Pattern）是一种设计模式，这种模式允许开发人员使用不同的标准来过滤一组对象，通过逻辑运算以解耦的方式把它们连接起来。这种类型的设计模式属于结构型模式，它结合多个标准来获得单一标准。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136public class Person &#123; private String name; private String gender; private String maritalStatus; public Person(String name,String gender,String maritalStatus)&#123; this.name = name; this.gender = gender; this.maritalStatus = maritalStatus; &#125; public String getName() &#123; return name; &#125; public String getGender() &#123; return gender; &#125; public String getMaritalStatus() &#123; return maritalStatus; &#125; &#125;public interface Criteria &#123; public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons);&#125;public class CriteriaMale implements Criteria &#123; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; return persons.stream().filter(person -&gt; person.getGender() .equalsIgnoreCase("MALE")).collect(Collectors.toList()); &#125;&#125;public class CriteriaFemale implements Criteria &#123; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; return persons.stream().filter(person -&gt; person.getGender() .equalsIgnoreCase("FEMALE")).collect(Collectors.toList()); &#125;&#125;public class CriteriaSingle implements Criteria &#123; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; return persons.stream().filter(person -&gt; person.getMaritalStatus() .equalsIgnoreCase("SINGLE")).collect(Collectors.toList()); &#125;&#125;public class AndCriteria implements Criteria &#123; private Criteria criteria; private Criteria otherCriteria; public AndCriteria(Criteria criteria, Criteria otherCriteria) &#123; this.criteria = criteria; this.otherCriteria = otherCriteria; &#125; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; List&lt;Person&gt; firstCriteriaPersons = criteria.meetCriteria(persons); return otherCriteria.meetCriteria(firstCriteriaPersons); &#125;&#125;public class OrCriteria implements Criteria &#123; private Criteria criteria; private Criteria otherCriteria; public OrCriteria(Criteria criteria, Criteria otherCriteria) &#123; this.criteria = criteria; this.otherCriteria = otherCriteria; &#125; @Override public List&lt;Person&gt; meetCriteria(List&lt;Person&gt; persons) &#123; List&lt;Person&gt; firstCriteriaItems = criteria.meetCriteria(persons); List&lt;Person&gt; otherCriteriaItems = otherCriteria.meetCriteria(persons); for (Person person : otherCriteriaItems) &#123; if(!firstCriteriaItems.contains(person))&#123; firstCriteriaItems.add(person); &#125; &#125; return firstCriteriaItems; &#125;&#125;public class CriteriaTest &#123; public static void main(String[] args) &#123; List&lt;Person&gt; persons = new ArrayList&lt;Person&gt;(); persons.add(new Person("Robert","Male", "Single")); persons.add(new Person("John","Male", "Married")); persons.add(new Person("Laura","Female", "Married")); persons.add(new Person("Diana","Female", "Single")); persons.add(new Person("Mike","Male", "Single")); persons.add(new Person("Bobby","Male", "Single")); Criteria male = new CriteriaMale(); Criteria female = new CriteriaFemale(); Criteria single = new CriteriaSingle(); Criteria singleMale = new AndCriteria(single, male); Criteria singleOrFemale = new OrCriteria(single, female); System.out.println("Males: "); printPersons(male.meetCriteria(persons)); System.out.println("\nFemales: "); printPersons(female.meetCriteria(persons)); System.out.println("\nSingle Males: "); printPersons(singleMale.meetCriteria(persons)); System.out.println("\nSingle Or Females: "); printPersons(singleOrFemale.meetCriteria(persons)); &#125; public static void printPersons(List&lt;Person&gt; persons)&#123; for (Person person : persons) &#123; System.out.println("Person : [ Name : " + person.getName() +", Gender : " + person.getGender() +", Marital Status : " + person.getMaritalStatus() +" ]"); &#125; &#125;&#125; 2.4. 组合模式组合模式（Composite Pattern），又叫部分整体模式，是用于把一组相似的对象当作一个单一的对象。组合模式依据树形结构来组合对象，用来表示部分以及整体层次。这种类型的设计模式属于结构型模式，它创建了对象组的树形结构。 这种模式创建了一个包含自己对象组的类。该类提供了修改相同对象组的方式。 我们通过下面的实例来演示组合模式的用法。实例演示了一个组织中员工的层次结构。 意图：将对象组合成树形结构以表示”部分-整体”的层次结构。组合模式使得用户对单个对象和组合对象的使用具有一致性。 主要解决：它在我们树型结构的问题中，模糊了简单元素和复杂元素的概念，客户程序可以向处理简单元素一样来处理复杂元素，从而使得客户程序与复杂元素的内部结构解耦。 何时使用： 您想表示对象的部分-整体层次结构（树形结构） 您希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象 如何解决：树枝和叶子实现统一接口，树枝内部组合该接口。 关键代码：树枝内部组合该接口，并且含有内部属性 List，里面放 Component。 应用实例： 算术表达式包括操作数、操作符和另一个操作数，其中，另一个操作符也可以是操作数、操作符和另一个操作数 在 JAVA AWT 和 SWING 中，对于 Button 和 Checkbox 是树叶，Container 是树枝 优点： 高层模块调用简单 节点自由增加 缺点：在使用组合模式时，其叶子和树枝的声明都是实现类，而不是接口，违反了依赖倒置原则。 使用场景：部分、整体场景，如树形菜单，文件、文件夹的管理。 注意事项：定义时为具体类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class Employee &#123; private String name; private String dept; private int salary; private List&lt;Employee&gt; subordinates; //构造函数 public Employee(String name,String dept, int sal) &#123; this.name = name; this.dept = dept; this.salary = sal; subordinates = new ArrayList&lt;&gt;(); &#125; public void add(Employee e) &#123; subordinates.add(e); &#125; public void remove(Employee e) &#123; subordinates.remove(e); &#125; public List&lt;Employee&gt; getSubordinates()&#123; return subordinates; &#125; @Override public String toString() &#123; return MoreObjects.toStringHelper(this) .add("name", name) .add("dept", dept) .add("salary", salary) .add("subordinates", subordinates) .toString(); &#125;&#125;public class CompositeTest &#123; public static void main(String[] args) &#123; Employee CEO = new Employee("John", "CEO", 30000); Employee headSales = new Employee("Robert", "Head Sales", 20000); Employee headMarketing = new Employee("Michel", "Head Marketing", 20000); Employee clerk1 = new Employee("Laura", "Marketing", 10000); Employee clerk2 = new Employee("Bob", "Marketing", 10000); Employee salesExecutive1 = new Employee("Richard", "Sales", 10000); Employee salesExecutive2 = new Employee("Rob", "Sales", 10000); CEO.add(headSales); CEO.add(headMarketing); headSales.add(salesExecutive1); headSales.add(salesExecutive2); headMarketing.add(clerk1); headMarketing.add(clerk2); //打印该组织的所有员工 System.out.println(CEO); CEO.getSubordinates().forEach(employee -&gt; &#123; System.out.println(employee); employee.getSubordinates().forEach(System.out::println); &#125;); &#125;&#125; 2.5. 装饰器模式装饰器模式（Decorator Pattern）允许向一个现有的对象添加新的功能，同时又不改变其结构。这种类型的设计模式属于结构型模式，它是作为现有的类的一个包装。 这种模式创建了一个装饰类，用来包装原有的类，并在保持类方法签名完整性的前提下，提供了额外的功能。 意图：动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活。 主要解决：一般的，我们为了扩展一个类经常使用继承方式实现，由于继承为类引入静态特征，并且随着扩展功能的增多，子类会很膨胀。 何时使用：在不想增加很多子类的情况下扩展类。 如何解决：将具体功能职责划分，同时继承装饰者模式。 关键代码： Component 类充当抽象角色，不应该具体实现 修饰类引用和继承 Component 类，具体扩展类重写父类方法。 应用实例： 孙悟空有 72 变，当他变成”庙宇”后，他的根本还是一只猴子，但是他又有了庙宇的功能 不论一幅画有没有画框都可以挂在墙上，但是通常都是有画框的，并且实际上是画框被挂在墙上。在挂在墙上之前，画可以被蒙上玻璃，装到框子里；这时画、玻璃和画框形成了一个物体。 优点：装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。 缺点：多层装饰比较复杂。 使用场景： 扩展一个类的功能 动态增加功能，动态撤销。 注意事项：可代替继承 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public interface Decorator &#123; void draw();&#125;public class CircleDecorator implements Decorator &#123; @Override public void draw() &#123; System.out.println("Decorator: CircleDecorator"); &#125;&#125;public class RedShapeDecorator extends ShapeDecorator &#123; public RedShapeDecorator(Decorator decorator) &#123; super(decorator); &#125; @Override public void draw() &#123; decorator.draw(); setRedBorder(decorator); &#125; private void setRedBorder(Decorator decorator) &#123; System.out.println("Border Color: Red"); &#125;&#125;public abstract class ShapeDecorator implements Decorator&#123; protected Decorator decorator ; public ShapeDecorator(Decorator decorator)&#123; this.decorator = decorator; &#125; @Override public void draw() &#123; decorator.draw(); &#125;&#125;public class Rectangle implements Decorator &#123; @Override public void draw() &#123; System.out.println("Decorator: Rectangle"); &#125;&#125;public class DecoratorTest &#123; public static void main(String[] args) &#123; Decorator circle = new CircleDecorator(); Decorator redCircle = new RedShapeDecorator(new CircleDecorator()); Decorator redRectangle = new RedShapeDecorator(new Rectangle()); System.out.println("Circle with normal border"); circle.draw(); out.println("\nCircle of red border"); redCircle.draw(); out.println("\nRectangle of red border"); redRectangle.draw(); &#125;&#125; 2.6. 外观模式外观模式（Facade Pattern）隐藏系统的复杂性，并向客户端提供了一个客户端可以访问系统的接口。这种类型的设计模式属于结构型模式，它向现有的系统添加一个接口，来隐藏系统的复杂性。 这种模式涉及到一个单一的类，该类提供了客户端请求的简化方法和对现有系统类方法的委托调用。 意图：为子系统中的一组接口提供一个一致的界面，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 主要解决：降低访问复杂系统的内部子系统时的复杂度，简化客户端与之的接口。 何时使用： 客户端不需要知道系统内部的复杂联系，整个系统只需提供一个”接待员”即可 定义系统的入口。 如何解决：客户端不与系统耦合，外观类与系统耦合。 关键代码：在客户端和复杂系统之间再加一层，这一层将调用顺序、依赖关系等处理好。 应用实例： 去医院看病，可能要去挂号、门诊、划价、取药，让患者或患者家属觉得很复杂，如果有提供接待人员，只让接待人员来处理，就很方便 JAVA 的三层开发模式 优点： 减少系统相互依赖 提高灵活性 提高了安全性 缺点：不符合开闭原则，如果要改东西很麻烦，继承重写都不合适。 使用场景： 为复杂的模块或子系统提供外界访问的模块 子系统相对独立 预防低水平人员带来的风险 注意事项：在层次化结构中，可以使用外观模式定义系统中每一层的入口。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public interface Facade &#123; void draw();&#125;public class RectangleFacade implements Facade &#123; @Override public void draw() &#123; System.out.println("Rectangle::draw()"); &#125;&#125;public class SquareFacade implements Facade &#123; @Override public void draw() &#123; System.out.println("Square::draw()"); &#125;&#125;public class FacadeMaker &#123; private Facade rectangleFacade; private Facade squareFacade; public FacadeMaker()&#123; rectangleFacade = new RectangleFacade(); squareFacade = new SquareFacade(); &#125; public void drawSquare()&#123; squareFacade.draw(); &#125; public void drawRectangle()&#123; rectangleFacade.draw(); &#125;&#125;public class FacadeTest &#123; public static void main(String[] args) &#123; FacadeMaker facadeMaker = new FacadeMaker(); facadeMaker.drawRectangle(); facadeMaker.drawSquare(); &#125;&#125; 2.7. 享元模式享元模式（Flyweight Pattern）主要用于减少创建对象的数量，以减少内存占用和提高性能。这种类型的设计模式属于结构型模式，它提供了减少对象数量从而改善应用所需的对象结构的方式。 享元模式尝试重用现有的同类对象，如果未找到匹配的对象，则创建新对象。 意图：运用共享技术有效地支持大量细粒度的对象。 主要解决：在有大量对象时，有可能会造成内存溢出，我们把其中共同的部分抽象出来，如果有相同的业务请求，直接返回在内存中已有的对象，避免重新创建。 何时使用： 系统中有大量对象 这些对象消耗大量内存 这些对象的状态大部分可以外部化 这些对象可以按照内蕴状态分为很多组，当把外蕴对象从对象中剔除出来时，每一组对象都可以用一个对象来代替 系统不依赖于这些对象身份，这些对象是不可分辨的 如何解决：用唯一标识码判断，如果在内存中有，则返回这个唯一标识码所标识的对象。 关键代码：用 HashMap 存储这些对象。 应用实例： JAVA 中的 String，如果有则返回，如果没有则创建一个字符串保存在字符串缓存池里面 数据库的数据池 优点：大大减少对象的创建，降低系统的内存，使效率提高。 缺点：提高了系统的复杂度，需要分离出外部状态和内部状态，而且外部状态具有固有化的性质，不应该随着内部状态的变化而变化，否则会造成系统的混乱。 使用场景： 系统有大量相似对象 需要缓冲池的场景 注意事项： 注意划分外部状态和内部状态，否则可能会引起线程安全问题 这些类必须有一个工厂对象加以控制 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public interface Flyweight &#123; void draw();&#125;public class CircleFlyweight implements Flyweight &#123; private String color; private int x; private int y; private int radius; public CircleFlyweight(String color)&#123; this.color = color; &#125; public void setX(int x) &#123; this.x = x; &#125; public void setY(int y) &#123; this.y = y; &#125; public void setRadius(int radius) &#123; this.radius = radius; &#125; @Override public void draw() &#123; System.out.println("Circle: Draw() [Color : " + color +", x : " + x +", y :" + y +", radius :" + radius); &#125;&#125;public class FlyweightFactory &#123; private static final HashMap&lt;String, Flyweight&gt; circleMap = new HashMap&lt;&gt;(); public static Flyweight getCircle(String color) &#123; CircleFlyweight circle = (CircleFlyweight) circleMap.get(color); if (circle == null) &#123; circle = new CircleFlyweight(color); circleMap.put(color, circle); System.out.println("Creating circle of color : " + color); &#125; return circle; &#125;&#125;public class FlyweightTest &#123; private static final String colors[] = &#123; "Red", "Green", "Blue", "White", "Black" &#125;; public static void main(String[] args) &#123; for(int i=0; i &lt; 20; ++i) &#123; CircleFlyweight circle = (CircleFlyweight)FlyweightFactory.getCircle(getRandomColor()); circle.setX(getRandomX()); circle.setY(getRandomY()); circle.setRadius(100); circle.draw(); &#125; &#125; private static String getRandomColor() &#123; return colors[(int)(Math.random()*colors.length)]; &#125; private static int getRandomX() &#123; return (int)(Math.random()*100 ); &#125; private static int getRandomY() &#123; return (int)(Math.random()*100); &#125;&#125; 2.8. 代理模式在代理模式（Proxy Pattern）中，一个类代表另一个类的功能。这种类型的设计模式属于结构型模式。 在代理模式中，我们创建具有现有对象的对象，以便向外界提供功能接口。 意图：为其他对象提供一种代理以控制对这个对象的访问。 主要解决：在直接访问对象时带来的问题，比如说：要访问的对象在远程的机器上。在面向对象系统中，有些对象由于某些原因（比如对象创建开销很大，或者某些操作需要安全控制，或者需要进程外的访问），直接访问会给使用者或者系统结构带来很多麻烦，我们可以在访问此对象时加上一个对此对象的访问层。 何时使用：想在访问一个类时做一些控制。 如何解决：增加中间层。 关键代码：实现与被代理类组合。 应用实例： Windows 里面的快捷方式 猪八戒去找高翠兰结果是孙悟空变的，可以这样理解：把高翠兰的外貌抽象出来，高翠兰本人和孙悟空都实现了这个接口，猪八戒访问高翠兰的时候看不出来这个是孙悟空，所以说孙悟空是高翠兰代理类 买火车票不一定在火车站买，也可以去代售点 一张支票或银行存单是账户中资金的代理。支票在市场交易中用来代替现金，并提供对签发人账号上资金的控制 spring aop 优点： 职责清晰 高扩展性 智能化 缺点： 由于在客户端和真实主题之间增加了代理对象，因此有些类型的代理模式可能会造成请求的处理速度变慢 实现代理模式需要额外的工作，有些代理模式的实现非常复杂 使用场景：按职责来划分，通常有以下使用场景： 远程代理 虚拟代理 Copy-on-Write 代理 保护（Protect or Access）代理 Cache代理 防火墙（Firewall）代理 同步化（Synchronization）代理 智能引用（Smart Reference）代理 注意事项： 和适配器模式的区别：适配器模式主要改变所考虑对象的接口，而代理模式不能改变所代理类的接口 和装饰器模式的区别：装饰器模式为了增强功能，而代理模式是为了加以控制 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public interface Image &#123; void display();&#125;public class RealImage implements Image &#123; private String fileName; public RealImage(String fileName) &#123; this.fileName = fileName; loadFromDisk(fileName); &#125; @Override public void display() &#123; System.out.println("Displaying " + fileName); &#125; private void loadFromDisk(String fileName) &#123; System.out.println("Loading " + fileName); &#125;&#125;public class ProxyImage implements Image&#123; private RealImage realImage; private String fileName; public ProxyImage(String fileName)&#123; this.fileName = fileName; &#125; @Override public void display() &#123; if(realImage == null)&#123; realImage = new RealImage(fileName); &#125; realImage.display(); &#125;&#125;public class ProxyTest &#123; public static void main(String[] args) &#123; Image image = new ProxyImage("test_10mb.jpg"); //图像将从磁盘加载 image.display(); System.out.println(""); //图像将无法从磁盘加载 image.display(); &#125;&#125; 3.行为型模式3.1. 责任链模式顾名思义，责任链模式（Chain of Responsibility Pattern）为请求创建了一个接收者对象的链。这种模式给予请求的类型，对请求的发送者和接收者进行解耦。这种类型的设计模式属于行为型模式。 在这种模式中，通常每个接收者都包含对另一个接收者的引用。如果一个对象不能处理该请求，那么它会把相同的请求传给下一个接收者，依此类推。 意图：避免请求发送者与接收者耦合在一起，让多个对象都有可能接收请求，将这些对象连接成一条链，并且沿着这条链传递请求，直到有对象处理它为止。 主要解决：职责链上的处理者负责处理请求，客户只需要将请求发送到职责链上即可，无须关心请求的处理细节和请求的传递，所以职责链将请求的发送者和请求的处理者解耦了。 何时使用：在处理消息的时候以过滤很多道。 如何解决：拦截的类都实现统一接口。 关键代码：Handler 里面聚合它自己，在 HanleRequest 里判断是否合适，如果没达到条件则向下传递，向谁传递之前 set 进去。 应用实例： 红楼梦中的”击鼓传花”。 JS 中的事件冒泡。 AVA WEB 中 Apache Tomcat 对 Encoding 的处理，Struts2 的拦截器，jsp servlet 的 Filter。 优点： 降低耦合度。它将请求的发送者和接收者解耦。 简化了对象。使得对象不需要知道链的结构。 增强给对象指派职责的灵活性。通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 增加新的请求处理类很方便。 缺点： 不能保证请求一定被接收。 系统性能将受到一定影响，而且在进行代码调试时不太方便，可能会造成循环调用。 可能不容易观察运行时的特征，有碍于除错。 使用场景： 有多个对象可以处理同一个请求，具体哪个对象处理该请求由运行时刻自动确定。 在不明确指定接收者的情况下，向多个对象中的一个提交一个请求 可动态指定一组对象处理请求。 注意事项： 在 JAVA WEB 中遇到很多应用。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public abstract class AbstractLogger &#123; public static int INFO = 1; public static int DEBUG = 2; public static int ERROR = 3; protected int level; /** * 责任链中的下一个元素 */ protected AbstractLogger nextLogger; public void setNextLogger(AbstractLogger nextLogger) &#123; this.nextLogger = nextLogger; &#125; public void logMessage(int level, String message) &#123; if (this.level &lt;= level) &#123; write(message); &#125; if (nextLogger != null) &#123; nextLogger.logMessage(level, message); &#125; &#125; abstract protected void write(String message);&#125;public class ConsoleLogger extends AbstractLogger &#123; public ConsoleLogger(int level) &#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("Standard Console::Logger: " + message); &#125;&#125;public class DebugLogger extends AbstractLogger &#123; public DebugLogger(int level) &#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("Debug::Logger: " + message); &#125;&#125;public class ErrorLogger extends AbstractLogger &#123; public ErrorLogger(int level) &#123; this.level = level; &#125; @Override protected void write(String message) &#123; System.out.println("Error Console::Logger: " + message); &#125;&#125;public class ChainPatternDemo &#123; private static AbstractLogger getChainOfLoggers() &#123; AbstractLogger errorLogger = new ErrorLogger(AbstractLogger.ERROR); AbstractLogger debugLogger = new DebugLogger(AbstractLogger.DEBUG); AbstractLogger consoleLogger = new ConsoleLogger(AbstractLogger.INFO); errorLogger.setNextLogger(debugLogger); debugLogger.setNextLogger(consoleLogger); return errorLogger; &#125; public static void main(String[] args) &#123; AbstractLogger loggerChain = getChainOfLoggers(); loggerChain.logMessage(AbstractLogger.INFO, "This is an information."); loggerChain.logMessage(AbstractLogger.DEBUG, "This is an debug level information."); loggerChain.logMessage(AbstractLogger.ERROR, "This is an error information."); &#125;&#125; 3.2. 命令模式命令模式（Command Pattern）是一种数据驱动的设计模式，它属于行为型模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。 意图：将一个请求封装成一个对象，从而使您可以用不同的请求对客户进行参数化。 主要解决：在软件系统中，行为请求者与行为实现者通常是一种紧耦合的关系，但某些场合，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合的设计就不太合适。 何时使用：在某些场合，比如要对行为进行”记录、撤销/重做、事务”等处理，这种无法抵御变化的紧耦合是不合适的。在这种情况下，如何将”行为请求者”与”行为实现者”解耦？将一组行为抽象为对象，可以实现二者之间的松耦合。 如何解决：通过调用者调用接受者执行命令，顺序：调用者→接受者→命令。 关键代码：定义三个角色：1、received 真正的命令执行对象 2、Command 3、invoker 使用命令对象的入口 应用实例：struts 1 中的 action 核心控制器 ActionServlet 只有一个，相当于 Invoker，而模型层的类会随着不同的应用有不同的模型类，相当于具体的 Command。 优点： 降低了系统耦合度。 新的命令可以很容易添加到系统中去。 缺点：使用命令模式可能会导致某些系统有过多的具体命令类。 使用场景：认为是命令的地方都可以使用命令模式，比如： 1、GUI 中每一个按钮都是一条命令。 2、模拟 CMD。 注意事项：系统需要支持命令的撤销(Undo)操作和恢复(Redo)操作，也可以考虑使用命令模式，见命令模式的扩展。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374public interface Order &#123; void execute();&#125;public class Stock &#123; private String name = "ABC"; private int quantity = 10; public void buy() &#123; System.out.println("Stock [ Name: " + name + ",Quantity:" + quantity + " ]bought "); &#125; public void sell() &#123; System.out.println("Stock [ Name: " + name + ",Quantity:" + quantity + " ]sold "); &#125;&#125;public class BuyStock implements Order &#123; private Stock abcStock; public BuyStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; @Override public void execute() &#123; abcStock.buy(); &#125;&#125;public class SellStock implements Order &#123; private Stock abcStock; public SellStock(Stock abcStock) &#123; this.abcStock = abcStock; &#125; @Override public void execute() &#123; abcStock.sell(); &#125;&#125;public class Broker &#123; private List&lt;Order&gt; orderList = new ArrayList&lt;&gt;(); public void takeOrder(Order order) &#123; orderList.add(order); &#125; public void placeOrders() &#123; for (Order order : orderList) &#123; order.execute(); &#125; orderList.clear(); &#125;&#125;public class CommandPatternDemo &#123; public static void main(String[] args) &#123; Stock abcStock = new Stock(); BuyStock buyStockOrder = new BuyStock(abcStock); SellStock sellStockOrder = new SellStock(abcStock); Broker broker = new Broker(); broker.takeOrder(buyStockOrder); broker.takeOrder(sellStockOrder); broker.placeOrders(); &#125;&#125; 3.3. 解释器模式解释器模式（Interpreter Pattern）提供了评估语言的语法或表达式的方式，它属于行为型模式。这种模式实现了一个表达式接口，该接口解释一个特定的上下文。这种模式被用在 SQL 解析、符号处理引擎等。 意图：给定一个语言，定义它的文法表示，并定义一个解释器，这个解释器使用该标识来解释语言中的句子。 主要解决：对于一些固定文法构建一个解释句子的解释器。 何时使用：如果一种特定类型的问题发生的频率足够高，那么可能就值得将该问题的各个实例表述为一个简单语言中的句子。这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。 如何解决：构件语法树，定义终结符与非终结符。 关键代码：构件环境类，包含解释器之外的一些全局信息，一般是 HashMap。 应用实例：编译器、运算表达式计算。 优点： 可扩展性比较好。 增加了新的解释表达式的方式。 易于实现简单文法。 缺点： 可利用场景比较少。 对于复杂的文法比较难维护。 解释器模式会引起类膨胀。 解释器模式采用递归调用方法。 使用场景： 可以将一个需要解释执行的语言中的句子表示为一个抽象语法树。 一些重复出现的问题可以用一种简单的语言来进行表达。 一个简单语法需要解释的场景。 注意事项：可利用场景比较少，JAVA 中如果碰到可以用 expression4J 代替。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public interface Expression &#123; public boolean interpret(String context);&#125;public class TerminalExpression implements Expression &#123; private String data; public TerminalExpression(String data) &#123; this.data = data; &#125; @Override public boolean interpret(String context) &#123; if (context.contains(data)) &#123; return true; &#125; return false; &#125;&#125;public class OrExpression implements Expression &#123; private Expression expr1 = null; private Expression expr2 = null; public OrExpression(Expression expr1, Expression expr2) &#123; this.expr1 = expr1; this.expr2 = expr2; &#125; @Override public boolean interpret(String context) &#123; return expr1.interpret(context) || expr2.interpret(context); &#125;&#125;public class AndExpression implements Expression &#123; private Expression expr1 = null; private Expression expr2 = null; public AndExpression(Expression expr1, Expression expr2) &#123; this.expr1 = expr1; this.expr2 = expr2; &#125; @Override public boolean interpret(String context) &#123; return expr1.interpret(context) &amp;&amp; expr2.interpret(context); &#125;&#125;public class InterpreterPatternDemo &#123; /** * 规则：Robert 和 John 是男性 */ public static Expression getMaleExpression() &#123; Expression robert = new TerminalExpression("Robert"); Expression john = new TerminalExpression("John"); return new OrExpression(robert, john); &#125; /** * 规则：Julie 是一个已婚的女性 */ public static Expression getMarriedWomanExpression() &#123; Expression julie = new TerminalExpression("Julie"); Expression married = new TerminalExpression("Married"); return new AndExpression(julie, married); &#125; public static void main(String[] args) &#123; Expression isMale = getMaleExpression(); Expression isMarriedWoman = getMarriedWomanExpression(); System.out.println("John is male? " + isMale.interpret("John")); System.out.println("Julie is a married women? " + isMarriedWoman.interpret("Married Julie")); &#125;&#125; 3.4. 迭代器模式迭代器模式（Iterator Pattern）是 Java 和 .Net 编程环境中非常常用的设计模式。这种模式用于顺序访问集合对象的元素，不需要知道集合对象的底层表示。 迭代器模式属于行为型模式。 意图：提供一种方法顺序访问一个聚合对象中各个元素, 而又无须暴露该对象的内部表示。 主要解决：不同的方式来遍历整个整合对象。 何时使用：遍历一个聚合对象。 如何解决：把在元素之间游走的责任交给迭代器，而不是聚合对象。 关键代码：定义接口：hasNext, next。 应用实例：JAVA 中的 iterator。 优点： 它支持以不同的方式遍历一个聚合对象。 迭代器简化了聚合类。 在同一个聚合上可以有多个遍历。 在迭代器模式中，增加新的聚合类和迭代器类都很方便，无须修改原有代码。 缺点：由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。 使用场景： 访问一个聚合对象的内容而无须暴露它的内部表示。 需要为聚合对象提供多种遍历方式。 为遍历不同的聚合结构提供一个统一的接口。 注意事项：迭代器模式就是分离了集合对象的遍历行为，抽象出一个迭代器类来负责，这样既可以做到不暴露集合的内部结构，又可让外部代码透明地访问集合内部的数据。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public interface Iterator &#123; public boolean hasNext(); public Object next();&#125;public interface Container &#123; public Iterator getIterator();&#125;public class NameRepository implements Container &#123; public String[] names = &#123;"Robert", "John", "Julie", "Lora"&#125;; @Override public Iterator getIterator() &#123; return new NameIterator(); &#125; private class NameIterator implements Iterator &#123; int index; @Override public boolean hasNext() &#123; if (index &lt; names.length) &#123; return true; &#125; return false; &#125; @Override public Object next() &#123; if (this.hasNext()) &#123; return names[index++]; &#125; return null; &#125; &#125;&#125;public class IteratorPatternDemo &#123; public static void main(String[] args) &#123; NameRepository namesRepository = new NameRepository(); for (Iterator iter = namesRepository.getIterator(); iter.hasNext(); ) &#123; String name = (String) iter.next(); System.out.println("Name : " + name); &#125; &#125;&#125; 3.5. 中介者模式中介者模式（Mediator Pattern）是用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信，并支持松耦合，使代码易于维护。中介者模式属于行为型模式。 意图：用一个中介对象来封装一系列的对象交互，中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。 主要解决：对象与对象之间存在大量的关联关系，这样势必会导致系统的结构变得很复杂，同时若一个对象发生改变，我们也需要跟踪与之相关联的对象，同时做出相应的处理。 何时使用：多个类相互耦合，形成了网状结构。 如何解决：将上述网状结构分离为星型结构。 关键代码：对象 Colleague 之间的通信封装到一个类中单独处理。 应用实例： 中国加入 WTO 之前是各个国家相互贸易，结构复杂，现在是各个国家通过 WTO 来互相贸易。 机场调度系统。 MVC 框架，其中C（控制器）就是 M（模型）和 V（视图）的中介者。 优点： 降低了类的复杂度，将一对多转化成了一对一。 各个类之间的解耦。 符合迪米特原则。 缺点：中介者会庞大，变得复杂难以维护。 使用场景： 系统中对象之间存在比较复杂的引用关系，导致它们之间的依赖关系结构混乱而且难以复用该对象。 想通过一个中间类来封装多个类中的行为，而又不想生成太多的子类。 注意事项：不应当在职责混乱的时候使用。 12345678910111213141516171819202122232425262728293031323334353637public class ChatRoom &#123; public static void showMessage(User user, String message) &#123; System.out.println(new Date().toString() + " [" + user.getName() + "] : " + message); &#125;&#125;public class MediatorPatternDemo &#123; public static void main(String[] args) &#123; User robert = new User("Robert"); User john = new User("John"); robert.sendMessage("Hi! John!"); john.sendMessage("Hello! Robert!"); &#125;&#125;public class User &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public User(String name) &#123; this.name = name; &#125; public void sendMessage(String message) &#123; ChatRoom.showMessage(this, message); &#125;&#125; 3.6. 备忘录模式备忘录模式（Memento Pattern）保存一个对象的某个状态，以便在适当的时候恢复对象。备忘录模式属于行为型模式。 意图：在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。 主要解决：所谓备忘录模式就是在不破坏封装的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，这样可以在以后将对象恢复到原先保存的状态。 何时使用：很多时候我们总是需要记录一个对象的内部状态，这样做的目的就是为了允许用户取消不确定或者错误的操作，能够恢复到他原先的状态，使得他有”后悔药”可吃。 如何解决：通过一个备忘录类专门存储对象状态。 关键代码：客户不与备忘录类耦合，与备忘录管理类耦合。 应用实例： 后悔药。 打游戏时的存档。 Windows 里的 ctri + z。 IE 中的后退。 数据库的事务管理。 优点： 给用户提供了一种可以恢复状态的机制，可以使用户能够比较方便地回到某个历史的状态。 实现了信息的封装，使得用户不需要关心状态的保存细节。 缺点：消耗资源。如果类的成员变量过多，势必会占用比较大的资源，而且每一次保存都会消耗一定的内存。 使用场景： 需要保存/恢复数据的相关状态场景。 提供一个可回滚的操作。 注意事项： 为了符合迪米特原则，还要增加一个管理备忘录的类。 为了节约内存，可使用原型模式+备忘录模式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class Memento &#123; private String state; public Memento(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125;&#125;public class Originator &#123; private String state; public void setState(String state) &#123; this.state = state; &#125; public String getState() &#123; return state; &#125; public Memento saveStateToMemento() &#123; return new Memento(state); &#125; public void getStateFromMemento(Memento Memento) &#123; state = Memento.getState(); &#125;&#125;public class CareTaker &#123; private List&lt;Memento&gt; mementoList = new ArrayList&lt;Memento&gt;(); public void add(Memento state) &#123; mementoList.add(state); &#125; public Memento get(int index) &#123; return mementoList.get(index); &#125;&#125;public class MementoPatternDemo &#123; public static void main(String[] args) &#123; Originator originator = new Originator(); CareTaker careTaker = new CareTaker(); originator.setState("State #1"); originator.setState("State #2"); careTaker.add(originator.saveStateToMemento()); originator.setState("State #3"); careTaker.add(originator.saveStateToMemento()); originator.setState("State #4"); System.out.println("Current State: " + originator.getState()); originator.getStateFromMemento(careTaker.get(0)); System.out.println("First saved State: " + originator.getState()); originator.getStateFromMemento(careTaker.get(1)); System.out.println("Second saved State: " + originator.getState()); &#125;&#125; 3.7. 观察者模式当对象间存在一对多关系时，则使用观察者模式（Observer Pattern）。比如，当一个对象被修改时，则会自动通知它的依赖对象。观察者模式属于行为型模式。 意图：定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 主要解决：一个对象状态改变给其他对象通知的问题，而且要考虑到易用和低耦合，保证高度的协作。 何时使用：一个对象（目标对象）的状态发生改变，所有的依赖对象（观察者对象）都将得到通知，进行广播通知。 如何解决：使用面向对象技术，可以将这种依赖关系弱化。 关键代码：在抽象类里有一个 ArrayList 存放观察者们。 应用实例： 拍卖的时候，拍卖师观察最高标价，然后通知给其他竞价者竞价。 西游记里面悟空请求菩萨降服红孩儿，菩萨洒了一地水招来一个老乌龟，这个乌龟就是观察者，他观察菩萨洒水这个动作。 优点： 观察者和被观察者是抽象耦合的。 建立一套触发机制。 缺点： 如果一个被观察者对象有很多的直接和间接的观察者的话，将所有的观察者都通知到会花费很多时间。 如果在观察者和观察目标之间有循环依赖的话，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 观察者模式没有相应的机制让观察者知道所观察的目标对象是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 使用场景： 一个抽象模型有两个方面，其中一个方面依赖于另一个方面。将这些方面封装在独立的对象中使它们可以各自独立地改变和复用。 一个对象的改变将导致其他一个或多个对象也发生改变，而不知道具体有多少对象将发生改变，可以降低对象之间的耦合度。 一个对象必须通知其他对象，而并不知道这些对象是谁。 需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 注意事项： JAVA 中已经有了对观察者模式的支持类。 避免循环引用。 如果顺序执行，某一观察者错误会导致系统卡壳，一般采用异步方式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class Subject &#123; private List&lt;Observer&gt; observers = new ArrayList&lt;&gt;(); private int state; public int getState() &#123; return state; &#125; public void setState(int state) &#123; this.state = state; notifyAllObservers(); &#125; public void attach(Observer observer) &#123; observers.add(observer); &#125; public void notifyAllObservers() &#123; for (Observer observer : observers) &#123; observer.update(); &#125; &#125;&#125;public abstract class Observer &#123; protected Subject subject; public abstract void update();&#125;public class BinaryObserver extends Observer &#123; public BinaryObserver(Subject subject) &#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println("Binary String: " + Integer.toBinaryString(subject.getState())); &#125;&#125;public class OctalObserver extends Observer &#123; public OctalObserver(Subject subject) &#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println("Octal String: " + Integer.toOctalString(subject.getState())); &#125;&#125;public class HexaObserver extends Observer &#123; public HexaObserver(Subject subject) &#123; this.subject = subject; this.subject.attach(this); &#125; @Override public void update() &#123; System.out.println("Hex String: " + Integer.toHexString(subject.getState()).toUpperCase()); &#125;&#125;public class ObserverPatternDemo &#123; public static void main(String[] args) &#123; Subject subject = new Subject(); new HexaObserver(subject); new OctalObserver(subject); new BinaryObserver(subject); System.out.println("First state change: 15"); subject.setState(15); System.out.println("Second state change: 10"); subject.setState(10); &#125;&#125; 3.8. 状态模式在状态模式（State Pattern）中，类的行为是基于它的状态改变的。这种类型的设计模式属于行为型模式。 在状态模式中，我们创建表示各种状态的对象和一个行为随着状态对象改变而改变的 context 对象。 意图：允许对象在内部状态发生改变时改变它的行为，对象看起来好像修改了它的类。 主要解决：对象的行为依赖于它的状态（属性），并且可以根据它的状态改变而改变它的相关行为。 何时使用：代码中包含大量与对象状态有关的条件语句。 如何解决：将各种具体的状态类抽象出来。 关键代码：通常命令模式的接口中只有一个方法。而状态模式的接口中有一个或者多个方法。而且，状态模式的实现类的方法，一般返回值，或者是改变实例变量的值。也就是说，状态模式一般和对象的状态有关。实现类的方法有不同的功能，覆盖接口中的方法。状态模式和命令模式一样，也可以用于消除 if…else 等条件选择语句。 应用实例： 打篮球的时候运动员可以有正常状态、不正常状态和超常状态。 曾侯乙编钟中，’钟是抽象接口’,’钟A’等是具体状态，’曾侯乙编钟’是具体环境（Context）。 优点： 封装了转换规则。 枚举可能的状态，在枚举状态之前需要确定状态种类。 将所有与某个状态有关的行为放到一个类中，并且可以方便地增加新的状态，只需要改变对象状态即可改变对象的行为。 允许状态转换逻辑与状态对象合成一体，而不是某一个巨大的条件语句块。 可以让多个环境对象共享一个状态对象，从而减少系统中对象的个数。 缺点： 状态模式的使用必然会增加系统类和对象的个数。 态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱。 状态模式对”开闭原则”的支持并不太好，对于可以切换状态的状态模式，增加新的状态类需要修改那些负责状态转换的源代码，否则无法切换到新增状态，而且修改某个状态类的行为也需修改对应类的源代码。 使用场景： 行为随状态改变而改变的场景。 条件、分支语句的代替者。 注意事项：在行为受状态约束的时候使用状态模式，而且状态不超过 5 个。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public interface State &#123; public void doAction(Context context);&#125;public class Context &#123; private State state; public Context() &#123; state = null; &#125; public void setState(State state) &#123; this.state = state; &#125; public State getState() &#123; return state; &#125;&#125;public class StartState implements State &#123; @Override public void doAction(Context context) &#123; System.out.println("Player is in start state"); context.setState(this); &#125; @Override public String toString() &#123; return "Start State"; &#125;&#125;public class StopState implements State &#123; @Override public void doAction(Context context) &#123; System.out.println("Player is in stop state"); context.setState(this); &#125; @Override public String toString() &#123; return "Stop State"; &#125;&#125; 3.9. 空对象模式在空对象模式（Null Object Pattern）中，一个空对象取代 NULL 对象实例的检查。Null 对象不是检查空值，而是反应一个不做任何动作的关系。这样的 Null 对象也可以在数据不可用的时候提供默认的行为。 在空对象模式中，我们创建一个指定各种要执行的操作的抽象类和扩展该类的实体类，还创建一个未对该类做任何实现的空对象类，该空对象类将无缝地使用在需要检查空值的地方。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public abstract class AbstractCustomer &#123; protected String name; public abstract boolean isNil(); public abstract String getName();&#125;public class RealCustomer extends AbstractCustomer &#123; public RealCustomer(String name) &#123; this.name = name; &#125; @Override public String getName() &#123; return name; &#125; @Override public boolean isNil() &#123; return false; &#125;&#125;public class NullCustomer extends AbstractCustomer &#123; @Override public String getName() &#123; return "Not Available in Customer Database"; &#125; @Override public boolean isNil() &#123; return true; &#125;&#125;public class NullPatternDemo &#123; public static void main(String[] args) &#123; AbstractCustomer customer1 = CustomerFactory.getCustomer("Rob"); AbstractCustomer customer2 = CustomerFactory.getCustomer("Bob"); AbstractCustomer customer3 = CustomerFactory.getCustomer("Julie"); AbstractCustomer customer4 = CustomerFactory.getCustomer("Laura"); System.out.println("Customers"); System.out.println(customer1.getName()); System.out.println(customer2.getName()); System.out.println(customer3.getName()); System.out.println(customer4.getName()); &#125;&#125;public class CustomerFactory &#123; public static final String[] names = &#123;"Rob", "Joe", "Julie"&#125;; public static AbstractCustomer getCustomer(String name) &#123; for (int i = 0; i &lt; names.length; i++) &#123; if (names[i].equalsIgnoreCase(name)) &#123; return new RealCustomer(name); &#125; &#125; return new NullCustomer(); &#125;&#125; 3.10. 策略模式在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。 在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。 意图：定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。 主要解决：在有多种算法相似的情况下，使用 if…else 所带来的复杂和难以维护。 何时使用：一个系统有许多许多类，而区分它们的只是他们直接的行为。 如何解决：将这些算法封装成一个一个的类，任意地替换。 关键代码：实现同一个接口。 应用实例： 诸葛亮的锦囊妙计，每一个锦囊就是一个策略。 旅行的出游方式，选择骑自行车、坐汽车，每一种旅行方式都是一个策略。 JAVA AWT 中的 LayoutManager。 优点： 算法可以自由切换。 避免使用多重条件判断。 扩展性良好。 缺点： 策略类会增多。 所有策略类都需要对外暴露。 使用场景： 如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。 一个系统需要动态地在几种算法中选择一种。 3、如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。 注意事项：如果一个系统的策略多于四个，就需要考虑使用混合模式，解决策略类膨胀的问题。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public interface Strategy &#123; public int doOperation(int num1, int num2);&#125;public class OperationAdd implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 + num2; &#125;&#125;public class OperationSubstract implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 - num2; &#125;&#125;public class OperationMultiply implements Strategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 * num2; &#125;&#125;public class Context &#123; private State state; public Context() &#123; state = null; &#125; public void setState(State state) &#123; this.state = state; &#125; public State getState() &#123; return state; &#125; private Strategy strategy; public Context(Strategy strategy)&#123; this.strategy = strategy; &#125; public int executeStrategy(int num1, int num2)&#123; return strategy.doOperation(num1, num2); &#125;&#125;public class StrategyPatternDemo &#123; public static void main(String[] args) &#123; Context context = new Context(new OperationAdd()); System.out.println("10 + 5 = " + context.executeStrategy(10, 5)); context = new Context(new OperationSubstract()); System.out.println("10 - 5 = " + context.executeStrategy(10, 5)); context = new Context(new OperationMultiply()); System.out.println("10 * 5 = " + context.executeStrategy(10, 5)); &#125;&#125; 3.11. 模板模式在模板模式（Template Pattern）中，一个抽象类公开定义了执行它的方法的方式/模板。它的子类可以按需要重写方法实现，但调用将以抽象类中定义的方式进行。这种类型的设计模式属于行为型模式。 意图：定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 主要解决：一些方法通用，却在每一个子类都重新写了这一方法。 何时使用：有一些通用的方法。 如何解决：将这些通用算法抽象出来。 关键代码：在抽象类实现，其他步骤在子类实现。 应用实例： 在造房子的时候，地基、走线、水管都一样，只有在建筑的后期才有加壁橱加栅栏等差异。 西游记里面菩萨定好的 81 难，这就是一个顶层的逻辑骨架。 spring 中对 Hibernate 的支持，将一些已经定好的方法封装起来，比如开启事务、获取 Session、关闭 Session 等，程序员不重复写那些已经规范好的代码，直接丢一个实体就可以保存。 优点： 封装不变部分，扩展可变部分。 提取公共代码，便于维护。 行为由父类控制，子类实现。 缺点：每一个不同的实现都需要一个子类来实现，导致类的个数增加，使得系统更加庞大。 使用场景： 有多个子类共有的方法，且逻辑相同。 重要的、复杂的方法，可以考虑作为模板方法。 注意事项：为防止恶意操作，一般模板方法都加上 final 关键词。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public abstract class Game &#123; abstract void initialize(); abstract void startPlay(); abstract void endPlay(); /** * 模板 */ public final void play() &#123; //初始化游戏 initialize(); //开始游戏 startPlay(); //结束游戏 endPlay(); &#125;&#125;public class Cricket extends Game &#123; @Override void endPlay() &#123; System.out.println("Cricket Game Finished!"); &#125; @Override void initialize() &#123; System.out.println("Cricket Game Initialized! Start playing."); &#125; @Override void startPlay() &#123; System.out.println("Cricket Game Started. Enjoy the game!"); &#125;&#125;public class Football extends Game &#123; @Override void endPlay() &#123; System.out.println("Football Game Finished!"); &#125; @Override void initialize() &#123; System.out.println("Football Game Initialized! Start playing."); &#125; @Override void startPlay() &#123; System.out.println("Football Game Started. Enjoy the game!"); &#125;&#125;public class TemplatePatternDemo &#123; public static void main(String[] args) &#123; Game game = new Cricket(); game.play(); System.out.println(); game = new Football(); game.play(); &#125;&#125; 3.12. 访问者模式在访问者模式（Visitor Pattern）中，我们使用了一个访问者类，它改变了元素类的执行算法。通过这种方式，元素的执行算法可以随着访问者改变而改变。这种类型的设计模式属于行为型模式。根据模式，元素对象已接受访问者对象，这样访问者对象就可以处理元素对象上的操作。 意图：主要将数据结构与数据操作分离。 主要解决：稳定的数据结构和易变的操作耦合问题。 何时使用：需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，使用访问者模式将这些封装到类中。 如何解决：在被访问的类里面加一个对外提供接待访问者的接口。 关键代码：在数据基础类里面有一个方法接受访问者，将自身引用传入访问者。 应用实例：您在朋友家做客，您是访问者，朋友接受您的访问，您通过朋友的描述，然后对朋友的描述做出一个判断，这就是访问者模式。 优点： 符合单一职责原则。 优秀的扩展性。 灵活性。 缺点： 具体元素对访问者公布细节，违反了迪米特原则。 具体元素变更比较困难。 违反了依赖倒置原则，依赖了具体类，没有依赖抽象。 使用场景： 对象结构中对象对应的类很少改变，但经常需要在此对象结构上定义新的操作。 需要对一个对象结构中的对象进行很多不同的并且不相关的操作，而需要避免让这些操作”污染”这些对象的类，也不希望在增加新操作时修改这些类。 注意事项：访问者可以对功能进行统一，可以做报表、UI、拦截器与过滤器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public interface ComputerPart &#123; public void accept(ComputerPartVisitor computerPartVisitor);&#125;public interface ComputerPartVisitor &#123; public void visit(Computer computer); public void visit(Mouse mouse); public void visit(Keyboard keyboard); public void visit(Monitor monitor);&#125;public class Keyboard implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125;public class Monitor implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125;public class Mouse implements ComputerPart &#123; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; computerPartVisitor.visit(this); &#125;&#125;public class Computer implements ComputerPart &#123; ComputerPart[] parts; public Computer() &#123; parts = new ComputerPart[]&#123;new Mouse(), new Keyboard(), new Monitor()&#125;; &#125; @Override public void accept(ComputerPartVisitor computerPartVisitor) &#123; for (int i = 0; i &lt; parts.length; i++) &#123; parts[i].accept(computerPartVisitor); &#125; computerPartVisitor.visit(this); &#125;&#125;public class ComputerPartDisplayVisitor implements ComputerPartVisitor &#123; @Override public void visit(Computer computer) &#123; System.out.println("Displaying Computer."); &#125; @Override public void visit(Mouse mouse) &#123; System.out.println("Displaying Mouse."); &#125; @Override public void visit(Keyboard keyboard) &#123; System.out.println("Displaying Keyboard."); &#125; @Override public void visit(Monitor monitor) &#123; System.out.println("Displaying Monitor."); &#125;&#125;public class VisitorPatternDemo &#123; public static void main(String[] args) &#123; ComputerPart computer = new Computer(); computer.accept(new ComputerPartDisplayVisitor()); &#125;&#125;]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git学习]]></title>
    <url>%2F2017%2F10%2F09%2FGit%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Git中文文档 Git 起步1.Git历史同生活中的许多伟大事物一样，Git 诞生于一个极富纷争大举创新的年代。Linux 内核开源项目有着为数众广的参与者。 绝大多数的 Linux 内核维护工作都花在了提交补丁和保存归档的繁琐事务上（1991－2002年间）。 到 2002 年，整个项目组开始启用一个专有的分布式版本控制系统 BitKeeper 来管理和维护代码。 到了 2005 年，开发 BitKeeper 的商业公司同 Linux 内核开源社区的合作关系结束，他们收回了 Linux 内核社区免费使用 BitKeeper 的权力。 这就迫使 Linux 开源社区（特别是 Linux 的缔造者 Linus Torvalds）基于使用 BitKeeper 时的经验教训，开发出自己的版本系统。 他们对新的系统制订了若干目标： 速度 简单的设计 对非线性开发模式的强力支持（允许成千上万个并行开发的分支） 完全分布式 有能力高效管理类似 Linux 内核一样的超大规模项目（速度和数据量） 自诞生于 2005 年以来，Git 日臻成熟完善，在高度易用的同时，仍然保留着初期设定的目标。 它的速度飞快，极其适合管理大项目，有着令人难以置信的非线性分支管理系统。 2.Git机制2.1. Git 保证完整性Git 中所有数据在存储前都计算校验和，然后以校验和来引用。 这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。 这个功能建构在 Git 底层，是构成 Git 哲学不可或缺的部分。 若你在传送过程中丢失信息或损坏文件，Git 就能发现。 Git 用以计算校验和的机制叫做 SHA-1 散列（hash，哈希）。 这是一个由 40 个十六进制字符（0-9 和 a-f）组成字符串，基于 Git 中文件的内容或目录结构计算出来。 SHA-1 哈希看起来是这样： 24b9da6552252987aa493b52f8696cd6d3b00373 Git 中使用这种哈希值的情况很多，你将经常看到这种哈希值。 实际上，Git 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。 2.2. 三种状态 Git 有三种状态，你的文件可能处于其中之一：已提交（committed）、已修改（modified）和已暂存（staged）。 已提交表示数据已经安全的保存在本地数据库中。 已修改表示修改了文件，但还没保存到数据库中。 已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。 由此引入 Git 项目的三个工作区域的概念：Git 仓库、工作目录 以及暂存区域。 2.3. Git 仓库、工作目录 、暂存区域 Git 仓库目录 是 Git 用来保存项目的元数据和对象数据库的地方。 这是 Git 中最重要的部分，从其它计算机克隆仓库时，拷贝的就是这里的数据。 工作目录 是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。 暂存区域 是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作`‘索引’’，不过一般说法还是叫暂存区域。 基本的 Git 工作流程如下： 在工作目录中修改文件。 暂存文件，将文件的快照放入暂存区域。 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。 如果 Git 目录中保存着的特定版本文件，就属于已提交状态。 如果作了修改并已放入暂存区域，就属于已暂存状态。 如果自上次取出后，作了修改但还没有放到暂存区域，就是已修改状态。 3.初次运行 Git 前的配置Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置： /etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。 ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。 当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。 每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。 在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\Users\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。 3.1. 用户配置当安装完 Git 应该做的第一件事就是设置你的用户名称与邮件地址。 这样做很重要，因为每一个 Git 的提交都会使用这些信息，并且它会写入到你的每一次提交中，不可更改： $ git config --global user.name &quot;John Doe&quot; $ git config --global user.email johndoe@example.com 再次强调，如果使用了 --global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 --global 选项的命令来配置。 很多 GUI 工具都会在第一次运行时帮助你配置这些信息。 3.2. 文本编辑器既然用户信息已经设置完毕，你可以配置默认文本编辑器了，当 Git 需要你输入信息时会调用它。 如果未配置，Git 会使用操作系统默认的文本编辑器，通常是 Vim。 如果你想使用不同的文本编辑器，例如 Emacs，可以这样做： $ git config --global core.editor emacs Warning Vim 和 Emacs 是像 Linux 与 Mac 等基于 Unix 的系统上开发者经常使用的流行的文本编辑器。 如果你对这些编辑器都不是很了解或者你使用的是 Windows 系统，那么可能需要搜索如何在 Git 中配置你最常用的编辑器。 如果你不设置编辑器并且不知道 Vim 或 Emacs 是什么，当它们运行起来后你可能会被弄糊涂、不知所措。 3.3. 检查配置信息如果想要检查你的配置，可以使用 git config --list 命令来列出所有 Git 当时能找到的配置。 $ git config --list user.name=John Doe user.email=johndoe@example.com color.status=auto color.branch=auto color.interactive=auto color.diff=auto ... 你可能会看到重复的变量名，因为 Git 会从不同的文件中读取同一个配置（例如：/etc/gitconfig 与 ~/.gitconfig）。 这种情况下，Git 会使用它找到的每一个变量的最后一个配置。 你可以通过输入 git config &lt;key&gt;： 来检查 Git 的某一项配置 $ git config user.name John Doe Git 基础1.获取 Git 仓库在现有目录中初始化仓库如果你打算使用 Git 来对现有的项目进行管理，你只需要进入该项目目录并输入： $ git init $ git add *.c $ git add LICENSE $ git commit -m &apos;initial project version&apos; 2.克隆现有的仓库$ git clone https://github.com/libgit2/libgit2 $ git clone https://github.com/libgit2/libgit2 mylibgit 这将执行与上一个命令相同的操作，不过在本地创建的仓库名字变为 mylibgit。 3.记录每次更新到仓库 2.1. 检查当前文件状态123$ git statusOn branch masternothing to commit, working directory clean 现在，让我们在项目下创建一个新的 README 文件。 如果之前并不存在这个文件，使用 git status 命令，你将看到一个新的未跟踪文件： $ echo &apos;My Project&apos; &gt; README $ git status On branch master Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) README nothing added to commit but untracked files present (use &quot;git add&quot; to track) 在状态报告中可以看到新建的 README 文件出现在 Untracked files 下面。 未跟踪的文件意味着 Git 在之前的快照（提交）中没有这些文件；Git 不会自动将之纳入跟踪范围，除非你明明白白地告诉它“我需要跟踪该文件”， 这样的处理让你不必担心将生成的二进制文件或其它不想被跟踪的文件包含进来。 不过现在的例子中，我们确实想要跟踪管理 README 这个文件。 2.2. 跟踪新文件使用命令 git add 开始跟踪一个文件。 所以，要跟踪 README 文件，运行： $ git add README 此时再运行 git status 命令，会看到 README 文件已被跟踪，并处于暂存状态： $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: README 只要在 Changes to be committed 这行下面的，就说明是已暂存状态。 如果此时提交，那么该文件此时此刻的版本将被留存在历史记录中。 你可能会想起之前我们使用 git init 后就运行了 git add (files) 命令，开始跟踪当前目录下的文件。 git add 命令使用文件或目录的路径作为参数；如果参数是目录的路径，该命令将递归地跟踪该目录下的所有文件。 2.3. 暂存已修改文件现在我们来修改一个已被跟踪的文件。 如果你修改了一个名为 CONTRIBUTING.md 的已被跟踪的文件，然后运行 git status 命令，会看到下面内容： $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: README Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 文件 CONTRIBUTING.md 出现在 Changes not staged for commit 这行下面，说明已跟踪文件的内容发生了变化，但还没有放到暂存区。 要暂存这次更新，需要运行 git add 命令。 这是个多功能命令：可以用它开始跟踪新文件，或者把已跟踪的文件放到暂存区，还能用于合并时把有冲突的文件标记为已解决状态等。 将这个命令理解为“添加内容到下一次提交中”而不是“将一个文件添加到项目中”要更加合适。 现在让我们运行 git add 将”CONTRIBUTING.md“放到暂存区，然后再看看 git status 的输出： $ git add CONTRIBUTING.md $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: README modified: CONTRIBUTING.md 现在两个文件都已暂存，下次提交时就会一并记录到仓库。 假设此时，你想要在 CONTRIBUTING.md 里再加条注释， 重新编辑存盘后，准备好提交。 不过且慢，再运行 git status 看看： $ vim CONTRIBUTING.md $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: README modified: CONTRIBUTING.md Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 怎么回事？ 现在 CONTRIBUTING.md 文件同时出现在暂存区和非暂存区。 这怎么可能呢？ 好吧，实际上 Git 只不过暂存了你运行 git add 命令时的版本， 如果你现在提交，CONTRIBUTING.md 的版本是你最后一次运行 git add 命令时的那个版本，而不是你运行 git commit 时，在工作目录中的当前版本。 所以，运行了 git add 之后又作了修订的文件，需要重新运行 git add 把最新版本重新暂存起来： $ git add CONTRIBUTING.md $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) new file: README modified: CONTRIBUTING.md 2.4. 状态简览git status 命令的输出十分详细，但其用语有些繁琐。 如果你使用 git status -s 命令或 git status --short 命令，你将得到一种更为紧凑的格式输出。 运行 git status -s ，状态报告输出如下： $ git status -s M README MM Rakefile A lib/git.rb M lib/simplegit.rb ?? LICENSE.txt 新添加的未跟踪文件前面有 ?? 标记，新添加到暂存区中的文件前面有 A 标记，修改过的文件前面有 M 标记。 你可能注意到了 M 有两个可以出现的位置，出现在右边的 M 表示该文件被修改了但是还没放入暂存区，出现在靠左边的 M 表示该文件被修改了并放入了暂存区。 例如，上面的状态报告显示： README 文件在工作区被修改了但是还没有将修改后的文件放入暂存区,lib/simplegit.rb 文件被修改了并将修改后的文件放入了暂存区。 而 Rakefile 在工作区被修改并提交到暂存区后又在工作区中被修改了，所以在暂存区和工作区都有该文件被修改了的记录。 2.5. 忽略文件一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。 来看一个实际的例子： $ cat .gitignore *.[oa] *~ 第一行告诉 Git 忽略所有以 .o 或 .a 结尾的文件。一般这类对象文件和存档文件都是编译过程中出现的。 第二行告诉 Git 忽略所有以波浪符（~）结尾的文件，许多文本编辑软件（比如 Emacs）都用这样的文件名保存副本。 此外，你可能还需要忽略 log，tmp 或者 pid 目录，以及自动生成的文档等等。 要养成一开始就设置好 .gitignore 文件的习惯，以免将来误提交这类无用的文件。 文件 .gitignore 的格式规范如下： 列表项 所有空行或者以 ＃ 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配。 匹配模式可以以（/）开头防止递归。 匹配模式可以以（/）结尾指定目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 所谓的 glob 模式是指 shell 所使用的简化了的正则表达式。 星号（*）匹配零个或多个任意字符；[abc] 匹配任何一个列在方括号中的字符（这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）；问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配（比如 [0-9] 表示匹配所有 0 到 9 的数字）。 使用两个星号（*) 表示匹配任意中间目录，比如a/**/z 可以匹配 a/z, a/b/z 或 a/b/c/z等。 2.6. 查看已暂存和未暂存的修改如果 git status 命令的输出对于你来说过于模糊，你想知道具体修改了什么地方，可以用 git diff 命令。git diff 将通过文件补丁的格式显示具体哪些行发生了改变。 假如再次修改 README 文件后暂存，然后编辑 CONTRIBUTING.md 文件后先不暂存， 运行 status 命令将会看到： $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: README Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 git diff： $ git diff diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md index 8ebb991..643e24f 100644 --- a/CONTRIBUTING.md +++ b/CONTRIBUTING.md @@ -65,7 +65,8 @@ branch directly, things can get messy. Please include a nice description of your changes when you submit your PR; if we have to read the whole diff to figure out why you&apos;re contributing in the first place, you&apos;re less likely to get feedback and have your change -merged in. +merged in. Also, split your changes into comprehensive chunks if your patch is +longer than a dozen lines. If you are starting to work on a particular area, feel free to submit a PR that highlights your work in progress (and note in the PR title that it&apos;s 此命令比较的是工作目录中当前文件和暂存区域快照之间的差异， 也就是修改之后还没有暂存起来的变化内容。 若要查看已暂存的将要添加到下次提交里的内容，可以用 git diff --cached 命令。（Git 1.6.1 及更高版本还允许使用 git diff --staged，效果是相同的，但更好记些。） $ git diff --staged diff --git a/README b/README new file mode 100644 index 0000000..03902a1 --- /dev/null +++ b/README @@ -0,0 +1 @@ +My Project 请注意，git diff 本身只显示尚未暂存的改动，而不是自上次提交以来所做的所有改动。 所以有时候你一下子暂存了所有更新过的文件后，运行 git diff 后却什么也没有，就是这个原因。 像之前说的，暂存 CONTRIBUTING.md 后再编辑，运行 git status 会看到暂存前后的两个版本。 如果我们的环境（终端输出）看起来如下： $ git add CONTRIBUTING.md $ echo &apos;# test line&apos; &gt;&gt; CONTRIBUTING.md $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: CONTRIBUTING.md Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 现在运行 git diff 看暂存前后的变化： $ git diff diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md index 643e24f..87f08c8 100644 --- a/CONTRIBUTING.md +++ b/CONTRIBUTING.md @@ -119,3 +119,4 @@ at the ## Starter Projects See our [projects list](https://github.com/libgit2/libgit2/blob/development/PROJECTS.md). +# test line 然后用 git diff --cached 查看已经暂存起来的变化：（--staged 和 --cached 是同义词） $ git diff --cached diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md index 8ebb991..643e24f 100644 --- a/CONTRIBUTING.md +++ b/CONTRIBUTING.md @@ -65,7 +65,8 @@ branch directly, things can get messy. Please include a nice description of your changes when you submit your PR; if we have to read the whole diff to figure out why you&apos;re contributing in the first place, you&apos;re less likely to get feedback and have your change -merged in. +merged in. Also, split your changes into comprehensive chunks if your patch is +longer than a dozen lines. If you are starting to work on a particular area, feel free to submit a PR that highlights your work in progress (and note in the PR title that it&apos;s Note Git Diff 的插件版本在本书中，我们使用 git diff 来分析文件差异。 但是，如果你喜欢通过图形化的方式或其它格式输出方式的话，可以使用 git difftool 命令来用 Araxis ，emerge 或 vimdiff 等软件输出 diff 分析结果。 使用 git difftool --tool-help 命令来看你的系统支持哪些 Git Diff 插件。 2.7. 提交更新现在的暂存区域已经准备妥当可以提交了。 在此之前，请一定要确认还有什么修改过的或新建的文件还没有 git add 过，否则提交的时候不会记录这些还没暂存起来的变化。 这些修改过的文件只保留在本地磁盘。 所以，每次准备提交前，先用 git status 看下，是不是都已暂存起来了， 然后再运行提交命令 git commit： $ git commit 这种方式会启动文本编辑器以便输入本次提交的说明。 (默认会启用 shell 的环境变量 $EDITOR 所指定的软件，一般都是 vim 或 emacs。当然也可以按照 起步 介绍的方式，使用 git config --global core.editor 命令设定你喜欢的编辑软件。） 编辑器会显示类似下面的文本信息（本例选用 Vim 的屏显方式展示）： # Please enter the commit message for your changes. Lines starting # with &apos;#&apos; will be ignored, and an empty message aborts the commit. # On branch master # Changes to be committed: # new file: README # modified: CONTRIBUTING.md # ~ ~ ~ &quot;.git/COMMIT_EDITMSG&quot; 9L, 283C 可以看到，默认的提交消息包含最后一次运行 git status 的输出，放在注释行里，另外开头还有一空行，供你输入提交说明。 你完全可以去掉这些注释行，不过留着也没关系，多少能帮你回想起这次更新的内容有哪些。 (如果想要更详细的对修改了哪些内容的提示，可以用 -v 选项，这会将你所做的改变的 diff 输出放到编辑器中从而使你知道本次提交具体做了哪些修改。） 退出编辑器时，Git 会丢掉注释行，用你输入提交附带信息生成一次提交。 另外，你也可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行，如下所示： $ git commit -m &quot;Story 182: Fix benchmarks for speed&quot; [master 463dc4f] Story 182: Fix benchmarks for speed 2 files changed, 2 insertions(+) create mode 100644 README 好，现在你已经创建了第一个提交！ 可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添加和删改过。 请记住，提交时记录的是放在暂存区域的快照。 任何还未暂存的仍然保持已修改状态，可以在下次提交时纳入版本管理。 每一次运行提交操作，都是对你项目作一次快照，以后可以回到这个状态，或者进行比较。 2.8. 跳过使用暂存区域尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。 Git 提供了一个跳过使用暂存区域的方式， 只要在提交的时候，给 git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤： $ git status On branch master Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) $ git commit -a -m &apos;added new benchmarks&apos; [master 83e38c7] added new benchmarks 1 file changed, 5 insertions(+), 0 deletions(-) 2.9. 移除文件要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。 可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。 如果只是简单地从工作目录中手工删除文件，运行 git status 时就会在 “Changes not staged for commit” 部分（也就是 未暂存清单）看到： $ rm PROJECTS.md $ git status On branch master Your branch is up-to-date with &apos;origin/master&apos;. Changes not staged for commit: (use &quot;git add/rm &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) deleted: PROJECTS.md no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 然后再运行 git rm 记录此次移除文件的操作： $ git rm PROJECTS.md rm &apos;PROJECTS.md&apos; $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) deleted: PROJECTS.md 下一次提交时，该文件就不再纳入版本管理了。 如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f（译注：即 force 的首字母）。 这是一种安全特性，用于防止误删还没有添加到快照的数据，这样的数据不能被 Git 恢复。 另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。 换句话说，你想让文件保留在磁盘，但是并不想让 Git 继续跟踪。 当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。 为达到这一目的，使用 --cached 选项： $ git rm --cached README git rm 命令后面可以列出文件或者目录的名字，也可以使用 glob 模式。 比方说： $ git rm log/\*.log 注意到星号 * 之前的反斜杠 \， 因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开。 此命令删除 log/ 目录下扩展名为 .log 的所有文件。 类似的比如： $ git rm \*~ 该命令为删除以 ~ 结尾的所有文件。 2.10. 移动文件不像其它的 VCS 系统，Git 并不显式跟踪文件移动操作。 如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。 不过 Git 非常聪明，它会推断出究竟发生了什么，至于具体是如何做到的，我们稍后再谈。 既然如此，当你看到 Git 的 mv 命令时一定会困惑不已。 要在 Git 中对文件改名，可以这么做： $ git mv file_from file_to 它会恰如预期般正常工作。 实际上，即便此时查看状态信息，也会明白无误地看到关于重命名操作的说明： $ git mv README.md README $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) renamed: README.md -&gt; README 其实，运行 git mv 就相当于运行了下面三条命令： $ mv README.md README $ git rm README.md $ git add README 如此分开操作，Git 也会意识到这是一次改名，所以不管何种方式结果都一样。 两者唯一的区别是，mv 是一条命令而另一种方式需要三条命令，直接用 git mv 轻便得多。 不过有时候用其他工具批处理改名的话，要记得在提交前删除老的文件名，再添加新的文件名。 3.查看提交历史3.1. 查看提交历史在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。 完成这个任务最简单而又有效的工具是 git log 命令。 接下来的例子会用我专门用于演示的 simplegit 项目， 运行下面的命令获取该项目源代码： git clone https://github.com/schacon/simplegit-progit 然后在此项目中运行 git log，应该会看到下面的输出： $ git log commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test commit a11bef06a3f659402fe7563abf99ad00de2209e6 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit 默认不用任何参数的话，git log 会按提交时间列出所有的更新，最近的更新排在最上面。 正如你所看到的，这个命令会列出每个提交的 SHA-1 校验和、作者的名字和电子邮件地址、提交时间以及提交说明。 git log 有许多选项可以帮助你搜寻你所要找的提交， 接下来我们介绍些最常用的。 一个常用的选项是 -p，用来显示每次提交的内容差异。 你也可以加上 -2 来仅显示最近两次提交： $ git log -p -2 commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number diff --git a/Rakefile b/Rakefile index a874b73..8f94139 100644 --- a/Rakefile +++ b/Rakefile @@ -5,7 +5,7 @@ require &apos;rake/gempackagetask&apos; spec = Gem::Specification.new do |s| s.platform = Gem::Platform::RUBY s.name = &quot;simplegit&quot; - s.version = &quot;0.1.0&quot; + s.version = &quot;0.1.1&quot; s.author = &quot;Scott Chacon&quot; s.email = &quot;schacon@gee-mail.com&quot; s.summary = &quot;A simple gem for using Git in Ruby code.&quot; commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test diff --git a/lib/simplegit.rb b/lib/simplegit.rb index a0a60ae..47c6340 100644 --- a/lib/simplegit.rb +++ b/lib/simplegit.rb @@ -18,8 +18,3 @@ class SimpleGit end end - -if $0 == __FILE__ - git = SimpleGit.new - puts git.show -end \ No newline at end of file 该选项除了显示基本信息之外，还附带了每次 commit 的变化。 当进行代码审查，或者快速浏览某个搭档提交的 commit 所带来的变化的时候，这个参数就非常有用了。 你也可以为 git log 附带一系列的总结性选项。 比如说，如果你想看到每次提交的简略的统计信息，你可以使用 –stat 选项： $ git log --stat commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number Rakefile | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test lib/simplegit.rb | 5 ----- 1 file changed, 5 deletions(-) commit a11bef06a3f659402fe7563abf99ad00de2209e6 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit README | 6 ++++++ Rakefile | 23 +++++++++++++++++++++++ lib/simplegit.rb | 25 +++++++++++++++++++++++++ 3 files changed, 54 insertions(+) 正如你所看到的，--stat 选项在每次提交的下面列出所有被修改过的文件、有多少文件被修改了以及被修改过的文件的哪些行被移除或是添加了。 在每次提交的最后还有一个总结。 另外一个常用的选项是 --pretty。 这个选项可以指定使用不同于默认格式的方式展示提交历史。 这个选项有一些内建的子选项供你使用。 比如用 oneline 将每个提交放在一行显示，查看的提交数很大时非常有用。 另外还有 short，full 和 fuller 可以用，展示的信息或多或少有些不同，请自己动手实践一下看看效果如何。 $ git log --pretty=oneline ca82a6dff817ec66f44342007202690a93763949 changed the version number 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 removed unnecessary test a11bef06a3f659402fe7563abf99ad00de2209e6 first commit 但最有意思的是 format，可以定制要显示的记录格式。 这样的输出对后期提取分析格外有用 — 因为你知道输出的格式不会随着 Git 的更新而发生改变： $ git log --pretty=format:&quot;%h - %an, %ar : %s&quot; ca82a6d - Scott Chacon, 6 years ago : changed the version number 085bb3b - Scott Chacon, 6 years ago : removed unnecessary test a11bef0 - Scott Chacon, 6 years ago : first commit git log --pretty=format 常用的选项 列出了常用的格式占位符写法及其代表的意义。 git log --pretty=format 常用的选项： |—————–+————|| 选项 | 说明 ||—————–|:———–|| %H | 提交对象（commit）的完整哈希字串 || %h | 提交对象的简短哈希字串 || %T | 树对象（tree）的完整哈希字串 || %t | 树对象的简短哈希字串 || %P | 父对象（parent）的完整哈希字串 || %p | 父对象的简短哈希字串 || %an | 作者（author）的名字|| %ae | 作者的电子邮件地址 || %ad | 作者修订日期（可以用 –date= 选项定制格式） || %ar | 作者修订日期，按多久以前的方式显示 || %cn | 提交者（committer）的名字 || %ce | 提交者的电子邮件地址 || %cd | 提交日期 || %cr | 提交日期，按多久以前的方式显示 || %s | 提交说明 ||—————–+————| 你一定奇怪 作者 和 提交者 之间究竟有何差别， 其实作者指的是实际作出修改的人，提交者指的是最后将此工作成果提交到仓库的人。 所以，当你为某个项目发布补丁，然后某个核心成员将你的补丁并入项目时，你就是作者，而那个核心成员就是提交者。 我们会在 分布式 Git 再详细介绍两者之间的细微差别。 当 oneline 或 format 与另一个 log 选项 --graph 结合使用时尤其有用。 这个选项添加了一些ASCII字符串来形象地展示你的分支、合并历史： $ git log --pretty=format:&quot;%h %s&quot; --graph * 2d3acf9 ignore errors from SIGCHLD on trap * 5e3ee11 Merge branch &apos;master&apos; of git://github.com/dustin/grit |\ | * 420eac9 Added a method for getting the current branch. * | 30e367c timeout code and tests * | 5a09431 add timeout protection to grit * | e1193f8 support for heads with slashes in them |/ * d6016bc require time for xmlschema * 11d191e Merge branch &apos;defunkt&apos; into local 以上只是简单介绍了一些 git log 命令支持的选项。 git log 的常用选项 列出了我们目前涉及到的和没涉及到的选项，以及它们是如何影响 log 命令的输出的：git log 的常用选项： |—————–+————|| 选项 | 说明 ||—————–|:———–|| -p | 按补丁格式显示每个更新之间的差异 || –stat | 显示每次更新的文件修改统计信息 || –shortstat | 只显示 –stat 中最后的行数修改添加移除统计 || –name-only | 仅在提交信息后显示已修改的文件清单 || –name-status | 显示新增、修改、删除的文件清单 || –abbrev-commit | 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符 || –relative-date | 使用较短的相对时间显示（比如，“2 weeks ago”）|| –graph | 显示 ASCII 图形表示的分支合并历史 || –pretty | 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式）） ||—————–+————| 3.2. 限制输出长度除了定制输出格式的选项之外，git log 还有许多非常实用的限制输出长度的选项，也就是只输出部分提交信息。 之前你已经看到过 -2 了，它只显示最近的两条提交， 实际上，这是 -&lt;n&gt; 选项的写法，其中的 n 可以是任何整数，表示仅显示最近的若干条提交。 不过实践中我们是不太用这个选项的，Git 在输出所有提交时会自动调用分页程序，所以你一次只会看到一页的内容。 另外还有按照时间作限制的选项，比如 --since 和 --until 也很有用。 例如，下面的命令列出所有最近两周内的提交： $ git log --since=2.weeks 这个命令可以在多种格式下工作，比如说具体的某一天 “2008-01-15”，或者是相对地多久以前 “2 years 1 day 3 minutes ago”。 还可以给出若干搜索条件，列出符合的提交。 用 --author 选项显示指定作者的提交，用 --grep 选项搜索提交说明中的关键字。 （请注意，如果要得到同时满足这两个选项搜索条件的提交，就必须用 --all-match 选项。否则，满足任意一个条件的提交都会被匹配出来） 另一个非常有用的筛选选项是 -S，可以列出那些添加或移除了某些字符串的提交。 比如说，你想找出添加或移除了某一个特定函数的引用的提交，你可以这样使用： $ git log -Sfunction_name 最后一个很实用的 git log 选项是路径（path）， 如果只关心某些文件或者目录的历史提交，可以在 git log 选项的最后指定它们的路径。 因为是放在最后位置上的选项，所以用两个短划线（--）隔开之前的选项和后面限定的路径名。 在 限制 git log 输出的选项 中列出了常用的选项： |—————–+————|| 选项 | 说明 ||—————–|:———–|| -(n) | 仅显示最近的 n 条提交 || –since, –after | 仅显示指定时间之后的提交 || –until, –before | 仅显示指定时间之前的提交 || –author | 仅显示指定作者相关的提交 || –committer | 仅显示指定提交者相关的提交 || –grep | 仅显示含指定关键字的提交 || -S | 仅显示添加或移除了某个关键字的提交 ||—————–+————| 来看一个实际的例子，如果要查看 Git 仓库中，2008 年 10 月期间，Junio Hamano 提交的但未合并的测试文件，可以用下面的查询命令： $ git log --pretty=&quot;%h - %s&quot; --author=gitster --since=&quot;2008-10-01&quot; \ --before=&quot;2008-11-01&quot; --no-merges -- t/ 5610e3b - Fix testcase failure when extended attributes are in use acd3b9e - Enhance hold_lock_file_for_{update,append}() API f563754 - demonstrate breakage of detached checkout with symbolic link HEAD d1a43f2 - reset --hard/read-tree --reset -u: remove unmerged new paths 51a94af - Fix &quot;checkout --track -b newbranch&quot; on detached HEAD b0ad11e - pull: allow &quot;git pull origin $something:$current_branch&quot; into an unborn branch 在近 40000 条提交中，上面的输出仅列出了符合条件的 6 条记录。 4.撤消操作4.1. 撤消操作在任何一个阶段，你都有可能想要撤消某些操作。 这里，我们将会学习几个撤消你所做修改的基本工具。 注意，有些撤消操作是不可逆的。 这是在使用 Git 的过程中，会因为操作失误而导致之前的工作丢失的少有的几个地方之一。 有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有 --amend 选项的提交命令尝试重新提交： $ git commit --amend 这个命令会将暂存区中的文件提交。 如果自上次提交以来你还未做任何修改（例如，在上次提交后马上执行了此命令），那么快照会保持不变，而你所修改的只是提交信息。 文本编辑器启动后，可以看到之前的提交信息。 编辑后保存会覆盖原来的提交信息。 例如，你提交后发现忘记了暂存某些需要的修改，可以像下面这样操作： $ git commit -m &apos;initial commit&apos; $ git add forgotten_file $ git commit --amend 最终你只会有一个提交 - 第二次提交将代替第一次提交的结果。 取消暂存的文件接下来的两个小节演示如何操作暂存区域与工作目录中已修改的文件。 这些命令在修改文件状态的同时，也会提示如何撤消操作。 例如，你已经修改了两个文件并且想要将它们作为两次独立的修改提交，但是却意外地输入了 git add * 暂存了它们两个。 如何只取消暂存两个中的一个呢？ git status 命令提示了你： $ git add * $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) renamed: README.md -&gt; README modified: CONTRIBUTING.md 在 “Changes to be committed” 文字正下方，提示使用 git reset HEAD &lt;file&gt;... 来取消暂存。 所以，我们可以这样来取消暂存 CONTRIBUTING.md 文件： $ git reset HEAD CONTRIBUTING.md Unstaged changes after reset: M CONTRIBUTING.md $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) renamed: README.md -&gt; README Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 这个命令有点儿奇怪，但是起作用了。 CONTRIBUTING.md 文件已经是修改未暂存的状态了。 Note虽然在调用时加上 --hard 选项可以令 git reset 成为一个危险的命令（译注：可能导致工作目录中所有当前进度丢失！），但本例中工作目录内的文件并不会被修改。 不加选项地调用 git reset 并不危险 — 它只会修改暂存区域。 到目前为止这个神奇的调用就是你需要对 git reset 命令了解的全部。我们将会在 重置揭密 中了解 reset 的更多细节以及如何掌握它做一些真正有趣的事。 4.2. 撤消对文件的修改如果你并不想保留对 CONTRIBUTING.md 文件的修改怎么办？ 你该如何方便地撤消修改 - 将它还原成上次提交时的样子（或者刚克隆完的样子，或者刚把它放入工作目录时的样子）？ 幸运的是，git status 也告诉了你应该如何做。 在最后一个例子中，未暂存区域是这样： Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: CONTRIBUTING.md 它非常清楚地告诉了你如何撤消之前所做的修改。 让我们来按照提示执行： $ git checkout -- CONTRIBUTING.md $ git status On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) renamed: README.md -&gt; README 可以看到那些修改已经被撤消了。 Important你需要知道 git checkout -- [file] 是一个危险的命令，这很重要。 你对那个文件做的任何修改都会消失 - 你只是拷贝了另一个文件来覆盖它。 除非你确实清楚不想要那个文件了，否则不要使用这个命令。 如果你仍然想保留对那个文件做出的修改，但是现在仍然需要撤消，我们将会在 Git 分支 介绍保存进度与分支；这些通常是更好的做法。 记住，在 Git 中任何 已提交的 东西几乎总是可以恢复的。 甚至那些被删除的分支中的提交或使用 --amend 选项覆盖的提交也可以恢复（阅读 数据恢复 了解数据恢复）。 然而，任何你未提交的东西丢失后很可能再也找不到了。 5.远程仓库的使用5.1. 远程仓库的使用为了能在任意 Git 项目上协作，你需要知道如何管理自己的远程仓库。 远程仓库是指托管在因特网或其他网络中的你的项目的版本库。 你可以有好几个远程仓库，通常有些仓库对你只读，有些则可以读写。 与他人协作涉及管理远程仓库以及根据需要推送或拉取数据。 管理远程仓库包括了解如何添加远程仓库、移除无效的远程仓库、管理不同的远程分支并定义它们是否被跟踪等等。 查看远程仓库如果想查看你已经配置的远程仓库服务器，可以运行 git remote 命令。 它会列出你指定的每一个远程服务器的简写。 如果你已经克隆了自己的仓库，那么至少应该能看到 origin - 这是 Git 给你克隆的仓库服务器的默认名字： $ git clone https://github.com/schacon/ticgit Cloning into &apos;ticgit&apos;... remote: Reusing existing pack: 1857, done. remote: Total 1857 (delta 0), reused 0 (delta 0) Receiving objects: 100% (1857/1857), 374.35 KiB | 268.00 KiB/s, done. Resolving deltas: 100% (772/772), done. Checking connectivity... done. $ cd ticgit $ git remote origin 你也可以指定选项 -v，会显示需要读写远程仓库使用的 Git 保存的简写与其对应的 URL。 $ git remote -v origin https://github.com/schacon/ticgit (fetch) origin https://github.com/schacon/ticgit (push) 如果你的远程仓库不止一个，该命令会将它们全部列出。 例如，与几个协作者合作的，拥有多个远程仓库的仓库看起来像下面这样： $ cd grit $ git remote -v bakkdoor https://github.com/bakkdoor/grit (fetch) bakkdoor https://github.com/bakkdoor/grit (push) cho45 https://github.com/cho45/grit (fetch) cho45 https://github.com/cho45/grit (push) defunkt https://github.com/defunkt/grit (fetch) defunkt https://github.com/defunkt/grit (push) koke git://github.com/koke/grit.git (fetch) koke git://github.com/koke/grit.git (push) origin git@github.com:mojombo/grit.git (fetch) origin git@github.com:mojombo/grit.git (push) 这样我们可以轻松拉取其中任何一个用户的贡献。 此外，我们大概还会有某些远程仓库的推送权限，虽然我们目前还不会在此介绍。 注意这些远程仓库使用了不同的协议；我们将会在 在服务器上搭建 Git 中了解关于它们的更多信息。 5.2. 添加远程仓库我在之前的章节中已经提到并展示了如何添加远程仓库的示例，不过这里将告诉你如何明确地做到这一点。 运行 git remote add &lt;shortname&gt; &lt;url&gt; 添加一个新的远程 Git 仓库，同时指定一个你可以轻松引用的简写： $ git remote origin $ git remote add pb https://github.com/paulboone/ticgit $ git remote -v origin https://github.com/schacon/ticgit (fetch) origin https://github.com/schacon/ticgit (push) pb https://github.com/paulboone/ticgit (fetch) pb https://github.com/paulboone/ticgit (push) 现在你可以在命令行中使用字符串 pb 来代替整个 URL。 例如，如果你想拉取 Paul 的仓库中有但你没有的信息，可以运行 git fetch pb： $ git fetch pb remote: Counting objects: 43, done. remote: Compressing objects: 100% (36/36), done. remote: Total 43 (delta 10), reused 31 (delta 5) Unpacking objects: 100% (43/43), done. From https://github.com/paulboone/ticgit * [new branch] master -&gt; pb/master * [new branch] ticgit -&gt; pb/ticgit 现在 Paul 的 master 分支可以在本地通过 pb/master 访问到 - 你可以将它合并到自己的某个分支中，或者如果你想要查看它的话，可以检出一个指向该点的本地分支。 5.3. 从远程仓库中抓取与拉取就如刚才所见，从远程仓库中获得数据，可以执行： $ git fetch [remote-name] 这个命令会访问远程仓库，从中拉取所有你还没有的数据。 执行完成后，你将会拥有那个远程仓库中所有分支的引用，可以随时合并或查看。 如果你使用 clone 命令克隆了一个仓库，命令会自动将其添加为远程仓库并默认以 “origin” 为简写。 所以，git fetch origin 会抓取克隆（或上一次抓取）后新推送的所有工作。 必须注意 git fetch 命令会将数据拉取到你的本地仓库 - 它并不会自动合并或修改你当前的工作。 当准备好时你必须手动将其合并入你的工作。 如果你有一个分支设置为跟踪一个远程分支，可以使用 git pull 命令来自动的抓取然后合并远程分支到当前分支。 这对你来说可能是一个更简单或更舒服的工作流程；默认情况下，git clone 命令会自动设置本地 master 分支跟踪克隆的远程仓库的 master 分支（或不管是什么名字的默认分支）。 运行 git pull 通常会从最初克隆的服务器上抓取数据并自动尝试合并到当前所在的分支。 推送到远程仓库当你想分享你的项目时，必须将其推送到上游。 这个命令很简单：git push [remote-name] [branch-name]。 当你想要将 master 分支推送到 origin 服务器时（再次说明，克隆时通常会自动帮你设置好那两个名字），那么运行这个命令就可以将你所做的备份到服务器： $ git push origin master 只有当你有所克隆服务器的写入权限，并且之前没有人推送过时，这条命令才能生效。 当你和其他人在同一时间克隆，他们先推送到上游然后你再推送到上游，你的推送就会毫无疑问地被拒绝。 你必须先将他们的工作拉取下来并将其合并进你的工作后才能推送。 5.4. 查看远程仓库如果想要查看某一个远程仓库的更多信息，可以使用 git remote show [remote-name] 命令。 如果想以一个特定的缩写名运行这个命令，例如 origin，会得到像下面类似的信息： $ git remote show origin * remote origin Fetch URL: https://github.com/schacon/ticgit Push URL: https://github.com/schacon/ticgit HEAD branch: master Remote branches: master tracked dev-branch tracked Local branch configured for &apos;git pull&apos;: master merges with remote master Local ref configured for &apos;git push&apos;: master pushes to master (up to date) 它同样会列出远程仓库的 URL 与跟踪分支的信息。 这些信息非常有用，它告诉你正处于 master 分支，并且如果运行 git pull，就会抓取所有的远程引用，然后将远程 master 分支合并到本地 master 分支。 它也会列出拉取到的所有远程引用。 这是一个经常遇到的简单例子。 如果你是 Git 的重度使用者，那么还可以通过 git remote show 看到更多的信息。 $ git remote show origin * remote origin URL: https://github.com/my-org/complex-project Fetch URL: https://github.com/my-org/complex-project Push URL: https://github.com/my-org/complex-project HEAD branch: master Remote branches: master tracked dev-branch tracked markdown-strip tracked issue-43 new (next fetch will store in remotes/origin) issue-45 new (next fetch will store in remotes/origin) refs/remotes/origin/issue-11 stale (use &apos;git remote prune&apos; to remove) Local branches configured for &apos;git pull&apos;: dev-branch merges with remote dev-branch master merges with remote master Local refs configured for &apos;git push&apos;: dev-branch pushes to dev-branch (up to date) markdown-strip pushes to markdown-strip (up to date) master pushes to master (up to date) 这个命令列出了当你在特定的分支上执行 git push 会自动地推送到哪一个远程分支。 它也同样地列出了哪些远程分支不在你的本地，哪些远程分支已经从服务器上移除了，还有当你执行 git pull 时哪些分支会自动合并。 远程仓库的移除与重命名如果想要重命名引用的名字可以运行 git remote rename 去修改一个远程仓库的简写名。 例如，想要将 pb 重命名为 paul，可以用 git remote rename 这样做： $ git remote rename pb paul $ git remote origin paul 值得注意的是这同样也会修改你的远程分支名字。 那些过去引用 pb/master 的现在会引用 paul/master。 如果因为一些原因想要移除一个远程仓库 - 你已经从服务器上搬走了或不再想使用某一个特定的镜像了，又或者某一个贡献者不再贡献了 - 可以使用 git remote rm ： $ git remote rm paul $ git remote origin 6.打标签6.1. 列出标签在 Git 中列出已有的标签是非常简单直观的。 只需要输入 git tag： $ git tag v0.1 v1.3 这个命令以字母顺序列出标签；但是它们出现的顺序并不重要。 你也可以使用特定的模式查找标签。 例如，Git 自身的源代码仓库包含标签的数量超过 500 个。 如果只对 1.8.5 系列感兴趣，可以运行： $ git tag -l &apos;v1.8.5*&apos; v1.8.5 v1.8.5-rc0 v1.8.5-rc1 v1.8.5-rc2 v1.8.5-rc3 v1.8.5.1 v1.8.5.2 v1.8.5.3 v1.8.5.4 v1.8.5.5 6.2. 创建标签Git 使用两种主要类型的标签：轻量标签（lightweight）与附注标签（annotated）。 一个轻量标签很像一个不会改变的分支 - 它只是一个特定提交的引用。 然而，附注标签是存储在 Git 数据库中的一个完整对象。 它们是可以被校验的；其中包含打标签者的名字、电子邮件地址、日期时间；还有一个标签信息；并且可以使用 GNU Privacy Guard （GPG）签名与验证。 通常建议创建附注标签，这样你可以拥有以上所有信息；但是如果你只是想用一个临时的标签，或者因为某些原因不想要保存那些信息，轻量标签也是可用的。 6.3. 附注标签在 Git 中创建一个附注标签是很简单的。 最简单的方式是当你在运行 tag 命令时指定 -a 选项： $ git tag -a v1.4 -m &apos;my version 1.4&apos; $ git tag v0.1 v1.3 v1.4 -m 选项指定了一条将会存储在标签中的信息。 如果没有为附注标签指定一条信息，Git 会运行编辑器要求你输入信息。 通过使用 git show 命令可以看到标签信息与对应的提交信息： $ git show v1.4 tag v1.4 Tagger: Ben Straub &lt;ben@straub.cc&gt; Date: Sat May 3 20:19:12 2014 -0700 my version 1.4 commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number 输出显示了打标签者的信息、打标签的日期时间、附注信息，然后显示具体的提交信息。 6.4. 轻量标签另一种给提交打标签的方式是使用轻量标签。 轻量标签本质上是将提交校验和存储到一个文件中 - 没有保存任何其他信息。 创建轻量标签，不需要使用 -a、-s 或 -m 选项，只需要提供标签名字： $ git tag v1.4-lw $ git tag v0.1 v1.3 v1.4 v1.4-lw v1.5 这时，如果在标签上运行 git show，你不会看到额外的标签信息。 命令只会显示出提交信息： $ git show v1.4-lw commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number 6.5. 后期打标签你也可以对过去的提交打标签。 假设提交历史是这样的： $ git log --pretty=oneline 15027957951b64cf874c3557a0f3547bd83b3ff6 Merge branch &apos;experiment&apos; a6b4c97498bd301d84096da251c98a07c7723e65 beginning write support 0d52aaab4479697da7686c15f77a3d64d9165190 one more thing 6d52a271eda8725415634dd79daabbc4d9b6008e Merge branch &apos;experiment&apos; 0b7434d86859cc7b8c3d5e1dddfed66ff742fcbc added a commit function 4682c3261057305bdd616e23b64b0857d832627b added a todo file 166ae0c4d3f420721acbb115cc33848dfcc2121a started write support 9fceb02d0ae598e95dc970b74767f19372d61af8 updated rakefile 964f16d36dfccde844893cac5b347e7b3d44abbc commit the todo 8a5cbc430f1a9c3d00faaeffd07798508422908a updated readme 现在，假设在 v1.2 时你忘记给项目打标签，也就是在 “updated rakefile” 提交。 你可以在之后补上标签。 要在那个提交上打标签，你需要在命令的末尾指定提交的校验和（或部分校验和）: $ git tag -a v1.2 9fceb02 可以看到你已经在那次提交上打上标签了： $ git tag v0.1 v1.2 v1.3 v1.4 v1.4-lw v1.5 $ git show v1.2 tag v1.2 Tagger: Scott Chacon &lt;schacon@gee-mail.com&gt; Date: Mon Feb 9 15:32:16 2009 -0800 version 1.2 commit 9fceb02d0ae598e95dc970b74767f19372d61af8 Author: Magnus Chacon &lt;mchacon@gee-mail.com&gt; Date: Sun Apr 27 20:43:35 2008 -0700 updated rakefile ... 6.6. 共享标签默认情况下，git push 命令并不会传送标签到远程仓库服务器上。 在创建完标签后你必须显式地推送标签到共享服务器上。 这个过程就像共享远程分支一样 - 你可以运行 git push origin [tagname]。 $ git push origin v1.5 Counting objects: 14, done. Delta compression using up to 8 threads. Compressing objects: 100% (12/12), done. Writing objects: 100% (14/14), 2.05 KiB | 0 bytes/s, done. Total 14 (delta 3), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.5 -&gt; v1.5 如果想要一次性推送很多标签，也可以使用带有 --tags 选项的 git push 命令。 这将会把所有不在远程仓库服务器上的标签全部传送到那里。 $ git push origin --tags Counting objects: 1, done. Writing objects: 100% (1/1), 160 bytes | 0 bytes/s, done. Total 1 (delta 0), reused 0 (delta 0) To git@github.com:schacon/simplegit.git * [new tag] v1.4 -&gt; v1.4 * [new tag] v1.4-lw -&gt; v1.4-lw 现在，当其他人从仓库中克隆或拉取，他们也能得到你的那些标签。 检出标签在 Git 中你并不能真的检出一个标签，因为它们并不能像分支一样来回移动。 如果你想要工作目录与仓库中特定的标签版本完全一样，可以使用 git checkout -b [branchname] [tagname] 在特定的标签上创建一个新分支： $ git checkout -b version2 v2.0.0 Switched to a new branch &apos;version2&apos; 当然，如果在这之后又进行了一次提交，version2 分支会因为改动向前移动了，那么 version2 分支就会和 v2.0.0 标签稍微有些不同，这时就应该当心了。 7.Git 别名在我们结束本章 Git 基础之前，正好有一个小技巧可以使你的 Git 体验更简单、容易、熟悉：别名。 我们不会在之后的章节中引用到或假定你使用过它们，但是你大概应该知道如何使用它们。 Git 并不会在你输入部分命令时自动推断出你想要的命令。 如果不想每次都输入完整的 Git 命令，可以通过 git config 文件来轻松地为每一个命令设置一个别名。 这里有一些例子你可以试试： $ git config --global alias.co checkout $ git config --global alias.br branch $ git config --global alias.ci commit $ git config --global alias.st status 这意味着，当要输入 git commit 时，只需要输入 git ci。 随着你继续不断地使用 Git，可能也会经常使用其他命令，所以创建别名时不要犹豫。 在创建你认为应该存在的命令时这个技术会很有用。 例如，为了解决取消暂存文件的易用性问题，可以向 Git 中添加你自己的取消暂存别名： $ git config --global alias.unstage &apos;reset HEAD --&apos; 这会使下面的两个命令等价： $ git unstage fileA $ git reset HEAD -- fileA 这样看起来更清楚一些。 通常也会添加一个 last 命令，像这样： $ git config --global alias.last &apos;log -1 HEAD&apos; 这样，可以轻松地看到最后一次提交： $ git last commit 66938dae3329c7aebe598c2246a8e6af90d04646 Author: Josh Goebel &lt;dreamer3@example.com&gt; Date: Tue Aug 26 19:48:51 2008 +0800 test for current head Signed-off-by: Scott Chacon &lt;schacon@example.com&gt; 可以看出，Git 只是简单地将别名替换为对应的命令。 然而，你可能想要执行外部命令，而不是一个 Git 子命令。 如果是那样的话，可以在命令前面加入 ! 符号。 如果你自己要写一些与 Git 仓库协作的工具的话，那会很有用。 我们现在演示将 git visual 定义为 gitk 的别名： $ git config --global alias.visual &apos;!gitk&apos;]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
</search>
